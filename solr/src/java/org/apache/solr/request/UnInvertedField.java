begin_unit
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.solr.request
package|package
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|request
package|;
end_package
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|FieldCache
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|DocTermOrds
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Term
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|TermsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TermQuery
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TermRangeQuery
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|StringHelper
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|noggit
operator|.
name|CharArr
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|params
operator|.
name|FacetParams
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|util
operator|.
name|NamedList
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|SolrException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|core
operator|.
name|SolrCore
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|schema
operator|.
name|FieldType
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|schema
operator|.
name|TrieField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|search
operator|.
name|*
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|util
operator|.
name|ByteUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|util
operator|.
name|LongPriorityQueue
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|util
operator|.
name|PrimUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|handler
operator|.
name|component
operator|.
name|StatsValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|handler
operator|.
name|component
operator|.
name|FieldFacetStats
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|OpenBitSet
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import
begin_comment
comment|/**  *  * Final form of the un-inverted field:  *   Each document points to a list of term numbers that are contained in that document.  *  *   Term numbers are in sorted order, and are encoded as variable-length deltas from the  *   previous term number.  Real term numbers start at 2 since 0 and 1 are reserved.  A  *   term number of 0 signals the end of the termNumber list.  *  *   There is a single int[maxDoc()] which either contains a pointer into a byte[] for  *   the termNumber lists, or directly contains the termNumber list if it fits in the 4  *   bytes of an integer.  If the first byte in the integer is 1, the next 3 bytes  *   are a pointer into a byte[] where the termNumber list starts.  *  *   There are actually 256 byte arrays, to compensate for the fact that the pointers  *   into the byte arrays are only 3 bytes long.  The correct byte array for a document  *   is a function of it's id.  *  *   To save space and speed up faceting, any term that matches enough documents will  *   not be un-inverted... it will be skipped while building the un-inverted field structure,  *   and will use a set intersection method during faceting.  *  *   To further save memory, the terms (the actual string values) are not all stored in  *   memory, but a TermIndex is used to convert term numbers to term values only  *   for the terms needed after faceting has completed.  Only every 128th term value  *   is stored, along with it's corresponding term number, and this is used as an  *   index to find the closest term and iterate until the desired number is hit (very  *   much like Lucene's own internal term index).  *  */
end_comment
begin_class
DECL|class|UnInvertedField
specifier|public
class|class
name|UnInvertedField
extends|extends
name|DocTermOrds
block|{
DECL|field|TNUM_OFFSET
specifier|private
specifier|static
name|int
name|TNUM_OFFSET
init|=
literal|2
decl_stmt|;
DECL|class|TopTerm
specifier|static
class|class
name|TopTerm
block|{
DECL|field|term
name|BytesRef
name|term
decl_stmt|;
DECL|field|termNum
name|int
name|termNum
decl_stmt|;
DECL|method|memSize
name|long
name|memSize
parameter_list|()
block|{
return|return
literal|8
operator|+
comment|// obj header
literal|8
operator|+
literal|8
operator|+
name|term
operator|.
name|length
operator|+
comment|//term
literal|4
return|;
comment|// int
block|}
block|}
DECL|field|memsz
name|long
name|memsz
decl_stmt|;
DECL|field|use
specifier|final
name|AtomicLong
name|use
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
comment|// number of uses
DECL|field|maxTermCounts
name|int
index|[]
name|maxTermCounts
init|=
operator|new
name|int
index|[
literal|1024
index|]
decl_stmt|;
DECL|field|bigTerms
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|TopTerm
argument_list|>
name|bigTerms
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|Integer
argument_list|,
name|TopTerm
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|deState
specifier|private
name|SolrIndexSearcher
operator|.
name|DocsEnumState
name|deState
decl_stmt|;
DECL|field|searcher
specifier|private
specifier|final
name|SolrIndexSearcher
name|searcher
decl_stmt|;
annotation|@
name|Override
DECL|method|visitTerm
specifier|protected
name|void
name|visitTerm
parameter_list|(
name|TermsEnum
name|te
parameter_list|,
name|int
name|termNum
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|termNum
operator|>=
name|maxTermCounts
operator|.
name|length
condition|)
block|{
comment|// resize by doubling - for very large number of unique terms, expanding
comment|// by 4K and resultant GC will dominate uninvert times.  Resize at end if material
name|int
index|[]
name|newMaxTermCounts
init|=
operator|new
name|int
index|[
name|maxTermCounts
operator|.
name|length
operator|*
literal|2
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|maxTermCounts
argument_list|,
literal|0
argument_list|,
name|newMaxTermCounts
argument_list|,
literal|0
argument_list|,
name|termNum
argument_list|)
expr_stmt|;
name|maxTermCounts
operator|=
name|newMaxTermCounts
expr_stmt|;
block|}
specifier|final
name|BytesRef
name|term
init|=
name|te
operator|.
name|term
argument_list|()
decl_stmt|;
if|if
condition|(
name|te
operator|.
name|docFreq
argument_list|()
operator|>
name|maxTermDocFreq
condition|)
block|{
name|TopTerm
name|topTerm
init|=
operator|new
name|TopTerm
argument_list|()
decl_stmt|;
name|topTerm
operator|.
name|term
operator|=
operator|new
name|BytesRef
argument_list|(
name|term
argument_list|)
expr_stmt|;
name|topTerm
operator|.
name|termNum
operator|=
name|termNum
expr_stmt|;
name|bigTerms
operator|.
name|put
argument_list|(
name|topTerm
operator|.
name|termNum
argument_list|,
name|topTerm
argument_list|)
expr_stmt|;
if|if
condition|(
name|deState
operator|==
literal|null
condition|)
block|{
name|deState
operator|=
operator|new
name|SolrIndexSearcher
operator|.
name|DocsEnumState
argument_list|()
expr_stmt|;
name|deState
operator|.
name|fieldName
operator|=
name|StringHelper
operator|.
name|intern
argument_list|(
name|field
argument_list|)
expr_stmt|;
comment|// deState.termsEnum = te.tenum;
name|deState
operator|.
name|termsEnum
operator|=
name|te
expr_stmt|;
comment|// TODO: check for MultiTermsEnum in SolrIndexSearcher could now fail?
name|deState
operator|.
name|docsEnum
operator|=
name|docsEnum
expr_stmt|;
name|deState
operator|.
name|minSetSizeCached
operator|=
name|maxTermDocFreq
expr_stmt|;
block|}
name|docsEnum
operator|=
name|deState
operator|.
name|docsEnum
expr_stmt|;
name|DocSet
name|set
init|=
name|searcher
operator|.
name|getDocSet
argument_list|(
name|deState
argument_list|)
decl_stmt|;
name|maxTermCounts
index|[
name|termNum
index|]
operator|=
name|set
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|setActualDocFreq
specifier|protected
name|void
name|setActualDocFreq
parameter_list|(
name|int
name|termNum
parameter_list|,
name|int
name|docFreq
parameter_list|)
block|{
name|maxTermCounts
index|[
name|termNum
index|]
operator|=
name|docFreq
expr_stmt|;
block|}
DECL|method|memSize
specifier|public
name|long
name|memSize
parameter_list|()
block|{
comment|// can cache the mem size since it shouldn't change
if|if
condition|(
name|memsz
operator|!=
literal|0
condition|)
return|return
name|memsz
return|;
name|long
name|sz
init|=
name|super
operator|.
name|ramUsedInBytes
argument_list|()
decl_stmt|;
name|sz
operator|+=
literal|8
operator|*
literal|8
operator|+
literal|32
expr_stmt|;
comment|// local fields
name|sz
operator|+=
name|bigTerms
operator|.
name|size
argument_list|()
operator|*
literal|64
expr_stmt|;
for|for
control|(
name|TopTerm
name|tt
range|:
name|bigTerms
operator|.
name|values
argument_list|()
control|)
block|{
name|sz
operator|+=
name|tt
operator|.
name|memSize
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|maxTermCounts
operator|!=
literal|null
condition|)
name|sz
operator|+=
name|maxTermCounts
operator|.
name|length
operator|*
literal|4
expr_stmt|;
if|if
condition|(
name|indexedTermsArray
operator|!=
literal|null
condition|)
block|{
comment|// assume 8 byte references?
name|sz
operator|+=
literal|8
operator|+
literal|8
operator|+
literal|8
operator|+
literal|8
operator|+
operator|(
name|indexedTermsArray
operator|.
name|length
operator|<<
literal|3
operator|)
operator|+
name|sizeOfIndexedStrings
expr_stmt|;
block|}
name|memsz
operator|=
name|sz
expr_stmt|;
return|return
name|sz
return|;
block|}
DECL|method|UnInvertedField
specifier|public
name|UnInvertedField
parameter_list|(
name|String
name|field
parameter_list|,
name|SolrIndexSearcher
name|searcher
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|field
argument_list|,
comment|// threshold, over which we use set intersections instead of counting
comment|// to (1) save memory, and (2) speed up faceting.
comment|// Add 2 for testing purposes so that there will always be some terms under
comment|// the threshold even when the index is very
comment|// small.
name|searcher
operator|.
name|maxDoc
argument_list|()
operator|/
literal|20
operator|+
literal|2
argument_list|,
name|DEFAULT_INDEX_INTERVAL_BITS
argument_list|)
expr_stmt|;
comment|//System.out.println("maxTermDocFreq=" + maxTermDocFreq + " maxDoc=" + searcher.maxDoc());
specifier|final
name|String
name|prefix
init|=
name|TrieField
operator|.
name|getMainValuePrefix
argument_list|(
name|searcher
operator|.
name|getSchema
argument_list|()
operator|.
name|getFieldType
argument_list|(
name|field
argument_list|)
argument_list|)
decl_stmt|;
name|this
operator|.
name|searcher
operator|=
name|searcher
expr_stmt|;
try|try
block|{
name|uninvert
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|,
name|prefix
operator|==
literal|null
condition|?
literal|null
else|:
operator|new
name|BytesRef
argument_list|(
name|prefix
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalStateException
name|ise
parameter_list|)
block|{
throw|throw
operator|new
name|SolrException
argument_list|(
name|SolrException
operator|.
name|ErrorCode
operator|.
name|BAD_REQUEST
argument_list|,
name|ise
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|tnums
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|target
range|:
name|tnums
control|)
block|{
if|if
condition|(
name|target
operator|!=
literal|null
operator|&&
name|target
operator|.
name|length
operator|>
operator|(
literal|1
operator|<<
literal|24
operator|)
operator|*
literal|.9
condition|)
block|{
name|SolrCore
operator|.
name|log
operator|.
name|warn
argument_list|(
literal|"Approaching too many values for UnInvertedField faceting on field '"
operator|+
name|field
operator|+
literal|"' : bucket size="
operator|+
name|target
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// free space if outrageously wasteful (tradeoff memory/cpu)
if|if
condition|(
operator|(
name|maxTermCounts
operator|.
name|length
operator|-
name|numTermsInField
operator|)
operator|>
literal|1024
condition|)
block|{
comment|// too much waste!
name|int
index|[]
name|newMaxTermCounts
init|=
operator|new
name|int
index|[
name|numTermsInField
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|maxTermCounts
argument_list|,
literal|0
argument_list|,
name|newMaxTermCounts
argument_list|,
literal|0
argument_list|,
name|numTermsInField
argument_list|)
expr_stmt|;
name|maxTermCounts
operator|=
name|newMaxTermCounts
expr_stmt|;
block|}
name|SolrCore
operator|.
name|log
operator|.
name|info
argument_list|(
literal|"UnInverted multi-valued field "
operator|+
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|//System.out.println("CREATED: " + toString() + " ti.index=" + ti.index);
block|}
DECL|method|getNumTerms
specifier|public
name|int
name|getNumTerms
parameter_list|()
block|{
return|return
name|numTermsInField
return|;
block|}
DECL|method|getCounts
specifier|public
name|NamedList
argument_list|<
name|Integer
argument_list|>
name|getCounts
parameter_list|(
name|SolrIndexSearcher
name|searcher
parameter_list|,
name|DocSet
name|baseDocs
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|limit
parameter_list|,
name|Integer
name|mincount
parameter_list|,
name|boolean
name|missing
parameter_list|,
name|String
name|sort
parameter_list|,
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
name|use
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|FieldType
name|ft
init|=
name|searcher
operator|.
name|getSchema
argument_list|()
operator|.
name|getFieldType
argument_list|(
name|field
argument_list|)
decl_stmt|;
name|NamedList
argument_list|<
name|Integer
argument_list|>
name|res
init|=
operator|new
name|NamedList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
comment|// order is important
name|DocSet
name|docs
init|=
name|baseDocs
decl_stmt|;
name|int
name|baseSize
init|=
name|docs
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|maxDoc
init|=
name|searcher
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
comment|//System.out.println("GET COUNTS field=" + field + " baseSize=" + baseSize + " minCount=" + mincount + " maxDoc=" + maxDoc + " numTermsInField=" + numTermsInField);
if|if
condition|(
name|baseSize
operator|>=
name|mincount
condition|)
block|{
specifier|final
name|int
index|[]
name|index
init|=
name|this
operator|.
name|index
decl_stmt|;
comment|// tricky: we add more more element than we need because we will reuse this array later
comment|// for ordering term ords before converting to term labels.
specifier|final
name|int
index|[]
name|counts
init|=
operator|new
name|int
index|[
name|numTermsInField
operator|+
literal|1
index|]
decl_stmt|;
comment|//
comment|// If there is prefix, find it's start and end term numbers
comment|//
name|int
name|startTerm
init|=
literal|0
decl_stmt|;
name|int
name|endTerm
init|=
name|numTermsInField
decl_stmt|;
comment|// one past the end
name|TermsEnum
name|te
init|=
name|getOrdTermsEnum
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|prefix
operator|!=
literal|null
operator|&&
name|prefix
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|BytesRef
name|prefixBr
init|=
operator|new
name|BytesRef
argument_list|(
name|prefix
argument_list|)
decl_stmt|;
if|if
condition|(
name|te
operator|.
name|seek
argument_list|(
name|prefixBr
argument_list|,
literal|true
argument_list|)
operator|==
name|TermsEnum
operator|.
name|SeekStatus
operator|.
name|END
condition|)
block|{
name|startTerm
operator|=
name|numTermsInField
expr_stmt|;
block|}
else|else
block|{
name|startTerm
operator|=
operator|(
name|int
operator|)
name|te
operator|.
name|ord
argument_list|()
expr_stmt|;
block|}
name|prefixBr
operator|.
name|append
argument_list|(
name|ByteUtils
operator|.
name|bigTerm
argument_list|)
expr_stmt|;
if|if
condition|(
name|te
operator|.
name|seek
argument_list|(
name|prefixBr
argument_list|,
literal|true
argument_list|)
operator|==
name|TermsEnum
operator|.
name|SeekStatus
operator|.
name|END
condition|)
block|{
name|endTerm
operator|=
name|numTermsInField
expr_stmt|;
block|}
else|else
block|{
name|endTerm
operator|=
operator|(
name|int
operator|)
name|te
operator|.
name|ord
argument_list|()
expr_stmt|;
block|}
block|}
comment|/***********       // Alternative 2: get the docSet of the prefix (could take a while) and       // then do the intersection with the baseDocSet first.       if (prefix != null&& prefix.length()> 0) {         docs = searcher.getDocSet(new ConstantScorePrefixQuery(new Term(field, ft.toInternal(prefix))), docs);         // The issue with this method are problems of returning 0 counts for terms w/o         // the prefix.  We can't just filter out those terms later because it may         // mean that we didn't collect enough terms in the queue (in the sorted case).       }       ***********/
name|boolean
name|doNegative
init|=
name|baseSize
operator|>
name|maxDoc
operator|>>
literal|1
operator|&&
name|termInstances
operator|>
literal|0
operator|&&
name|startTerm
operator|==
literal|0
operator|&&
name|endTerm
operator|==
name|numTermsInField
operator|&&
name|docs
operator|instanceof
name|BitDocSet
decl_stmt|;
if|if
condition|(
name|doNegative
condition|)
block|{
name|OpenBitSet
name|bs
init|=
call|(
name|OpenBitSet
call|)
argument_list|(
operator|(
name|BitDocSet
operator|)
name|docs
argument_list|)
operator|.
name|getBits
argument_list|()
operator|.
name|clone
argument_list|()
decl_stmt|;
name|bs
operator|.
name|flip
argument_list|(
literal|0
argument_list|,
name|maxDoc
argument_list|)
expr_stmt|;
comment|// TODO: when iterator across negative elements is available, use that
comment|// instead of creating a new bitset and inverting.
name|docs
operator|=
operator|new
name|BitDocSet
argument_list|(
name|bs
argument_list|,
name|maxDoc
operator|-
name|baseSize
argument_list|)
expr_stmt|;
comment|// simply negating will mean that we have deleted docs in the set.
comment|// that should be OK, as their entries in our table should be empty.
comment|//System.out.println("  NEG");
block|}
comment|// For the biggest terms, do straight set intersections
for|for
control|(
name|TopTerm
name|tt
range|:
name|bigTerms
operator|.
name|values
argument_list|()
control|)
block|{
comment|//System.out.println("  do big termNum=" + tt.termNum + " term=" + tt.term.utf8ToString());
comment|// TODO: counts could be deferred if sorted==false
if|if
condition|(
name|tt
operator|.
name|termNum
operator|>=
name|startTerm
operator|&&
name|tt
operator|.
name|termNum
operator|<
name|endTerm
condition|)
block|{
name|counts
index|[
name|tt
operator|.
name|termNum
index|]
operator|=
name|searcher
operator|.
name|numDocs
argument_list|(
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|tt
operator|.
name|term
argument_list|)
argument_list|)
argument_list|,
name|docs
argument_list|)
expr_stmt|;
comment|//System.out.println("    count=" + counts[tt.termNum]);
block|}
else|else
block|{
comment|//System.out.println("SKIP term=" + tt.termNum);
block|}
block|}
comment|// TODO: we could short-circuit counting altogether for sorted faceting
comment|// where we already have enough terms from the bigTerms
comment|// TODO: we could shrink the size of the collection array, and
comment|// additionally break when the termNumber got above endTerm, but
comment|// it would require two extra conditionals in the inner loop (although
comment|// they would be predictable for the non-prefix case).
comment|// Perhaps a different copy of the code would be warranted.
if|if
condition|(
name|termInstances
operator|>
literal|0
condition|)
block|{
name|DocIterator
name|iter
init|=
name|docs
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|int
name|doc
init|=
name|iter
operator|.
name|nextDoc
argument_list|()
decl_stmt|;
comment|//System.out.println("iter doc=" + doc);
name|int
name|code
init|=
name|index
index|[
name|doc
index|]
decl_stmt|;
if|if
condition|(
operator|(
name|code
operator|&
literal|0xff
operator|)
operator|==
literal|1
condition|)
block|{
comment|//System.out.println("  ptr");
name|int
name|pos
init|=
name|code
operator|>>>
literal|8
decl_stmt|;
name|int
name|whichArray
init|=
operator|(
name|doc
operator|>>>
literal|16
operator|)
operator|&
literal|0xff
decl_stmt|;
name|byte
index|[]
name|arr
init|=
name|tnums
index|[
name|whichArray
index|]
decl_stmt|;
name|int
name|tnum
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|int
name|delta
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|byte
name|b
init|=
name|arr
index|[
name|pos
operator|++
index|]
decl_stmt|;
name|delta
operator|=
operator|(
name|delta
operator|<<
literal|7
operator|)
operator||
operator|(
name|b
operator|&
literal|0x7f
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|b
operator|&
literal|0x80
operator|)
operator|==
literal|0
condition|)
break|break;
block|}
if|if
condition|(
name|delta
operator|==
literal|0
condition|)
break|break;
name|tnum
operator|+=
name|delta
operator|-
name|TNUM_OFFSET
expr_stmt|;
comment|//System.out.println("    tnum=" + tnum);
name|counts
index|[
name|tnum
index|]
operator|++
expr_stmt|;
block|}
block|}
else|else
block|{
comment|//System.out.println("  inlined");
name|int
name|tnum
init|=
literal|0
decl_stmt|;
name|int
name|delta
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|delta
operator|=
operator|(
name|delta
operator|<<
literal|7
operator|)
operator||
operator|(
name|code
operator|&
literal|0x7f
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|code
operator|&
literal|0x80
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|delta
operator|==
literal|0
condition|)
break|break;
name|tnum
operator|+=
name|delta
operator|-
name|TNUM_OFFSET
expr_stmt|;
comment|//System.out.println("    tnum=" + tnum);
name|counts
index|[
name|tnum
index|]
operator|++
expr_stmt|;
name|delta
operator|=
literal|0
expr_stmt|;
block|}
name|code
operator|>>>=
literal|8
expr_stmt|;
block|}
block|}
block|}
block|}
name|CharArr
name|spare
init|=
operator|new
name|CharArr
argument_list|()
decl_stmt|;
name|int
name|off
init|=
name|offset
decl_stmt|;
name|int
name|lim
init|=
name|limit
operator|>=
literal|0
condition|?
name|limit
else|:
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
if|if
condition|(
name|sort
operator|.
name|equals
argument_list|(
name|FacetParams
operator|.
name|FACET_SORT_COUNT
argument_list|)
operator|||
name|sort
operator|.
name|equals
argument_list|(
name|FacetParams
operator|.
name|FACET_SORT_COUNT_LEGACY
argument_list|)
condition|)
block|{
name|int
name|maxsize
init|=
name|limit
operator|>
literal|0
condition|?
name|offset
operator|+
name|limit
else|:
name|Integer
operator|.
name|MAX_VALUE
operator|-
literal|1
decl_stmt|;
name|maxsize
operator|=
name|Math
operator|.
name|min
argument_list|(
name|maxsize
argument_list|,
name|numTermsInField
argument_list|)
expr_stmt|;
name|LongPriorityQueue
name|queue
init|=
operator|new
name|LongPriorityQueue
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|maxsize
argument_list|,
literal|1000
argument_list|)
argument_list|,
name|maxsize
argument_list|,
name|Long
operator|.
name|MIN_VALUE
argument_list|)
decl_stmt|;
name|int
name|min
init|=
name|mincount
operator|-
literal|1
decl_stmt|;
comment|// the smallest value in the top 'N' values
comment|//System.out.println("START=" + startTerm + " END=" + endTerm);
for|for
control|(
name|int
name|i
init|=
name|startTerm
init|;
name|i
operator|<
name|endTerm
condition|;
name|i
operator|++
control|)
block|{
name|int
name|c
init|=
name|doNegative
condition|?
name|maxTermCounts
index|[
name|i
index|]
operator|-
name|counts
index|[
name|i
index|]
else|:
name|counts
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|c
operator|>
name|min
condition|)
block|{
comment|// NOTE: we use c>min rather than c>=min as an optimization because we are going in
comment|// index order, so we already know that the keys are ordered.  This can be very
comment|// important if a lot of the counts are repeated (like zero counts would be).
comment|// smaller term numbers sort higher, so subtract the term number instead
name|long
name|pair
init|=
operator|(
operator|(
operator|(
name|long
operator|)
name|c
operator|)
operator|<<
literal|32
operator|)
operator|+
operator|(
name|Integer
operator|.
name|MAX_VALUE
operator|-
name|i
operator|)
decl_stmt|;
name|boolean
name|displaced
init|=
name|queue
operator|.
name|insert
argument_list|(
name|pair
argument_list|)
decl_stmt|;
if|if
condition|(
name|displaced
condition|)
name|min
operator|=
call|(
name|int
call|)
argument_list|(
name|queue
operator|.
name|top
argument_list|()
operator|>>>
literal|32
argument_list|)
expr_stmt|;
block|}
block|}
comment|// now select the right page from the results
comment|// if we are deep paging, we don't have to order the highest "offset" counts.
name|int
name|collectCount
init|=
name|Math
operator|.
name|max
argument_list|(
literal|0
argument_list|,
name|queue
operator|.
name|size
argument_list|()
operator|-
name|off
argument_list|)
decl_stmt|;
assert|assert
name|collectCount
operator|<=
name|lim
assert|;
comment|// the start and end indexes of our list "sorted" (starting with the highest value)
name|int
name|sortedIdxStart
init|=
name|queue
operator|.
name|size
argument_list|()
operator|-
operator|(
name|collectCount
operator|-
literal|1
operator|)
decl_stmt|;
name|int
name|sortedIdxEnd
init|=
name|queue
operator|.
name|size
argument_list|()
operator|+
literal|1
decl_stmt|;
specifier|final
name|long
index|[]
name|sorted
init|=
name|queue
operator|.
name|sort
argument_list|(
name|collectCount
argument_list|)
decl_stmt|;
specifier|final
name|int
index|[]
name|indirect
init|=
name|counts
decl_stmt|;
comment|// reuse the counts array for the index into the tnums array
assert|assert
name|indirect
operator|.
name|length
operator|>=
name|sortedIdxEnd
assert|;
for|for
control|(
name|int
name|i
init|=
name|sortedIdxStart
init|;
name|i
operator|<
name|sortedIdxEnd
condition|;
name|i
operator|++
control|)
block|{
name|long
name|pair
init|=
name|sorted
index|[
name|i
index|]
decl_stmt|;
name|int
name|c
init|=
call|(
name|int
call|)
argument_list|(
name|pair
operator|>>>
literal|32
argument_list|)
decl_stmt|;
name|int
name|tnum
init|=
name|Integer
operator|.
name|MAX_VALUE
operator|-
operator|(
name|int
operator|)
name|pair
decl_stmt|;
name|indirect
index|[
name|i
index|]
operator|=
name|i
expr_stmt|;
comment|// store the index for indirect sorting
name|sorted
index|[
name|i
index|]
operator|=
name|tnum
expr_stmt|;
comment|// reuse the "sorted" array to store the term numbers for indirect sorting
comment|// add a null label for now... we'll fill it in later.
name|res
operator|.
name|add
argument_list|(
literal|null
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
comment|// now sort the indexes by the term numbers
name|PrimUtils
operator|.
name|sort
argument_list|(
name|sortedIdxStart
argument_list|,
name|sortedIdxEnd
argument_list|,
name|indirect
argument_list|,
operator|new
name|PrimUtils
operator|.
name|IntComparator
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|int
name|a
parameter_list|,
name|int
name|b
parameter_list|)
block|{
return|return
operator|(
name|int
operator|)
name|sorted
index|[
name|a
index|]
operator|-
operator|(
name|int
operator|)
name|sorted
index|[
name|b
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|lessThan
parameter_list|(
name|int
name|a
parameter_list|,
name|int
name|b
parameter_list|)
block|{
return|return
name|sorted
index|[
name|a
index|]
operator|<
name|sorted
index|[
name|b
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|int
name|a
parameter_list|,
name|int
name|b
parameter_list|)
block|{
return|return
name|sorted
index|[
name|a
index|]
operator|==
name|sorted
index|[
name|b
index|]
return|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// convert the term numbers to term values and set
comment|// as the label
comment|//System.out.println("sortStart=" + sortedIdxStart + " end=" + sortedIdxEnd);
for|for
control|(
name|int
name|i
init|=
name|sortedIdxStart
init|;
name|i
operator|<
name|sortedIdxEnd
condition|;
name|i
operator|++
control|)
block|{
name|int
name|idx
init|=
name|indirect
index|[
name|i
index|]
decl_stmt|;
name|int
name|tnum
init|=
operator|(
name|int
operator|)
name|sorted
index|[
name|idx
index|]
decl_stmt|;
name|String
name|label
init|=
name|getReadableValue
argument_list|(
name|getTermValue
argument_list|(
name|te
argument_list|,
name|tnum
argument_list|)
argument_list|,
name|ft
argument_list|,
name|spare
argument_list|)
decl_stmt|;
comment|//System.out.println("  label=" + label);
name|res
operator|.
name|setName
argument_list|(
name|idx
operator|-
name|sortedIdxStart
argument_list|,
name|label
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// add results in index order
name|int
name|i
init|=
name|startTerm
decl_stmt|;
if|if
condition|(
name|mincount
operator|<=
literal|0
condition|)
block|{
comment|// if mincount<=0, then we won't discard any terms and we know exactly
comment|// where to start.
name|i
operator|=
name|startTerm
operator|+
name|off
expr_stmt|;
name|off
operator|=
literal|0
expr_stmt|;
block|}
for|for
control|(
init|;
name|i
operator|<
name|endTerm
condition|;
name|i
operator|++
control|)
block|{
name|int
name|c
init|=
name|doNegative
condition|?
name|maxTermCounts
index|[
name|i
index|]
operator|-
name|counts
index|[
name|i
index|]
else|:
name|counts
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|c
operator|<
name|mincount
operator|||
operator|--
name|off
operator|>=
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|--
name|lim
operator|<
literal|0
condition|)
break|break;
name|String
name|label
init|=
name|getReadableValue
argument_list|(
name|getTermValue
argument_list|(
name|te
argument_list|,
name|i
argument_list|)
argument_list|,
name|ft
argument_list|,
name|spare
argument_list|)
decl_stmt|;
name|res
operator|.
name|add
argument_list|(
name|label
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|missing
condition|)
block|{
comment|// TODO: a faster solution for this?
name|res
operator|.
name|add
argument_list|(
literal|null
argument_list|,
name|SimpleFacets
operator|.
name|getFieldMissingCount
argument_list|(
name|searcher
argument_list|,
name|baseDocs
argument_list|,
name|field
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|//System.out.println("  res=" + res);
return|return
name|res
return|;
block|}
comment|/**    * Collect statistics about the UninvertedField.  Code is very similar to {@link #getCounts(org.apache.solr.search.SolrIndexSearcher, org.apache.solr.search.DocSet, int, int, Integer, boolean, String, String)}    * It can be used to calculate stats on multivalued fields.    *<p/>    * This method is mainly used by the {@link org.apache.solr.handler.component.StatsComponent}.    *    * @param searcher The Searcher to use to gather the statistics    * @param baseDocs The {@link org.apache.solr.search.DocSet} to gather the stats on    * @param facet One or more fields to facet on.    * @return The {@link org.apache.solr.handler.component.StatsValues} collected    * @throws IOException    */
DECL|method|getStats
specifier|public
name|StatsValues
name|getStats
parameter_list|(
name|SolrIndexSearcher
name|searcher
parameter_list|,
name|DocSet
name|baseDocs
parameter_list|,
name|String
index|[]
name|facet
parameter_list|)
throws|throws
name|IOException
block|{
comment|//this function is ripped off nearly wholesale from the getCounts function to use
comment|//for multiValued fields within the StatsComponent.  may be useful to find common
comment|//functionality between the two and refactor code somewhat
name|use
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|StatsValues
name|allstats
init|=
operator|new
name|StatsValues
argument_list|()
decl_stmt|;
name|DocSet
name|docs
init|=
name|baseDocs
decl_stmt|;
name|int
name|baseSize
init|=
name|docs
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|maxDoc
init|=
name|searcher
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|baseSize
operator|<=
literal|0
condition|)
return|return
name|allstats
return|;
name|FieldType
name|ft
init|=
name|searcher
operator|.
name|getSchema
argument_list|()
operator|.
name|getFieldType
argument_list|(
name|field
argument_list|)
decl_stmt|;
name|DocSet
name|missing
init|=
name|docs
operator|.
name|andNot
argument_list|(
name|searcher
operator|.
name|getDocSet
argument_list|(
operator|new
name|TermRangeQuery
argument_list|(
name|field
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
specifier|final
name|FieldFacetStats
index|[]
name|finfo
init|=
operator|new
name|FieldFacetStats
index|[
name|facet
operator|.
name|length
index|]
decl_stmt|;
comment|//Initialize facetstats, if facets have been passed in
name|FieldCache
operator|.
name|DocTermsIndex
name|si
decl_stmt|;
for|for
control|(
name|String
name|f
range|:
name|facet
control|)
block|{
name|FieldType
name|facet_ft
init|=
name|searcher
operator|.
name|getSchema
argument_list|()
operator|.
name|getFieldType
argument_list|(
name|f
argument_list|)
decl_stmt|;
try|try
block|{
name|si
operator|=
name|FieldCache
operator|.
name|DEFAULT
operator|.
name|getTermsIndex
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|,
name|f
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"failed to open field cache for: "
operator|+
name|f
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|finfo
index|[
name|i
index|]
operator|=
operator|new
name|FieldFacetStats
argument_list|(
name|f
argument_list|,
name|si
argument_list|,
name|facet_ft
argument_list|,
name|numTermsInField
argument_list|)
expr_stmt|;
name|i
operator|++
expr_stmt|;
block|}
specifier|final
name|int
index|[]
name|index
init|=
name|this
operator|.
name|index
decl_stmt|;
specifier|final
name|int
index|[]
name|counts
init|=
operator|new
name|int
index|[
name|numTermsInField
index|]
decl_stmt|;
comment|//keep track of the number of times we see each word in the field for all the documents in the docset
name|TermsEnum
name|te
init|=
name|getOrdTermsEnum
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|doNegative
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|finfo
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|//if we're collecting statistics with a facet field, can't do inverted counting
name|doNegative
operator|=
name|baseSize
operator|>
name|maxDoc
operator|>>
literal|1
operator|&&
name|termInstances
operator|>
literal|0
operator|&&
name|docs
operator|instanceof
name|BitDocSet
expr_stmt|;
block|}
if|if
condition|(
name|doNegative
condition|)
block|{
name|OpenBitSet
name|bs
init|=
call|(
name|OpenBitSet
call|)
argument_list|(
operator|(
name|BitDocSet
operator|)
name|docs
argument_list|)
operator|.
name|getBits
argument_list|()
operator|.
name|clone
argument_list|()
decl_stmt|;
name|bs
operator|.
name|flip
argument_list|(
literal|0
argument_list|,
name|maxDoc
argument_list|)
expr_stmt|;
comment|// TODO: when iterator across negative elements is available, use that
comment|// instead of creating a new bitset and inverting.
name|docs
operator|=
operator|new
name|BitDocSet
argument_list|(
name|bs
argument_list|,
name|maxDoc
operator|-
name|baseSize
argument_list|)
expr_stmt|;
comment|// simply negating will mean that we have deleted docs in the set.
comment|// that should be OK, as their entries in our table should be empty.
block|}
comment|// For the biggest terms, do straight set intersections
for|for
control|(
name|TopTerm
name|tt
range|:
name|bigTerms
operator|.
name|values
argument_list|()
control|)
block|{
comment|// TODO: counts could be deferred if sorted==false
if|if
condition|(
name|tt
operator|.
name|termNum
operator|>=
literal|0
operator|&&
name|tt
operator|.
name|termNum
operator|<
name|numTermsInField
condition|)
block|{
specifier|final
name|Term
name|t
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|tt
operator|.
name|term
argument_list|)
decl_stmt|;
if|if
condition|(
name|finfo
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|counts
index|[
name|tt
operator|.
name|termNum
index|]
operator|=
name|searcher
operator|.
name|numDocs
argument_list|(
operator|new
name|TermQuery
argument_list|(
name|t
argument_list|)
argument_list|,
name|docs
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//COULD BE VERY SLOW
comment|//if we're collecting stats for facet fields, we need to iterate on all matching documents
name|DocSet
name|bigTermDocSet
init|=
name|searcher
operator|.
name|getDocSet
argument_list|(
operator|new
name|TermQuery
argument_list|(
name|t
argument_list|)
argument_list|)
operator|.
name|intersection
argument_list|(
name|docs
argument_list|)
decl_stmt|;
name|DocIterator
name|iter
init|=
name|bigTermDocSet
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|int
name|doc
init|=
name|iter
operator|.
name|nextDoc
argument_list|()
decl_stmt|;
name|counts
index|[
name|tt
operator|.
name|termNum
index|]
operator|++
expr_stmt|;
for|for
control|(
name|FieldFacetStats
name|f
range|:
name|finfo
control|)
block|{
name|f
operator|.
name|facetTermNum
argument_list|(
name|doc
argument_list|,
name|tt
operator|.
name|termNum
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
if|if
condition|(
name|termInstances
operator|>
literal|0
condition|)
block|{
name|DocIterator
name|iter
init|=
name|docs
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|int
name|doc
init|=
name|iter
operator|.
name|nextDoc
argument_list|()
decl_stmt|;
name|int
name|code
init|=
name|index
index|[
name|doc
index|]
decl_stmt|;
if|if
condition|(
operator|(
name|code
operator|&
literal|0xff
operator|)
operator|==
literal|1
condition|)
block|{
name|int
name|pos
init|=
name|code
operator|>>>
literal|8
decl_stmt|;
name|int
name|whichArray
init|=
operator|(
name|doc
operator|>>>
literal|16
operator|)
operator|&
literal|0xff
decl_stmt|;
name|byte
index|[]
name|arr
init|=
name|tnums
index|[
name|whichArray
index|]
decl_stmt|;
name|int
name|tnum
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|int
name|delta
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|byte
name|b
init|=
name|arr
index|[
name|pos
operator|++
index|]
decl_stmt|;
name|delta
operator|=
operator|(
name|delta
operator|<<
literal|7
operator|)
operator||
operator|(
name|b
operator|&
literal|0x7f
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|b
operator|&
literal|0x80
operator|)
operator|==
literal|0
condition|)
break|break;
block|}
if|if
condition|(
name|delta
operator|==
literal|0
condition|)
break|break;
name|tnum
operator|+=
name|delta
operator|-
name|TNUM_OFFSET
expr_stmt|;
name|counts
index|[
name|tnum
index|]
operator|++
expr_stmt|;
for|for
control|(
name|FieldFacetStats
name|f
range|:
name|finfo
control|)
block|{
name|f
operator|.
name|facetTermNum
argument_list|(
name|doc
argument_list|,
name|tnum
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|int
name|tnum
init|=
literal|0
decl_stmt|;
name|int
name|delta
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|delta
operator|=
operator|(
name|delta
operator|<<
literal|7
operator|)
operator||
operator|(
name|code
operator|&
literal|0x7f
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|code
operator|&
literal|0x80
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|delta
operator|==
literal|0
condition|)
break|break;
name|tnum
operator|+=
name|delta
operator|-
name|TNUM_OFFSET
expr_stmt|;
name|counts
index|[
name|tnum
index|]
operator|++
expr_stmt|;
for|for
control|(
name|FieldFacetStats
name|f
range|:
name|finfo
control|)
block|{
name|f
operator|.
name|facetTermNum
argument_list|(
name|doc
argument_list|,
name|tnum
argument_list|)
expr_stmt|;
block|}
name|delta
operator|=
literal|0
expr_stmt|;
block|}
name|code
operator|>>>=
literal|8
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// add results in index order
name|CharArr
name|spare
init|=
operator|new
name|CharArr
argument_list|()
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|numTermsInField
condition|;
name|i
operator|++
control|)
block|{
name|int
name|c
init|=
name|doNegative
condition|?
name|maxTermCounts
index|[
name|i
index|]
operator|-
name|counts
index|[
name|i
index|]
else|:
name|counts
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|c
operator|==
literal|0
condition|)
continue|continue;
name|String
name|label
init|=
name|getReadableValue
argument_list|(
name|getTermValue
argument_list|(
name|te
argument_list|,
name|i
argument_list|)
argument_list|,
name|ft
argument_list|,
name|spare
argument_list|)
decl_stmt|;
comment|// TODO: we should avoid this re-parse
name|Double
name|value
init|=
name|Double
operator|.
name|parseDouble
argument_list|(
name|label
argument_list|)
decl_stmt|;
name|allstats
operator|.
name|accumulate
argument_list|(
name|value
argument_list|,
name|c
argument_list|)
expr_stmt|;
comment|//as we've parsed the termnum into a value, lets also accumulate fieldfacet statistics
for|for
control|(
name|FieldFacetStats
name|f
range|:
name|finfo
control|)
block|{
name|f
operator|.
name|accumulateTermNum
argument_list|(
name|i
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
name|int
name|c
init|=
name|missing
operator|.
name|size
argument_list|()
decl_stmt|;
name|allstats
operator|.
name|addMissing
argument_list|(
name|c
argument_list|)
expr_stmt|;
if|if
condition|(
name|finfo
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|allstats
operator|.
name|facets
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|StatsValues
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
for|for
control|(
name|FieldFacetStats
name|f
range|:
name|finfo
control|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|StatsValues
argument_list|>
name|facetStatsValues
init|=
name|f
operator|.
name|facetStatsValues
decl_stmt|;
name|FieldType
name|facetType
init|=
name|searcher
operator|.
name|getSchema
argument_list|()
operator|.
name|getFieldType
argument_list|(
name|f
operator|.
name|name
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|StatsValues
argument_list|>
name|entry
range|:
name|facetStatsValues
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|termLabel
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|int
name|missingCount
init|=
name|searcher
operator|.
name|numDocs
argument_list|(
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|f
operator|.
name|name
argument_list|,
name|facetType
operator|.
name|toInternal
argument_list|(
name|termLabel
argument_list|)
argument_list|)
argument_list|)
argument_list|,
name|missing
argument_list|)
decl_stmt|;
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|addMissing
argument_list|(
name|missingCount
argument_list|)
expr_stmt|;
block|}
name|allstats
operator|.
name|facets
operator|.
name|put
argument_list|(
name|f
operator|.
name|name
argument_list|,
name|facetStatsValues
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|allstats
return|;
block|}
DECL|method|getReadableValue
name|String
name|getReadableValue
parameter_list|(
name|BytesRef
name|termval
parameter_list|,
name|FieldType
name|ft
parameter_list|,
name|CharArr
name|spare
parameter_list|)
block|{
if|if
condition|(
name|spare
operator|==
literal|null
condition|)
block|{
name|spare
operator|=
operator|new
name|CharArr
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|spare
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
name|ft
operator|.
name|indexedToReadable
argument_list|(
name|termval
argument_list|,
name|spare
argument_list|)
expr_stmt|;
return|return
name|spare
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/** may return a reused BytesRef */
DECL|method|getTermValue
name|BytesRef
name|getTermValue
parameter_list|(
name|TermsEnum
name|te
parameter_list|,
name|int
name|termNum
parameter_list|)
throws|throws
name|IOException
block|{
comment|//System.out.println("getTermValue termNum=" + termNum + " this=" + this + " numTerms=" + numTermsInField);
if|if
condition|(
name|bigTerms
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// see if the term is one of our big terms.
name|TopTerm
name|tt
init|=
name|bigTerms
operator|.
name|get
argument_list|(
name|termNum
argument_list|)
decl_stmt|;
if|if
condition|(
name|tt
operator|!=
literal|null
condition|)
block|{
comment|//System.out.println("  return big " + tt.term);
return|return
name|tt
operator|.
name|term
return|;
block|}
block|}
return|return
name|lookupTerm
argument_list|(
name|te
argument_list|,
name|termNum
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|toString
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|long
name|indexSize
init|=
name|indexedTermsArray
operator|==
literal|null
condition|?
literal|0
else|:
operator|(
literal|8
operator|+
literal|8
operator|+
literal|8
operator|+
literal|8
operator|+
operator|(
name|indexedTermsArray
operator|.
name|length
operator|<<
literal|3
operator|)
operator|+
name|sizeOfIndexedStrings
operator|)
decl_stmt|;
comment|// assume 8 byte references?
return|return
literal|"{field="
operator|+
name|field
operator|+
literal|",memSize="
operator|+
name|memSize
argument_list|()
operator|+
literal|",tindexSize="
operator|+
name|indexSize
operator|+
literal|",time="
operator|+
name|total_time
operator|+
literal|",phase1="
operator|+
name|phase1_time
operator|+
literal|",nTerms="
operator|+
name|numTermsInField
operator|+
literal|",bigTerms="
operator|+
name|bigTerms
operator|.
name|size
argument_list|()
operator|+
literal|",termInstances="
operator|+
name|termInstances
operator|+
literal|",uses="
operator|+
name|use
operator|.
name|get
argument_list|()
operator|+
literal|"}"
return|;
block|}
comment|//////////////////////////////////////////////////////////////////
comment|//////////////////////////// caching /////////////////////////////
comment|//////////////////////////////////////////////////////////////////
DECL|method|getUnInvertedField
specifier|public
specifier|static
name|UnInvertedField
name|getUnInvertedField
parameter_list|(
name|String
name|field
parameter_list|,
name|SolrIndexSearcher
name|searcher
parameter_list|)
throws|throws
name|IOException
block|{
name|SolrCache
argument_list|<
name|String
argument_list|,
name|UnInvertedField
argument_list|>
name|cache
init|=
name|searcher
operator|.
name|getFieldValueCache
argument_list|()
decl_stmt|;
if|if
condition|(
name|cache
operator|==
literal|null
condition|)
block|{
return|return
operator|new
name|UnInvertedField
argument_list|(
name|field
argument_list|,
name|searcher
argument_list|)
return|;
block|}
name|UnInvertedField
name|uif
init|=
name|cache
operator|.
name|get
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|uif
operator|==
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|cache
init|)
block|{
name|uif
operator|=
name|cache
operator|.
name|get
argument_list|(
name|field
argument_list|)
expr_stmt|;
if|if
condition|(
name|uif
operator|==
literal|null
condition|)
block|{
name|uif
operator|=
operator|new
name|UnInvertedField
argument_list|(
name|field
argument_list|,
name|searcher
argument_list|)
expr_stmt|;
name|cache
operator|.
name|put
argument_list|(
name|field
argument_list|,
name|uif
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|uif
return|;
block|}
block|}
end_class
end_unit
