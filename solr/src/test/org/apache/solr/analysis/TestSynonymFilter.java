begin_unit
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.solr.analysis
package|package
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|analysis
package|;
end_package
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Token
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Tokenizer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|WhitespaceTokenizer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|FlagsAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PayloadAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TypeAttribute
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_comment
comment|/**  * @version $Id$  */
end_comment
begin_class
DECL|class|TestSynonymFilter
specifier|public
class|class
name|TestSynonymFilter
extends|extends
name|BaseTokenTestCase
block|{
DECL|method|strings
specifier|static
name|List
argument_list|<
name|String
argument_list|>
name|strings
parameter_list|(
name|String
name|str
parameter_list|)
block|{
name|String
index|[]
name|arr
init|=
name|str
operator|.
name|split
argument_list|(
literal|" "
argument_list|)
decl_stmt|;
return|return
name|Arrays
operator|.
name|asList
argument_list|(
name|arr
argument_list|)
return|;
block|}
DECL|method|assertTokenizesTo
specifier|static
name|void
name|assertTokenizesTo
parameter_list|(
name|SynonymMap
name|dict
parameter_list|,
name|String
name|input
parameter_list|,
name|String
name|expected
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|WhitespaceTokenizer
argument_list|(
name|DEFAULT_VERSION
argument_list|,
operator|new
name|StringReader
argument_list|(
name|input
argument_list|)
argument_list|)
decl_stmt|;
name|SynonymFilter
name|stream
init|=
operator|new
name|SynonymFilter
argument_list|(
name|tokenizer
argument_list|,
name|dict
argument_list|)
decl_stmt|;
name|assertTokenStreamContents
argument_list|(
name|stream
argument_list|,
name|expected
argument_list|)
expr_stmt|;
block|}
DECL|method|assertTokenizesTo
specifier|static
name|void
name|assertTokenizesTo
parameter_list|(
name|SynonymMap
name|dict
parameter_list|,
name|String
name|input
parameter_list|,
name|String
name|expected
index|[]
parameter_list|,
name|int
name|posIncs
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|WhitespaceTokenizer
argument_list|(
name|DEFAULT_VERSION
argument_list|,
operator|new
name|StringReader
argument_list|(
name|input
argument_list|)
argument_list|)
decl_stmt|;
name|SynonymFilter
name|stream
init|=
operator|new
name|SynonymFilter
argument_list|(
name|tokenizer
argument_list|,
name|dict
argument_list|)
decl_stmt|;
name|assertTokenStreamContents
argument_list|(
name|stream
argument_list|,
name|expected
argument_list|,
name|posIncs
argument_list|)
expr_stmt|;
block|}
DECL|method|assertTokenizesTo
specifier|static
name|void
name|assertTokenizesTo
parameter_list|(
name|SynonymMap
name|dict
parameter_list|,
name|List
argument_list|<
name|Token
argument_list|>
name|input
parameter_list|,
name|String
name|expected
index|[]
parameter_list|,
name|int
name|posIncs
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
name|TokenStream
name|tokenizer
init|=
operator|new
name|IterTokenStream
argument_list|(
name|input
argument_list|)
decl_stmt|;
name|SynonymFilter
name|stream
init|=
operator|new
name|SynonymFilter
argument_list|(
name|tokenizer
argument_list|,
name|dict
argument_list|)
decl_stmt|;
name|assertTokenStreamContents
argument_list|(
name|stream
argument_list|,
name|expected
argument_list|,
name|posIncs
argument_list|)
expr_stmt|;
block|}
DECL|method|assertTokenizesTo
specifier|static
name|void
name|assertTokenizesTo
parameter_list|(
name|SynonymMap
name|dict
parameter_list|,
name|List
argument_list|<
name|Token
argument_list|>
name|input
parameter_list|,
name|String
name|expected
index|[]
parameter_list|,
name|int
name|startOffsets
index|[]
parameter_list|,
name|int
name|endOffsets
index|[]
parameter_list|,
name|int
name|posIncs
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
name|TokenStream
name|tokenizer
init|=
operator|new
name|IterTokenStream
argument_list|(
name|input
argument_list|)
decl_stmt|;
name|SynonymFilter
name|stream
init|=
operator|new
name|SynonymFilter
argument_list|(
name|tokenizer
argument_list|,
name|dict
argument_list|)
decl_stmt|;
name|assertTokenStreamContents
argument_list|(
name|stream
argument_list|,
name|expected
argument_list|,
name|startOffsets
argument_list|,
name|endOffsets
argument_list|,
name|posIncs
argument_list|)
expr_stmt|;
block|}
DECL|method|testMatching
specifier|public
name|void
name|testMatching
parameter_list|()
throws|throws
name|IOException
block|{
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|false
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"ab"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a c"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"ac"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"aa"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"bb"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"z x c v"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zxcv"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"x c"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"xc"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"$"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"$"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"aa"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a $"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"aa"
block|,
literal|"$"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"$ a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"$"
block|,
literal|"aa"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"aa"
block|,
literal|"aa"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"b"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"bb"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"z x c v"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"zxcv"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"z x c $"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"z"
block|,
literal|"xc"
block|,
literal|"$"
block|}
argument_list|)
expr_stmt|;
comment|// repeats
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"ab"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"ab"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
comment|// FIXME: the below test intended to be { "ab" }
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a b"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ab"
block|,
literal|"ab"
block|,
literal|"ab"
block|}
argument_list|)
expr_stmt|;
comment|// check for lack of recursion
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"zoo"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zoo"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"zoo zoo $ zoo"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"$"
block|,
literal|"zoo"
block|}
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"zoo"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zoo zoo"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
comment|// FIXME: the below test intended to be { "zoo", "zoo", "zoo", "zoo", "$", "zoo", "zoo" }
comment|// maybe this was just a typo in the old test????
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"zoo zoo $ zoo"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"$"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testIncludeOrig
specifier|public
name|void
name|testIncludeOrig
parameter_list|()
throws|throws
name|IOException
block|{
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|true
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"ab"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a c"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"ac"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"aa"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"bb"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"z x c v"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zxcv"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"x c"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"xc"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"$"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"$"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"$ a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"$"
block|,
literal|"a"
block|,
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a $"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"aa"
block|,
literal|"$"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"$ a !"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"$"
block|,
literal|"a"
block|,
literal|"aa"
block|,
literal|"!"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"aa"
block|,
literal|"a"
block|,
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"b"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"b"
block|,
literal|"bb"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"z x c v"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"z"
block|,
literal|"zxcv"
block|,
literal|"x"
block|,
literal|"c"
block|,
literal|"v"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"z x c $"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"z"
block|,
literal|"x"
block|,
literal|"xc"
block|,
literal|"c"
block|,
literal|"$"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
comment|// check for lack of recursion
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"zoo zoo"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zoo"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
comment|// CHECKME: I think the previous test (with 4 zoo's), was just a typo.
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"zoo zoo $ zoo"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"$"
block|,
literal|"zoo"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"zoo"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zoo zoo"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"zoo zoo $ zoo"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"$"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|,
literal|"zoo"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testMapMerge
specifier|public
name|void
name|testMapMerge
parameter_list|()
throws|throws
name|IOException
block|{
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|false
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a5,5"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a3,3"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a3"
block|,
literal|"a5"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|2
block|}
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"b3,3"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"b5,5"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"b"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"b3"
block|,
literal|"b5"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|2
block|}
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"A3,3"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"A5,5"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a3"
block|,
literal|"A3"
block|,
literal|"a5"
block|,
literal|"A5"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|2
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a1"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a1"
block|,
literal|"a3"
block|,
literal|"A3"
block|,
literal|"a5"
block|,
literal|"A5"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|2
block|,
literal|0
block|,
literal|2
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a2,2"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a4,4 a6,2"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a1"
block|,
literal|"a2"
block|,
literal|"a3"
block|,
literal|"A3"
block|,
literal|"a4"
block|,
literal|"a5"
block|,
literal|"A5"
block|,
literal|"a6"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testOverlap
specifier|public
name|void
name|testOverlap
parameter_list|()
throws|throws
name|IOException
block|{
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|false
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"qwe"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"qq/ww/ee"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"qwe"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"xx"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"qwe"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"yy"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"qwe"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"zz"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"$"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"$"
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"qwe"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"qq"
block|,
literal|"ww"
block|,
literal|"ee"
block|,
literal|"xx"
block|,
literal|"yy"
block|,
literal|"zz"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
comment|// test merging within the map
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a5,5 a8,3 a10,2"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"a3,3 a7,4 a9,2 a11,2 a111,100"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
literal|"a"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a3"
block|,
literal|"a5"
block|,
literal|"a7"
block|,
literal|"a8"
block|,
literal|"a9"
block|,
literal|"a10"
block|,
literal|"a11"
block|,
literal|"a111"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|2
block|,
literal|2
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|100
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testPositionIncrements
specifier|public
name|void
name|testPositionIncrements
parameter_list|()
throws|throws
name|IOException
block|{
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|false
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
comment|// test that generated tokens start at the same posInc as the original
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"aa"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"a,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|5
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"a,0"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|}
argument_list|)
expr_stmt|;
comment|// test that offset of first replacement is ignored (always takes the orig offset)
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"bb,100"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"b,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"bb"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|5
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"b,0"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"bb"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|}
argument_list|)
expr_stmt|;
comment|// test that subsequent tokens are adjusted accordingly
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"c"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"cc,100 c2,2"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"c,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"cc"
block|,
literal|"c2"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|5
block|,
literal|2
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"c,0"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"cc"
block|,
literal|"c2"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testPositionIncrementsWithOrig
specifier|public
name|void
name|testPositionIncrementsWithOrig
parameter_list|()
throws|throws
name|IOException
block|{
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|true
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
comment|// test that generated tokens start at the same offset as the original
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"aa"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"a,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|5
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"a,0"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"aa"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
comment|// test that offset of first replacement is ignored (always takes the orig offset)
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"bb,100"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"b,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"b"
block|,
literal|"bb"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|5
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"b,0"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"b"
block|,
literal|"bb"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|0
block|}
argument_list|)
expr_stmt|;
comment|// test that subsequent tokens are adjusted accordingly
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"c"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"cc,100 c2,2"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"c,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"c"
block|,
literal|"cc"
block|,
literal|"c2"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|5
block|,
literal|0
block|,
literal|2
block|}
argument_list|)
expr_stmt|;
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"c,0"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"c"
block|,
literal|"cc"
block|,
literal|"c2"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|0
block|,
literal|2
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testOffsetBug
specifier|public
name|void
name|testOffsetBug
parameter_list|()
throws|throws
name|IOException
block|{
comment|// With the following rules:
comment|// a a=>b
comment|// x=>y
comment|// analysing "a x" causes "y" to have a bad offset (end less than start)
comment|// SOLR-167
name|SynonymMap
name|map
init|=
operator|new
name|SynonymMap
argument_list|()
decl_stmt|;
name|boolean
name|orig
init|=
literal|false
decl_stmt|;
name|boolean
name|merge
init|=
literal|true
decl_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"a a"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"b"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
name|map
operator|.
name|add
argument_list|(
name|strings
argument_list|(
literal|"x"
argument_list|)
argument_list|,
name|tokens
argument_list|(
literal|"y"
argument_list|)
argument_list|,
name|orig
argument_list|,
name|merge
argument_list|)
expr_stmt|;
comment|// "a a x" => "b y"
name|assertTokenizesTo
argument_list|(
name|map
argument_list|,
name|tokens
argument_list|(
literal|"a,1,0,1 a,1,2,3 x,1,4,5"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"b"
block|,
literal|"y"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|4
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|3
block|,
literal|5
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
comment|/***    * Return a list of tokens according to a test string format:    * a b c  =>  returns List<Token> [a,b,c]    * a/b   => tokens a and b share the same spot (b.positionIncrement=0)    * a,3/b/c => a,b,c all share same position (a.positionIncrement=3, b.positionIncrement=0, c.positionIncrement=0)    * a,1,10,11  => "a" with positionIncrement=1, startOffset=10, endOffset=11    * @deprecated does not support attributes api    */
DECL|method|tokens
specifier|private
name|List
argument_list|<
name|Token
argument_list|>
name|tokens
parameter_list|(
name|String
name|str
parameter_list|)
block|{
name|String
index|[]
name|arr
init|=
name|str
operator|.
name|split
argument_list|(
literal|" "
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Token
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|Token
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|arr
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
index|[]
name|toks
init|=
name|arr
index|[
name|i
index|]
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|String
index|[]
name|params
init|=
name|toks
index|[
literal|0
index|]
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
name|int
name|posInc
decl_stmt|;
name|int
name|start
decl_stmt|;
name|int
name|end
decl_stmt|;
if|if
condition|(
name|params
operator|.
name|length
operator|>
literal|1
condition|)
block|{
name|posInc
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|params
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|posInc
operator|=
literal|1
expr_stmt|;
block|}
if|if
condition|(
name|params
operator|.
name|length
operator|>
literal|2
condition|)
block|{
name|start
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|params
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|start
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|params
operator|.
name|length
operator|>
literal|3
condition|)
block|{
name|end
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|params
index|[
literal|3
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|end
operator|=
name|start
operator|+
name|params
index|[
literal|0
index|]
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
name|Token
name|t
init|=
operator|new
name|Token
argument_list|(
name|params
index|[
literal|0
index|]
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
literal|"TEST"
argument_list|)
decl_stmt|;
name|t
operator|.
name|setPositionIncrement
argument_list|(
name|posInc
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|t
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|1
init|;
name|j
operator|<
name|toks
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
name|t
operator|=
operator|new
name|Token
argument_list|(
name|toks
index|[
name|j
index|]
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|"TEST"
argument_list|)
expr_stmt|;
name|t
operator|.
name|setPositionIncrement
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * @deprecated does not support custom attributes    */
DECL|class|IterTokenStream
specifier|private
specifier|static
class|class
name|IterTokenStream
extends|extends
name|TokenStream
block|{
DECL|field|tokens
specifier|final
name|Token
name|tokens
index|[]
decl_stmt|;
DECL|field|index
name|int
name|index
init|=
literal|0
decl_stmt|;
DECL|field|termAtt
name|CharTermAttribute
name|termAtt
init|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|offsetAtt
name|OffsetAttribute
name|offsetAtt
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|posIncAtt
name|PositionIncrementAttribute
name|posIncAtt
init|=
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|flagsAtt
name|FlagsAttribute
name|flagsAtt
init|=
name|addAttribute
argument_list|(
name|FlagsAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|typeAtt
name|TypeAttribute
name|typeAtt
init|=
name|addAttribute
argument_list|(
name|TypeAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|payloadAtt
name|PayloadAttribute
name|payloadAtt
init|=
name|addAttribute
argument_list|(
name|PayloadAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|method|IterTokenStream
specifier|public
name|IterTokenStream
parameter_list|(
name|Token
modifier|...
name|tokens
parameter_list|)
block|{
name|super
argument_list|()
expr_stmt|;
name|this
operator|.
name|tokens
operator|=
name|tokens
expr_stmt|;
block|}
DECL|method|IterTokenStream
specifier|public
name|IterTokenStream
parameter_list|(
name|Collection
argument_list|<
name|Token
argument_list|>
name|tokens
parameter_list|)
block|{
name|this
argument_list|(
name|tokens
operator|.
name|toArray
argument_list|(
operator|new
name|Token
index|[
name|tokens
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|incrementToken
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|index
operator|>=
name|tokens
operator|.
name|length
condition|)
return|return
literal|false
return|;
else|else
block|{
name|clearAttributes
argument_list|()
expr_stmt|;
name|Token
name|token
init|=
name|tokens
index|[
name|index
operator|++
index|]
decl_stmt|;
name|termAtt
operator|.
name|setEmpty
argument_list|()
operator|.
name|append
argument_list|(
name|token
operator|.
name|term
argument_list|()
argument_list|)
expr_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|token
operator|.
name|startOffset
argument_list|()
argument_list|,
name|token
operator|.
name|endOffset
argument_list|()
argument_list|)
expr_stmt|;
name|posIncAtt
operator|.
name|setPositionIncrement
argument_list|(
name|token
operator|.
name|getPositionIncrement
argument_list|()
argument_list|)
expr_stmt|;
name|flagsAtt
operator|.
name|setFlags
argument_list|(
name|token
operator|.
name|getFlags
argument_list|()
argument_list|)
expr_stmt|;
name|typeAtt
operator|.
name|setType
argument_list|(
name|token
operator|.
name|type
argument_list|()
argument_list|)
expr_stmt|;
name|payloadAtt
operator|.
name|setPayload
argument_list|(
name|token
operator|.
name|getPayload
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
end_class
end_unit
