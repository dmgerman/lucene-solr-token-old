begin_unit
begin_package
DECL|package|org.apache.lucene.search.highlight
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|highlight
package|;
end_package
begin_comment
comment|/**  * Copyright 2002-2004 The Apache Software Foundation  *  * Licensed under the Apache License, Version 2.0 (the "License");  * you may not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Reader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|StringTokenizer
import|;
end_import
begin_import
import|import
name|junit
operator|.
name|framework
operator|.
name|TestCase
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|LowerCaseTokenizer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Token
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|standard
operator|.
name|StandardAnalyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Document
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Field
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|queryParser
operator|.
name|ParseException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|queryParser
operator|.
name|QueryParser
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Hits
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|MultiSearcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Query
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Searcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|RAMDirectory
import|;
end_import
begin_comment
comment|/**  * JUnit Test for Highlighter class.  * @author mark@searcharea.co.uk  */
end_comment
begin_class
DECL|class|HighlighterTest
specifier|public
class|class
name|HighlighterTest
extends|extends
name|TestCase
implements|implements
name|Formatter
block|{
DECL|field|reader
specifier|private
name|IndexReader
name|reader
decl_stmt|;
DECL|field|FIELD_NAME
specifier|private
specifier|static
specifier|final
name|String
name|FIELD_NAME
init|=
literal|"contents"
decl_stmt|;
DECL|field|query
specifier|private
name|Query
name|query
decl_stmt|;
DECL|field|ramDir
name|RAMDirectory
name|ramDir
decl_stmt|;
DECL|field|searcher
specifier|public
name|Searcher
name|searcher
init|=
literal|null
decl_stmt|;
DECL|field|hits
specifier|public
name|Hits
name|hits
init|=
literal|null
decl_stmt|;
DECL|field|numHighlights
name|int
name|numHighlights
init|=
literal|0
decl_stmt|;
DECL|field|analyzer
name|Analyzer
name|analyzer
init|=
operator|new
name|StandardAnalyzer
argument_list|()
decl_stmt|;
DECL|field|texts
name|String
name|texts
index|[]
init|=
block|{
literal|"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot"
block|,
literal|"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy"
block|,
literal|"JFK has been shot"
block|,
literal|"John Kennedy has been shot"
block|,
literal|"This text has a typo in referring to Keneddy"
block|}
decl_stmt|;
comment|/** 	 * Constructor for HighlightExtractorTest. 	 * @param arg0 	 */
DECL|method|HighlighterTest
specifier|public
name|HighlighterTest
parameter_list|(
name|String
name|arg0
parameter_list|)
block|{
name|super
argument_list|(
name|arg0
argument_list|)
expr_stmt|;
block|}
DECL|method|testSimpleHighlighter
specifier|public
name|void
name|testSimpleHighlighter
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"Kennedy"
argument_list|)
expr_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|40
argument_list|)
argument_list|)
expr_stmt|;
name|int
name|maxNumFragmentsRequired
init|=
literal|2
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragments
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|,
name|maxNumFragmentsRequired
argument_list|,
literal|"..."
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\t"
operator|+
name|result
argument_list|)
expr_stmt|;
block|}
comment|//Not sure we can assert anything here - just running to check we dont throw any exceptions
block|}
DECL|method|testGetBestFragmentsSimpleQuery
specifier|public
name|void
name|testGetBestFragmentsSimpleQuery
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"Kennedy"
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|4
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetFuzzyFragments
specifier|public
name|void
name|testGetFuzzyFragments
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"Kinnedy~"
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|4
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetWildCardFragments
specifier|public
name|void
name|testGetWildCardFragments
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"K?nnedy"
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|4
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetMidWildCardFragments
specifier|public
name|void
name|testGetMidWildCardFragments
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"K*dy"
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|5
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetRangeFragments
specifier|public
name|void
name|testGetRangeFragments
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
name|FIELD_NAME
operator|+
literal|":[kannedy TO kznnedy]"
argument_list|)
expr_stmt|;
comment|//bug?needs lower case
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|5
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetBestFragmentsPhrase
specifier|public
name|void
name|testGetBestFragmentsPhrase
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"\"John Kennedy\""
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
comment|//Currently highlights "John" and "Kennedy" separately
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|2
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetBestFragmentsMultiTerm
specifier|public
name|void
name|testGetBestFragmentsMultiTerm
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"John Kenn*"
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|5
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetBestFragmentsWithOr
specifier|public
name|void
name|testGetBestFragmentsWithOr
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"JFK OR Kennedy"
argument_list|)
expr_stmt|;
name|doStandardHighlights
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|5
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetBestSingleFragment
specifier|public
name|void
name|testGetBestSingleFragment
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"Kennedy"
argument_list|)
expr_stmt|;
comment|//		QueryHighlightExtractor highlighter = new QueryHighlightExtractor(this, query, new StandardAnalyzer());
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|40
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\t"
operator|+
name|result
argument_list|)
expr_stmt|;
block|}
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|4
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetBestSingleFragmentWithWeights
specifier|public
name|void
name|testGetBestSingleFragmentWithWeights
parameter_list|()
throws|throws
name|Exception
block|{
name|WeightedTerm
index|[]
name|wTerms
init|=
operator|new
name|WeightedTerm
index|[
literal|2
index|]
decl_stmt|;
name|wTerms
index|[
literal|0
index|]
operator|=
operator|new
name|WeightedTerm
argument_list|(
literal|10f
argument_list|,
literal|"hello"
argument_list|)
expr_stmt|;
name|wTerms
index|[
literal|1
index|]
operator|=
operator|new
name|WeightedTerm
argument_list|(
literal|1f
argument_list|,
literal|"kennedy"
argument_list|)
expr_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
operator|new
name|QueryScorer
argument_list|(
name|wTerms
argument_list|)
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|texts
index|[
literal|0
index|]
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|2
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|texts
index|[
literal|0
index|]
argument_list|)
operator|.
name|trim
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find best section using weighted terms. Found: ["
operator|+
name|result
operator|+
literal|"]"
argument_list|,
literal|"<B>Hello</B>"
operator|.
name|equals
argument_list|(
name|result
argument_list|)
argument_list|)
expr_stmt|;
comment|//readjust weights
name|wTerms
index|[
literal|1
index|]
operator|.
name|setWeight
argument_list|(
literal|50f
argument_list|)
expr_stmt|;
name|tokenStream
operator|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|texts
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|highlighter
operator|=
operator|new
name|Highlighter
argument_list|(
operator|new
name|QueryScorer
argument_list|(
name|wTerms
argument_list|)
argument_list|)
expr_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|2
argument_list|)
argument_list|)
expr_stmt|;
name|result
operator|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|texts
index|[
literal|0
index|]
argument_list|)
operator|.
name|trim
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find best section using weighted terms. Found: "
operator|+
name|result
argument_list|,
literal|"<B>kennedy</B>"
operator|.
name|equals
argument_list|(
name|result
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// tests a "complex" analyzer that produces multiple
comment|// overlapping tokens
DECL|method|testOverlapAnalyzer
specifier|public
name|void
name|testOverlapAnalyzer
parameter_list|()
throws|throws
name|Exception
block|{
name|HashMap
name|synonyms
init|=
operator|new
name|HashMap
argument_list|()
decl_stmt|;
name|synonyms
operator|.
name|put
argument_list|(
literal|"football"
argument_list|,
literal|"soccer,footie"
argument_list|)
expr_stmt|;
name|Analyzer
name|analyzer
init|=
operator|new
name|SynonymAnalyzer
argument_list|(
name|synonyms
argument_list|)
decl_stmt|;
name|String
name|srchkey
init|=
literal|"football"
decl_stmt|;
name|String
name|s
init|=
literal|"football-soccer in the euro 2004 footie competition"
decl_stmt|;
name|Query
name|query
init|=
name|QueryParser
operator|.
name|parse
argument_list|(
name|srchkey
argument_list|,
literal|"bookid"
argument_list|,
name|analyzer
argument_list|)
decl_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|null
argument_list|,
operator|new
name|StringReader
argument_list|(
name|s
argument_list|)
argument_list|)
decl_stmt|;
comment|// Get 3 best fragments and seperate with a "..."
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragments
argument_list|(
name|tokenStream
argument_list|,
name|s
argument_list|,
literal|3
argument_list|,
literal|"..."
argument_list|)
decl_stmt|;
name|String
name|expectedResult
init|=
literal|"<B>football</B>-<B>soccer</B> in the euro 2004<B>footie</B> competition"
decl_stmt|;
name|assertTrue
argument_list|(
literal|"overlapping analyzer should handle highlights OK"
argument_list|,
name|expectedResult
operator|.
name|equals
argument_list|(
name|result
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetSimpleHighlight
specifier|public
name|void
name|testGetSimpleHighlight
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"Kennedy"
argument_list|)
expr_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\t"
operator|+
name|result
argument_list|)
expr_stmt|;
block|}
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|4
argument_list|)
expr_stmt|;
block|}
DECL|method|testGetTextFragments
specifier|public
name|void
name|testGetTextFragments
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"Kennedy"
argument_list|)
expr_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|20
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|stringResults
index|[]
init|=
name|highlighter
operator|.
name|getBestFragments
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|,
literal|10
argument_list|)
decl_stmt|;
name|tokenStream
operator|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
expr_stmt|;
name|TextFragment
name|fragmentResults
index|[]
init|=
name|highlighter
operator|.
name|getBestTextFragments
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|,
literal|true
argument_list|,
literal|10
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find correct number of text Fragments: "
operator|+
name|fragmentResults
operator|.
name|length
operator|+
literal|" vs "
operator|+
name|stringResults
operator|.
name|length
argument_list|,
name|fragmentResults
operator|.
name|length
operator|==
name|stringResults
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|stringResults
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|fragmentResults
index|[
name|j
index|]
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to find same text Fragments: "
operator|+
name|fragmentResults
index|[
name|j
index|]
operator|+
literal|" found"
argument_list|,
name|fragmentResults
index|[
name|j
index|]
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
name|stringResults
index|[
name|j
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|testMaxSizeHighlight
specifier|public
name|void
name|testMaxSizeHighlight
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"meat"
argument_list|)
expr_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setMaxDocBytesToAnalyze
argument_list|(
literal|30
argument_list|)
expr_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|texts
index|[
literal|0
index|]
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|texts
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Setting MaxDocBytesToAnalyze should have prevented "
operator|+
literal|"us from finding matches for this record"
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
DECL|method|testUnRewrittenQuery
specifier|public
name|void
name|testUnRewrittenQuery
parameter_list|()
throws|throws
name|IOException
throws|,
name|ParseException
block|{
comment|//test to show how rewritten query can still be used
name|searcher
operator|=
operator|new
name|IndexSearcher
argument_list|(
name|ramDir
argument_list|)
expr_stmt|;
name|Analyzer
name|analyzer
init|=
operator|new
name|StandardAnalyzer
argument_list|()
decl_stmt|;
name|Query
name|query
init|=
name|QueryParser
operator|.
name|parse
argument_list|(
literal|"JF? or Kenned*"
argument_list|,
name|FIELD_NAME
argument_list|,
name|analyzer
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Searching with primitive query"
argument_list|)
expr_stmt|;
comment|//forget to set this and...
comment|//query=query.rewrite(reader);
name|Hits
name|hits
init|=
name|searcher
operator|.
name|search
argument_list|(
name|query
argument_list|)
decl_stmt|;
comment|//create an instance of the highlighter with the tags used to surround highlighted text
comment|//		QueryHighlightExtractor highlighter = new QueryHighlightExtractor(this, query, new StandardAnalyzer());
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|40
argument_list|)
argument_list|)
expr_stmt|;
name|int
name|maxNumFragmentsRequired
init|=
literal|3
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|highlightedText
init|=
name|highlighter
operator|.
name|getBestFragments
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|,
name|maxNumFragmentsRequired
argument_list|,
literal|"..."
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|highlightedText
argument_list|)
expr_stmt|;
block|}
comment|//We expect to have zero highlights if the query is multi-terms and is not rewritten!
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
DECL|method|testNoFragments
specifier|public
name|void
name|testNoFragments
parameter_list|()
throws|throws
name|Exception
block|{
name|doSearching
argument_list|(
literal|"AnInvalidQueryWhichShouldYieldNoResults"
argument_list|)
expr_stmt|;
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|highlightFragmentSizeInBytes
init|=
literal|40
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|texts
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|texts
index|[
name|i
index|]
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|)
decl_stmt|;
name|assertNull
argument_list|(
literal|"The highlight result should be null for text with no query terms"
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|testMultiSearcher
specifier|public
name|void
name|testMultiSearcher
parameter_list|()
throws|throws
name|Exception
block|{
comment|//setup index 1
name|RAMDirectory
name|ramDir1
init|=
operator|new
name|RAMDirectory
argument_list|()
decl_stmt|;
name|IndexWriter
name|writer1
init|=
operator|new
name|IndexWriter
argument_list|(
name|ramDir1
argument_list|,
operator|new
name|StandardAnalyzer
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|Document
name|d
init|=
operator|new
name|Document
argument_list|()
decl_stmt|;
name|Field
name|f
init|=
operator|new
name|Field
argument_list|(
name|FIELD_NAME
argument_list|,
literal|"multiOne"
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|d
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
name|writer1
operator|.
name|addDocument
argument_list|(
name|d
argument_list|)
expr_stmt|;
name|writer1
operator|.
name|optimize
argument_list|()
expr_stmt|;
name|writer1
operator|.
name|close
argument_list|()
expr_stmt|;
name|IndexReader
name|reader1
init|=
name|IndexReader
operator|.
name|open
argument_list|(
name|ramDir1
argument_list|)
decl_stmt|;
comment|//setup index 2
name|RAMDirectory
name|ramDir2
init|=
operator|new
name|RAMDirectory
argument_list|()
decl_stmt|;
name|IndexWriter
name|writer2
init|=
operator|new
name|IndexWriter
argument_list|(
name|ramDir2
argument_list|,
operator|new
name|StandardAnalyzer
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|d
operator|=
operator|new
name|Document
argument_list|()
expr_stmt|;
name|f
operator|=
operator|new
name|Field
argument_list|(
name|FIELD_NAME
argument_list|,
literal|"multiTwo"
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|d
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
name|writer2
operator|.
name|addDocument
argument_list|(
name|d
argument_list|)
expr_stmt|;
name|writer2
operator|.
name|optimize
argument_list|()
expr_stmt|;
name|writer2
operator|.
name|close
argument_list|()
expr_stmt|;
name|IndexReader
name|reader2
init|=
name|IndexReader
operator|.
name|open
argument_list|(
name|ramDir2
argument_list|)
decl_stmt|;
name|IndexSearcher
name|searchers
index|[]
init|=
operator|new
name|IndexSearcher
index|[
literal|2
index|]
decl_stmt|;
name|searchers
index|[
literal|0
index|]
operator|=
operator|new
name|IndexSearcher
argument_list|(
name|ramDir1
argument_list|)
expr_stmt|;
name|searchers
index|[
literal|1
index|]
operator|=
operator|new
name|IndexSearcher
argument_list|(
name|ramDir2
argument_list|)
expr_stmt|;
name|MultiSearcher
name|multiSearcher
init|=
operator|new
name|MultiSearcher
argument_list|(
name|searchers
argument_list|)
decl_stmt|;
name|query
operator|=
name|QueryParser
operator|.
name|parse
argument_list|(
literal|"multi*"
argument_list|,
name|FIELD_NAME
argument_list|,
operator|new
name|StandardAnalyzer
argument_list|()
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Searching for: "
operator|+
name|query
operator|.
name|toString
argument_list|(
name|FIELD_NAME
argument_list|)
argument_list|)
expr_stmt|;
comment|//at this point the multisearcher calls combine(query[])
name|hits
operator|=
name|multiSearcher
operator|.
name|search
argument_list|(
name|query
argument_list|)
expr_stmt|;
comment|//query = QueryParser.parse("multi*", FIELD_NAME, new StandardAnalyzer());
name|Query
name|expandedQueries
index|[]
init|=
operator|new
name|Query
index|[
literal|2
index|]
decl_stmt|;
name|expandedQueries
index|[
literal|0
index|]
operator|=
name|query
operator|.
name|rewrite
argument_list|(
name|reader1
argument_list|)
expr_stmt|;
name|expandedQueries
index|[
literal|1
index|]
operator|=
name|query
operator|.
name|rewrite
argument_list|(
name|reader2
argument_list|)
expr_stmt|;
name|query
operator|=
name|query
operator|.
name|combine
argument_list|(
name|expandedQueries
argument_list|)
expr_stmt|;
comment|//create an instance of the highlighter with the tags used to surround highlighted text
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|highlightedText
init|=
name|highlighter
operator|.
name|getBestFragment
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|highlightedText
argument_list|)
expr_stmt|;
block|}
name|assertTrue
argument_list|(
literal|"Failed to find correct number of highlights "
operator|+
name|numHighlights
operator|+
literal|" found"
argument_list|,
name|numHighlights
operator|==
literal|2
argument_list|)
expr_stmt|;
block|}
comment|/*  	public void testBigramAnalyzer() throws IOException, ParseException 	{ 		//test to ensure analyzers with none-consecutive start/end offsets 		//dont double-highlight text 		//setup index 1 		RAMDirectory ramDir = new RAMDirectory(); 		Analyzer bigramAnalyzer=new CJKAnalyzer(); 		IndexWriter writer = new IndexWriter(ramDir,bigramAnalyzer , true); 		Document d = new Document(); 		Field f = new Field(FIELD_NAME, "java abc def", true, true, true); 		d.add(f); 		writer.addDocument(d); 		writer.close(); 		IndexReader reader = IndexReader.open(ramDir);  		IndexSearcher searcher=new IndexSearcher(reader); 		query = QueryParser.parse("abc", FIELD_NAME, bigramAnalyzer); 		System.out.println("Searching for: " + query.toString(FIELD_NAME)); 		hits = searcher.search(query);  		Highlighter highlighter = 			new Highlighter(this,new QueryFragmentScorer(query));  		for (int i = 0; i< hits.length(); i++) 		{ 			String text = hits.doc(i).get(FIELD_NAME); 			TokenStream tokenStream=bigramAnalyzer.tokenStream(FIELD_NAME,new StringReader(text)); 			String highlightedText = highlighter.getBestFragment(tokenStream,text); 			System.out.println(highlightedText); 		}  	} */
DECL|method|highlightTerm
specifier|public
name|String
name|highlightTerm
parameter_list|(
name|String
name|originalText
parameter_list|,
name|TokenGroup
name|group
parameter_list|)
block|{
if|if
condition|(
name|group
operator|.
name|getTotalScore
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
name|originalText
return|;
block|}
name|numHighlights
operator|++
expr_stmt|;
comment|//update stats used in assertions
return|return
literal|"<b>"
operator|+
name|originalText
operator|+
literal|"</b>"
return|;
block|}
DECL|method|doSearching
specifier|public
name|void
name|doSearching
parameter_list|(
name|String
name|queryString
parameter_list|)
throws|throws
name|Exception
block|{
name|searcher
operator|=
operator|new
name|IndexSearcher
argument_list|(
name|ramDir
argument_list|)
expr_stmt|;
name|query
operator|=
name|QueryParser
operator|.
name|parse
argument_list|(
name|queryString
argument_list|,
name|FIELD_NAME
argument_list|,
operator|new
name|StandardAnalyzer
argument_list|()
argument_list|)
expr_stmt|;
comment|//for any multi-term queries to work (prefix, wildcard, range,fuzzy etc) you must use a rewritten query!
name|query
operator|=
name|query
operator|.
name|rewrite
argument_list|(
name|reader
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Searching for: "
operator|+
name|query
operator|.
name|toString
argument_list|(
name|FIELD_NAME
argument_list|)
argument_list|)
expr_stmt|;
name|hits
operator|=
name|searcher
operator|.
name|search
argument_list|(
name|query
argument_list|)
expr_stmt|;
block|}
DECL|method|doStandardHighlights
name|void
name|doStandardHighlights
parameter_list|()
throws|throws
name|Exception
block|{
name|Highlighter
name|highlighter
init|=
operator|new
name|Highlighter
argument_list|(
name|this
argument_list|,
operator|new
name|QueryScorer
argument_list|(
name|query
argument_list|)
argument_list|)
decl_stmt|;
name|highlighter
operator|.
name|setTextFragmenter
argument_list|(
operator|new
name|SimpleFragmenter
argument_list|(
literal|20
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|text
init|=
name|hits
operator|.
name|doc
argument_list|(
name|i
argument_list|)
operator|.
name|get
argument_list|(
name|FIELD_NAME
argument_list|)
decl_stmt|;
name|int
name|maxNumFragmentsRequired
init|=
literal|2
decl_stmt|;
name|String
name|fragmentSeparator
init|=
literal|"..."
decl_stmt|;
name|TokenStream
name|tokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|FIELD_NAME
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|result
init|=
name|highlighter
operator|.
name|getBestFragments
argument_list|(
name|tokenStream
argument_list|,
name|text
argument_list|,
name|maxNumFragmentsRequired
argument_list|,
name|fragmentSeparator
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\t"
operator|+
name|result
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * @see TestCase#setUp() 	 */
DECL|method|setUp
specifier|protected
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|ramDir
operator|=
operator|new
name|RAMDirectory
argument_list|()
expr_stmt|;
name|IndexWriter
name|writer
init|=
operator|new
name|IndexWriter
argument_list|(
name|ramDir
argument_list|,
operator|new
name|StandardAnalyzer
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|texts
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|addDoc
argument_list|(
name|writer
argument_list|,
name|texts
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|writer
operator|.
name|optimize
argument_list|()
expr_stmt|;
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|reader
operator|=
name|IndexReader
operator|.
name|open
argument_list|(
name|ramDir
argument_list|)
expr_stmt|;
name|numHighlights
operator|=
literal|0
expr_stmt|;
block|}
DECL|method|addDoc
specifier|private
name|void
name|addDoc
parameter_list|(
name|IndexWriter
name|writer
parameter_list|,
name|String
name|text
parameter_list|)
throws|throws
name|IOException
block|{
name|Document
name|d
init|=
operator|new
name|Document
argument_list|()
decl_stmt|;
name|Field
name|f
init|=
operator|new
name|Field
argument_list|(
name|FIELD_NAME
argument_list|,
name|text
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|d
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
name|writer
operator|.
name|addDocument
argument_list|(
name|d
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * @see TestCase#tearDown() 	 */
DECL|method|tearDown
specifier|protected
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
name|super
operator|.
name|tearDown
argument_list|()
expr_stmt|;
block|}
block|}
end_class
begin_comment
comment|//===================================================================
end_comment
begin_comment
comment|//========== BEGIN TEST SUPPORTING CLASSES
end_comment
begin_comment
comment|//========== THESE LOOK LIKE, WITH SOME MORE EFFORT THESE COULD BE
end_comment
begin_comment
comment|//========== MADE MORE GENERALLY USEFUL.
end_comment
begin_comment
comment|// TODO - make synonyms all interchangeable with each other and produce
end_comment
begin_comment
comment|// a version that does antonyms(?) - the "is a specialised type of ...."
end_comment
begin_comment
comment|// so that car=audi, bmw and volkswagen but bmw != audi so different
end_comment
begin_comment
comment|// behaviour to synonyms
end_comment
begin_comment
comment|//===================================================================
end_comment
begin_class
DECL|class|SynonymAnalyzer
class|class
name|SynonymAnalyzer
extends|extends
name|Analyzer
block|{
DECL|field|synonyms
specifier|private
name|Map
name|synonyms
decl_stmt|;
DECL|method|SynonymAnalyzer
specifier|public
name|SynonymAnalyzer
parameter_list|(
name|Map
name|synonyms
parameter_list|)
block|{
name|this
operator|.
name|synonyms
operator|=
name|synonyms
expr_stmt|;
block|}
comment|/* (non-Javadoc) 	 * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String, java.io.Reader) 	 */
DECL|method|tokenStream
specifier|public
name|TokenStream
name|tokenStream
parameter_list|(
name|String
name|arg0
parameter_list|,
name|Reader
name|arg1
parameter_list|)
block|{
return|return
operator|new
name|SynonymTokenizer
argument_list|(
operator|new
name|LowerCaseTokenizer
argument_list|(
name|arg1
argument_list|)
argument_list|,
name|synonyms
argument_list|)
return|;
block|}
block|}
end_class
begin_comment
comment|/**  * Expands a token stream with synonyms (TODO - make the synonyms analyzed by choice of analyzer)  * @author MAHarwood  */
end_comment
begin_class
DECL|class|SynonymTokenizer
class|class
name|SynonymTokenizer
extends|extends
name|TokenStream
block|{
DECL|field|realStream
specifier|private
name|TokenStream
name|realStream
decl_stmt|;
DECL|field|currentRealToken
specifier|private
name|Token
name|currentRealToken
init|=
literal|null
decl_stmt|;
DECL|field|synonyms
specifier|private
name|Map
name|synonyms
decl_stmt|;
DECL|field|st
name|StringTokenizer
name|st
init|=
literal|null
decl_stmt|;
DECL|method|SynonymTokenizer
specifier|public
name|SynonymTokenizer
parameter_list|(
name|TokenStream
name|realStream
parameter_list|,
name|Map
name|synonyms
parameter_list|)
block|{
name|this
operator|.
name|realStream
operator|=
name|realStream
expr_stmt|;
name|this
operator|.
name|synonyms
operator|=
name|synonyms
expr_stmt|;
block|}
DECL|method|next
specifier|public
name|Token
name|next
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|currentRealToken
operator|==
literal|null
condition|)
block|{
name|Token
name|nextRealToken
init|=
name|realStream
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|nextRealToken
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|String
name|expansions
init|=
operator|(
name|String
operator|)
name|synonyms
operator|.
name|get
argument_list|(
name|nextRealToken
operator|.
name|termText
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|expansions
operator|==
literal|null
condition|)
block|{
return|return
name|nextRealToken
return|;
block|}
name|st
operator|=
operator|new
name|StringTokenizer
argument_list|(
name|expansions
argument_list|,
literal|","
argument_list|)
expr_stmt|;
if|if
condition|(
name|st
operator|.
name|hasMoreTokens
argument_list|()
condition|)
block|{
name|currentRealToken
operator|=
name|nextRealToken
expr_stmt|;
block|}
return|return
name|currentRealToken
return|;
block|}
else|else
block|{
name|String
name|nextExpandedValue
init|=
name|st
operator|.
name|nextToken
argument_list|()
decl_stmt|;
name|Token
name|expandedToken
init|=
operator|new
name|Token
argument_list|(
name|nextExpandedValue
argument_list|,
name|currentRealToken
operator|.
name|startOffset
argument_list|()
argument_list|,
name|currentRealToken
operator|.
name|endOffset
argument_list|()
argument_list|)
decl_stmt|;
name|expandedToken
operator|.
name|setPositionIncrement
argument_list|(
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|st
operator|.
name|hasMoreTokens
argument_list|()
condition|)
block|{
name|currentRealToken
operator|=
literal|null
expr_stmt|;
name|st
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|expandedToken
return|;
block|}
block|}
block|}
end_class
end_unit
