begin_unit
begin_package
DECL|package|org.apache.lucene.analysis
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
package|;
end_package
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|ref
operator|.
name|WeakReference
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|AttributeImpl
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|AttributeSource
import|;
end_import
begin_comment
comment|/**  * This TokenFilter provides the ability to set aside attribute states  * that have already been analyzed.  This is useful in situations where multiple fields share  * many common analysis steps and then go their separate ways.  *<p/>  * It is also useful for doing things like entity extraction or proper noun analysis as  * part of the analysis workflow and saving off those tokens for use in another field.  *  *<pre> TeeSinkTokenFilter source1 = new TeeSinkTokenFilter(new WhitespaceTokenizer(reader1)); TeeSinkTokenFilter.SinkTokenStream sink1 = source1.newSinkTokenStream(); TeeSinkTokenFilter.SinkTokenStream sink2 = source1.newSinkTokenStream();  TeeSinkTokenFilter source2 = new TeeSinkTokenFilter(new WhitespaceTokenizer(reader2)); source2.addSinkTokenStream(sink1); source2.addSinkTokenStream(sink2);  TokenStream final1 = new LowerCaseFilter(source1); TokenStream final2 = source2; TokenStream final3 = new EntityDetect(sink1); TokenStream final4 = new URLDetect(sink2);  d.add(new Field("f1", final1)); d.add(new Field("f2", final2)); d.add(new Field("f3", final3)); d.add(new Field("f4", final4));  *</pre>  * In this example,<code>sink1</code> and<code>sink2<code> will both get tokens from both  *<code>reader1</code> and<code>reader2</code> after whitespace tokenizer  * and now we can further wrap any of these in extra analysis, and more "sources" can be inserted if desired.  * It is important, that tees are consumed before sinks (in the above example, the field names must be  * less the sink's field names). If you are not sure, which stream is consumed first, you can simply  * add another sink and then pass all tokens to the sinks at once using {@link #consumeAllTokens}.  * This TokenFilter is exhausted after this. In the above example, change  * the example above to:  *<pre> ... TokenStream final1 = new LowerCaseFilter(source1.newSinkTokenStream()); TokenStream final2 = source2.newSinkTokenStream(); sink1.consumeAllTokens(); sink2.consumeAllTokens(); ...  *</pre>  * In this case, the fields can be added in any order, because the sources are not used anymore and all sinks are ready.  *<p>Note, the EntityDetect and URLDetect TokenStreams are for the example and do not currently exist in Lucene.  */
end_comment
begin_class
DECL|class|TeeSinkTokenFilter
specifier|public
specifier|final
class|class
name|TeeSinkTokenFilter
extends|extends
name|TokenFilter
block|{
DECL|field|sinks
specifier|private
specifier|final
name|List
name|sinks
init|=
operator|new
name|LinkedList
argument_list|()
decl_stmt|;
comment|/**    * Instantiates a new TeeSinkTokenFilter.    */
DECL|method|TeeSinkTokenFilter
specifier|public
name|TeeSinkTokenFilter
parameter_list|(
name|TokenStream
name|input
parameter_list|)
block|{
name|super
argument_list|(
name|input
argument_list|)
expr_stmt|;
block|}
comment|/**    * Returns a new {@link SinkTokenStream} that receives all tokens consumed by this stream.    */
DECL|method|newSinkTokenStream
specifier|public
name|SinkTokenStream
name|newSinkTokenStream
parameter_list|()
block|{
return|return
name|newSinkTokenStream
argument_list|(
name|ACCEPT_ALL_FILTER
argument_list|)
return|;
block|}
comment|/**    * Returns a new {@link SinkTokenStream} that receives all tokens consumed by this stream    * that pass the supplied filter.    * @see SinkFilter    */
DECL|method|newSinkTokenStream
specifier|public
name|SinkTokenStream
name|newSinkTokenStream
parameter_list|(
name|SinkFilter
name|filter
parameter_list|)
block|{
name|SinkTokenStream
name|sink
init|=
operator|new
name|SinkTokenStream
argument_list|(
name|this
operator|.
name|cloneAttributes
argument_list|()
argument_list|,
name|filter
argument_list|)
decl_stmt|;
name|this
operator|.
name|sinks
operator|.
name|add
argument_list|(
operator|new
name|WeakReference
argument_list|(
name|sink
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|sink
return|;
block|}
comment|/**    * Adds a {@link SinkTokenStream} created by another<code>TeeSinkTokenFilter</code>    * to this one. The supplied stream will also receive all consumed tokens.    * This method can be used to pass tokens from two different tees to one sink.    */
DECL|method|addSinkTokenStream
specifier|public
name|void
name|addSinkTokenStream
parameter_list|(
specifier|final
name|SinkTokenStream
name|sink
parameter_list|)
block|{
comment|// check that sink has correct factory
if|if
condition|(
operator|!
name|this
operator|.
name|getAttributeFactory
argument_list|()
operator|.
name|equals
argument_list|(
name|sink
operator|.
name|getAttributeFactory
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The supplied sink is not compatible to this tee"
argument_list|)
throw|;
block|}
comment|// add eventually missing attribute impls to the existing sink
for|for
control|(
name|Iterator
name|it
init|=
name|this
operator|.
name|cloneAttributes
argument_list|()
operator|.
name|getAttributeImplsIterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|sink
operator|.
name|addAttributeImpl
argument_list|(
operator|(
name|AttributeImpl
operator|)
name|it
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|sinks
operator|.
name|add
argument_list|(
operator|new
name|WeakReference
argument_list|(
name|sink
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    *<code>TeeSinkTokenFilter</code> passes all tokens to the added sinks    * when itsself is consumed. To be sure, that all tokens from the input    * stream are passed to the sinks, you can call this methods.    * This instance is exhausted after this, but all sinks are instant available.    */
DECL|method|consumeAllTokens
specifier|public
name|void
name|consumeAllTokens
parameter_list|()
throws|throws
name|IOException
block|{
while|while
condition|(
name|incrementToken
argument_list|()
condition|)
empty_stmt|;
block|}
DECL|method|incrementToken
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|input
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
comment|// capture state lazily - maybe no SinkFilter accepts this state
name|AttributeSource
operator|.
name|State
name|state
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Iterator
name|it
init|=
name|sinks
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|SinkTokenStream
name|sink
init|=
call|(
name|SinkTokenStream
call|)
argument_list|(
operator|(
name|WeakReference
operator|)
name|it
operator|.
name|next
argument_list|()
argument_list|)
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|sink
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|sink
operator|.
name|accept
argument_list|(
name|this
argument_list|)
condition|)
block|{
if|if
condition|(
name|state
operator|==
literal|null
condition|)
block|{
name|state
operator|=
name|this
operator|.
name|captureState
argument_list|()
expr_stmt|;
block|}
name|sink
operator|.
name|addState
argument_list|(
name|state
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * TODO: Missing Docs    */
DECL|interface|SinkFilter
specifier|public
specifier|static
interface|interface
name|SinkFilter
block|{
DECL|method|accept
name|boolean
name|accept
parameter_list|(
name|AttributeSource
name|source
parameter_list|)
function_decl|;
block|}
DECL|class|SinkTokenStream
specifier|public
specifier|static
specifier|final
class|class
name|SinkTokenStream
extends|extends
name|TokenStream
block|{
DECL|field|cachedStates
specifier|private
specifier|final
name|List
name|cachedStates
init|=
operator|new
name|LinkedList
argument_list|()
decl_stmt|;
DECL|field|it
specifier|private
name|Iterator
name|it
init|=
literal|null
decl_stmt|;
DECL|field|filter
specifier|private
name|SinkFilter
name|filter
decl_stmt|;
DECL|method|SinkTokenStream
specifier|private
name|SinkTokenStream
parameter_list|(
name|AttributeSource
name|source
parameter_list|,
name|SinkFilter
name|filter
parameter_list|)
block|{
name|super
argument_list|(
name|source
argument_list|)
expr_stmt|;
name|this
operator|.
name|filter
operator|=
name|filter
expr_stmt|;
block|}
DECL|method|accept
specifier|private
name|boolean
name|accept
parameter_list|(
name|AttributeSource
name|source
parameter_list|)
block|{
return|return
name|filter
operator|.
name|accept
argument_list|(
name|source
argument_list|)
return|;
block|}
DECL|method|addState
specifier|private
name|void
name|addState
parameter_list|(
name|AttributeSource
operator|.
name|State
name|state
parameter_list|)
block|{
if|if
condition|(
name|it
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"The tee must be consumed before sinks are consumed."
argument_list|)
throw|;
block|}
name|cachedStates
operator|.
name|add
argument_list|(
name|state
argument_list|)
expr_stmt|;
block|}
DECL|method|incrementToken
specifier|public
specifier|final
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
comment|// lazy init the iterator
if|if
condition|(
name|it
operator|==
literal|null
condition|)
block|{
name|it
operator|=
name|cachedStates
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|it
operator|.
name|hasNext
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|AttributeSource
operator|.
name|State
name|state
init|=
operator|(
name|State
operator|)
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|restoreState
argument_list|(
name|state
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
DECL|method|reset
specifier|public
specifier|final
name|void
name|reset
parameter_list|()
block|{
name|it
operator|=
name|cachedStates
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
block|}
DECL|field|ACCEPT_ALL_FILTER
specifier|private
specifier|static
specifier|final
name|SinkFilter
name|ACCEPT_ALL_FILTER
init|=
operator|new
name|SinkFilter
argument_list|()
block|{
specifier|public
name|boolean
name|accept
parameter_list|(
name|AttributeSource
name|source
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
block|}
decl_stmt|;
block|}
end_class
end_unit
