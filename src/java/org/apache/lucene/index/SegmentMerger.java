begin_unit
begin_package
DECL|package|org.apache.lucene.index
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
package|;
end_package
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Document
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
operator|.
name|FieldOption
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MergePolicy
operator|.
name|MergeAbortedException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexOutput
import|;
end_import
begin_comment
comment|/**  * The SegmentMerger class combines two or more Segments, represented by an IndexReader ({@link #add},  * into a single Segment.  After adding the appropriate readers, call the merge method to combine the   * segments.  *<P>   * If the compoundFile flag is set, then the segments will be merged into a compound file.  *     *   * @see #merge  * @see #add  */
end_comment
begin_class
DECL|class|SegmentMerger
specifier|final
class|class
name|SegmentMerger
block|{
comment|/** norms header placeholder */
DECL|field|NORMS_HEADER
specifier|static
specifier|final
name|byte
index|[]
name|NORMS_HEADER
init|=
operator|new
name|byte
index|[]
block|{
literal|'N'
block|,
literal|'R'
block|,
literal|'M'
block|,
operator|-
literal|1
block|}
decl_stmt|;
DECL|field|directory
specifier|private
name|Directory
name|directory
decl_stmt|;
DECL|field|segment
specifier|private
name|String
name|segment
decl_stmt|;
DECL|field|termIndexInterval
specifier|private
name|int
name|termIndexInterval
init|=
name|IndexWriter
operator|.
name|DEFAULT_TERM_INDEX_INTERVAL
decl_stmt|;
DECL|field|readers
specifier|private
name|List
name|readers
init|=
operator|new
name|ArrayList
argument_list|()
decl_stmt|;
DECL|field|fieldInfos
specifier|private
name|FieldInfos
name|fieldInfos
decl_stmt|;
DECL|field|mergedDocs
specifier|private
name|int
name|mergedDocs
decl_stmt|;
DECL|field|checkAbort
specifier|private
specifier|final
name|CheckAbort
name|checkAbort
decl_stmt|;
comment|// Whether we should merge doc stores (stored fields and
comment|// vectors files).  When all segments we are merging
comment|// already share the same doc store files, we don't need
comment|// to merge the doc stores.
DECL|field|mergeDocStores
specifier|private
name|boolean
name|mergeDocStores
decl_stmt|;
comment|/** Maximum number of contiguous documents to bulk-copy       when merging stored fields */
DECL|field|MAX_RAW_MERGE_DOCS
specifier|private
specifier|final
specifier|static
name|int
name|MAX_RAW_MERGE_DOCS
init|=
literal|4192
decl_stmt|;
comment|/** This ctor used only by test code.    *     * @param dir The Directory to merge the other segments into    * @param name The name of the new segment    */
DECL|method|SegmentMerger
name|SegmentMerger
parameter_list|(
name|Directory
name|dir
parameter_list|,
name|String
name|name
parameter_list|)
block|{
name|directory
operator|=
name|dir
expr_stmt|;
name|segment
operator|=
name|name
expr_stmt|;
name|checkAbort
operator|=
operator|new
name|CheckAbort
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
block|{
specifier|public
name|void
name|work
parameter_list|(
name|double
name|units
parameter_list|)
throws|throws
name|MergeAbortedException
block|{
comment|// do nothing
block|}
block|}
expr_stmt|;
block|}
DECL|method|SegmentMerger
name|SegmentMerger
parameter_list|(
name|IndexWriter
name|writer
parameter_list|,
name|String
name|name
parameter_list|,
name|MergePolicy
operator|.
name|OneMerge
name|merge
parameter_list|)
block|{
name|directory
operator|=
name|writer
operator|.
name|getDirectory
argument_list|()
expr_stmt|;
name|segment
operator|=
name|name
expr_stmt|;
if|if
condition|(
name|merge
operator|!=
literal|null
condition|)
block|{
name|checkAbort
operator|=
operator|new
name|CheckAbort
argument_list|(
name|merge
argument_list|,
name|directory
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|checkAbort
operator|=
operator|new
name|CheckAbort
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
block|{
specifier|public
name|void
name|work
parameter_list|(
name|double
name|units
parameter_list|)
throws|throws
name|MergeAbortedException
block|{
comment|// do nothing
block|}
block|}
expr_stmt|;
block|}
name|termIndexInterval
operator|=
name|writer
operator|.
name|getTermIndexInterval
argument_list|()
expr_stmt|;
block|}
DECL|method|hasProx
name|boolean
name|hasProx
parameter_list|()
block|{
return|return
name|fieldInfos
operator|.
name|hasProx
argument_list|()
return|;
block|}
comment|/**    * Add an IndexReader to the collection of readers that are to be merged    * @param reader    */
DECL|method|add
specifier|final
name|void
name|add
parameter_list|(
name|IndexReader
name|reader
parameter_list|)
block|{
name|readers
operator|.
name|add
argument_list|(
name|reader
argument_list|)
expr_stmt|;
block|}
comment|/**    *     * @param i The index of the reader to return    * @return The ith reader to be merged    */
DECL|method|segmentReader
specifier|final
name|IndexReader
name|segmentReader
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
operator|(
name|IndexReader
operator|)
name|readers
operator|.
name|get
argument_list|(
name|i
argument_list|)
return|;
block|}
comment|/**    * Merges the readers specified by the {@link #add} method into the directory passed to the constructor    * @return The number of documents that were merged    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|merge
specifier|final
name|int
name|merge
parameter_list|()
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
return|return
name|merge
argument_list|(
literal|true
argument_list|)
return|;
block|}
comment|/**    * Merges the readers specified by the {@link #add} method    * into the directory passed to the constructor.    * @param mergeDocStores if false, we will not merge the    * stored fields nor vectors files    * @return The number of documents that were merged    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|merge
specifier|final
name|int
name|merge
parameter_list|(
name|boolean
name|mergeDocStores
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|this
operator|.
name|mergeDocStores
operator|=
name|mergeDocStores
expr_stmt|;
comment|// NOTE: it's important to add calls to
comment|// checkAbort.work(...) if you make any changes to this
comment|// method that will spend alot of time.  The frequency
comment|// of this check impacts how long
comment|// IndexWriter.close(false) takes to actually stop the
comment|// threads.
name|mergedDocs
operator|=
name|mergeFields
argument_list|()
expr_stmt|;
name|mergeTerms
argument_list|()
expr_stmt|;
name|mergeNorms
argument_list|()
expr_stmt|;
if|if
condition|(
name|mergeDocStores
operator|&&
name|fieldInfos
operator|.
name|hasVectors
argument_list|()
condition|)
name|mergeVectors
argument_list|()
expr_stmt|;
return|return
name|mergedDocs
return|;
block|}
comment|/**    * close all IndexReaders that have been added.    * Should not be called before merge().    * @throws IOException    */
DECL|method|closeReaders
specifier|final
name|void
name|closeReaders
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|Iterator
name|iter
init|=
name|readers
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
operator|(
operator|(
name|IndexReader
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|createCompoundFile
specifier|final
name|List
name|createCompoundFile
parameter_list|(
name|String
name|fileName
parameter_list|)
throws|throws
name|IOException
block|{
name|CompoundFileWriter
name|cfsWriter
init|=
operator|new
name|CompoundFileWriter
argument_list|(
name|directory
argument_list|,
name|fileName
argument_list|,
name|checkAbort
argument_list|)
decl_stmt|;
name|List
name|files
init|=
operator|new
name|ArrayList
argument_list|(
name|IndexFileNames
operator|.
name|COMPOUND_EXTENSIONS
operator|.
name|length
operator|+
literal|1
argument_list|)
decl_stmt|;
comment|// Basic files
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|IndexFileNames
operator|.
name|COMPOUND_EXTENSIONS
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|ext
init|=
name|IndexFileNames
operator|.
name|COMPOUND_EXTENSIONS
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|ext
operator|.
name|equals
argument_list|(
name|IndexFileNames
operator|.
name|PROX_EXTENSION
argument_list|)
operator|&&
operator|!
name|hasProx
argument_list|()
condition|)
continue|continue;
if|if
condition|(
name|mergeDocStores
operator|||
operator|(
operator|!
name|ext
operator|.
name|equals
argument_list|(
name|IndexFileNames
operator|.
name|FIELDS_EXTENSION
argument_list|)
operator|&&
operator|!
name|ext
operator|.
name|equals
argument_list|(
name|IndexFileNames
operator|.
name|FIELDS_INDEX_EXTENSION
argument_list|)
operator|)
condition|)
name|files
operator|.
name|add
argument_list|(
name|segment
operator|+
literal|"."
operator|+
name|ext
argument_list|)
expr_stmt|;
block|}
comment|// Fieldable norm files
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fieldInfos
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|FieldInfo
name|fi
init|=
name|fieldInfos
operator|.
name|fieldInfo
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|fi
operator|.
name|isIndexed
operator|&&
operator|!
name|fi
operator|.
name|omitNorms
condition|)
block|{
name|files
operator|.
name|add
argument_list|(
name|segment
operator|+
literal|"."
operator|+
name|IndexFileNames
operator|.
name|NORMS_EXTENSION
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
comment|// Vector files
if|if
condition|(
name|fieldInfos
operator|.
name|hasVectors
argument_list|()
operator|&&
name|mergeDocStores
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|IndexFileNames
operator|.
name|VECTOR_EXTENSIONS
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|files
operator|.
name|add
argument_list|(
name|segment
operator|+
literal|"."
operator|+
name|IndexFileNames
operator|.
name|VECTOR_EXTENSIONS
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Now merge all added files
name|Iterator
name|it
init|=
name|files
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|it
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|cfsWriter
operator|.
name|addFile
argument_list|(
operator|(
name|String
operator|)
name|it
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Perform the merge
name|cfsWriter
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|files
return|;
block|}
DECL|method|addIndexed
specifier|private
name|void
name|addIndexed
parameter_list|(
name|IndexReader
name|reader
parameter_list|,
name|FieldInfos
name|fInfos
parameter_list|,
name|Collection
name|names
parameter_list|,
name|boolean
name|storeTermVectors
parameter_list|,
name|boolean
name|storePositionWithTermVector
parameter_list|,
name|boolean
name|storeOffsetWithTermVector
parameter_list|,
name|boolean
name|storePayloads
parameter_list|,
name|boolean
name|omitTFAndPositions
parameter_list|)
throws|throws
name|IOException
block|{
name|Iterator
name|i
init|=
name|names
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|i
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|String
name|field
init|=
operator|(
name|String
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|fInfos
operator|.
name|add
argument_list|(
name|field
argument_list|,
literal|true
argument_list|,
name|storeTermVectors
argument_list|,
name|storePositionWithTermVector
argument_list|,
name|storeOffsetWithTermVector
argument_list|,
operator|!
name|reader
operator|.
name|hasNorms
argument_list|(
name|field
argument_list|)
argument_list|,
name|storePayloads
argument_list|,
name|omitTFAndPositions
argument_list|)
expr_stmt|;
block|}
block|}
DECL|field|matchingSegmentReaders
specifier|private
name|SegmentReader
index|[]
name|matchingSegmentReaders
decl_stmt|;
DECL|field|rawDocLengths
specifier|private
name|int
index|[]
name|rawDocLengths
decl_stmt|;
DECL|field|rawDocLengths2
specifier|private
name|int
index|[]
name|rawDocLengths2
decl_stmt|;
DECL|method|setMatchingSegmentReaders
specifier|private
name|void
name|setMatchingSegmentReaders
parameter_list|()
block|{
comment|// If the i'th reader is a SegmentReader and has
comment|// identical fieldName -> number mapping, then this
comment|// array will be non-null at position i:
name|int
name|numReaders
init|=
name|readers
operator|.
name|size
argument_list|()
decl_stmt|;
name|matchingSegmentReaders
operator|=
operator|new
name|SegmentReader
index|[
name|numReaders
index|]
expr_stmt|;
comment|// If this reader is a SegmentReader, and all of its
comment|// field name -> number mappings match the "merged"
comment|// FieldInfos, then we can do a bulk copy of the
comment|// stored fields:
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numReaders
condition|;
name|i
operator|++
control|)
block|{
name|IndexReader
name|reader
init|=
operator|(
name|IndexReader
operator|)
name|readers
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|instanceof
name|SegmentReader
condition|)
block|{
name|SegmentReader
name|segmentReader
init|=
operator|(
name|SegmentReader
operator|)
name|reader
decl_stmt|;
name|boolean
name|same
init|=
literal|true
decl_stmt|;
name|FieldInfos
name|segmentFieldInfos
init|=
name|segmentReader
operator|.
name|fieldInfos
argument_list|()
decl_stmt|;
name|int
name|numFieldInfos
init|=
name|segmentFieldInfos
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|same
operator|&&
name|j
operator|<
name|numFieldInfos
condition|;
name|j
operator|++
control|)
block|{
name|same
operator|=
name|fieldInfos
operator|.
name|fieldName
argument_list|(
name|j
argument_list|)
operator|.
name|equals
argument_list|(
name|segmentFieldInfos
operator|.
name|fieldName
argument_list|(
name|j
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|same
condition|)
block|{
name|matchingSegmentReaders
index|[
name|i
index|]
operator|=
name|segmentReader
expr_stmt|;
block|}
block|}
block|}
comment|// Used for bulk-reading raw bytes for stored fields
name|rawDocLengths
operator|=
operator|new
name|int
index|[
name|MAX_RAW_MERGE_DOCS
index|]
expr_stmt|;
name|rawDocLengths2
operator|=
operator|new
name|int
index|[
name|MAX_RAW_MERGE_DOCS
index|]
expr_stmt|;
block|}
comment|/**    *     * @return The number of documents in all of the readers    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|mergeFields
specifier|private
specifier|final
name|int
name|mergeFields
parameter_list|()
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
if|if
condition|(
operator|!
name|mergeDocStores
condition|)
block|{
comment|// When we are not merging by doc stores, their field
comment|// name -> number mapping are the same.  So, we start
comment|// with the fieldInfos of the last segment in this
comment|// case, to keep that numbering.
specifier|final
name|SegmentReader
name|sr
init|=
operator|(
name|SegmentReader
operator|)
name|readers
operator|.
name|get
argument_list|(
name|readers
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|fieldInfos
operator|=
operator|(
name|FieldInfos
operator|)
name|sr
operator|.
name|core
operator|.
name|fieldInfos
operator|.
name|clone
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|fieldInfos
operator|=
operator|new
name|FieldInfos
argument_list|()
expr_stmt|;
comment|// merge field names
block|}
for|for
control|(
name|Iterator
name|iter
init|=
name|readers
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|IndexReader
name|reader
init|=
operator|(
name|IndexReader
operator|)
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|reader
operator|instanceof
name|SegmentReader
condition|)
block|{
name|SegmentReader
name|segmentReader
init|=
operator|(
name|SegmentReader
operator|)
name|reader
decl_stmt|;
name|FieldInfos
name|readerFieldInfos
init|=
name|segmentReader
operator|.
name|fieldInfos
argument_list|()
decl_stmt|;
name|int
name|numReaderFieldInfos
init|=
name|readerFieldInfos
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|numReaderFieldInfos
condition|;
name|j
operator|++
control|)
block|{
name|FieldInfo
name|fi
init|=
name|readerFieldInfos
operator|.
name|fieldInfo
argument_list|(
name|j
argument_list|)
decl_stmt|;
name|fieldInfos
operator|.
name|add
argument_list|(
name|fi
operator|.
name|name
argument_list|,
name|fi
operator|.
name|isIndexed
argument_list|,
name|fi
operator|.
name|storeTermVector
argument_list|,
name|fi
operator|.
name|storePositionWithTermVector
argument_list|,
name|fi
operator|.
name|storeOffsetWithTermVector
argument_list|,
operator|!
name|reader
operator|.
name|hasNorms
argument_list|(
name|fi
operator|.
name|name
argument_list|)
argument_list|,
name|fi
operator|.
name|storePayloads
argument_list|,
name|fi
operator|.
name|omitTermFreqAndPositions
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR_WITH_POSITION_OFFSET
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR_WITH_POSITION
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR_WITH_OFFSET
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|OMIT_TERM_FREQ_AND_POSITIONS
argument_list|)
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|STORES_PAYLOADS
argument_list|)
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|INDEXED
argument_list|)
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|fieldInfos
operator|.
name|add
argument_list|(
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|UNINDEXED
argument_list|)
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
name|fieldInfos
operator|.
name|write
argument_list|(
name|directory
argument_list|,
name|segment
operator|+
literal|".fnm"
argument_list|)
expr_stmt|;
name|int
name|docCount
init|=
literal|0
decl_stmt|;
name|setMatchingSegmentReaders
argument_list|()
expr_stmt|;
if|if
condition|(
name|mergeDocStores
condition|)
block|{
comment|// merge field values
specifier|final
name|FieldsWriter
name|fieldsWriter
init|=
operator|new
name|FieldsWriter
argument_list|(
name|directory
argument_list|,
name|segment
argument_list|,
name|fieldInfos
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|idx
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Iterator
name|iter
init|=
name|readers
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|IndexReader
name|reader
init|=
operator|(
name|IndexReader
operator|)
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
specifier|final
name|SegmentReader
name|matchingSegmentReader
init|=
name|matchingSegmentReaders
index|[
name|idx
operator|++
index|]
decl_stmt|;
name|FieldsReader
name|matchingFieldsReader
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|matchingSegmentReader
operator|!=
literal|null
condition|)
block|{
specifier|final
name|FieldsReader
name|fieldsReader
init|=
name|matchingSegmentReader
operator|.
name|getFieldsReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|fieldsReader
operator|!=
literal|null
operator|&&
name|fieldsReader
operator|.
name|canReadRawDocs
argument_list|()
condition|)
block|{
name|matchingFieldsReader
operator|=
name|fieldsReader
expr_stmt|;
block|}
block|}
if|if
condition|(
name|reader
operator|.
name|hasDeletions
argument_list|()
condition|)
block|{
name|docCount
operator|+=
name|copyFieldsWithDeletions
argument_list|(
name|fieldsWriter
argument_list|,
name|reader
argument_list|,
name|matchingFieldsReader
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|docCount
operator|+=
name|copyFieldsNoDeletions
argument_list|(
name|fieldsWriter
argument_list|,
name|reader
argument_list|,
name|matchingFieldsReader
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|fieldsWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
specifier|final
name|String
name|fileName
init|=
name|segment
operator|+
literal|"."
operator|+
name|IndexFileNames
operator|.
name|FIELDS_INDEX_EXTENSION
decl_stmt|;
specifier|final
name|long
name|fdxFileLength
init|=
name|directory
operator|.
name|fileLength
argument_list|(
name|fileName
argument_list|)
decl_stmt|;
if|if
condition|(
literal|4
operator|+
operator|(
operator|(
name|long
operator|)
name|docCount
operator|)
operator|*
literal|8
operator|!=
name|fdxFileLength
condition|)
comment|// This is most likely a bug in Sun JRE 1.6.0_04/_05;
comment|// we detect that the bug has struck, here, and
comment|// throw an exception to prevent the corruption from
comment|// entering the index.  See LUCENE-1282 for
comment|// details.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"mergeFields produced an invalid result: docCount is "
operator|+
name|docCount
operator|+
literal|" but fdx file size is "
operator|+
name|fdxFileLength
operator|+
literal|" file="
operator|+
name|fileName
operator|+
literal|" file exists?="
operator|+
name|directory
operator|.
name|fileExists
argument_list|(
name|fileName
argument_list|)
operator|+
literal|"; now aborting this merge to prevent index corruption"
argument_list|)
throw|;
block|}
else|else
comment|// If we are skipping the doc stores, that means there
comment|// are no deletions in any of these segments, so we
comment|// just sum numDocs() of each segment to get total docCount
for|for
control|(
name|Iterator
name|iter
init|=
name|readers
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|docCount
operator|+=
operator|(
operator|(
name|IndexReader
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|numDocs
argument_list|()
expr_stmt|;
block|}
return|return
name|docCount
return|;
block|}
DECL|method|copyFieldsWithDeletions
specifier|private
name|int
name|copyFieldsWithDeletions
parameter_list|(
specifier|final
name|FieldsWriter
name|fieldsWriter
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|,
specifier|final
name|FieldsReader
name|matchingFieldsReader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
throws|,
name|CorruptIndexException
block|{
name|int
name|docCount
init|=
literal|0
decl_stmt|;
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|matchingFieldsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|maxDoc
condition|;
control|)
block|{
if|if
condition|(
name|reader
operator|.
name|isDeleted
argument_list|(
name|j
argument_list|)
condition|)
block|{
comment|// skip deleted docs
operator|++
name|j
expr_stmt|;
continue|continue;
block|}
comment|// We can optimize this case (doing a bulk byte copy) since the field
comment|// numbers are identical
name|int
name|start
init|=
name|j
decl_stmt|,
name|numDocs
init|=
literal|0
decl_stmt|;
do|do
block|{
name|j
operator|++
expr_stmt|;
name|numDocs
operator|++
expr_stmt|;
if|if
condition|(
name|j
operator|>=
name|maxDoc
condition|)
break|break;
if|if
condition|(
name|reader
operator|.
name|isDeleted
argument_list|(
name|j
argument_list|)
condition|)
block|{
name|j
operator|++
expr_stmt|;
break|break;
block|}
block|}
do|while
condition|(
name|numDocs
operator|<
name|MAX_RAW_MERGE_DOCS
condition|)
do|;
name|IndexInput
name|stream
init|=
name|matchingFieldsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|start
argument_list|,
name|numDocs
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addRawDocuments
argument_list|(
name|stream
argument_list|,
name|rawDocLengths
argument_list|,
name|numDocs
argument_list|)
expr_stmt|;
name|docCount
operator|+=
name|numDocs
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|numDocs
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|maxDoc
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|reader
operator|.
name|isDeleted
argument_list|(
name|j
argument_list|)
condition|)
block|{
comment|// skip deleted docs
continue|continue;
block|}
comment|// NOTE: it's very important to first assign to doc then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|Document
name|doc
init|=
name|reader
operator|.
name|document
argument_list|(
name|j
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|docCount
operator|++
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|docCount
return|;
block|}
DECL|method|copyFieldsNoDeletions
specifier|private
name|int
name|copyFieldsNoDeletions
parameter_list|(
specifier|final
name|FieldsWriter
name|fieldsWriter
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|,
specifier|final
name|FieldsReader
name|matchingFieldsReader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
throws|,
name|CorruptIndexException
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
name|int
name|docCount
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|matchingFieldsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
while|while
condition|(
name|docCount
operator|<
name|maxDoc
condition|)
block|{
name|int
name|len
init|=
name|Math
operator|.
name|min
argument_list|(
name|MAX_RAW_MERGE_DOCS
argument_list|,
name|maxDoc
operator|-
name|docCount
argument_list|)
decl_stmt|;
name|IndexInput
name|stream
init|=
name|matchingFieldsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|docCount
argument_list|,
name|len
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addRawDocuments
argument_list|(
name|stream
argument_list|,
name|rawDocLengths
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|docCount
operator|+=
name|len
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|len
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
init|;
name|docCount
operator|<
name|maxDoc
condition|;
name|docCount
operator|++
control|)
block|{
comment|// NOTE: it's very important to first assign to doc then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|Document
name|doc
init|=
name|reader
operator|.
name|document
argument_list|(
name|docCount
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|docCount
return|;
block|}
comment|/**    * Merge the TermVectors from each of the segments into the new one.    * @throws IOException    */
DECL|method|mergeVectors
specifier|private
specifier|final
name|void
name|mergeVectors
parameter_list|()
throws|throws
name|IOException
block|{
name|TermVectorsWriter
name|termVectorsWriter
init|=
operator|new
name|TermVectorsWriter
argument_list|(
name|directory
argument_list|,
name|segment
argument_list|,
name|fieldInfos
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|idx
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Iterator
name|iter
init|=
name|readers
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|SegmentReader
name|matchingSegmentReader
init|=
name|matchingSegmentReaders
index|[
name|idx
operator|++
index|]
decl_stmt|;
name|TermVectorsReader
name|matchingVectorsReader
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|matchingSegmentReader
operator|!=
literal|null
condition|)
block|{
name|TermVectorsReader
name|vectorsReader
init|=
name|matchingSegmentReader
operator|.
name|getTermVectorsReaderOrig
argument_list|()
decl_stmt|;
comment|// If the TV* files are an older format then they cannot read raw docs:
if|if
condition|(
name|vectorsReader
operator|!=
literal|null
operator|&&
name|vectorsReader
operator|.
name|canReadRawDocs
argument_list|()
condition|)
block|{
name|matchingVectorsReader
operator|=
name|vectorsReader
expr_stmt|;
block|}
block|}
specifier|final
name|IndexReader
name|reader
init|=
operator|(
name|IndexReader
operator|)
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|reader
operator|.
name|hasDeletions
argument_list|()
condition|)
block|{
name|copyVectorsWithDeletions
argument_list|(
name|termVectorsWriter
argument_list|,
name|matchingVectorsReader
argument_list|,
name|reader
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|copyVectorsNoDeletions
argument_list|(
name|termVectorsWriter
argument_list|,
name|matchingVectorsReader
argument_list|,
name|reader
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|termVectorsWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
specifier|final
name|String
name|fileName
init|=
name|segment
operator|+
literal|"."
operator|+
name|IndexFileNames
operator|.
name|VECTORS_INDEX_EXTENSION
decl_stmt|;
specifier|final
name|long
name|tvxSize
init|=
name|directory
operator|.
name|fileLength
argument_list|(
name|fileName
argument_list|)
decl_stmt|;
if|if
condition|(
literal|4
operator|+
operator|(
operator|(
name|long
operator|)
name|mergedDocs
operator|)
operator|*
literal|16
operator|!=
name|tvxSize
condition|)
comment|// This is most likely a bug in Sun JRE 1.6.0_04/_05;
comment|// we detect that the bug has struck, here, and
comment|// throw an exception to prevent the corruption from
comment|// entering the index.  See LUCENE-1282 for
comment|// details.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"mergeVectors produced an invalid result: mergedDocs is "
operator|+
name|mergedDocs
operator|+
literal|" but tvx size is "
operator|+
name|tvxSize
operator|+
literal|" file="
operator|+
name|fileName
operator|+
literal|" file exists?="
operator|+
name|directory
operator|.
name|fileExists
argument_list|(
name|fileName
argument_list|)
operator|+
literal|"; now aborting this merge to prevent index corruption"
argument_list|)
throw|;
block|}
DECL|method|copyVectorsWithDeletions
specifier|private
name|void
name|copyVectorsWithDeletions
parameter_list|(
specifier|final
name|TermVectorsWriter
name|termVectorsWriter
parameter_list|,
specifier|final
name|TermVectorsReader
name|matchingVectorsReader
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|matchingVectorsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
for|for
control|(
name|int
name|docNum
init|=
literal|0
init|;
name|docNum
operator|<
name|maxDoc
condition|;
control|)
block|{
if|if
condition|(
name|reader
operator|.
name|isDeleted
argument_list|(
name|docNum
argument_list|)
condition|)
block|{
comment|// skip deleted docs
operator|++
name|docNum
expr_stmt|;
continue|continue;
block|}
comment|// We can optimize this case (doing a bulk byte copy) since the field
comment|// numbers are identical
name|int
name|start
init|=
name|docNum
decl_stmt|,
name|numDocs
init|=
literal|0
decl_stmt|;
do|do
block|{
name|docNum
operator|++
expr_stmt|;
name|numDocs
operator|++
expr_stmt|;
if|if
condition|(
name|docNum
operator|>=
name|maxDoc
condition|)
break|break;
if|if
condition|(
name|reader
operator|.
name|isDeleted
argument_list|(
name|docNum
argument_list|)
condition|)
block|{
name|docNum
operator|++
expr_stmt|;
break|break;
block|}
block|}
do|while
condition|(
name|numDocs
operator|<
name|MAX_RAW_MERGE_DOCS
condition|)
do|;
name|matchingVectorsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|start
argument_list|,
name|numDocs
argument_list|)
expr_stmt|;
name|termVectorsWriter
operator|.
name|addRawDocuments
argument_list|(
name|matchingVectorsReader
argument_list|,
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|numDocs
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|numDocs
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|docNum
init|=
literal|0
init|;
name|docNum
operator|<
name|maxDoc
condition|;
name|docNum
operator|++
control|)
block|{
if|if
condition|(
name|reader
operator|.
name|isDeleted
argument_list|(
name|docNum
argument_list|)
condition|)
block|{
comment|// skip deleted docs
continue|continue;
block|}
comment|// NOTE: it's very important to first assign to vectors then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|TermFreqVector
index|[]
name|vectors
init|=
name|reader
operator|.
name|getTermFreqVectors
argument_list|(
name|docNum
argument_list|)
decl_stmt|;
name|termVectorsWriter
operator|.
name|addAllDocVectors
argument_list|(
name|vectors
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|copyVectorsNoDeletions
specifier|private
name|void
name|copyVectorsNoDeletions
parameter_list|(
specifier|final
name|TermVectorsWriter
name|termVectorsWriter
parameter_list|,
specifier|final
name|TermVectorsReader
name|matchingVectorsReader
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|matchingVectorsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
name|int
name|docCount
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|docCount
operator|<
name|maxDoc
condition|)
block|{
name|int
name|len
init|=
name|Math
operator|.
name|min
argument_list|(
name|MAX_RAW_MERGE_DOCS
argument_list|,
name|maxDoc
operator|-
name|docCount
argument_list|)
decl_stmt|;
name|matchingVectorsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|docCount
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|termVectorsWriter
operator|.
name|addRawDocuments
argument_list|(
name|matchingVectorsReader
argument_list|,
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|docCount
operator|+=
name|len
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|len
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|docNum
init|=
literal|0
init|;
name|docNum
operator|<
name|maxDoc
condition|;
name|docNum
operator|++
control|)
block|{
comment|// NOTE: it's very important to first assign to vectors then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|TermFreqVector
index|[]
name|vectors
init|=
name|reader
operator|.
name|getTermFreqVectors
argument_list|(
name|docNum
argument_list|)
decl_stmt|;
name|termVectorsWriter
operator|.
name|addAllDocVectors
argument_list|(
name|vectors
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|field|queue
specifier|private
name|SegmentMergeQueue
name|queue
init|=
literal|null
decl_stmt|;
DECL|method|mergeTerms
specifier|private
specifier|final
name|void
name|mergeTerms
parameter_list|()
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|SegmentWriteState
name|state
init|=
operator|new
name|SegmentWriteState
argument_list|(
literal|null
argument_list|,
name|directory
argument_list|,
name|segment
argument_list|,
literal|null
argument_list|,
name|mergedDocs
argument_list|,
literal|0
argument_list|,
name|termIndexInterval
argument_list|)
decl_stmt|;
specifier|final
name|FormatPostingsFieldsConsumer
name|consumer
init|=
operator|new
name|FormatPostingsFieldsWriter
argument_list|(
name|state
argument_list|,
name|fieldInfos
argument_list|)
decl_stmt|;
try|try
block|{
name|queue
operator|=
operator|new
name|SegmentMergeQueue
argument_list|(
name|readers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|mergeTermInfos
argument_list|(
name|consumer
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|consumer
operator|.
name|finish
argument_list|()
expr_stmt|;
if|if
condition|(
name|queue
operator|!=
literal|null
condition|)
name|queue
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
DECL|field|omitTermFreqAndPositions
name|boolean
name|omitTermFreqAndPositions
decl_stmt|;
DECL|method|mergeTermInfos
specifier|private
specifier|final
name|void
name|mergeTermInfos
parameter_list|(
specifier|final
name|FormatPostingsFieldsConsumer
name|consumer
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|int
name|base
init|=
literal|0
decl_stmt|;
specifier|final
name|int
name|readerCount
init|=
name|readers
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|readerCount
condition|;
name|i
operator|++
control|)
block|{
name|IndexReader
name|reader
init|=
operator|(
name|IndexReader
operator|)
name|readers
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|TermEnum
name|termEnum
init|=
name|reader
operator|.
name|terms
argument_list|()
decl_stmt|;
name|SegmentMergeInfo
name|smi
init|=
operator|new
name|SegmentMergeInfo
argument_list|(
name|base
argument_list|,
name|termEnum
argument_list|,
name|reader
argument_list|)
decl_stmt|;
name|int
index|[]
name|docMap
init|=
name|smi
operator|.
name|getDocMap
argument_list|()
decl_stmt|;
if|if
condition|(
name|docMap
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|docMaps
operator|==
literal|null
condition|)
block|{
name|docMaps
operator|=
operator|new
name|int
index|[
name|readerCount
index|]
index|[]
expr_stmt|;
name|delCounts
operator|=
operator|new
name|int
index|[
name|readerCount
index|]
expr_stmt|;
block|}
name|docMaps
index|[
name|i
index|]
operator|=
name|docMap
expr_stmt|;
name|delCounts
index|[
name|i
index|]
operator|=
name|smi
operator|.
name|reader
operator|.
name|maxDoc
argument_list|()
operator|-
name|smi
operator|.
name|reader
operator|.
name|numDocs
argument_list|()
expr_stmt|;
block|}
name|base
operator|+=
name|reader
operator|.
name|numDocs
argument_list|()
expr_stmt|;
assert|assert
name|reader
operator|.
name|numDocs
argument_list|()
operator|==
name|reader
operator|.
name|maxDoc
argument_list|()
operator|-
name|smi
operator|.
name|delCount
assert|;
if|if
condition|(
name|smi
operator|.
name|next
argument_list|()
condition|)
name|queue
operator|.
name|add
argument_list|(
name|smi
argument_list|)
expr_stmt|;
comment|// initialize queue
else|else
name|smi
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|SegmentMergeInfo
index|[]
name|match
init|=
operator|new
name|SegmentMergeInfo
index|[
name|readers
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|String
name|currentField
init|=
literal|null
decl_stmt|;
name|FormatPostingsTermsConsumer
name|termsConsumer
init|=
literal|null
decl_stmt|;
while|while
condition|(
name|queue
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|matchSize
init|=
literal|0
decl_stmt|;
comment|// pop matching terms
name|match
index|[
name|matchSize
operator|++
index|]
operator|=
operator|(
name|SegmentMergeInfo
operator|)
name|queue
operator|.
name|pop
argument_list|()
expr_stmt|;
name|Term
name|term
init|=
name|match
index|[
literal|0
index|]
operator|.
name|term
decl_stmt|;
name|SegmentMergeInfo
name|top
init|=
operator|(
name|SegmentMergeInfo
operator|)
name|queue
operator|.
name|top
argument_list|()
decl_stmt|;
while|while
condition|(
name|top
operator|!=
literal|null
operator|&&
name|term
operator|.
name|compareTo
argument_list|(
name|top
operator|.
name|term
argument_list|)
operator|==
literal|0
condition|)
block|{
name|match
index|[
name|matchSize
operator|++
index|]
operator|=
operator|(
name|SegmentMergeInfo
operator|)
name|queue
operator|.
name|pop
argument_list|()
expr_stmt|;
name|top
operator|=
operator|(
name|SegmentMergeInfo
operator|)
name|queue
operator|.
name|top
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|currentField
operator|!=
name|term
operator|.
name|field
condition|)
block|{
name|currentField
operator|=
name|term
operator|.
name|field
expr_stmt|;
if|if
condition|(
name|termsConsumer
operator|!=
literal|null
condition|)
name|termsConsumer
operator|.
name|finish
argument_list|()
expr_stmt|;
specifier|final
name|FieldInfo
name|fieldInfo
init|=
name|fieldInfos
operator|.
name|fieldInfo
argument_list|(
name|currentField
argument_list|)
decl_stmt|;
name|termsConsumer
operator|=
name|consumer
operator|.
name|addField
argument_list|(
name|fieldInfo
argument_list|)
expr_stmt|;
name|omitTermFreqAndPositions
operator|=
name|fieldInfo
operator|.
name|omitTermFreqAndPositions
expr_stmt|;
block|}
name|int
name|df
init|=
name|appendPostings
argument_list|(
name|termsConsumer
argument_list|,
name|match
argument_list|,
name|matchSize
argument_list|)
decl_stmt|;
comment|// add new TermInfo
name|checkAbort
operator|.
name|work
argument_list|(
name|df
operator|/
literal|3.0
argument_list|)
expr_stmt|;
while|while
condition|(
name|matchSize
operator|>
literal|0
condition|)
block|{
name|SegmentMergeInfo
name|smi
init|=
name|match
index|[
operator|--
name|matchSize
index|]
decl_stmt|;
if|if
condition|(
name|smi
operator|.
name|next
argument_list|()
condition|)
name|queue
operator|.
name|add
argument_list|(
name|smi
argument_list|)
expr_stmt|;
comment|// restore queue
else|else
name|smi
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// done with a segment
block|}
block|}
block|}
DECL|field|payloadBuffer
specifier|private
name|byte
index|[]
name|payloadBuffer
decl_stmt|;
DECL|field|docMaps
specifier|private
name|int
index|[]
index|[]
name|docMaps
decl_stmt|;
DECL|method|getDocMaps
name|int
index|[]
index|[]
name|getDocMaps
parameter_list|()
block|{
return|return
name|docMaps
return|;
block|}
DECL|field|delCounts
specifier|private
name|int
index|[]
name|delCounts
decl_stmt|;
DECL|method|getDelCounts
name|int
index|[]
name|getDelCounts
parameter_list|()
block|{
return|return
name|delCounts
return|;
block|}
comment|/** Process postings from multiple segments all positioned on the    *  same term. Writes out merged entries into freqOutput and    *  the proxOutput streams.    *    * @param smis array of segments    * @param n number of cells in the array actually occupied    * @return number of documents across all segments where this term was found    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|appendPostings
specifier|private
specifier|final
name|int
name|appendPostings
parameter_list|(
specifier|final
name|FormatPostingsTermsConsumer
name|termsConsumer
parameter_list|,
name|SegmentMergeInfo
index|[]
name|smis
parameter_list|,
name|int
name|n
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
specifier|final
name|FormatPostingsDocsConsumer
name|docConsumer
init|=
name|termsConsumer
operator|.
name|addTerm
argument_list|(
name|smis
index|[
literal|0
index|]
operator|.
name|term
operator|.
name|text
argument_list|)
decl_stmt|;
name|int
name|df
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|n
condition|;
name|i
operator|++
control|)
block|{
name|SegmentMergeInfo
name|smi
init|=
name|smis
index|[
name|i
index|]
decl_stmt|;
name|TermPositions
name|postings
init|=
name|smi
operator|.
name|getPositions
argument_list|()
decl_stmt|;
assert|assert
name|postings
operator|!=
literal|null
assert|;
name|int
name|base
init|=
name|smi
operator|.
name|base
decl_stmt|;
name|int
index|[]
name|docMap
init|=
name|smi
operator|.
name|getDocMap
argument_list|()
decl_stmt|;
name|postings
operator|.
name|seek
argument_list|(
name|smi
operator|.
name|termEnum
argument_list|)
expr_stmt|;
while|while
condition|(
name|postings
operator|.
name|next
argument_list|()
condition|)
block|{
name|df
operator|++
expr_stmt|;
name|int
name|doc
init|=
name|postings
operator|.
name|doc
argument_list|()
decl_stmt|;
if|if
condition|(
name|docMap
operator|!=
literal|null
condition|)
name|doc
operator|=
name|docMap
index|[
name|doc
index|]
expr_stmt|;
comment|// map around deletions
name|doc
operator|+=
name|base
expr_stmt|;
comment|// convert to merged space
specifier|final
name|int
name|freq
init|=
name|postings
operator|.
name|freq
argument_list|()
decl_stmt|;
specifier|final
name|FormatPostingsPositionsConsumer
name|posConsumer
init|=
name|docConsumer
operator|.
name|addDoc
argument_list|(
name|doc
argument_list|,
name|freq
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|omitTermFreqAndPositions
condition|)
block|{
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|freq
condition|;
name|j
operator|++
control|)
block|{
specifier|final
name|int
name|position
init|=
name|postings
operator|.
name|nextPosition
argument_list|()
decl_stmt|;
specifier|final
name|int
name|payloadLength
init|=
name|postings
operator|.
name|getPayloadLength
argument_list|()
decl_stmt|;
if|if
condition|(
name|payloadLength
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|payloadBuffer
operator|==
literal|null
operator|||
name|payloadBuffer
operator|.
name|length
operator|<
name|payloadLength
condition|)
name|payloadBuffer
operator|=
operator|new
name|byte
index|[
name|payloadLength
index|]
expr_stmt|;
name|postings
operator|.
name|getPayload
argument_list|(
name|payloadBuffer
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|posConsumer
operator|.
name|addPosition
argument_list|(
name|position
argument_list|,
name|payloadBuffer
argument_list|,
literal|0
argument_list|,
name|payloadLength
argument_list|)
expr_stmt|;
block|}
name|posConsumer
operator|.
name|finish
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|docConsumer
operator|.
name|finish
argument_list|()
expr_stmt|;
return|return
name|df
return|;
block|}
DECL|method|mergeNorms
specifier|private
name|void
name|mergeNorms
parameter_list|()
throws|throws
name|IOException
block|{
name|byte
index|[]
name|normBuffer
init|=
literal|null
decl_stmt|;
name|IndexOutput
name|output
init|=
literal|null
decl_stmt|;
try|try
block|{
name|int
name|numFieldInfos
init|=
name|fieldInfos
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numFieldInfos
condition|;
name|i
operator|++
control|)
block|{
name|FieldInfo
name|fi
init|=
name|fieldInfos
operator|.
name|fieldInfo
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|fi
operator|.
name|isIndexed
operator|&&
operator|!
name|fi
operator|.
name|omitNorms
condition|)
block|{
if|if
condition|(
name|output
operator|==
literal|null
condition|)
block|{
name|output
operator|=
name|directory
operator|.
name|createOutput
argument_list|(
name|segment
operator|+
literal|"."
operator|+
name|IndexFileNames
operator|.
name|NORMS_EXTENSION
argument_list|)
expr_stmt|;
name|output
operator|.
name|writeBytes
argument_list|(
name|NORMS_HEADER
argument_list|,
name|NORMS_HEADER
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Iterator
name|iter
init|=
name|readers
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|IndexReader
name|reader
init|=
operator|(
name|IndexReader
operator|)
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|normBuffer
operator|==
literal|null
operator|||
name|normBuffer
operator|.
name|length
operator|<
name|maxDoc
condition|)
block|{
comment|// the buffer is too small for the current segment
name|normBuffer
operator|=
operator|new
name|byte
index|[
name|maxDoc
index|]
expr_stmt|;
block|}
name|reader
operator|.
name|norms
argument_list|(
name|fi
operator|.
name|name
argument_list|,
name|normBuffer
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|reader
operator|.
name|hasDeletions
argument_list|()
condition|)
block|{
comment|//optimized case for segments without deleted docs
name|output
operator|.
name|writeBytes
argument_list|(
name|normBuffer
argument_list|,
name|maxDoc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// this segment has deleted docs, so we have to
comment|// check for every doc if it is deleted or not
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|maxDoc
condition|;
name|k
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|reader
operator|.
name|isDeleted
argument_list|(
name|k
argument_list|)
condition|)
block|{
name|output
operator|.
name|writeByte
argument_list|(
name|normBuffer
index|[
name|k
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|checkAbort
operator|.
name|work
argument_list|(
name|maxDoc
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|output
operator|!=
literal|null
condition|)
block|{
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|class|CheckAbort
specifier|static
class|class
name|CheckAbort
block|{
DECL|field|workCount
specifier|private
name|double
name|workCount
decl_stmt|;
DECL|field|merge
specifier|private
name|MergePolicy
operator|.
name|OneMerge
name|merge
decl_stmt|;
DECL|field|dir
specifier|private
name|Directory
name|dir
decl_stmt|;
DECL|method|CheckAbort
specifier|public
name|CheckAbort
parameter_list|(
name|MergePolicy
operator|.
name|OneMerge
name|merge
parameter_list|,
name|Directory
name|dir
parameter_list|)
block|{
name|this
operator|.
name|merge
operator|=
name|merge
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
block|}
comment|/**      * Records the fact that roughly units amount of work      * have been done since this method was last called.      * When adding time-consuming code into SegmentMerger,      * you should test different values for units to ensure      * that the time in between calls to merge.checkAborted      * is up to ~ 1 second.      */
DECL|method|work
specifier|public
name|void
name|work
parameter_list|(
name|double
name|units
parameter_list|)
throws|throws
name|MergePolicy
operator|.
name|MergeAbortedException
block|{
name|workCount
operator|+=
name|units
expr_stmt|;
if|if
condition|(
name|workCount
operator|>=
literal|10000.0
condition|)
block|{
name|merge
operator|.
name|checkAborted
argument_list|(
name|dir
argument_list|)
expr_stmt|;
name|workCount
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
block|}
end_class
end_unit
