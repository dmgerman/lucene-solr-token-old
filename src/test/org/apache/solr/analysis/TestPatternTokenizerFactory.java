begin_unit
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.solr.analysis
package|package
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|analysis
package|;
end_package
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|CharReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|CharStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|MappingCharFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|NormalizeCharMap
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Token
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_class
DECL|class|TestPatternTokenizerFactory
specifier|public
class|class
name|TestPatternTokenizerFactory
extends|extends
name|BaseTokenTestCase
block|{
DECL|method|testSplitting
specifier|public
name|void
name|testSplitting
parameter_list|()
throws|throws
name|Exception
block|{
name|String
name|qpattern
init|=
literal|"\\'([^\\']+)\\'"
decl_stmt|;
comment|// get stuff between "'"
name|String
index|[]
index|[]
name|tests
init|=
block|{
comment|// group  pattern        input                    output
block|{
literal|"-1"
block|,
literal|"--"
block|,
literal|"aaa--bbb--ccc"
block|,
literal|"aaa bbb ccc"
block|}
block|,
block|{
literal|"-1"
block|,
literal|":"
block|,
literal|"aaa:bbb:ccc"
block|,
literal|"aaa bbb ccc"
block|}
block|,
block|{
literal|"-1"
block|,
literal|"\\p{Space}"
block|,
literal|"aaa   bbb \t\tccc  "
block|,
literal|"aaa bbb ccc"
block|}
block|,
block|{
literal|"-1"
block|,
literal|":"
block|,
literal|"boo:and:foo"
block|,
literal|"boo and foo"
block|}
block|,
block|{
literal|"-1"
block|,
literal|"o"
block|,
literal|"boo:and:foo"
block|,
literal|"b :and:f"
block|}
block|,
block|{
literal|"0"
block|,
literal|":"
block|,
literal|"boo:and:foo"
block|,
literal|": :"
block|}
block|,
block|{
literal|"0"
block|,
name|qpattern
block|,
literal|"aaa 'bbb' 'ccc'"
block|,
literal|"'bbb' 'ccc'"
block|}
block|,
block|{
literal|"1"
block|,
name|qpattern
block|,
literal|"aaa 'bbb' 'ccc'"
block|,
literal|"bbb ccc"
block|}
block|}
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|String
index|[]
name|test
range|:
name|tests
control|)
block|{
name|args
operator|.
name|put
argument_list|(
name|PatternTokenizerFactory
operator|.
name|GROUP
argument_list|,
name|test
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|PatternTokenizerFactory
operator|.
name|PATTERN
argument_list|,
name|test
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|PatternTokenizerFactory
name|tokenizer
init|=
operator|new
name|PatternTokenizerFactory
argument_list|()
decl_stmt|;
name|tokenizer
operator|.
name|init
argument_list|(
name|args
argument_list|)
expr_stmt|;
name|TokenStream
name|stream
init|=
name|tokenizer
operator|.
name|create
argument_list|(
operator|new
name|StringReader
argument_list|(
name|test
index|[
literal|2
index|]
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|out
init|=
name|TestHyphenatedWordsFilter
operator|.
name|tsToString
argument_list|(
name|stream
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|test
index|[
literal|2
index|]
operator|+
literal|" ==> "
operator|+
name|out
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"pattern: "
operator|+
name|test
index|[
literal|1
index|]
operator|+
literal|" with input: "
operator|+
name|test
index|[
literal|2
index|]
argument_list|,
name|test
index|[
literal|3
index|]
argument_list|,
name|out
argument_list|)
expr_stmt|;
comment|// Make sure it is the same as if we called 'split'
comment|// test disabled, as we remove empty tokens
comment|/*if( "-1".equals( test[0] ) ) {         String[] split = test[2].split( test[1] );         stream = tokenizer.create( new StringReader( test[2] ) );         int i=0;         for( Token t = stream.next(); null != t; t = stream.next() )          {           assertEquals( "split: "+test[1] + " "+i, split[i++], new String(t.termBuffer(), 0, t.termLength()) );         }       }*/
block|}
block|}
DECL|method|testOffsetCorrection
specifier|public
name|void
name|testOffsetCorrection
parameter_list|()
throws|throws
name|Exception
block|{
specifier|final
name|String
name|INPUT
init|=
literal|"G&uuml;nther G&uuml;nther is here"
decl_stmt|;
comment|// create MappingCharFilter
name|MappingCharFilterFactory
name|cfFactory
init|=
operator|new
name|MappingCharFilterFactory
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|mappingRules
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|mappingRules
operator|.
name|add
argument_list|(
literal|"\"&uuml;\" => \"Ã¼\""
argument_list|)
expr_stmt|;
name|NormalizeCharMap
name|normMap
init|=
operator|new
name|NormalizeCharMap
argument_list|()
decl_stmt|;
name|cfFactory
operator|.
name|parseRules
argument_list|(
name|mappingRules
argument_list|,
name|normMap
argument_list|)
expr_stmt|;
name|CharStream
name|charStream
init|=
operator|new
name|MappingCharFilter
argument_list|(
name|normMap
argument_list|,
name|CharReader
operator|.
name|get
argument_list|(
operator|new
name|StringReader
argument_list|(
name|INPUT
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
comment|// create PatternTokenizer
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
name|PatternTokenizerFactory
operator|.
name|PATTERN
argument_list|,
literal|"[,;/\\s]+"
argument_list|)
expr_stmt|;
name|PatternTokenizerFactory
name|tokFactory
init|=
operator|new
name|PatternTokenizerFactory
argument_list|()
decl_stmt|;
name|tokFactory
operator|.
name|init
argument_list|(
name|args
argument_list|)
expr_stmt|;
name|TokenStream
name|stream
init|=
name|tokFactory
operator|.
name|create
argument_list|(
name|charStream
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Token
argument_list|>
name|result
init|=
name|getTokens
argument_list|(
name|stream
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Token
argument_list|>
name|expect
init|=
name|tokens
argument_list|(
literal|"GÃ¼nther,1,0,12 GÃ¼nther,1,13,25 is,1,26,28 here,1,29,33"
argument_list|)
decl_stmt|;
name|assertTokEqualOff
argument_list|(
name|expect
argument_list|,
name|result
argument_list|)
expr_stmt|;
name|charStream
operator|.
name|reset
argument_list|()
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|PatternTokenizerFactory
operator|.
name|PATTERN
argument_list|,
literal|"GÃ¼nther"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|PatternTokenizerFactory
operator|.
name|GROUP
argument_list|,
literal|"0"
argument_list|)
expr_stmt|;
name|tokFactory
operator|=
operator|new
name|PatternTokenizerFactory
argument_list|()
expr_stmt|;
name|tokFactory
operator|.
name|init
argument_list|(
name|args
argument_list|)
expr_stmt|;
name|stream
operator|=
name|tokFactory
operator|.
name|create
argument_list|(
name|charStream
argument_list|)
expr_stmt|;
name|result
operator|=
name|getTokens
argument_list|(
name|stream
argument_list|)
expr_stmt|;
name|expect
operator|=
name|tokens
argument_list|(
literal|"GÃ¼nther,1,0,12 GÃ¼nther,1,13,25"
argument_list|)
expr_stmt|;
name|assertTokEqualOff
argument_list|(
name|expect
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
block|}
end_class
end_unit
