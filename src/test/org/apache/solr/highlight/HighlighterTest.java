begin_unit
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.solr.highlight
package|package
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|highlight
package|;
end_package
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Token
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|WhitespaceAnalyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|core
operator|.
name|SolrCore
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|util
operator|.
name|*
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|params
operator|.
name|HighlightParams
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import
begin_comment
comment|/**  * Tests some basic functionality of Solr while demonstrating good  * Best Practices for using AbstractSolrTestCase  */
end_comment
begin_class
DECL|class|HighlighterTest
specifier|public
class|class
name|HighlighterTest
extends|extends
name|AbstractSolrTestCase
block|{
DECL|field|LONG_TEXT
specifier|private
specifier|static
name|String
name|LONG_TEXT
init|=
literal|"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is "
operator|+
literal|"is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is "
operator|+
literal|"is is is is is is is is is is is is is "
operator|+
literal|"is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated "
operator|+
literal|"at all--we want two disjoint long fragments."
decl_stmt|;
DECL|method|getSchemaFile
annotation|@
name|Override
specifier|public
name|String
name|getSchemaFile
parameter_list|()
block|{
return|return
literal|"schema.xml"
return|;
block|}
DECL|method|getSolrConfigFile
annotation|@
name|Override
specifier|public
name|String
name|getSolrConfigFile
parameter_list|()
block|{
return|return
literal|"solrconfig.xml"
return|;
block|}
annotation|@
name|Override
DECL|method|setUp
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
comment|// if you override setUp or tearDown, you better call
comment|// the super classes version
name|super
operator|.
name|setUp
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|tearDown
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
comment|// if you override setUp or tearDown, you better call
comment|// the super classes version
name|super
operator|.
name|tearDown
argument_list|()
expr_stmt|;
block|}
DECL|method|testConfig
specifier|public
name|void
name|testConfig
parameter_list|()
block|{
name|SolrHighlighter
name|highlighter
init|=
name|h
operator|.
name|getCore
argument_list|()
operator|.
name|getHighlighter
argument_list|()
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"highlighter"
argument_list|)
expr_stmt|;
comment|// Make sure we loaded the one formatter
name|SolrFormatter
name|fmt1
init|=
name|highlighter
operator|.
name|formatters
operator|.
name|get
argument_list|(
literal|null
argument_list|)
decl_stmt|;
name|SolrFormatter
name|fmt2
init|=
name|highlighter
operator|.
name|formatters
operator|.
name|get
argument_list|(
literal|""
argument_list|)
decl_stmt|;
name|assertSame
argument_list|(
name|fmt1
argument_list|,
name|fmt2
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|fmt1
operator|instanceof
name|HtmlFormatter
argument_list|)
expr_stmt|;
comment|// Make sure we loaded the one formatter
name|SolrFragmenter
name|gap
init|=
name|highlighter
operator|.
name|fragmenters
operator|.
name|get
argument_list|(
literal|"gap"
argument_list|)
decl_stmt|;
name|SolrFragmenter
name|regex
init|=
name|highlighter
operator|.
name|fragmenters
operator|.
name|get
argument_list|(
literal|"regex"
argument_list|)
decl_stmt|;
name|SolrFragmenter
name|frag
init|=
name|highlighter
operator|.
name|fragmenters
operator|.
name|get
argument_list|(
literal|null
argument_list|)
decl_stmt|;
name|assertSame
argument_list|(
name|gap
argument_list|,
name|frag
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|gap
operator|instanceof
name|GapFragmenter
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|regex
operator|instanceof
name|RegexFragmenter
argument_list|)
expr_stmt|;
block|}
DECL|method|testMergeContiguous
specifier|public
name|void
name|testMergeContiguous
parameter_list|()
throws|throws
name|Exception
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
name|HighlightParams
operator|.
name|HIGHLIGHT
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"df"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|HighlightParams
operator|.
name|FIELDS
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|HighlightParams
operator|.
name|SNIPPETS
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
literal|4
argument_list|)
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|HighlightParams
operator|.
name|FRAGSIZE
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
literal|40
argument_list|)
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|HighlightParams
operator|.
name|MERGE_CONTIGUOUS_FRAGMENTS
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|String
name|input
init|=
literal|"this is some long text.  It has the word long in many places.  In fact, it has long on some different fragments.  "
operator|+
literal|"Let us see what happens to long in this case."
decl_stmt|;
name|String
name|gold
init|=
literal|"this is some<em>long</em> text.  It has the word<em>long</em> in many places.  In fact, it has<em>long</em> on some different fragments.  "
operator|+
literal|"Let us see what happens to<em>long</em> in this case."
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
name|input
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Merge Contiguous"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='"
operator|+
name|gold
operator|+
literal|"']"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"f.t_text."
operator|+
name|HighlightParams
operator|.
name|MERGE_CONTIGUOUS_FRAGMENTS
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
name|input
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Merge Contiguous"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='"
operator|+
name|gold
operator|+
literal|"']"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
name|HighlightParams
operator|.
name|MERGE_CONTIGUOUS_FRAGMENTS
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"f.t_text."
operator|+
name|HighlightParams
operator|.
name|MERGE_CONTIGUOUS_FRAGMENTS
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Merge Contiguous"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='this is some<em>long</em> text.  It has']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.=' the word<em>long</em> in many places.  In fact, it has']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='<em>long</em> on some different fragments.  Let us']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.=' see what happens to<em>long</em> in this case.']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testTermVecHighlight
specifier|public
name|void
name|testTermVecHighlight
parameter_list|()
block|{
comment|// do summarization using term vectors
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"tv_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.snippets"
argument_list|,
literal|"2"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"tv_text"
argument_list|,
name|LONG_TEXT
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str[.='a<em>long</em> days night this should be a piece of text which']"
argument_list|,
literal|"//arr[@name='tv_text']/str[.='<em>long</em> fragments.']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testTermOffsetsTokenStream
specifier|public
name|void
name|testTermOffsetsTokenStream
parameter_list|()
throws|throws
name|Exception
block|{
name|String
index|[]
name|multivalued
init|=
block|{
literal|"a b c d"
block|,
literal|"e f g"
block|,
literal|"h"
block|,
literal|"i j k l m n"
block|}
decl_stmt|;
name|Analyzer
name|a1
init|=
operator|new
name|WhitespaceAnalyzer
argument_list|()
decl_stmt|;
name|TermOffsetsTokenStream
name|tots
init|=
operator|new
name|TermOffsetsTokenStream
argument_list|(
name|a1
operator|.
name|tokenStream
argument_list|(
literal|""
argument_list|,
operator|new
name|StringReader
argument_list|(
literal|"a b c d e f g h i j k l m n"
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|v
range|:
name|multivalued
control|)
block|{
name|TokenStream
name|ts1
init|=
name|tots
operator|.
name|getMultiValuedTokenStream
argument_list|(
name|v
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|Analyzer
name|a2
init|=
operator|new
name|WhitespaceAnalyzer
argument_list|()
decl_stmt|;
name|TokenStream
name|ts2
init|=
name|a2
operator|.
name|tokenStream
argument_list|(
literal|""
argument_list|,
operator|new
name|StringReader
argument_list|(
name|v
argument_list|)
argument_list|)
decl_stmt|;
name|Token
name|t1
init|=
operator|new
name|Token
argument_list|()
decl_stmt|;
name|Token
name|t2
init|=
operator|new
name|Token
argument_list|()
decl_stmt|;
for|for
control|(
name|t1
operator|=
name|ts1
operator|.
name|next
argument_list|(
name|t1
argument_list|)
init|;
name|t1
operator|!=
literal|null
condition|;
name|t1
operator|=
name|ts1
operator|.
name|next
argument_list|(
name|t1
argument_list|)
control|)
block|{
name|t2
operator|=
name|ts2
operator|.
name|next
argument_list|(
name|t2
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|t2
argument_list|,
name|t1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|testTermVecMultiValuedHighlight
specifier|public
name|void
name|testTermVecMultiValuedHighlight
parameter_list|()
throws|throws
name|Exception
block|{
comment|// do summarization using term vectors on multivalued field
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"tv_mv_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.snippets"
argument_list|,
literal|"2"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"tv_mv_text"
argument_list|,
name|LONG_TEXT
argument_list|,
literal|"tv_mv_text"
argument_list|,
name|LONG_TEXT
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_mv_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_mv_text']/str[.='a<em>long</em> days night this should be a piece of text which']"
argument_list|,
literal|"//arr[@name='tv_mv_text']/str[.='<em>long</em> fragments.']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testDisMaxHighlight
specifier|public
name|void
name|testDisMaxHighlight
parameter_list|()
block|{
comment|// same test run through dismax handler
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"tv_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"qf"
argument_list|,
literal|"tv_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"q.alt"
argument_list|,
literal|"*:*"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"dismax"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"tv_text"
argument_list|,
literal|"a long day's night"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str"
argument_list|)
expr_stmt|;
comment|// try the same thing without a q param
name|assertQ
argument_list|(
literal|"Should not explode..."
argument_list|,
comment|// q.alt should return everything
name|sumLRF
operator|.
name|makeRequest
argument_list|(
operator|new
name|String
index|[]
block|{
literal|null
block|}
argument_list|)
argument_list|,
comment|// empty query
literal|"//result[@numFound='1']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testMultiValueAnalysisHighlight
specifier|public
name|void
name|testMultiValueAnalysisHighlight
parameter_list|()
block|{
comment|// do summarization using re-analysis of the field
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"textgap"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"df"
argument_list|,
literal|"textgap"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"textgap"
argument_list|,
literal|"first entry hasnt queryword"
argument_list|,
literal|"textgap"
argument_list|,
literal|"second entry has queryword long"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='textgap']/str"
argument_list|)
expr_stmt|;
block|}
DECL|method|testMultiValueBestFragmentHighlight
specifier|public
name|void
name|testMultiValueBestFragmentHighlight
parameter_list|()
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"textgap"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"df"
argument_list|,
literal|"textgap"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"textgap"
argument_list|,
literal|"first entry has one word foo"
argument_list|,
literal|"textgap"
argument_list|,
literal|"second entry has both words foo bar"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Best fragment summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"foo bar"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='textgap']/str[.=\'second entry has both words<em>foo</em><em>bar</em>\']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testDefaultFieldHighlight
specifier|public
name|void
name|testDefaultFieldHighlight
parameter_list|()
block|{
comment|// do summarization using re-analysis of the field
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"df"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
literal|"a long day's night"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str"
argument_list|)
expr_stmt|;
block|}
DECL|method|testHighlightDisabled
specifier|public
name|void
name|testHighlightDisabled
parameter_list|()
block|{
comment|// ensure highlighting can be explicitly disabled
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
literal|"a long day's night"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"not(//lst[@name='highlighting'])"
argument_list|)
expr_stmt|;
block|}
DECL|method|testTwoFieldHighlight
specifier|public
name|void
name|testTwoFieldHighlight
parameter_list|()
block|{
comment|// do summarization using re-analysis of the field
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text tv_text"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
literal|"a long day's night"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|,
literal|"tv_text"
argument_list|,
literal|"a long night's day"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str"
argument_list|)
expr_stmt|;
block|}
DECL|method|testFieldMatch
specifier|public
name|void
name|testFieldMatch
parameter_list|()
block|{
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text1"
argument_list|,
literal|"random words for highlighting tests"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|,
literal|"t_text2"
argument_list|,
literal|"more random words for second field"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text1 t_text2"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
comment|// default should highlight both random and words in both fields
name|assertQ
argument_list|(
literal|"Test Default"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text1:random OR t_text2:words"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text1']/str[.='<em>random</em><em>words</em> for highlighting tests']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text2']/str[.='more<em>random</em><em>words</em> for second field']"
argument_list|)
expr_stmt|;
comment|// requireFieldMatch=true - highlighting should only occur if term matched in that field
name|args
operator|.
name|put
argument_list|(
literal|"hl.requireFieldMatch"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Test RequireFieldMatch"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text1:random OR t_text2:words"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text1']/str[.='<em>random</em> words for highlighting tests']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text2']/str[.='more random<em>words</em> for second field']"
argument_list|)
expr_stmt|;
comment|// test case for un-optimized index
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text1"
argument_list|,
literal|"random words for highlighting tests"
argument_list|,
literal|"id"
argument_list|,
literal|"2"
argument_list|,
literal|"t_text2"
argument_list|,
literal|"more random words for second field"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|delI
argument_list|(
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Test RequireFieldMatch on un-optimized index"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text1:random OR t_text2:words"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='2']"
argument_list|,
literal|"//lst[@name='2']/arr[@name='t_text1']/str[.='<em>random</em> words for highlighting tests']"
argument_list|,
literal|"//lst[@name='2']/arr[@name='t_text2']/str[.='more random<em>words</em> for second field']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testCustomSimpleFormatterHighlight
specifier|public
name|void
name|testCustomSimpleFormatterHighlight
parameter_list|()
block|{
comment|// do summarization using a custom formatter
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.simple.pre"
argument_list|,
literal|"<B>"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.simple.post"
argument_list|,
literal|"</B>"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
literal|"a long days night"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='a<B>long</B> days night']"
argument_list|)
expr_stmt|;
comment|// test a per-field override
name|args
operator|.
name|put
argument_list|(
literal|"f.t_text.hl.simple.pre"
argument_list|,
literal|"<I>"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"f.t_text.hl.simple.post"
argument_list|,
literal|"</I>"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='a<I>long</I> days night']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testLongFragment
specifier|public
name|void
name|testLongFragment
parameter_list|()
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"tv_text"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|String
name|text
init|=
literal|"junit: [mkdir] Created dir: /home/klaas/worio/backend/trunk/build-src/solr-nightly/build/test-results [junit] Running org.apache.solr.BasicFunctionalityTest [junit] Tests run: 7, Failures: 0, Errors: 0, Time elapsed: 5.36 sec [junit] Running org.apache.solr.ConvertedLegacyTest [junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 8.268 sec [junit] Running org.apache.solr.DisMaxRequestHandlerTest [junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 1.56 sec [junit] Running org.apache.solr.HighlighterTest [junit] Tests run: 7, Failures: 0, Errors: 0, Time elapsed: 4.979 sec [junit] Running org.apache.solr.OutputWriterTest [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0.797 sec [junit] Running org.apache.solr.SampleTest [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 1.021 sec [junit] Running org.apache.solr.analysis.TestBufferedTokenStream [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0.05 sec [junit] Running org.apache.solr.analysis.TestRemoveDuplicatesTokenFilter [junit] Tests run: 3, Failures: 0, Errors: 0, Time elapsed: 0.054 sec [junit] Running org.apache.solr.analysis.TestSynonymFilter [junit] Tests run: 6, Failures: 0, Errors: 0, Time elapsed: 0.081 sec [junit] Running org.apache.solr.analysis.TestWordDelimiterFilter [junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 1.714 sec [junit] Running org.apache.solr.search.TestDocSet [junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.788 sec [junit] Running org.apache.solr.util.SolrPluginUtilsTest [junit] Tests run: 5, Failures: 0, Errors: 0, Time elapsed: 3.519 sec [junit] Running org.apache.solr.util.TestOpenBitSet [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0.533 sec"
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"tv_text"
argument_list|,
name|text
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:dir"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str"
argument_list|)
expr_stmt|;
block|}
DECL|method|testMaxChars
specifier|public
name|void
name|testMaxChars
parameter_list|()
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"fl"
argument_list|,
literal|"id score"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.snippets"
argument_list|,
literal|"10"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
name|LONG_TEXT
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"token at start of text"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:disjoint"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[count(str)=1]"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.maxAnalyzedChars"
argument_list|,
literal|"20"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"token at end of text"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:disjoint"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1'][not(*)]"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.maxAnalyzedChars"
argument_list|,
literal|"-1"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"token at start of text"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:disjoint"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[count(str)=1]"
argument_list|)
expr_stmt|;
block|}
DECL|method|testRegexFragmenter
specifier|public
name|void
name|testRegexFragmenter
parameter_list|()
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"fl"
argument_list|,
literal|"id score"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.snippets"
argument_list|,
literal|"10"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fragmenter"
argument_list|,
literal|"regex"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.regex.pattern"
argument_list|,
literal|"[-\\w ,\"']{20,200}"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.regex.slop"
argument_list|,
literal|".9"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|String
name|t
init|=
literal|"This is an example of a sentence. Another example \"sentence\" with "
operator|+
literal|"special characters\nand a line-break! Miscellaneous character like ^ are "
operator|+
literal|"unknowns and end up being bad example s of sentences? I wonder how "
operator|+
literal|"slashes/other punctuation fare in these examples?"
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
name|t
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"regex fragmenter"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:example"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//arr/str[.='This is an<em>example</em> of a sentence']"
argument_list|,
literal|"//arr/str[.='. Another<em>example</em> \"sentence\" with special characters\nand a line-break']"
argument_list|,
literal|"//arr/str[.=' ^ are unknowns and end up being bad<em>example</em> s of sentences']"
argument_list|,
literal|"//arr/str[.='/other punctuation fare in these<em>examples</em>?']"
argument_list|)
expr_stmt|;
comment|// try with some punctuation included
name|args
operator|.
name|put
argument_list|(
literal|"hl.regex.pattern"
argument_list|,
literal|"[-\\w ,^/\\n\"']{20,200}"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"regex fragmenter 2"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:example"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//arr/str[.='This is an<em>example</em> of a sentence']"
argument_list|,
literal|"//arr/str[.='. Another<em>example</em> \"sentence\" with special characters\nand a line-break']"
argument_list|,
literal|"//arr/str[.='! Miscellaneous character like ^ are unknowns and end up being bad<em>example</em> s of sentences']"
argument_list|,
literal|"//arr/str[.='? I wonder how slashes/other punctuation fare in these<em>examples</em>?']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testVariableFragsize
specifier|public
name|void
name|testVariableFragsize
parameter_list|()
block|{
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"tv_text"
argument_list|,
literal|"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
comment|// default length
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"tv_text"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str[.='a<em>long</em> days night this should be a piece of text which']"
argument_list|)
expr_stmt|;
comment|// 25
name|args
operator|.
name|put
argument_list|(
literal|"hl.fragsize"
argument_list|,
literal|"25"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str[.='a<em>long</em> days night']"
argument_list|)
expr_stmt|;
comment|// 0 - NullFragmenter
name|args
operator|.
name|put
argument_list|(
literal|"hl.fragsize"
argument_list|,
literal|"0"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Basic summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:long"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='1']/arr[@name='tv_text']/str[.='a<em>long</em> days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testAlternateSummary
specifier|public
name|void
name|testAlternateSummary
parameter_list|()
block|{
comment|//long document
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"tv_text"
argument_list|,
literal|"keyword is only here"
argument_list|,
literal|"t_text"
argument_list|,
literal|"a piece of text to be substituted"
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
comment|// do summarization
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fragsize"
argument_list|,
literal|"0"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
comment|// no alternate
name|assertQ
argument_list|(
literal|"Alternate summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:keyword"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1' and count(*)=0]"
argument_list|)
expr_stmt|;
comment|// with an alternate
name|args
operator|.
name|put
argument_list|(
literal|"hl.alternateField"
argument_list|,
literal|"id"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Alternate summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:keyword"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1' and count(*)=1]"
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']/arr[@name='t_text']/str[.='1']"
argument_list|)
expr_stmt|;
comment|// with an alternate + max length
name|args
operator|.
name|put
argument_list|(
literal|"hl.alternateField"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.maxAlternateFieldLength"
argument_list|,
literal|"15"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Alternate summarization"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"tv_text:keyword"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1' and count(*)=1]"
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']/arr[@name='t_text']/str[.='a piece of text']"
argument_list|)
expr_stmt|;
block|}
DECL|method|testPhraseHighlighter
specifier|public
name|void
name|testPhraseHighlighter
parameter_list|()
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|args
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fl"
argument_list|,
literal|"t_text"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.fragsize"
argument_list|,
literal|"40"
argument_list|)
expr_stmt|;
name|args
operator|.
name|put
argument_list|(
literal|"hl.snippets"
argument_list|,
literal|"10"
argument_list|)
expr_stmt|;
name|TestHarness
operator|.
name|LocalRequestFactory
name|sumLRF
init|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
decl_stmt|;
comment|// String borrowed from Lucene's HighlighterTest
name|String
name|t
init|=
literal|"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy"
decl_stmt|;
name|assertU
argument_list|(
name|adoc
argument_list|(
literal|"t_text"
argument_list|,
name|t
argument_list|,
literal|"id"
argument_list|,
literal|"1"
argument_list|)
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|commit
argument_list|()
argument_list|)
expr_stmt|;
name|assertU
argument_list|(
name|optimize
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|oldHighlight1
init|=
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='This piece of<em>text</em><em>refers</em> to Kennedy']"
decl_stmt|;
name|String
name|oldHighlight2
init|=
literal|"//lst[@name='1']/arr[@name='t_text']/str[.=' at the beginning then has a longer piece of<em>text</em>']"
decl_stmt|;
name|String
name|oldHighlight3
init|=
literal|"//lst[@name='1']/arr[@name='t_text']/str[.=' with another<em>reference</em> to Kennedy']"
decl_stmt|;
name|String
name|newHighlight1
init|=
literal|"//lst[@name='1']/arr[@name='t_text']/str[.='This piece of<em>text</em><em>refers</em> to Kennedy']"
decl_stmt|;
comment|// check if old functionality is still the same
name|assertQ
argument_list|(
literal|"Phrase highlighting - old"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:\"text refers\""
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
name|oldHighlight1
argument_list|,
name|oldHighlight2
argument_list|,
name|oldHighlight3
argument_list|)
expr_stmt|;
name|assertQ
argument_list|(
literal|"Phrase highlighting - old"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:text refers"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
name|oldHighlight1
argument_list|,
name|oldHighlight2
argument_list|,
name|oldHighlight3
argument_list|)
expr_stmt|;
comment|// now check if Lucene-794 highlighting works as expected
name|args
operator|.
name|put
argument_list|(
literal|"hl.usePhraseHighlighter"
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
name|sumLRF
operator|=
name|h
operator|.
name|getRequestFactory
argument_list|(
literal|"standard"
argument_list|,
literal|0
argument_list|,
literal|200
argument_list|,
name|args
argument_list|)
expr_stmt|;
comment|// check phrase highlighting
name|assertQ
argument_list|(
literal|"Phrase highlighting - Lucene-794"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:\"text refers\""
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
name|newHighlight1
argument_list|)
expr_stmt|;
comment|// non phrase queries should be highlighted as they were before this fix
name|assertQ
argument_list|(
literal|"Phrase highlighting - Lucene-794"
argument_list|,
name|sumLRF
operator|.
name|makeRequest
argument_list|(
literal|"t_text:text refers"
argument_list|)
argument_list|,
literal|"//lst[@name='highlighting']/lst[@name='1']"
argument_list|,
name|oldHighlight1
argument_list|,
name|oldHighlight2
argument_list|,
name|oldHighlight3
argument_list|)
expr_stmt|;
block|}
block|}
end_class
end_unit
