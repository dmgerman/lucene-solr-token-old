begin_unit
begin_package
DECL|package|org.apache.lucene.facet.taxonomy.directory
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|facet
operator|.
name|taxonomy
operator|.
name|directory
package|;
end_package
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReadWriteLock
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|logging
operator|.
name|Level
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|logging
operator|.
name|Logger
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|facet
operator|.
name|taxonomy
operator|.
name|CategoryPath
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|facet
operator|.
name|taxonomy
operator|.
name|InconsistentTaxonomyException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|facet
operator|.
name|taxonomy
operator|.
name|TaxonomyReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|facet
operator|.
name|taxonomy
operator|.
name|directory
operator|.
name|Consts
operator|.
name|LoadFullPathOnly
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|CorruptIndexException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|DocsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MultiFields
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|DocIdSetIterator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|AlreadyClosedException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Bits
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|collections
operator|.
name|LRUHashMap
import|;
end_import
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_comment
comment|/**  * A {@link TaxonomyReader} which retrieves stored taxonomy information from a  * {@link Directory}.  *<P>  * Reading from the on-disk index on every method call is too slow, so this  * implementation employs caching: Some methods cache recent requests and their  * results, while other methods prefetch all the data into memory and then  * provide answers directly from in-memory tables. See the documentation of  * individual methods for comments on their performance.  *   * @lucene.experimental  */
end_comment
begin_class
DECL|class|DirectoryTaxonomyReader
specifier|public
class|class
name|DirectoryTaxonomyReader
implements|implements
name|TaxonomyReader
block|{
DECL|field|logger
specifier|private
specifier|static
specifier|final
name|Logger
name|logger
init|=
name|Logger
operator|.
name|getLogger
argument_list|(
name|DirectoryTaxonomyReader
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
DECL|field|indexReader
specifier|private
name|IndexReader
name|indexReader
decl_stmt|;
comment|// The following lock is used to allow multiple threads to read from the
comment|// index concurrently, while having them block during the very short
comment|// critical moment of refresh() (see comments below). Note, however, that
comment|// we only read from the index when we don't have the entry in our cache,
comment|// and the caches are locked separately.
DECL|field|indexReaderLock
specifier|private
name|ReadWriteLock
name|indexReaderLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|// The following are the limited-size LRU caches used to cache the latest
comment|// results from getOrdinal() and getLabel().
comment|// Because LRUHashMap is not thread-safe, we need to synchronize on this
comment|// object when using it. Unfortunately, this is not optimal under heavy
comment|// contention because it means that while one thread is using the cache
comment|// (reading or modifying) others are blocked from using it - or even
comment|// starting to do benign things like calculating the hash function. A more
comment|// efficient approach would be to use a non-locking (as much as possible)
comment|// concurrent solution, along the lines of java.util.concurrent.ConcurrentHashMap
comment|// but with LRU semantics.
comment|// However, even in the current sub-optimal implementation we do not make
comment|// the mistake of locking out readers while waiting for disk in a cache
comment|// miss - below, we do not hold cache lock while reading missing data from
comment|// disk.
DECL|field|ordinalCache
specifier|private
specifier|final
name|LRUHashMap
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
name|ordinalCache
decl_stmt|;
DECL|field|categoryCache
specifier|private
specifier|final
name|LRUHashMap
argument_list|<
name|Integer
argument_list|,
name|String
argument_list|>
name|categoryCache
decl_stmt|;
comment|// getParent() needs to be extremely efficient, to the point that we need
comment|// to fetch all the data in advance into memory, and answer these calls
comment|// from memory. Currently we use a large integer array, which is
comment|// initialized when the taxonomy is opened, and potentially enlarged
comment|// when it is refresh()ed.
comment|// These arrays are not syncrhonized. Rather, the reference to the array
comment|// is volatile, and the only writing operation (refreshPrefetchArrays)
comment|// simply creates a new array and replaces the reference. The volatility
comment|// of the reference ensures the correct atomic replacement and its
comment|// visibility properties (the content of the array is visible when the
comment|// new reference is visible).
DECL|field|parentArray
specifier|private
name|ParentArray
name|parentArray
decl_stmt|;
DECL|field|delimiter
specifier|private
name|char
name|delimiter
init|=
name|Consts
operator|.
name|DEFAULT_DELIMITER
decl_stmt|;
DECL|field|closed
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
comment|/**    * Open for reading a taxonomy stored in a given {@link Directory}.    * @param directory    *    The {@link Directory} in which to the taxonomy lives. Note that    *    the taxonomy is read directly to that directory (not from a    *    subdirectory of it).    * @throws CorruptIndexException if the Taxonomy is corrupted.    * @throws IOException if another error occurred.    */
DECL|method|DirectoryTaxonomyReader
specifier|public
name|DirectoryTaxonomyReader
parameter_list|(
name|Directory
name|directory
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|indexReader
operator|=
name|openIndexReader
argument_list|(
name|directory
argument_list|)
expr_stmt|;
comment|// These are the default cache sizes; they can be configured after
comment|// construction with the cache's setMaxSize() method
name|ordinalCache
operator|=
operator|new
name|LRUHashMap
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
argument_list|(
literal|4000
argument_list|)
expr_stmt|;
name|categoryCache
operator|=
operator|new
name|LRUHashMap
argument_list|<
name|Integer
argument_list|,
name|String
argument_list|>
argument_list|(
literal|4000
argument_list|)
expr_stmt|;
comment|// TODO (Facet): consider lazily create parent array when asked, not in the constructor
name|parentArray
operator|=
operator|new
name|ParentArray
argument_list|()
expr_stmt|;
name|parentArray
operator|.
name|refresh
argument_list|(
name|indexReader
argument_list|)
expr_stmt|;
block|}
DECL|method|openIndexReader
specifier|protected
name|IndexReader
name|openIndexReader
parameter_list|(
name|Directory
name|directory
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
return|return
name|IndexReader
operator|.
name|open
argument_list|(
name|directory
argument_list|)
return|;
block|}
comment|/**    * @throws AlreadyClosedException if this IndexReader is closed    */
DECL|method|ensureOpen
specifier|protected
specifier|final
name|void
name|ensureOpen
parameter_list|()
throws|throws
name|AlreadyClosedException
block|{
if|if
condition|(
name|indexReader
operator|.
name|getRefCount
argument_list|()
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|AlreadyClosedException
argument_list|(
literal|"this TaxonomyReader is closed"
argument_list|)
throw|;
block|}
block|}
comment|/**    * setCacheSize controls the maximum allowed size of each of the caches    * used by {@link #getPath(int)} and {@link #getOrdinal(CategoryPath)}.    *<P>    * Currently, if the given size is smaller than the current size of    * a cache, it will not shrink, and rather we be limited to its current    * size.    * @param size the new maximum cache size, in number of entries.    */
DECL|method|setCacheSize
specifier|public
name|void
name|setCacheSize
parameter_list|(
name|int
name|size
parameter_list|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|categoryCache
init|)
block|{
name|categoryCache
operator|.
name|setMaxSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|ordinalCache
init|)
block|{
name|ordinalCache
operator|.
name|setMaxSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * setDelimiter changes the character that the taxonomy uses in its    * internal storage as a delimiter between category components. Do not    * use this method unless you really know what you are doing.    *<P>    * If you do use this method, make sure you call it before any other    * methods that actually queries the taxonomy. Moreover, make sure you    * always pass the same delimiter for all LuceneTaxonomyWriter and    * LuceneTaxonomyReader objects you create.    */
DECL|method|setDelimiter
specifier|public
name|void
name|setDelimiter
parameter_list|(
name|char
name|delimiter
parameter_list|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|this
operator|.
name|delimiter
operator|=
name|delimiter
expr_stmt|;
block|}
DECL|method|getOrdinal
specifier|public
name|int
name|getOrdinal
parameter_list|(
name|CategoryPath
name|categoryPath
parameter_list|)
throws|throws
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|categoryPath
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
name|ROOT_ORDINAL
return|;
block|}
name|String
name|path
init|=
name|categoryPath
operator|.
name|toString
argument_list|(
name|delimiter
argument_list|)
decl_stmt|;
comment|// First try to find the answer in the LRU cache:
synchronized|synchronized
init|(
name|ordinalCache
init|)
block|{
name|Integer
name|res
init|=
name|ordinalCache
operator|.
name|get
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|res
operator|!=
literal|null
condition|)
block|{
return|return
name|res
operator|.
name|intValue
argument_list|()
return|;
block|}
block|}
comment|// If we're still here, we have a cache miss. We need to fetch the
comment|// value from disk, and then also put it in the cache:
name|int
name|ret
init|=
name|TaxonomyReader
operator|.
name|INVALID_ORDINAL
decl_stmt|;
try|try
block|{
name|indexReaderLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// TODO (Facet): avoid Multi*?
name|Bits
name|liveDocs
init|=
name|MultiFields
operator|.
name|getLiveDocs
argument_list|(
name|indexReader
argument_list|)
decl_stmt|;
name|DocsEnum
name|docs
init|=
name|MultiFields
operator|.
name|getTermDocsEnum
argument_list|(
name|indexReader
argument_list|,
name|liveDocs
argument_list|,
name|Consts
operator|.
name|FULL
argument_list|,
operator|new
name|BytesRef
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|docs
operator|!=
literal|null
operator|&&
name|docs
operator|.
name|nextDoc
argument_list|()
operator|!=
name|DocIdSetIterator
operator|.
name|NO_MORE_DOCS
condition|)
block|{
name|ret
operator|=
name|docs
operator|.
name|docID
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|indexReaderLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// Put the new value in the cache. Note that it is possible that while
comment|// we were doing the above fetching (without the cache locked), some
comment|// other thread already added the same category to the cache. We do
comment|// not care about this possibilty, as LRUCache replaces previous values
comment|// of the same keys (it doesn't store duplicates).
synchronized|synchronized
init|(
name|ordinalCache
init|)
block|{
comment|// GB: new Integer(int); creates a new object each and every time.
comment|// Integer.valueOf(int) might not (See JavaDoc).
name|ordinalCache
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|Integer
operator|.
name|valueOf
argument_list|(
name|ret
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
DECL|method|getPath
specifier|public
name|CategoryPath
name|getPath
parameter_list|(
name|int
name|ordinal
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// TODO (Facet): Currently, the LRU cache we use (getCategoryCache) holds
comment|// strings with delimiters, not CategoryPath objects, so even if
comment|// we have a cache hit, we need to process the string and build a new
comment|// CategoryPath object every time. What is preventing us from putting
comment|// the actual CategoryPath object in the cache is the fact that these
comment|// objects are mutable. So we should create an immutable (read-only)
comment|// interface that CategoryPath implements, and this method should
comment|// return this interface, not the writable CategoryPath.
name|String
name|label
init|=
name|getLabel
argument_list|(
name|ordinal
argument_list|)
decl_stmt|;
if|if
condition|(
name|label
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
operator|new
name|CategoryPath
argument_list|(
name|label
argument_list|,
name|delimiter
argument_list|)
return|;
block|}
DECL|method|getPath
specifier|public
name|boolean
name|getPath
parameter_list|(
name|int
name|ordinal
parameter_list|,
name|CategoryPath
name|result
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|String
name|label
init|=
name|getLabel
argument_list|(
name|ordinal
argument_list|)
decl_stmt|;
if|if
condition|(
name|label
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|result
operator|.
name|clear
argument_list|()
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|label
argument_list|,
name|delimiter
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
DECL|method|getLabel
specifier|private
name|String
name|getLabel
parameter_list|(
name|int
name|catID
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// First try to find the answer in the LRU cache. It is very
comment|// unfortunate that we need to allocate an Integer object here -
comment|// it would have been better if we used a hash table specifically
comment|// designed for int keys...
comment|// GB: new Integer(int); creates a new object each and every time.
comment|// Integer.valueOf(int) might not (See JavaDoc).
name|Integer
name|catIDInteger
init|=
name|Integer
operator|.
name|valueOf
argument_list|(
name|catID
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|categoryCache
init|)
block|{
name|String
name|res
init|=
name|categoryCache
operator|.
name|get
argument_list|(
name|catIDInteger
argument_list|)
decl_stmt|;
if|if
condition|(
name|res
operator|!=
literal|null
condition|)
block|{
return|return
name|res
return|;
block|}
block|}
comment|// If we're still here, we have a cache miss. We need to fetch the
comment|// value from disk, and then also put it in the cache:
name|String
name|ret
decl_stmt|;
try|try
block|{
name|indexReaderLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// The taxonomy API dictates that if we get an invalid category
comment|// ID, we should return null, If we don't check this here, we
comment|// can some sort of an exception from the document() call below.
comment|// NOTE: Currently, we *do not* cache this return value; There
comment|// isn't much point to do so, because checking the validity of
comment|// the docid doesn't require disk access - just comparing with
comment|// the number indexReader.maxDoc().
if|if
condition|(
name|catID
operator|<
literal|0
operator|||
name|catID
operator|>=
name|indexReader
operator|.
name|maxDoc
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
specifier|final
name|LoadFullPathOnly
name|loader
init|=
operator|new
name|LoadFullPathOnly
argument_list|()
decl_stmt|;
name|indexReader
operator|.
name|document
argument_list|(
name|catID
argument_list|,
name|loader
argument_list|)
expr_stmt|;
name|ret
operator|=
name|loader
operator|.
name|getFullPath
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|indexReaderLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// Put the new value in the cache. Note that it is possible that while
comment|// we were doing the above fetching (without the cache locked), some
comment|// other thread already added the same category to the cache. We do
comment|// not care about this possibility, as LRUCache replaces previous
comment|// values of the same keys (it doesn't store duplicates).
synchronized|synchronized
init|(
name|categoryCache
init|)
block|{
name|categoryCache
operator|.
name|put
argument_list|(
name|catIDInteger
argument_list|,
name|ret
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
DECL|method|getParent
specifier|public
name|int
name|getParent
parameter_list|(
name|int
name|ordinal
parameter_list|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// Note how we don't need to hold the read lock to do the following,
comment|// because the array reference is volatile, ensuring the correct
comment|// visibility and ordering: if we get the new reference, the new
comment|// data is also visible to this thread.
return|return
name|getParentArray
argument_list|()
index|[
name|ordinal
index|]
return|;
block|}
comment|/**    * getParentArray() returns an int array of size getSize() listing the    * ordinal of the parent category of each category in the taxonomy.    *<P>    * The caller can hold on to the array it got indefinitely - it is    * guaranteed that no-one else will modify it. The other side of the    * same coin is that the caller must treat the array it got as read-only    * and<B>not modify it</B>, because other callers might have gotten the    * same array too, and getParent() calls are also answered from the    * same array.    *<P>    * The getParentArray() call is extremely efficient, merely returning    * a reference to an array that already exists. For a caller that plans    * to call getParent() for many categories, using getParentArray() and    * the array it returns is a somewhat faster approach because it avoids    * the overhead of method calls and volatile dereferencing.    *<P>    * If you use getParentArray() instead of getParent(), remember that    * the array you got is (naturally) not modified after a refresh(),    * so you should always call getParentArray() again after a refresh().    */
DECL|method|getParentArray
specifier|public
name|int
index|[]
name|getParentArray
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// Note how we don't need to hold the read lock to do the following,
comment|// because the array reference is volatile, ensuring the correct
comment|// visibility and ordering: if we get the new reference, the new
comment|// data is also visible to this thread.
return|return
name|parentArray
operator|.
name|getArray
argument_list|()
return|;
block|}
comment|// Note that refresh() is synchronized (it is the only synchronized
comment|// method in this class) to ensure that it never gets called concurrently
comment|// with itself.
DECL|method|refresh
specifier|public
specifier|synchronized
name|boolean
name|refresh
parameter_list|()
throws|throws
name|IOException
throws|,
name|InconsistentTaxonomyException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|/*      * Since refresh() can be a lengthy operation, it is very important that we      * avoid locking out all readers for its duration. This is why we don't hold      * the indexReaderLock write lock for the entire duration of this method. In      * fact, it is enough to hold it only during a single assignment! Other      * comments in this method will explain this.      */
comment|// note that the lengthy operation indexReader.reopen() does not
comment|// modify the reader, so we can do it without holding a lock. We can
comment|// safely read indexReader without holding the write lock, because
comment|// no other thread can be writing at this time (this method is the
comment|// only possible writer, and it is "synchronized" to avoid this case).
name|IndexReader
name|r2
init|=
name|IndexReader
operator|.
name|openIfChanged
argument_list|(
name|indexReader
argument_list|)
decl_stmt|;
if|if
condition|(
name|r2
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
comment|// no changes, nothing to do
block|}
comment|// validate that a refresh is valid at this point, i.e. that the taxonomy
comment|// was not recreated since this reader was last opened or refresshed.
name|String
name|t1
init|=
name|indexReader
operator|.
name|getCommitUserData
argument_list|()
operator|.
name|get
argument_list|(
name|DirectoryTaxonomyWriter
operator|.
name|INDEX_CREATE_TIME
argument_list|)
decl_stmt|;
name|String
name|t2
init|=
name|r2
operator|.
name|getCommitUserData
argument_list|()
operator|.
name|get
argument_list|(
name|DirectoryTaxonomyWriter
operator|.
name|INDEX_CREATE_TIME
argument_list|)
decl_stmt|;
if|if
condition|(
name|t1
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|t2
operator|!=
literal|null
condition|)
block|{
name|r2
operator|.
name|close
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|InconsistentTaxonomyException
argument_list|(
literal|"Taxonomy was recreated at: "
operator|+
name|t2
argument_list|)
throw|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|t1
operator|.
name|equals
argument_list|(
name|t2
argument_list|)
condition|)
block|{
name|r2
operator|.
name|close
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|InconsistentTaxonomyException
argument_list|(
literal|"Taxonomy was recreated at: "
operator|+
name|t2
operator|+
literal|"  !=  "
operator|+
name|t1
argument_list|)
throw|;
block|}
name|IndexReader
name|oldreader
init|=
name|indexReader
decl_stmt|;
comment|// we can close the old searcher, but need to synchronize this
comment|// so that we don't close it in the middle that another routine
comment|// is reading from it.
name|indexReaderLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|indexReader
operator|=
name|r2
expr_stmt|;
name|indexReaderLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
comment|// We can close the old reader, but need to be certain that we
comment|// don't close it while another method is reading from it.
comment|// Luckily, we can be certain of that even without putting the
comment|// oldreader.close() in the locked section. The reason is that
comment|// after lock() succeeded above, we know that all existing readers
comment|// had finished (this is what a read-write lock ensures). New
comment|// readers, starting after the unlock() we just did, already got
comment|// the new indexReader we set above. So nobody can be possibly
comment|// using the old indexReader, and we can close it:
name|oldreader
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// We prefetch some of the arrays to make requests much faster.
comment|// Let's refresh these prefetched arrays; This refresh is much
comment|// is made more efficient by assuming that it is enough to read
comment|// the values for new categories (old categories could not have been
comment|// changed or deleted)
comment|// Note that this this done without the write lock being held,
comment|// which means that it is possible that during a refresh(), a
comment|// reader will have some methods (like getOrdinal and getCategory)
comment|// return fresh information, while getParent()
comment|// (only to be prefetched now) still return older information.
comment|// We consider this to be acceptable. The important thing,
comment|// however, is that refreshPrefetchArrays() itself writes to
comment|// the arrays in a correct manner (see discussion there)
name|parentArray
operator|.
name|refresh
argument_list|(
name|indexReader
argument_list|)
expr_stmt|;
comment|// Remove any INVALID_ORDINAL values from the ordinal cache,
comment|// because it is possible those are now answered by the new data!
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|i
init|=
name|ordinalCache
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|i
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Entry
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
name|e
init|=
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|intValue
argument_list|()
operator|==
name|INVALID_ORDINAL
condition|)
block|{
name|i
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
return|return
literal|true
return|;
block|}
DECL|method|close
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|closed
condition|)
block|{
name|decRef
argument_list|()
expr_stmt|;
name|closed
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|/** Do the actual closing, free up resources */
DECL|method|doClose
specifier|private
name|void
name|doClose
parameter_list|()
throws|throws
name|IOException
block|{
name|indexReader
operator|.
name|close
argument_list|()
expr_stmt|;
name|closed
operator|=
literal|true
expr_stmt|;
name|parentArray
operator|=
literal|null
expr_stmt|;
name|childrenArrays
operator|=
literal|null
expr_stmt|;
name|categoryCache
operator|.
name|clear
argument_list|()
expr_stmt|;
name|ordinalCache
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
DECL|method|getSize
specifier|public
name|int
name|getSize
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|indexReaderLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|indexReader
operator|.
name|numDocs
argument_list|()
return|;
block|}
finally|finally
block|{
name|indexReaderLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|getCommitUserData
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getCommitUserData
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
return|return
name|indexReader
operator|.
name|getCommitUserData
argument_list|()
return|;
block|}
DECL|field|childrenArrays
specifier|private
name|ChildrenArrays
name|childrenArrays
decl_stmt|;
DECL|field|childrenArraysRebuild
name|Object
name|childrenArraysRebuild
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
DECL|method|getChildrenArrays
specifier|public
name|ChildrenArrays
name|getChildrenArrays
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// Check if the taxonomy grew since we built the array, and if it
comment|// did, create new (and larger) arrays and fill them as required.
comment|// We do all this under a lock, two prevent to concurrent calls to
comment|// needlessly do the same array building at the same time.
synchronized|synchronized
init|(
name|childrenArraysRebuild
init|)
block|{
name|int
name|num
init|=
name|getSize
argument_list|()
decl_stmt|;
name|int
name|first
decl_stmt|;
if|if
condition|(
name|childrenArrays
operator|==
literal|null
condition|)
block|{
name|first
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|first
operator|=
name|childrenArrays
operator|.
name|getYoungestChildArray
argument_list|()
operator|.
name|length
expr_stmt|;
block|}
comment|// If the taxonomy hasn't grown, we can return the existing object
comment|// immediately
if|if
condition|(
name|first
operator|==
name|num
condition|)
block|{
return|return
name|childrenArrays
return|;
block|}
comment|// Otherwise, build new arrays for a new ChildrenArray object.
comment|// These arrays start with an enlarged copy of the previous arrays,
comment|// and then are modified to take into account the new categories:
name|int
index|[]
name|newYoungestChildArray
init|=
operator|new
name|int
index|[
name|num
index|]
decl_stmt|;
name|int
index|[]
name|newOlderSiblingArray
init|=
operator|new
name|int
index|[
name|num
index|]
decl_stmt|;
comment|// In Java 6, we could just do Arrays.copyOf()...
if|if
condition|(
name|childrenArrays
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|childrenArrays
operator|.
name|getYoungestChildArray
argument_list|()
argument_list|,
literal|0
argument_list|,
name|newYoungestChildArray
argument_list|,
literal|0
argument_list|,
name|childrenArrays
operator|.
name|getYoungestChildArray
argument_list|()
operator|.
name|length
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|childrenArrays
operator|.
name|getOlderSiblingArray
argument_list|()
argument_list|,
literal|0
argument_list|,
name|newOlderSiblingArray
argument_list|,
literal|0
argument_list|,
name|childrenArrays
operator|.
name|getOlderSiblingArray
argument_list|()
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
name|int
index|[]
name|parents
init|=
name|getParentArray
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|first
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
name|newYoungestChildArray
index|[
name|i
index|]
operator|=
name|INVALID_ORDINAL
expr_stmt|;
block|}
comment|// In the loop below we can ignore the root category (0) because
comment|// it has no parent
if|if
condition|(
name|first
operator|==
literal|0
condition|)
block|{
name|first
operator|=
literal|1
expr_stmt|;
name|newOlderSiblingArray
index|[
literal|0
index|]
operator|=
name|INVALID_ORDINAL
expr_stmt|;
block|}
for|for
control|(
name|int
name|i
init|=
name|first
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
comment|// Note that parents[i] is always< i, so the right-hand-side of
comment|// the following line is already set when we get here.
name|newOlderSiblingArray
index|[
name|i
index|]
operator|=
name|newYoungestChildArray
index|[
name|parents
index|[
name|i
index|]
index|]
expr_stmt|;
name|newYoungestChildArray
index|[
name|parents
index|[
name|i
index|]
index|]
operator|=
name|i
expr_stmt|;
block|}
comment|// Finally switch to the new arrays
name|childrenArrays
operator|=
operator|new
name|ChildrenArraysImpl
argument_list|(
name|newYoungestChildArray
argument_list|,
name|newOlderSiblingArray
argument_list|)
expr_stmt|;
return|return
name|childrenArrays
return|;
block|}
block|}
DECL|method|toString
specifier|public
name|String
name|toString
parameter_list|(
name|int
name|max
parameter_list|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|int
name|upperl
init|=
name|Math
operator|.
name|min
argument_list|(
name|max
argument_list|,
name|this
operator|.
name|indexReader
operator|.
name|maxDoc
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|upperl
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|CategoryPath
name|category
init|=
name|this
operator|.
name|getPath
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|category
operator|==
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|i
operator|+
literal|": NULL!! \n"
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|category
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|i
operator|+
literal|": EMPTY STRING!! \n"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|sb
operator|.
name|append
argument_list|(
name|i
operator|+
literal|": "
operator|+
name|category
operator|.
name|toString
argument_list|()
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|logger
operator|.
name|isLoggable
argument_list|(
name|Level
operator|.
name|FINEST
argument_list|)
condition|)
block|{
name|logger
operator|.
name|log
argument_list|(
name|Level
operator|.
name|FINEST
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|class|ChildrenArraysImpl
specifier|private
specifier|static
specifier|final
class|class
name|ChildrenArraysImpl
implements|implements
name|ChildrenArrays
block|{
DECL|field|youngestChildArray
DECL|field|olderSiblingArray
specifier|private
name|int
index|[]
name|youngestChildArray
decl_stmt|,
name|olderSiblingArray
decl_stmt|;
DECL|method|ChildrenArraysImpl
specifier|public
name|ChildrenArraysImpl
parameter_list|(
name|int
index|[]
name|youngestChildArray
parameter_list|,
name|int
index|[]
name|olderSiblingArray
parameter_list|)
block|{
name|this
operator|.
name|youngestChildArray
operator|=
name|youngestChildArray
expr_stmt|;
name|this
operator|.
name|olderSiblingArray
operator|=
name|olderSiblingArray
expr_stmt|;
block|}
DECL|method|getOlderSiblingArray
specifier|public
name|int
index|[]
name|getOlderSiblingArray
parameter_list|()
block|{
return|return
name|olderSiblingArray
return|;
block|}
DECL|method|getYoungestChildArray
specifier|public
name|int
index|[]
name|getYoungestChildArray
parameter_list|()
block|{
return|return
name|youngestChildArray
return|;
block|}
block|}
comment|/**    * Expert:  This method is only for expert use.    * Note also that any call to refresh() will invalidate the returned reader,    * so the caller needs to take care of appropriate locking.    *     * @return lucene indexReader    */
DECL|method|getInternalIndexReader
name|IndexReader
name|getInternalIndexReader
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
return|return
name|this
operator|.
name|indexReader
return|;
block|}
comment|/**    * Expert: decreases the refCount of this TaxonomyReader instance.     * If the refCount drops to 0, then pending changes (if any) are     * committed to the taxonomy index and this reader is closed.     * @throws IOException     */
DECL|method|decRef
specifier|public
name|void
name|decRef
parameter_list|()
throws|throws
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|indexReader
operator|.
name|getRefCount
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|// Do not decRef the indexReader - doClose does it by calling reader.close()
name|doClose
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|indexReader
operator|.
name|decRef
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Expert: returns the current refCount for this taxonomy reader    */
DECL|method|getRefCount
specifier|public
name|int
name|getRefCount
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
return|return
name|this
operator|.
name|indexReader
operator|.
name|getRefCount
argument_list|()
return|;
block|}
comment|/**    * Expert: increments the refCount of this TaxonomyReader instance.     * RefCounts are used to determine when a taxonomy reader can be closed     * safely, i.e. as soon as there are no more references.     * Be sure to always call a corresponding decRef(), in a finally clause;     * otherwise the reader may never be closed.     */
DECL|method|incRef
specifier|public
name|void
name|incRef
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|this
operator|.
name|indexReader
operator|.
name|incRef
argument_list|()
expr_stmt|;
block|}
block|}
end_class
end_unit
