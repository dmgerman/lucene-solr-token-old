begin_unit
begin_package
DECL|package|org.apache.lucene.util.bkd
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|bkd
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|CodecUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|ByteArrayDataInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexOutput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|TrackingDirectoryWrapper
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ArrayUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IOUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|InPlaceMergeSorter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|LongBitSet
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|OfflineSorter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|OfflineSorter
operator|.
name|ByteSequencesWriter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RamUsageEstimator
import|;
end_import
begin_comment
comment|// TODO
end_comment
begin_comment
comment|//   - the compression is somewhat stupid now (delta vInt for 1024 docIDs, no compression for the byte[] values even though they have high locality)
end_comment
begin_comment
comment|//   - allow variable length byte[] (across docs and dims), but this is quite a bit more hairy
end_comment
begin_comment
comment|//   - we could also index "auto-prefix terms" here, and use better compression, and maybe only use for the "fully contained" case so we'd
end_comment
begin_comment
comment|//     only index docIDs
end_comment
begin_comment
comment|//   - the index could be efficiently encoded as an FST, so we don't have wasteful
end_comment
begin_comment
comment|//     (monotonic) long[] leafBlockFPs; or we could use MonotonicLongValues ... but then
end_comment
begin_comment
comment|//     the index is already plenty small: 60M OSM points --> 1.1 MB with 128 points
end_comment
begin_comment
comment|//     per leaf, and you can reduce that by putting more points per leaf
end_comment
begin_comment
comment|//   - we could use threads while building; the higher nodes are very parallelizable
end_comment
begin_comment
comment|/** Recursively builds a block KD-tree to assign all incoming points in N-dim space to smaller  *  and smaller N-dim rectangles (cells) until the number of points in a given  *  rectangle is&lt;=<code>maxPointsInLeafNode</code>.  The tree is  *  fully balanced, which means the leaf nodes will have between 50% and 100% of  *  the requested<code>maxPointsInLeafNode</code>.  Values that fall exactly  *  on a cell boundary may be in either cell.  *  *<p>The number of dimensions can be 1 to 255, but every byte[] value is fixed length.  *  *<p>  *  See<a href="https://www.cs.duke.edu/~pankaj/publications/papers/bkd-sstd.pdf">this paper</a> for details.  *  *<p>This consumes heap during writing: it allocates a<code>LongBitSet(numPoints)</code>,   *  and then uses up to the specified {@code maxMBSortInHeap} heap space for writing.  *  *<p>  *<b>NOTE</b>: This can write at most Integer.MAX_VALUE *<code>maxPointsInLeafNode</code> total points, and  *  * @lucene.experimental */
end_comment
begin_class
DECL|class|BKDWriter
specifier|public
class|class
name|BKDWriter
implements|implements
name|Closeable
block|{
DECL|field|CODEC_NAME
specifier|public
specifier|static
specifier|final
name|String
name|CODEC_NAME
init|=
literal|"BKD"
decl_stmt|;
DECL|field|VERSION_START
specifier|public
specifier|static
specifier|final
name|int
name|VERSION_START
init|=
literal|0
decl_stmt|;
DECL|field|VERSION_CURRENT
specifier|public
specifier|static
specifier|final
name|int
name|VERSION_CURRENT
init|=
name|VERSION_START
decl_stmt|;
comment|/** How many bytes each docs takes in the fixed-width offline format */
DECL|field|bytesPerDoc
specifier|private
specifier|final
name|int
name|bytesPerDoc
decl_stmt|;
comment|/** Default maximum number of point in each leaf block */
DECL|field|DEFAULT_MAX_POINTS_IN_LEAF_NODE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_POINTS_IN_LEAF_NODE
init|=
literal|1024
decl_stmt|;
comment|/** Default maximum heap to use, before spilling to (slower) disk */
DECL|field|DEFAULT_MAX_MB_SORT_IN_HEAP
specifier|public
specifier|static
specifier|final
name|float
name|DEFAULT_MAX_MB_SORT_IN_HEAP
init|=
literal|16.0f
decl_stmt|;
comment|/** Maximum number of dimensions */
DECL|field|MAX_DIMS
specifier|public
specifier|static
specifier|final
name|int
name|MAX_DIMS
init|=
literal|255
decl_stmt|;
comment|/** How many dimensions we are indexing */
DECL|field|numDims
specifier|protected
specifier|final
name|int
name|numDims
decl_stmt|;
comment|/** How many bytes each value in each dimension takes. */
DECL|field|bytesPerDim
specifier|protected
specifier|final
name|int
name|bytesPerDim
decl_stmt|;
comment|/** numDims * bytesPerDim */
DECL|field|packedBytesLength
specifier|protected
specifier|final
name|int
name|packedBytesLength
decl_stmt|;
DECL|field|tempDir
specifier|final
name|TrackingDirectoryWrapper
name|tempDir
decl_stmt|;
DECL|field|tempFileNamePrefix
specifier|final
name|String
name|tempFileNamePrefix
decl_stmt|;
DECL|field|scratchDiff
specifier|final
name|byte
index|[]
name|scratchDiff
decl_stmt|;
DECL|field|scratchPackedValue
specifier|final
name|byte
index|[]
name|scratchPackedValue
decl_stmt|;
DECL|field|scratch1
specifier|final
name|byte
index|[]
name|scratch1
decl_stmt|;
DECL|field|scratch2
specifier|final
name|byte
index|[]
name|scratch2
decl_stmt|;
DECL|field|offlinePointWriter
specifier|private
name|OfflinePointWriter
name|offlinePointWriter
decl_stmt|;
DECL|field|heapPointWriter
specifier|private
name|HeapPointWriter
name|heapPointWriter
decl_stmt|;
DECL|field|tempInput
specifier|private
name|IndexOutput
name|tempInput
decl_stmt|;
DECL|field|maxPointsInLeafNode
specifier|protected
specifier|final
name|int
name|maxPointsInLeafNode
decl_stmt|;
DECL|field|maxPointsSortInHeap
specifier|private
specifier|final
name|int
name|maxPointsSortInHeap
decl_stmt|;
DECL|field|pointCount
specifier|private
name|long
name|pointCount
decl_stmt|;
DECL|method|BKDWriter
specifier|public
name|BKDWriter
parameter_list|(
name|Directory
name|tempDir
parameter_list|,
name|String
name|tempFileNamePrefix
parameter_list|,
name|int
name|numDims
parameter_list|,
name|int
name|bytesPerDim
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|numDims
argument_list|,
name|bytesPerDim
argument_list|,
name|DEFAULT_MAX_POINTS_IN_LEAF_NODE
argument_list|,
name|DEFAULT_MAX_MB_SORT_IN_HEAP
argument_list|)
expr_stmt|;
block|}
DECL|method|BKDWriter
specifier|public
name|BKDWriter
parameter_list|(
name|Directory
name|tempDir
parameter_list|,
name|String
name|tempFileNamePrefix
parameter_list|,
name|int
name|numDims
parameter_list|,
name|int
name|bytesPerDim
parameter_list|,
name|int
name|maxPointsInLeafNode
parameter_list|,
name|double
name|maxMBSortInHeap
parameter_list|)
throws|throws
name|IOException
block|{
name|verifyParams
argument_list|(
name|numDims
argument_list|,
name|maxPointsInLeafNode
argument_list|,
name|maxMBSortInHeap
argument_list|)
expr_stmt|;
comment|// We use tracking dir to deal with removing files on exception, so each place that
comment|// creates temp files doesn't need crazy try/finally/sucess logic:
name|this
operator|.
name|tempDir
operator|=
operator|new
name|TrackingDirectoryWrapper
argument_list|(
name|tempDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|tempFileNamePrefix
operator|=
name|tempFileNamePrefix
expr_stmt|;
name|this
operator|.
name|maxPointsInLeafNode
operator|=
name|maxPointsInLeafNode
expr_stmt|;
name|this
operator|.
name|numDims
operator|=
name|numDims
expr_stmt|;
name|this
operator|.
name|bytesPerDim
operator|=
name|bytesPerDim
expr_stmt|;
name|packedBytesLength
operator|=
name|numDims
operator|*
name|bytesPerDim
expr_stmt|;
name|scratchDiff
operator|=
operator|new
name|byte
index|[
name|bytesPerDim
index|]
expr_stmt|;
name|scratchPackedValue
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
name|scratch1
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
name|scratch2
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
comment|// dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)
name|bytesPerDoc
operator|=
name|packedBytesLength
operator|+
name|RamUsageEstimator
operator|.
name|NUM_BYTES_LONG
operator|+
name|RamUsageEstimator
operator|.
name|NUM_BYTES_INT
expr_stmt|;
comment|// As we recurse, we compute temporary partitions of the data, halving the
comment|// number of points at each recursion.  Once there are few enough points,
comment|// we can switch to sorting in heap instead of offline (on disk).  At any
comment|// time in the recursion, we hold the number of points at that level, plus
comment|// all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X
comment|// what that level would consume, so we multiply by 0.5 to convert from
comment|// bytes to points here.  Each dimension has its own sorted partition, so
comment|// we must divide by numDims as wel.
name|maxPointsSortInHeap
operator|=
call|(
name|int
call|)
argument_list|(
literal|0.5
operator|*
operator|(
name|maxMBSortInHeap
operator|*
literal|1024
operator|*
literal|1024
operator|)
operator|/
operator|(
name|bytesPerDoc
operator|*
name|numDims
operator|)
argument_list|)
expr_stmt|;
comment|// Finally, we must be able to hold at least the leaf node in heap during build:
if|if
condition|(
name|maxPointsSortInHeap
operator|<
name|maxPointsInLeafNode
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxMBSortInHeap="
operator|+
name|maxMBSortInHeap
operator|+
literal|" only allows for maxPointsSortInHeap="
operator|+
name|maxPointsSortInHeap
operator|+
literal|", but this is less than maxPointsInLeafNode="
operator|+
name|maxPointsInLeafNode
operator|+
literal|"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode"
argument_list|)
throw|;
block|}
comment|// We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:
name|heapPointWriter
operator|=
operator|new
name|HeapPointWriter
argument_list|(
literal|16
argument_list|,
name|maxPointsSortInHeap
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
block|}
DECL|method|verifyParams
specifier|public
specifier|static
name|void
name|verifyParams
parameter_list|(
name|int
name|numDims
parameter_list|,
name|int
name|maxPointsInLeafNode
parameter_list|,
name|double
name|maxMBSortInHeap
parameter_list|)
block|{
comment|// We encode dim in a single byte in the splitPackedValues, but we only expose 4 bits for it now, in case we want to use
comment|// remaining 4 bits for another purpose later
if|if
condition|(
name|numDims
argument_list|<
literal|1
operator|||
name|numDims
argument_list|>
name|MAX_DIMS
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"numDims must be 1 .. "
operator|+
name|MAX_DIMS
operator|+
literal|" (got: "
operator|+
name|numDims
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxPointsInLeafNode
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxPointsInLeafNode must be> 0; got "
operator|+
name|maxPointsInLeafNode
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxPointsInLeafNode
operator|>
name|ArrayUtil
operator|.
name|MAX_ARRAY_LENGTH
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxPointsInLeafNode must be<= ArrayUtil.MAX_ARRAY_LENGTH (= "
operator|+
name|ArrayUtil
operator|.
name|MAX_ARRAY_LENGTH
operator|+
literal|"); got "
operator|+
name|maxPointsInLeafNode
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxMBSortInHeap
operator|<
literal|0.0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxMBSortInHeap must be>= 0.0 (got: "
operator|+
name|maxMBSortInHeap
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
comment|/** If the current segment has too many points then we switchover to temp files / offline sort. */
DECL|method|switchToOffline
specifier|private
name|void
name|switchToOffline
parameter_list|()
throws|throws
name|IOException
block|{
comment|// For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:
name|offlinePointWriter
operator|=
operator|new
name|OfflinePointWriter
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|tempInput
operator|=
name|offlinePointWriter
operator|.
name|out
expr_stmt|;
name|PointReader
name|reader
init|=
name|heapPointWriter
operator|.
name|getReader
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|pointCount
condition|;
name|i
operator|++
control|)
block|{
name|boolean
name|hasNext
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
assert|;
name|offlinePointWriter
operator|.
name|append
argument_list|(
name|reader
operator|.
name|packedValue
argument_list|()
argument_list|,
name|i
argument_list|,
name|heapPointWriter
operator|.
name|docIDs
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|heapPointWriter
operator|=
literal|null
expr_stmt|;
block|}
DECL|method|add
specifier|public
name|void
name|add
parameter_list|(
name|byte
index|[]
name|packedValue
parameter_list|,
name|int
name|docID
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|packedValue
operator|.
name|length
operator|!=
name|packedBytesLength
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"packedValue should be length="
operator|+
name|packedBytesLength
operator|+
literal|" (got: "
operator|+
name|packedValue
operator|.
name|length
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|pointCount
operator|>=
name|maxPointsSortInHeap
condition|)
block|{
if|if
condition|(
name|offlinePointWriter
operator|==
literal|null
condition|)
block|{
name|switchToOffline
argument_list|()
expr_stmt|;
block|}
name|offlinePointWriter
operator|.
name|append
argument_list|(
name|packedValue
argument_list|,
name|pointCount
argument_list|,
name|docID
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Not too many points added yet, continue using heap:
name|heapPointWriter
operator|.
name|append
argument_list|(
name|packedValue
argument_list|,
name|pointCount
argument_list|,
name|docID
argument_list|)
expr_stmt|;
block|}
name|pointCount
operator|++
expr_stmt|;
block|}
comment|// TODO: if we fixed each partition step to just record the file offset at the "split point", we could probably handle variable length
comment|// encoding and not have our own ByteSequencesReader/Writer
comment|/** If dim=-1 we sort by docID, else by that dim. */
DECL|method|sortHeapPointWriter
specifier|private
name|void
name|sortHeapPointWriter
parameter_list|(
specifier|final
name|HeapPointWriter
name|writer
parameter_list|,
name|int
name|start
parameter_list|,
name|int
name|length
parameter_list|,
name|int
name|dim
parameter_list|)
block|{
assert|assert
name|pointCount
operator|<
name|Integer
operator|.
name|MAX_VALUE
assert|;
comment|// All buffered points are still in heap; just do in-place sort:
operator|new
name|InPlaceMergeSorter
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|void
name|swap
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
name|int
name|docID
init|=
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
decl_stmt|;
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
operator|=
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
expr_stmt|;
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
operator|=
name|docID
expr_stmt|;
name|long
name|ord
init|=
name|writer
operator|.
name|ords
index|[
name|i
index|]
decl_stmt|;
name|writer
operator|.
name|ords
index|[
name|i
index|]
operator|=
name|writer
operator|.
name|ords
index|[
name|j
index|]
expr_stmt|;
name|writer
operator|.
name|ords
index|[
name|j
index|]
operator|=
name|ord
expr_stmt|;
comment|// scratch1 = values[i]
name|writer
operator|.
name|readPackedValue
argument_list|(
name|i
argument_list|,
name|scratch1
argument_list|)
expr_stmt|;
comment|// scratch2 = values[j]
name|writer
operator|.
name|readPackedValue
argument_list|(
name|j
argument_list|,
name|scratch2
argument_list|)
expr_stmt|;
comment|// values[i] = scratch2
name|writer
operator|.
name|writePackedValue
argument_list|(
name|i
argument_list|,
name|scratch2
argument_list|)
expr_stmt|;
comment|// values[j] = scratch1
name|writer
operator|.
name|writePackedValue
argument_list|(
name|j
argument_list|,
name|scratch1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|compare
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
name|writer
operator|.
name|readPackedValue
argument_list|(
name|i
argument_list|,
name|scratch1
argument_list|)
expr_stmt|;
name|writer
operator|.
name|readPackedValue
argument_list|(
name|j
argument_list|,
name|scratch2
argument_list|)
expr_stmt|;
name|int
name|cmp
init|=
name|BKDUtil
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|scratch1
argument_list|,
name|dim
argument_list|,
name|scratch2
argument_list|,
name|dim
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// Tie-break
name|cmp
operator|=
name|Integer
operator|.
name|compare
argument_list|(
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
argument_list|,
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
return|return
name|Long
operator|.
name|compare
argument_list|(
name|writer
operator|.
name|ords
index|[
name|i
index|]
argument_list|,
name|writer
operator|.
name|ords
index|[
name|j
index|]
argument_list|)
return|;
block|}
block|}
operator|.
name|sort
argument_list|(
name|start
argument_list|,
name|start
operator|+
name|length
argument_list|)
expr_stmt|;
block|}
DECL|method|sort
specifier|private
name|PointWriter
name|sort
parameter_list|(
name|int
name|dim
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|heapPointWriter
operator|!=
literal|null
condition|)
block|{
assert|assert
name|tempInput
operator|==
literal|null
assert|;
comment|// We never spilled the incoming points to disk, so now we sort in heap:
name|HeapPointWriter
name|sorted
decl_stmt|;
if|if
condition|(
name|dim
operator|==
literal|0
condition|)
block|{
comment|// First dim can re-use the current heap writer
name|sorted
operator|=
name|heapPointWriter
expr_stmt|;
block|}
else|else
block|{
comment|// Subsequent dims need a private copy
name|sorted
operator|=
operator|new
name|HeapPointWriter
argument_list|(
operator|(
name|int
operator|)
name|pointCount
argument_list|,
operator|(
name|int
operator|)
name|pointCount
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|sorted
operator|.
name|copyFrom
argument_list|(
name|heapPointWriter
argument_list|)
expr_stmt|;
block|}
name|sortHeapPointWriter
argument_list|(
name|sorted
argument_list|,
literal|0
argument_list|,
operator|(
name|int
operator|)
name|pointCount
argument_list|,
name|dim
argument_list|)
expr_stmt|;
name|sorted
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|sorted
return|;
block|}
else|else
block|{
comment|// Offline sort:
assert|assert
name|tempInput
operator|!=
literal|null
assert|;
specifier|final
name|ByteArrayDataInput
name|reader
init|=
operator|new
name|ByteArrayDataInput
argument_list|()
decl_stmt|;
name|Comparator
argument_list|<
name|BytesRef
argument_list|>
name|cmp
init|=
operator|new
name|Comparator
argument_list|<
name|BytesRef
argument_list|>
argument_list|()
block|{
specifier|private
specifier|final
name|ByteArrayDataInput
name|readerB
init|=
operator|new
name|ByteArrayDataInput
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|BytesRef
name|a
parameter_list|,
name|BytesRef
name|b
parameter_list|)
block|{
name|reader
operator|.
name|reset
argument_list|(
name|a
operator|.
name|bytes
argument_list|,
name|a
operator|.
name|offset
argument_list|,
name|a
operator|.
name|length
argument_list|)
expr_stmt|;
name|reader
operator|.
name|readBytes
argument_list|(
name|scratch1
argument_list|,
literal|0
argument_list|,
name|scratch1
operator|.
name|length
argument_list|)
expr_stmt|;
specifier|final
name|int
name|docIDA
init|=
name|reader
operator|.
name|readVInt
argument_list|()
decl_stmt|;
specifier|final
name|long
name|ordA
init|=
name|reader
operator|.
name|readVLong
argument_list|()
decl_stmt|;
name|reader
operator|.
name|reset
argument_list|(
name|b
operator|.
name|bytes
argument_list|,
name|b
operator|.
name|offset
argument_list|,
name|b
operator|.
name|length
argument_list|)
expr_stmt|;
name|reader
operator|.
name|readBytes
argument_list|(
name|scratch2
argument_list|,
literal|0
argument_list|,
name|scratch2
operator|.
name|length
argument_list|)
expr_stmt|;
specifier|final
name|int
name|docIDB
init|=
name|reader
operator|.
name|readVInt
argument_list|()
decl_stmt|;
specifier|final
name|long
name|ordB
init|=
name|reader
operator|.
name|readVLong
argument_list|()
decl_stmt|;
name|int
name|cmp
init|=
name|BKDUtil
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|scratch1
argument_list|,
name|dim
argument_list|,
name|scratch2
argument_list|,
name|dim
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// Tie-break
name|cmp
operator|=
name|Integer
operator|.
name|compare
argument_list|(
name|docIDA
argument_list|,
name|docIDB
argument_list|)
expr_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
return|return
name|Long
operator|.
name|compare
argument_list|(
name|ordA
argument_list|,
name|ordB
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|// TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:
name|IndexOutput
index|[]
name|lastWriter
init|=
operator|new
name|IndexOutput
index|[
literal|1
index|]
decl_stmt|;
name|OfflineSorter
name|sorter
init|=
operator|new
name|OfflineSorter
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|cmp
argument_list|)
block|{
comment|/** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */
annotation|@
name|Override
specifier|protected
name|ByteSequencesWriter
name|getWriter
parameter_list|(
name|IndexOutput
name|out
parameter_list|)
block|{
name|lastWriter
index|[
literal|0
index|]
operator|=
name|out
expr_stmt|;
return|return
operator|new
name|ByteSequencesWriter
argument_list|(
name|out
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|byte
index|[]
name|bytes
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|len
operator|!=
name|bytesPerDoc
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"len="
operator|+
name|len
operator|+
literal|" bytesPerDoc="
operator|+
name|bytesPerDoc
argument_list|)
throw|;
block|}
name|out
operator|.
name|writeBytes
argument_list|(
name|bytes
argument_list|,
name|off
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
block|}
return|;
block|}
comment|/** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */
annotation|@
name|Override
specifier|protected
name|ByteSequencesReader
name|getReader
parameter_list|(
name|IndexInput
name|in
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|ByteSequencesReader
argument_list|(
name|in
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|read
parameter_list|(
name|BytesRefBuilder
name|ref
parameter_list|)
throws|throws
name|IOException
block|{
name|ref
operator|.
name|grow
argument_list|(
name|bytesPerDoc
argument_list|)
expr_stmt|;
try|try
block|{
name|in
operator|.
name|readBytes
argument_list|(
name|ref
operator|.
name|bytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|bytesPerDoc
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|EOFException
name|eofe
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
name|ref
operator|.
name|setLength
argument_list|(
name|bytesPerDoc
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
return|;
block|}
block|}
decl_stmt|;
name|sorter
operator|.
name|sort
argument_list|(
name|tempInput
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
assert|assert
name|lastWriter
index|[
literal|0
index|]
operator|!=
literal|null
assert|;
return|return
operator|new
name|OfflinePointWriter
argument_list|(
name|tempDir
argument_list|,
name|lastWriter
index|[
literal|0
index|]
argument_list|,
name|packedBytesLength
argument_list|,
name|pointCount
argument_list|)
return|;
block|}
block|}
comment|/** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */
DECL|method|finish
specifier|public
name|long
name|finish
parameter_list|(
name|IndexOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
comment|//System.out.println("\nBKDTreeWriter.finish pointCount=" + pointCount + " out=" + out + " heapWriter=" + heapWriter);
comment|// TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recruse...)
comment|// Catch user silliness:
if|if
condition|(
name|heapPointWriter
operator|==
literal|null
operator|&&
name|tempInput
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"already finished"
argument_list|)
throw|;
block|}
if|if
condition|(
name|offlinePointWriter
operator|!=
literal|null
condition|)
block|{
name|offlinePointWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|LongBitSet
name|ordBitSet
init|=
operator|new
name|LongBitSet
argument_list|(
name|pointCount
argument_list|)
decl_stmt|;
name|long
name|countPerLeaf
init|=
name|pointCount
decl_stmt|;
name|long
name|innerNodeCount
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|countPerLeaf
operator|>
name|maxPointsInLeafNode
condition|)
block|{
name|countPerLeaf
operator|=
operator|(
name|countPerLeaf
operator|+
literal|1
operator|)
operator|/
literal|2
expr_stmt|;
name|innerNodeCount
operator|*=
literal|2
expr_stmt|;
block|}
comment|//System.out.println("innerNodeCount=" + innerNodeCount);
if|if
condition|(
literal|1
operator|+
literal|2
operator|*
name|innerNodeCount
operator|>=
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"too many nodes; increase maxPointsInLeafNode (currently "
operator|+
name|maxPointsInLeafNode
operator|+
literal|") and reindex"
argument_list|)
throw|;
block|}
name|innerNodeCount
operator|--
expr_stmt|;
name|int
name|numLeaves
init|=
call|(
name|int
call|)
argument_list|(
name|innerNodeCount
operator|+
literal|1
argument_list|)
decl_stmt|;
comment|// NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each
comment|// step of the recursion to recompute the split dim:
comment|// Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.
name|byte
index|[]
name|splitPackedValues
init|=
operator|new
name|byte
index|[
name|Math
operator|.
name|toIntExact
argument_list|(
name|numLeaves
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
argument_list|)
index|]
decl_stmt|;
comment|// +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)
name|long
index|[]
name|leafBlockFPs
init|=
operator|new
name|long
index|[
name|numLeaves
index|]
decl_stmt|;
comment|// Make sure the math above "worked":
assert|assert
name|pointCount
operator|/
name|numLeaves
operator|<=
name|maxPointsInLeafNode
operator|:
literal|"pointCount="
operator|+
name|pointCount
operator|+
literal|" numLeaves="
operator|+
name|numLeaves
operator|+
literal|" maxPointsInLeafNode="
operator|+
name|maxPointsInLeafNode
assert|;
comment|// Sort all docs once by each dimension:
name|PathSlice
index|[]
name|sortedPointWriters
init|=
operator|new
name|PathSlice
index|[
name|numDims
index|]
decl_stmt|;
name|byte
index|[]
name|minPacked
init|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
decl_stmt|;
name|byte
index|[]
name|maxPacked
init|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
decl_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|maxPacked
argument_list|,
operator|(
name|byte
operator|)
literal|0xff
argument_list|)
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|//long t0 = System.nanoTime();
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|sortedPointWriters
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|sort
argument_list|(
name|dim
argument_list|)
argument_list|,
literal|0
argument_list|,
name|pointCount
argument_list|)
expr_stmt|;
block|}
comment|//long t1 = System.nanoTime();
comment|//System.out.println("sort time: " + ((t1-t0)/1000000.0) + " msec");
if|if
condition|(
name|tempInput
operator|!=
literal|null
condition|)
block|{
name|tempDir
operator|.
name|deleteFile
argument_list|(
name|tempInput
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tempInput
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
assert|assert
name|heapPointWriter
operator|!=
literal|null
assert|;
name|heapPointWriter
operator|=
literal|null
expr_stmt|;
block|}
name|build
argument_list|(
literal|1
argument_list|,
name|numLeaves
argument_list|,
name|sortedPointWriters
argument_list|,
name|ordBitSet
argument_list|,
name|out
argument_list|,
name|minPacked
argument_list|,
name|maxPacked
argument_list|,
name|splitPackedValues
argument_list|,
name|leafBlockFPs
argument_list|)
expr_stmt|;
for|for
control|(
name|PathSlice
name|slice
range|:
name|sortedPointWriters
control|)
block|{
name|slice
operator|.
name|writer
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
comment|// If no exception, we should have cleaned everything up:
assert|assert
name|tempDir
operator|.
name|getCreatedFiles
argument_list|()
operator|.
name|isEmpty
argument_list|()
assert|;
comment|//long t2 = System.nanoTime();
comment|//System.out.println("write time: " + ((t2-t1)/1000000.0) + " msec");
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|success
operator|==
literal|false
condition|)
block|{
name|IOUtils
operator|.
name|deleteFilesIgnoringExceptions
argument_list|(
name|tempDir
argument_list|,
name|tempDir
operator|.
name|getCreatedFiles
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|//System.out.println("Total nodes: " + innerNodeCount);
comment|// Write index:
name|long
name|indexFP
init|=
name|out
operator|.
name|getFilePointer
argument_list|()
decl_stmt|;
name|writeIndex
argument_list|(
name|out
argument_list|,
name|leafBlockFPs
argument_list|,
name|splitPackedValues
argument_list|)
expr_stmt|;
return|return
name|indexFP
return|;
block|}
comment|/** Subclass can change how it writes the index. */
DECL|method|writeIndex
specifier|protected
name|void
name|writeIndex
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|long
index|[]
name|leafBlockFPs
parameter_list|,
name|byte
index|[]
name|splitPackedValues
parameter_list|)
throws|throws
name|IOException
block|{
name|CodecUtil
operator|.
name|writeHeader
argument_list|(
name|out
argument_list|,
name|CODEC_NAME
argument_list|,
name|VERSION_CURRENT
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|numDims
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|maxPointsInLeafNode
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|bytesPerDim
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|leafBlockFPs
operator|.
name|length
argument_list|)
expr_stmt|;
comment|// TODO: for 1D case, don't waste the first byte of each split value (it's always 0)
comment|// NOTE: splitPackedValues[0] is unused, because nodeID is 1-based:
name|out
operator|.
name|writeBytes
argument_list|(
name|splitPackedValues
argument_list|,
literal|0
argument_list|,
name|splitPackedValues
operator|.
name|length
argument_list|)
expr_stmt|;
name|long
name|lastFP
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|leafBlockFPs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|long
name|delta
init|=
name|leafBlockFPs
index|[
name|i
index|]
operator|-
name|lastFP
decl_stmt|;
name|out
operator|.
name|writeVLong
argument_list|(
name|delta
argument_list|)
expr_stmt|;
name|lastFP
operator|=
name|leafBlockFPs
index|[
name|i
index|]
expr_stmt|;
block|}
block|}
DECL|method|writeLeafBlockDocs
specifier|protected
name|void
name|writeLeafBlockDocs
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|int
index|[]
name|docIDs
parameter_list|,
name|int
name|start
parameter_list|,
name|int
name|count
parameter_list|)
throws|throws
name|IOException
block|{
name|out
operator|.
name|writeVInt
argument_list|(
name|count
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|out
operator|.
name|writeInt
argument_list|(
name|docIDs
index|[
name|start
operator|+
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|writeLeafBlockPackedValue
specifier|protected
name|void
name|writeLeafBlockPackedValue
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|byte
index|[]
name|bytes
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|out
operator|.
name|writeBytes
argument_list|(
name|bytes
argument_list|,
literal|0
argument_list|,
name|length
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|close
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|tempInput
operator|!=
literal|null
condition|)
block|{
comment|// NOTE: this should only happen on exception, e.g. caller calls close w/o calling finish:
try|try
block|{
name|tempInput
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|tempDir
operator|.
name|deleteFile
argument_list|(
name|tempInput
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tempInput
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/** Sliced reference to points in an OfflineSorter.ByteSequencesWriter file. */
DECL|class|PathSlice
specifier|private
specifier|static
specifier|final
class|class
name|PathSlice
block|{
DECL|field|writer
specifier|final
name|PointWriter
name|writer
decl_stmt|;
DECL|field|start
specifier|final
name|long
name|start
decl_stmt|;
DECL|field|count
specifier|final
name|long
name|count
decl_stmt|;
DECL|method|PathSlice
specifier|public
name|PathSlice
parameter_list|(
name|PointWriter
name|writer
parameter_list|,
name|long
name|start
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|this
operator|.
name|writer
operator|=
name|writer
expr_stmt|;
name|this
operator|.
name|start
operator|=
name|start
expr_stmt|;
name|this
operator|.
name|count
operator|=
name|count
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|toString
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"PathSlice(start="
operator|+
name|start
operator|+
literal|" count="
operator|+
name|count
operator|+
literal|" writer="
operator|+
name|writer
operator|+
literal|")"
return|;
block|}
block|}
comment|/** Marks bits for the ords (points) that belong in the right sub tree (those docs that have values>= the splitValue). */
DECL|method|markRightTree
specifier|private
name|byte
index|[]
name|markRightTree
parameter_list|(
name|long
name|rightCount
parameter_list|,
name|int
name|splitDim
parameter_list|,
name|PathSlice
name|source
parameter_list|,
name|LongBitSet
name|ordBitSet
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Now we mark ords that fall into the right half, so we can partition on all other dims that are not the split dim:
assert|assert
name|ordBitSet
operator|.
name|cardinality
argument_list|()
operator|==
literal|0
operator|:
literal|"cardinality="
operator|+
name|ordBitSet
operator|.
name|cardinality
argument_list|()
assert|;
comment|// Read the split value, then mark all ords in the right tree (larger than the split value):
try|try
init|(
name|PointReader
name|reader
init|=
name|source
operator|.
name|writer
operator|.
name|getReader
argument_list|(
name|source
operator|.
name|start
operator|+
name|source
operator|.
name|count
operator|-
name|rightCount
argument_list|)
init|)
block|{
name|boolean
name|result
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|result
assert|;
name|System
operator|.
name|arraycopy
argument_list|(
name|reader
operator|.
name|packedValue
argument_list|()
argument_list|,
name|splitDim
operator|*
name|bytesPerDim
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
name|ordBitSet
operator|.
name|set
argument_list|(
name|reader
operator|.
name|ord
argument_list|()
argument_list|)
expr_stmt|;
comment|// Start at 1 because we already did the first value above (so we could keep the split value):
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|rightCount
condition|;
name|i
operator|++
control|)
block|{
name|result
operator|=
name|reader
operator|.
name|next
argument_list|()
expr_stmt|;
assert|assert
name|result
assert|;
name|ordBitSet
operator|.
name|set
argument_list|(
name|reader
operator|.
name|ord
argument_list|()
argument_list|)
expr_stmt|;
block|}
assert|assert
name|rightCount
operator|==
name|ordBitSet
operator|.
name|cardinality
argument_list|()
operator|:
literal|"rightCount="
operator|+
name|rightCount
operator|+
literal|" cardinality="
operator|+
name|ordBitSet
operator|.
name|cardinality
argument_list|()
assert|;
block|}
return|return
name|scratch1
return|;
block|}
comment|/** Called only in assert */
DECL|method|valueInBounds
specifier|private
name|boolean
name|valueInBounds
parameter_list|(
name|byte
index|[]
name|packedValue
parameter_list|,
name|byte
index|[]
name|minPackedValue
parameter_list|,
name|byte
index|[]
name|maxPackedValue
parameter_list|)
block|{
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
if|if
condition|(
name|BKDUtil
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|packedValue
argument_list|,
name|dim
argument_list|,
name|minPackedValue
argument_list|,
name|dim
argument_list|)
operator|<
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|BKDUtil
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|packedValue
argument_list|,
name|dim
argument_list|,
name|maxPackedValue
argument_list|,
name|dim
argument_list|)
operator|>
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|// TODO: make this protected when we want to subclass to play with different splitting criteria
DECL|method|split
specifier|private
name|int
name|split
parameter_list|(
name|byte
index|[]
name|minPackedValue
parameter_list|,
name|byte
index|[]
name|maxPackedValue
parameter_list|)
block|{
comment|// Find which dim has the largest span so we can split on it:
name|int
name|splitDim
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|BKDUtil
operator|.
name|subtract
argument_list|(
name|bytesPerDim
argument_list|,
name|dim
argument_list|,
name|maxPackedValue
argument_list|,
name|minPackedValue
argument_list|,
name|scratchDiff
argument_list|)
expr_stmt|;
if|if
condition|(
name|splitDim
operator|==
operator|-
literal|1
operator|||
name|BKDUtil
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|scratchDiff
argument_list|,
literal|0
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|)
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|scratchDiff
argument_list|,
literal|0
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
name|splitDim
operator|=
name|dim
expr_stmt|;
block|}
block|}
comment|//System.out.println("SPLIT: " + splitDim);
return|return
name|splitDim
return|;
block|}
comment|/** Only called in the 1D case, to pull a partition back into heap once    *  the point count is low enough while recursing. */
DECL|method|switchToHeap
specifier|private
name|PathSlice
name|switchToHeap
parameter_list|(
name|PathSlice
name|source
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|count
init|=
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|count
argument_list|)
decl_stmt|;
try|try
init|(
name|PointWriter
name|writer
init|=
operator|new
name|HeapPointWriter
argument_list|(
name|count
argument_list|,
name|count
argument_list|,
name|packedBytesLength
argument_list|)
init|;
name|PointReader
name|reader
operator|=
name|source
operator|.
name|writer
operator|.
name|getReader
argument_list|(
name|source
operator|.
name|start
argument_list|)
init|;
init|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|boolean
name|hasNext
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
assert|;
name|writer
operator|.
name|append
argument_list|(
name|reader
operator|.
name|packedValue
argument_list|()
argument_list|,
name|reader
operator|.
name|ord
argument_list|()
argument_list|,
name|reader
operator|.
name|docID
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|PathSlice
argument_list|(
name|writer
argument_list|,
literal|0
argument_list|,
name|count
argument_list|)
return|;
block|}
block|}
comment|/** The array (sized numDims) of PathSlice describe the cell we have currently recursed to. */
DECL|method|build
specifier|private
name|void
name|build
parameter_list|(
name|int
name|nodeID
parameter_list|,
name|int
name|leafNodeOffset
parameter_list|,
name|PathSlice
index|[]
name|slices
parameter_list|,
name|LongBitSet
name|ordBitSet
parameter_list|,
name|IndexOutput
name|out
parameter_list|,
name|byte
index|[]
name|minPackedValue
parameter_list|,
name|byte
index|[]
name|maxPackedValue
parameter_list|,
name|byte
index|[]
name|splitPackedValues
parameter_list|,
name|long
index|[]
name|leafBlockFPs
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|PathSlice
name|slice
range|:
name|slices
control|)
block|{
assert|assert
name|slice
operator|.
name|count
operator|==
name|slices
index|[
literal|0
index|]
operator|.
name|count
assert|;
block|}
if|if
condition|(
name|numDims
operator|==
literal|1
operator|&&
name|slices
index|[
literal|0
index|]
operator|.
name|writer
operator|instanceof
name|OfflinePointWriter
operator|&&
name|slices
index|[
literal|0
index|]
operator|.
name|count
operator|<=
name|maxPointsSortInHeap
condition|)
block|{
comment|// Special case for 1D, to cutover to heap once we recurse deeply enough:
name|slices
index|[
literal|0
index|]
operator|=
name|switchToHeap
argument_list|(
name|slices
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nodeID
operator|>=
name|leafNodeOffset
condition|)
block|{
comment|// Leaf node: write block
name|PathSlice
name|source
init|=
name|slices
index|[
literal|0
index|]
decl_stmt|;
if|if
condition|(
name|source
operator|.
name|writer
operator|instanceof
name|HeapPointWriter
operator|==
literal|false
condition|)
block|{
comment|// Adversarial cases can cause this, e.g. very lopsided data, all equal points
name|source
operator|=
name|switchToHeap
argument_list|(
name|source
argument_list|)
expr_stmt|;
block|}
comment|// We ensured that maxPointsSortInHeap was>= maxPointsInLeafNode, so we better be in heap at this point:
name|HeapPointWriter
name|heapSource
init|=
operator|(
name|HeapPointWriter
operator|)
name|source
operator|.
name|writer
decl_stmt|;
comment|// Save the block file pointer:
name|leafBlockFPs
index|[
name|nodeID
operator|-
name|leafNodeOffset
index|]
operator|=
name|out
operator|.
name|getFilePointer
argument_list|()
expr_stmt|;
comment|// Write docIDs first, as their own chunk, so that at intersect time we can add all docIDs w/o
comment|// loading the values:
name|writeLeafBlockDocs
argument_list|(
name|out
argument_list|,
name|heapSource
operator|.
name|docIDs
argument_list|,
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|start
argument_list|)
argument_list|,
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|count
argument_list|)
argument_list|)
expr_stmt|;
comment|// TODO: we should delta compress / only write suffix bytes, like terms dict (the values will all be "close together" since we are at
comment|// a leaf cell):
comment|// Now write the full values:
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|source
operator|.
name|count
condition|;
name|i
operator|++
control|)
block|{
comment|// TODO: we could do bulk copying here, avoiding the intermediate copy:
name|heapSource
operator|.
name|readPackedValue
argument_list|(
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|start
operator|+
name|i
argument_list|)
argument_list|,
name|scratchPackedValue
argument_list|)
expr_stmt|;
comment|// Make sure this value does in fact fall within this leaf cell:
assert|assert
name|valueInBounds
argument_list|(
name|scratchPackedValue
argument_list|,
name|minPackedValue
argument_list|,
name|maxPackedValue
argument_list|)
assert|;
name|writeLeafBlockPackedValue
argument_list|(
name|out
argument_list|,
name|scratchPackedValue
argument_list|,
literal|0
argument_list|,
name|scratchPackedValue
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Inner node: partition/recurse
name|int
name|splitDim
init|=
name|split
argument_list|(
name|minPackedValue
argument_list|,
name|maxPackedValue
argument_list|)
decl_stmt|;
name|PathSlice
name|source
init|=
name|slices
index|[
name|splitDim
index|]
decl_stmt|;
assert|assert
name|nodeID
operator|<
name|splitPackedValues
operator|.
name|length
operator|:
literal|"nodeID="
operator|+
name|nodeID
operator|+
literal|" splitValues.length="
operator|+
name|splitPackedValues
operator|.
name|length
assert|;
comment|// How many points will be in the left tree:
name|long
name|rightCount
init|=
name|source
operator|.
name|count
operator|/
literal|2
decl_stmt|;
name|long
name|leftCount
init|=
name|source
operator|.
name|count
operator|-
name|rightCount
decl_stmt|;
name|byte
index|[]
name|splitValue
init|=
name|markRightTree
argument_list|(
name|rightCount
argument_list|,
name|splitDim
argument_list|,
name|source
argument_list|,
name|ordBitSet
argument_list|)
decl_stmt|;
name|int
name|address
init|=
name|nodeID
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
decl_stmt|;
name|splitPackedValues
index|[
name|address
index|]
operator|=
operator|(
name|byte
operator|)
name|splitDim
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|splitValue
argument_list|,
literal|0
argument_list|,
name|splitPackedValues
argument_list|,
name|address
operator|+
literal|1
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
comment|// Partition all PathSlice that are not the split dim into sorted left and right sets, so we can recurse:
name|PathSlice
index|[]
name|leftSlices
init|=
operator|new
name|PathSlice
index|[
name|numDims
index|]
decl_stmt|;
name|PathSlice
index|[]
name|rightSlices
init|=
operator|new
name|PathSlice
index|[
name|numDims
index|]
decl_stmt|;
name|byte
index|[]
name|minSplitPackedValue
init|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|minPackedValue
argument_list|,
literal|0
argument_list|,
name|minSplitPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|byte
index|[]
name|maxSplitPackedValue
init|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|maxPackedValue
argument_list|,
literal|0
argument_list|,
name|maxSplitPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
if|if
condition|(
name|dim
operator|==
name|splitDim
condition|)
block|{
comment|// No need to partition on this dim since it's a simple slice of the incoming already sorted slice.
name|leftSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|source
operator|.
name|writer
argument_list|,
name|source
operator|.
name|start
argument_list|,
name|leftCount
argument_list|)
expr_stmt|;
name|rightSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|source
operator|.
name|writer
argument_list|,
name|source
operator|.
name|start
operator|+
name|leftCount
argument_list|,
name|rightCount
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|splitValue
argument_list|,
literal|0
argument_list|,
name|minSplitPackedValue
argument_list|,
name|dim
operator|*
name|bytesPerDim
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|splitValue
argument_list|,
literal|0
argument_list|,
name|maxSplitPackedValue
argument_list|,
name|dim
operator|*
name|bytesPerDim
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
continue|continue;
block|}
try|try
init|(
name|PointWriter
name|leftPointWriter
init|=
name|getPointWriter
argument_list|(
name|leftCount
argument_list|)
init|;              PointWriter rightPointWriter = getPointWriter(source.count - leftCount)
empty_stmt|;
name|PointReader
name|reader
init|=
name|slices
index|[
name|dim
index|]
operator|.
name|writer
operator|.
name|getReader
argument_list|(
name|slices
index|[
name|dim
index|]
operator|.
name|start
argument_list|)
decl_stmt|;
block|)
block|{
comment|// Partition this source according to how the splitDim split the values:
name|int
name|nextRightCount
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|source
operator|.
name|count
condition|;
name|i
operator|++
control|)
block|{
name|boolean
name|result
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|result
assert|;
name|byte
index|[]
name|packedValue
init|=
name|reader
operator|.
name|packedValue
argument_list|()
decl_stmt|;
name|long
name|ord
init|=
name|reader
operator|.
name|ord
argument_list|()
decl_stmt|;
name|int
name|docID
init|=
name|reader
operator|.
name|docID
argument_list|()
decl_stmt|;
if|if
condition|(
name|ordBitSet
operator|.
name|get
argument_list|(
name|ord
argument_list|)
condition|)
block|{
name|rightPointWriter
operator|.
name|append
argument_list|(
name|packedValue
argument_list|,
name|ord
argument_list|,
name|docID
argument_list|)
expr_stmt|;
name|nextRightCount
operator|++
expr_stmt|;
block|}
else|else
block|{
name|leftPointWriter
operator|.
name|append
argument_list|(
name|packedValue
argument_list|,
name|ord
argument_list|,
name|docID
argument_list|)
expr_stmt|;
block|}
block|}
name|leftSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|leftPointWriter
argument_list|,
literal|0
argument_list|,
name|leftCount
argument_list|)
expr_stmt|;
name|rightSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|rightPointWriter
argument_list|,
literal|0
argument_list|,
name|rightCount
argument_list|)
expr_stmt|;
assert|assert
name|rightCount
operator|==
name|nextRightCount
operator|:
literal|"rightCount="
operator|+
name|rightCount
operator|+
literal|" nextRightCount="
operator|+
name|nextRightCount
assert|;
block|}
block|}
name|ordBitSet
operator|.
name|clear
argument_list|(
literal|0
argument_list|,
name|pointCount
argument_list|)
expr_stmt|;
comment|// Recurse on left tree:
name|build
argument_list|(
literal|2
operator|*
name|nodeID
argument_list|,
name|leafNodeOffset
argument_list|,
name|leftSlices
argument_list|,
name|ordBitSet
argument_list|,
name|out
argument_list|,
name|minPackedValue
argument_list|,
name|maxSplitPackedValue
argument_list|,
name|splitPackedValues
argument_list|,
name|leafBlockFPs
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
comment|// Don't destroy the dim we split on because we just re-used what our caller above gave us for that dim:
if|if
condition|(
name|dim
operator|!=
name|splitDim
condition|)
block|{
name|leftSlices
index|[
name|dim
index|]
operator|.
name|writer
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
block|}
comment|// TODO: we could "tail recurse" here?  have our parent discard its refs as we recurse right?
comment|// Recurse on right tree:
name|build
argument_list|(
literal|2
operator|*
name|nodeID
operator|+
literal|1
argument_list|,
name|leafNodeOffset
argument_list|,
name|rightSlices
argument_list|,
name|ordBitSet
argument_list|,
name|out
argument_list|,
name|minSplitPackedValue
argument_list|,
name|maxPackedValue
argument_list|,
name|splitPackedValues
argument_list|,
name|leafBlockFPs
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
comment|// Don't destroy the dim we split on because we just re-used what our caller above gave us for that dim:
if|if
condition|(
name|dim
operator|!=
name|splitDim
condition|)
block|{
name|rightSlices
index|[
name|dim
index|]
operator|.
name|writer
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class
begin_function
DECL|method|getPointWriter
name|PointWriter
name|getPointWriter
parameter_list|(
name|long
name|count
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|count
operator|<=
name|maxPointsSortInHeap
condition|)
block|{
name|int
name|size
init|=
name|Math
operator|.
name|toIntExact
argument_list|(
name|count
argument_list|)
decl_stmt|;
return|return
operator|new
name|HeapPointWriter
argument_list|(
name|size
argument_list|,
name|size
argument_list|,
name|packedBytesLength
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|OfflinePointWriter
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|packedBytesLength
argument_list|)
return|;
block|}
block|}
end_function
unit|}
end_unit
