begin_unit
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.lucene.util.bkd
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|bkd
package|;
end_package
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|CodecUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MergeState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|ByteArrayDataInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|ChecksumIndexInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IOContext
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexOutput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|TrackingDirectoryWrapper
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ArrayUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|FixedBitSet
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IOUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntroSorter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|LongBitSet
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|NumericUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|OfflineSorter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|PriorityQueue
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|StringHelper
import|;
end_import
begin_comment
comment|// TODO
end_comment
begin_comment
comment|//   - the compression is somewhat stupid now (delta vInt for 1024 docIDs, no compression for the byte[] values even though they have high locality)
end_comment
begin_comment
comment|//   - allow variable length byte[] (across docs and dims), but this is quite a bit more hairy
end_comment
begin_comment
comment|//   - we could also index "auto-prefix terms" here, and use better compression, and maybe only use for the "fully contained" case so we'd
end_comment
begin_comment
comment|//     only index docIDs
end_comment
begin_comment
comment|//   - the index could be efficiently encoded as an FST, so we don't have wasteful
end_comment
begin_comment
comment|//     (monotonic) long[] leafBlockFPs; or we could use MonotonicLongValues ... but then
end_comment
begin_comment
comment|//     the index is already plenty small: 60M OSM points --> 1.1 MB with 128 points
end_comment
begin_comment
comment|//     per leaf, and you can reduce that by putting more points per leaf
end_comment
begin_comment
comment|//   - we could use threads while building; the higher nodes are very parallelizable
end_comment
begin_comment
comment|/** Recursively builds a block KD-tree to assign all incoming points in N-dim space to smaller  *  and smaller N-dim rectangles (cells) until the number of points in a given  *  rectangle is&lt;=<code>maxPointsInLeafNode</code>.  The tree is  *  fully balanced, which means the leaf nodes will have between 50% and 100% of  *  the requested<code>maxPointsInLeafNode</code>.  Values that fall exactly  *  on a cell boundary may be in either cell.  *  *<p>The number of dimensions can be 1 to 255, but every byte[] value is fixed length.  *  *<p>  *  See<a href="https://www.cs.duke.edu/~pankaj/publications/papers/bkd-sstd.pdf">this paper</a> for details.  *  *<p>This consumes heap during writing: it allocates a<code>LongBitSet(numPoints)</code>,   *  and then uses up to the specified {@code maxMBSortInHeap} heap space for writing.  *  *<p>  *<b>NOTE</b>: This can write at most Integer.MAX_VALUE *<code>maxPointsInLeafNode</code> total points, and  *  * @lucene.experimental */
end_comment
begin_class
DECL|class|BKDWriter
specifier|public
class|class
name|BKDWriter
implements|implements
name|Closeable
block|{
DECL|field|CODEC_NAME
specifier|public
specifier|static
specifier|final
name|String
name|CODEC_NAME
init|=
literal|"BKD"
decl_stmt|;
DECL|field|VERSION_START
specifier|public
specifier|static
specifier|final
name|int
name|VERSION_START
init|=
literal|0
decl_stmt|;
DECL|field|VERSION_CURRENT
specifier|public
specifier|static
specifier|final
name|int
name|VERSION_CURRENT
init|=
name|VERSION_START
decl_stmt|;
comment|/** How many bytes each docs takes in the fixed-width offline format */
DECL|field|bytesPerDoc
specifier|private
specifier|final
name|int
name|bytesPerDoc
decl_stmt|;
comment|/** Default maximum number of point in each leaf block */
DECL|field|DEFAULT_MAX_POINTS_IN_LEAF_NODE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_POINTS_IN_LEAF_NODE
init|=
literal|1024
decl_stmt|;
comment|/** Default maximum heap to use, before spilling to (slower) disk */
DECL|field|DEFAULT_MAX_MB_SORT_IN_HEAP
specifier|public
specifier|static
specifier|final
name|float
name|DEFAULT_MAX_MB_SORT_IN_HEAP
init|=
literal|16.0f
decl_stmt|;
comment|/** Maximum number of dimensions */
DECL|field|MAX_DIMS
specifier|public
specifier|static
specifier|final
name|int
name|MAX_DIMS
init|=
literal|8
decl_stmt|;
comment|/** How many dimensions we are indexing */
DECL|field|numDims
specifier|protected
specifier|final
name|int
name|numDims
decl_stmt|;
comment|/** How many bytes each value in each dimension takes. */
DECL|field|bytesPerDim
specifier|protected
specifier|final
name|int
name|bytesPerDim
decl_stmt|;
comment|/** numDims * bytesPerDim */
DECL|field|packedBytesLength
specifier|protected
specifier|final
name|int
name|packedBytesLength
decl_stmt|;
DECL|field|tempDir
specifier|final
name|TrackingDirectoryWrapper
name|tempDir
decl_stmt|;
DECL|field|tempFileNamePrefix
specifier|final
name|String
name|tempFileNamePrefix
decl_stmt|;
DECL|field|maxMBSortInHeap
specifier|final
name|double
name|maxMBSortInHeap
decl_stmt|;
DECL|field|scratchDiff
specifier|final
name|byte
index|[]
name|scratchDiff
decl_stmt|;
DECL|field|scratch1
specifier|final
name|byte
index|[]
name|scratch1
decl_stmt|;
DECL|field|scratch2
specifier|final
name|byte
index|[]
name|scratch2
decl_stmt|;
DECL|field|scratchBytesRef
specifier|final
name|BytesRef
name|scratchBytesRef
init|=
operator|new
name|BytesRef
argument_list|()
decl_stmt|;
DECL|field|commonPrefixLengths
specifier|final
name|int
index|[]
name|commonPrefixLengths
decl_stmt|;
DECL|field|docsSeen
specifier|protected
specifier|final
name|FixedBitSet
name|docsSeen
decl_stmt|;
DECL|field|offlinePointWriter
specifier|private
name|OfflinePointWriter
name|offlinePointWriter
decl_stmt|;
DECL|field|heapPointWriter
specifier|private
name|HeapPointWriter
name|heapPointWriter
decl_stmt|;
DECL|field|tempInput
specifier|private
name|IndexOutput
name|tempInput
decl_stmt|;
DECL|field|maxPointsInLeafNode
specifier|protected
specifier|final
name|int
name|maxPointsInLeafNode
decl_stmt|;
DECL|field|maxPointsSortInHeap
specifier|private
specifier|final
name|int
name|maxPointsSortInHeap
decl_stmt|;
comment|/** Minimum per-dim values, packed */
DECL|field|minPackedValue
specifier|protected
specifier|final
name|byte
index|[]
name|minPackedValue
decl_stmt|;
comment|/** Maximum per-dim values, packed */
DECL|field|maxPackedValue
specifier|protected
specifier|final
name|byte
index|[]
name|maxPackedValue
decl_stmt|;
DECL|field|pointCount
specifier|protected
name|long
name|pointCount
decl_stmt|;
comment|/** true if we have so many values that we must write ords using long (8 bytes) instead of int (4 bytes) */
DECL|field|longOrds
specifier|private
specifier|final
name|boolean
name|longOrds
decl_stmt|;
comment|/** An upper bound on how many points the caller will add (includes deletions) */
DECL|field|totalPointCount
specifier|private
specifier|final
name|long
name|totalPointCount
decl_stmt|;
comment|/** True if every document has at most one value.  We specialize this case by not bothering to store the ord since it's redundant with docID.  */
DECL|field|singleValuePerDoc
specifier|private
specifier|final
name|boolean
name|singleValuePerDoc
decl_stmt|;
DECL|field|maxDoc
specifier|private
specifier|final
name|int
name|maxDoc
decl_stmt|;
DECL|method|BKDWriter
specifier|public
name|BKDWriter
parameter_list|(
name|int
name|maxDoc
parameter_list|,
name|Directory
name|tempDir
parameter_list|,
name|String
name|tempFileNamePrefix
parameter_list|,
name|int
name|numDims
parameter_list|,
name|int
name|bytesPerDim
parameter_list|,
name|long
name|totalPointCount
parameter_list|,
name|boolean
name|singleValuePerDoc
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|maxDoc
argument_list|,
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|numDims
argument_list|,
name|bytesPerDim
argument_list|,
name|DEFAULT_MAX_POINTS_IN_LEAF_NODE
argument_list|,
name|DEFAULT_MAX_MB_SORT_IN_HEAP
argument_list|,
name|totalPointCount
argument_list|,
name|singleValuePerDoc
argument_list|)
expr_stmt|;
block|}
DECL|method|BKDWriter
specifier|public
name|BKDWriter
parameter_list|(
name|int
name|maxDoc
parameter_list|,
name|Directory
name|tempDir
parameter_list|,
name|String
name|tempFileNamePrefix
parameter_list|,
name|int
name|numDims
parameter_list|,
name|int
name|bytesPerDim
parameter_list|,
name|int
name|maxPointsInLeafNode
parameter_list|,
name|double
name|maxMBSortInHeap
parameter_list|,
name|long
name|totalPointCount
parameter_list|,
name|boolean
name|singleValuePerDoc
parameter_list|)
throws|throws
name|IOException
block|{
name|verifyParams
argument_list|(
name|numDims
argument_list|,
name|maxPointsInLeafNode
argument_list|,
name|maxMBSortInHeap
argument_list|,
name|totalPointCount
argument_list|)
expr_stmt|;
comment|// We use tracking dir to deal with removing files on exception, so each place that
comment|// creates temp files doesn't need crazy try/finally/sucess logic:
name|this
operator|.
name|tempDir
operator|=
operator|new
name|TrackingDirectoryWrapper
argument_list|(
name|tempDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|tempFileNamePrefix
operator|=
name|tempFileNamePrefix
expr_stmt|;
name|this
operator|.
name|maxPointsInLeafNode
operator|=
name|maxPointsInLeafNode
expr_stmt|;
name|this
operator|.
name|numDims
operator|=
name|numDims
expr_stmt|;
name|this
operator|.
name|bytesPerDim
operator|=
name|bytesPerDim
expr_stmt|;
name|this
operator|.
name|totalPointCount
operator|=
name|totalPointCount
expr_stmt|;
name|this
operator|.
name|maxDoc
operator|=
name|maxDoc
expr_stmt|;
name|docsSeen
operator|=
operator|new
name|FixedBitSet
argument_list|(
name|maxDoc
argument_list|)
expr_stmt|;
name|packedBytesLength
operator|=
name|numDims
operator|*
name|bytesPerDim
expr_stmt|;
name|scratchDiff
operator|=
operator|new
name|byte
index|[
name|bytesPerDim
index|]
expr_stmt|;
name|scratchBytesRef
operator|.
name|length
operator|=
name|packedBytesLength
expr_stmt|;
name|scratch1
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
name|scratch2
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
name|commonPrefixLengths
operator|=
operator|new
name|int
index|[
name|numDims
index|]
expr_stmt|;
name|minPackedValue
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
name|maxPackedValue
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
comment|// If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).
name|longOrds
operator|=
name|totalPointCount
operator|>
name|Integer
operator|.
name|MAX_VALUE
expr_stmt|;
name|this
operator|.
name|singleValuePerDoc
operator|=
name|singleValuePerDoc
expr_stmt|;
comment|// dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)
if|if
condition|(
name|singleValuePerDoc
condition|)
block|{
comment|// Lucene only supports up to 2.1 docs, so we better not need longOrds in this case:
assert|assert
name|longOrds
operator|==
literal|false
assert|;
name|bytesPerDoc
operator|=
name|packedBytesLength
operator|+
name|Integer
operator|.
name|BYTES
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|longOrds
condition|)
block|{
name|bytesPerDoc
operator|=
name|packedBytesLength
operator|+
name|Long
operator|.
name|BYTES
operator|+
name|Integer
operator|.
name|BYTES
expr_stmt|;
block|}
else|else
block|{
name|bytesPerDoc
operator|=
name|packedBytesLength
operator|+
name|Integer
operator|.
name|BYTES
operator|+
name|Integer
operator|.
name|BYTES
expr_stmt|;
block|}
comment|// As we recurse, we compute temporary partitions of the data, halving the
comment|// number of points at each recursion.  Once there are few enough points,
comment|// we can switch to sorting in heap instead of offline (on disk).  At any
comment|// time in the recursion, we hold the number of points at that level, plus
comment|// all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X
comment|// what that level would consume, so we multiply by 0.5 to convert from
comment|// bytes to points here.  Each dimension has its own sorted partition, so
comment|// we must divide by numDims as wel.
name|maxPointsSortInHeap
operator|=
call|(
name|int
call|)
argument_list|(
literal|0.5
operator|*
operator|(
name|maxMBSortInHeap
operator|*
literal|1024
operator|*
literal|1024
operator|)
operator|/
operator|(
name|bytesPerDoc
operator|*
name|numDims
operator|)
argument_list|)
expr_stmt|;
comment|// Finally, we must be able to hold at least the leaf node in heap during build:
if|if
condition|(
name|maxPointsSortInHeap
operator|<
name|maxPointsInLeafNode
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxMBSortInHeap="
operator|+
name|maxMBSortInHeap
operator|+
literal|" only allows for maxPointsSortInHeap="
operator|+
name|maxPointsSortInHeap
operator|+
literal|", but this is less than maxPointsInLeafNode="
operator|+
name|maxPointsInLeafNode
operator|+
literal|"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode"
argument_list|)
throw|;
block|}
comment|// We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:
name|heapPointWriter
operator|=
operator|new
name|HeapPointWriter
argument_list|(
literal|16
argument_list|,
name|maxPointsSortInHeap
argument_list|,
name|packedBytesLength
argument_list|,
name|longOrds
argument_list|,
name|singleValuePerDoc
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxMBSortInHeap
operator|=
name|maxMBSortInHeap
expr_stmt|;
block|}
DECL|method|verifyParams
specifier|public
specifier|static
name|void
name|verifyParams
parameter_list|(
name|int
name|numDims
parameter_list|,
name|int
name|maxPointsInLeafNode
parameter_list|,
name|double
name|maxMBSortInHeap
parameter_list|,
name|long
name|totalPointCount
parameter_list|)
block|{
comment|// We encode dim in a single byte in the splitPackedValues, but we only expose 4 bits for it now, in case we want to use
comment|// remaining 4 bits for another purpose later
if|if
condition|(
name|numDims
argument_list|<
literal|1
operator|||
name|numDims
argument_list|>
name|MAX_DIMS
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"numDims must be 1 .. "
operator|+
name|MAX_DIMS
operator|+
literal|" (got: "
operator|+
name|numDims
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxPointsInLeafNode
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxPointsInLeafNode must be> 0; got "
operator|+
name|maxPointsInLeafNode
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxPointsInLeafNode
operator|>
name|ArrayUtil
operator|.
name|MAX_ARRAY_LENGTH
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxPointsInLeafNode must be<= ArrayUtil.MAX_ARRAY_LENGTH (= "
operator|+
name|ArrayUtil
operator|.
name|MAX_ARRAY_LENGTH
operator|+
literal|"); got "
operator|+
name|maxPointsInLeafNode
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxMBSortInHeap
operator|<
literal|0.0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxMBSortInHeap must be>= 0.0 (got: "
operator|+
name|maxMBSortInHeap
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|totalPointCount
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"totalPointCount must be>=0 (got: "
operator|+
name|totalPointCount
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
comment|/** If the current segment has too many points then we spill over to temp files / offline sort. */
DECL|method|spillToOffline
specifier|private
name|void
name|spillToOffline
parameter_list|()
throws|throws
name|IOException
block|{
comment|// For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:
name|offlinePointWriter
operator|=
operator|new
name|OfflinePointWriter
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|packedBytesLength
argument_list|,
name|longOrds
argument_list|,
literal|"spill"
argument_list|,
literal|0
argument_list|,
name|singleValuePerDoc
argument_list|)
expr_stmt|;
name|tempInput
operator|=
name|offlinePointWriter
operator|.
name|out
expr_stmt|;
name|PointReader
name|reader
init|=
name|heapPointWriter
operator|.
name|getReader
argument_list|(
literal|0
argument_list|,
name|pointCount
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|pointCount
condition|;
name|i
operator|++
control|)
block|{
name|boolean
name|hasNext
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
assert|;
name|offlinePointWriter
operator|.
name|append
argument_list|(
name|reader
operator|.
name|packedValue
argument_list|()
argument_list|,
name|i
argument_list|,
name|heapPointWriter
operator|.
name|docIDs
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|heapPointWriter
operator|=
literal|null
expr_stmt|;
block|}
DECL|method|add
specifier|public
name|void
name|add
parameter_list|(
name|byte
index|[]
name|packedValue
parameter_list|,
name|int
name|docID
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|packedValue
operator|.
name|length
operator|!=
name|packedBytesLength
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"packedValue should be length="
operator|+
name|packedBytesLength
operator|+
literal|" (got: "
operator|+
name|packedValue
operator|.
name|length
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|pointCount
operator|>=
name|maxPointsSortInHeap
condition|)
block|{
if|if
condition|(
name|offlinePointWriter
operator|==
literal|null
condition|)
block|{
name|spillToOffline
argument_list|()
expr_stmt|;
block|}
name|offlinePointWriter
operator|.
name|append
argument_list|(
name|packedValue
argument_list|,
name|pointCount
argument_list|,
name|docID
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Not too many points added yet, continue using heap:
name|heapPointWriter
operator|.
name|append
argument_list|(
name|packedValue
argument_list|,
name|pointCount
argument_list|,
name|docID
argument_list|)
expr_stmt|;
block|}
comment|// TODO: we could specialize for the 1D case:
if|if
condition|(
name|pointCount
operator|==
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|packedValue
argument_list|,
literal|0
argument_list|,
name|minPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|packedValue
argument_list|,
literal|0
argument_list|,
name|maxPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|int
name|offset
init|=
name|dim
operator|*
name|bytesPerDim
decl_stmt|;
if|if
condition|(
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|packedValue
argument_list|,
name|offset
argument_list|,
name|minPackedValue
argument_list|,
name|offset
argument_list|)
operator|<
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|packedValue
argument_list|,
name|offset
argument_list|,
name|minPackedValue
argument_list|,
name|offset
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|packedValue
argument_list|,
name|offset
argument_list|,
name|maxPackedValue
argument_list|,
name|offset
argument_list|)
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|packedValue
argument_list|,
name|offset
argument_list|,
name|maxPackedValue
argument_list|,
name|offset
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|pointCount
operator|++
expr_stmt|;
if|if
condition|(
name|pointCount
operator|>
name|totalPointCount
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"totalPointCount="
operator|+
name|totalPointCount
operator|+
literal|" was passed when we were created, but we just hit "
operator|+
name|pointCount
operator|+
literal|" values"
argument_list|)
throw|;
block|}
name|docsSeen
operator|.
name|set
argument_list|(
name|docID
argument_list|)
expr_stmt|;
block|}
comment|/** How many points have been added so far */
DECL|method|getPointCount
specifier|public
name|long
name|getPointCount
parameter_list|()
block|{
return|return
name|pointCount
return|;
block|}
DECL|class|MergeReader
specifier|private
specifier|static
class|class
name|MergeReader
block|{
DECL|field|bkd
specifier|final
name|BKDReader
name|bkd
decl_stmt|;
DECL|field|state
specifier|final
name|BKDReader
operator|.
name|IntersectState
name|state
decl_stmt|;
DECL|field|docMap
specifier|final
name|MergeState
operator|.
name|DocMap
name|docMap
decl_stmt|;
comment|/** Base offset for all our docIDs */
DECL|field|docIDBase
specifier|final
name|int
name|docIDBase
decl_stmt|;
comment|/** Current doc ID */
DECL|field|docID
specifier|public
name|int
name|docID
decl_stmt|;
comment|/** Which doc in this block we are up to */
DECL|field|docBlockUpto
specifier|private
name|int
name|docBlockUpto
decl_stmt|;
comment|/** How many docs in the current block */
DECL|field|docsInBlock
specifier|private
name|int
name|docsInBlock
decl_stmt|;
comment|/** Which leaf block we are up to */
DECL|field|blockID
specifier|private
name|int
name|blockID
decl_stmt|;
DECL|method|MergeReader
specifier|public
name|MergeReader
parameter_list|(
name|BKDReader
name|bkd
parameter_list|,
name|MergeState
operator|.
name|DocMap
name|docMap
parameter_list|,
name|int
name|docIDBase
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|bkd
operator|=
name|bkd
expr_stmt|;
name|state
operator|=
operator|new
name|BKDReader
operator|.
name|IntersectState
argument_list|(
name|bkd
operator|.
name|in
operator|.
name|clone
argument_list|()
argument_list|,
name|bkd
operator|.
name|numDims
argument_list|,
name|bkd
operator|.
name|packedBytesLength
argument_list|,
name|bkd
operator|.
name|maxPointsInLeafNode
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|this
operator|.
name|docMap
operator|=
name|docMap
expr_stmt|;
name|this
operator|.
name|docIDBase
operator|=
name|docIDBase
expr_stmt|;
name|long
name|minFP
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
comment|//System.out.println("MR.init " + this + " bkdreader=" + bkd + " leafBlockFPs.length=" + bkd.leafBlockFPs.length);
for|for
control|(
name|long
name|fp
range|:
name|bkd
operator|.
name|leafBlockFPs
control|)
block|{
name|minFP
operator|=
name|Math
operator|.
name|min
argument_list|(
name|minFP
argument_list|,
name|fp
argument_list|)
expr_stmt|;
comment|//System.out.println("  leaf fp=" + fp);
block|}
name|state
operator|.
name|in
operator|.
name|seek
argument_list|(
name|minFP
argument_list|)
expr_stmt|;
block|}
DECL|method|next
specifier|public
name|boolean
name|next
parameter_list|()
throws|throws
name|IOException
block|{
comment|//System.out.println("MR.next this=" + this);
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|docBlockUpto
operator|==
name|docsInBlock
condition|)
block|{
if|if
condition|(
name|blockID
operator|==
name|bkd
operator|.
name|leafBlockFPs
operator|.
name|length
condition|)
block|{
comment|//System.out.println("  done!");
return|return
literal|false
return|;
block|}
comment|//System.out.println("  new block @ fp=" + state.in.getFilePointer());
name|docsInBlock
operator|=
name|bkd
operator|.
name|readDocIDs
argument_list|(
name|state
operator|.
name|in
argument_list|,
name|state
operator|.
name|in
operator|.
name|getFilePointer
argument_list|()
argument_list|,
name|state
operator|.
name|scratchDocIDs
argument_list|)
expr_stmt|;
assert|assert
name|docsInBlock
operator|>
literal|0
assert|;
name|docBlockUpto
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|bkd
operator|.
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|int
name|prefix
init|=
name|state
operator|.
name|in
operator|.
name|readVInt
argument_list|()
decl_stmt|;
name|state
operator|.
name|commonPrefixLengths
index|[
name|dim
index|]
operator|=
name|prefix
expr_stmt|;
if|if
condition|(
name|prefix
operator|>
literal|0
condition|)
block|{
name|state
operator|.
name|in
operator|.
name|readBytes
argument_list|(
name|state
operator|.
name|scratchPackedValue
argument_list|,
name|dim
operator|*
name|bkd
operator|.
name|bytesPerDim
argument_list|,
name|prefix
argument_list|)
expr_stmt|;
block|}
block|}
name|blockID
operator|++
expr_stmt|;
block|}
name|int
name|oldDocID
init|=
name|state
operator|.
name|scratchDocIDs
index|[
name|docBlockUpto
operator|++
index|]
decl_stmt|;
name|int
name|mappedDocID
decl_stmt|;
if|if
condition|(
name|docMap
operator|==
literal|null
condition|)
block|{
name|mappedDocID
operator|=
name|oldDocID
expr_stmt|;
block|}
else|else
block|{
name|mappedDocID
operator|=
name|docMap
operator|.
name|get
argument_list|(
name|oldDocID
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|bkd
operator|.
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|int
name|prefix
init|=
name|state
operator|.
name|commonPrefixLengths
index|[
name|dim
index|]
decl_stmt|;
name|state
operator|.
name|in
operator|.
name|readBytes
argument_list|(
name|state
operator|.
name|scratchPackedValue
argument_list|,
name|dim
operator|*
name|bkd
operator|.
name|bytesPerDim
operator|+
name|prefix
argument_list|,
name|bkd
operator|.
name|bytesPerDim
operator|-
name|prefix
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mappedDocID
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// Not deleted!
name|docID
operator|=
name|mappedDocID
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
DECL|class|BKDMergeQueue
specifier|private
specifier|static
class|class
name|BKDMergeQueue
extends|extends
name|PriorityQueue
argument_list|<
name|MergeReader
argument_list|>
block|{
DECL|field|bytesPerDim
specifier|private
specifier|final
name|int
name|bytesPerDim
decl_stmt|;
DECL|method|BKDMergeQueue
specifier|public
name|BKDMergeQueue
parameter_list|(
name|int
name|bytesPerDim
parameter_list|,
name|int
name|maxSize
parameter_list|)
block|{
name|super
argument_list|(
name|maxSize
argument_list|)
expr_stmt|;
name|this
operator|.
name|bytesPerDim
operator|=
name|bytesPerDim
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|lessThan
specifier|public
name|boolean
name|lessThan
parameter_list|(
name|MergeReader
name|a
parameter_list|,
name|MergeReader
name|b
parameter_list|)
block|{
assert|assert
name|a
operator|!=
name|b
assert|;
name|int
name|cmp
init|=
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|a
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|<
literal|0
condition|)
block|{
return|return
literal|true
return|;
block|}
elseif|else
if|if
condition|(
name|cmp
operator|>
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// Tie break by sorting smaller docIDs earlier:
return|return
name|a
operator|.
name|docIDBase
operator|<
name|b
operator|.
name|docIDBase
return|;
block|}
block|}
comment|/** More efficient bulk-add for incoming {@link BKDReader}s.  This does a merge sort of the already    *  sorted values and currently only works when numDims==1.  This returns -1 if all documents containing    *  dimensional values were deleted. */
DECL|method|merge
specifier|public
name|long
name|merge
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|List
argument_list|<
name|MergeState
operator|.
name|DocMap
argument_list|>
name|docMaps
parameter_list|,
name|List
argument_list|<
name|BKDReader
argument_list|>
name|readers
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|docIDBases
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|numDims
operator|!=
literal|1
condition|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"numDims must be 1 but got "
operator|+
name|numDims
argument_list|)
throw|;
block|}
if|if
condition|(
name|pointCount
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"cannot mix add and merge"
argument_list|)
throw|;
block|}
comment|//System.out.println("BKDW.merge segs=" + readers.size());
comment|// Catch user silliness:
if|if
condition|(
name|heapPointWriter
operator|==
literal|null
operator|&&
name|tempInput
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"already finished"
argument_list|)
throw|;
block|}
comment|// Mark that we already finished:
name|heapPointWriter
operator|=
literal|null
expr_stmt|;
assert|assert
name|docMaps
operator|==
literal|null
operator|||
name|readers
operator|.
name|size
argument_list|()
operator|==
name|docMaps
operator|.
name|size
argument_list|()
assert|;
name|BKDMergeQueue
name|queue
init|=
operator|new
name|BKDMergeQueue
argument_list|(
name|bytesPerDim
argument_list|,
name|readers
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|readers
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|BKDReader
name|bkd
init|=
name|readers
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|MergeState
operator|.
name|DocMap
name|docMap
decl_stmt|;
if|if
condition|(
name|docMaps
operator|==
literal|null
condition|)
block|{
name|docMap
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|docMap
operator|=
name|docMaps
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
name|MergeReader
name|reader
init|=
operator|new
name|MergeReader
argument_list|(
name|bkd
argument_list|,
name|docMap
argument_list|,
name|docIDBases
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|.
name|next
argument_list|()
condition|)
block|{
name|queue
operator|.
name|add
argument_list|(
name|reader
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|queue
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
name|int
name|leafCount
init|=
literal|0
decl_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|leafBlockFPs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|leafBlockStartValues
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// Target halfway between min and max allowed for the leaf:
name|int
name|pointsPerLeafBlock
init|=
call|(
name|int
call|)
argument_list|(
literal|0.75
operator|*
name|maxPointsInLeafNode
argument_list|)
decl_stmt|;
comment|//System.out.println("POINTS PER: " + pointsPerLeafBlock);
name|byte
index|[]
name|lastPackedValue
init|=
operator|new
name|byte
index|[
name|bytesPerDim
index|]
decl_stmt|;
name|byte
index|[]
name|firstPackedValue
init|=
operator|new
name|byte
index|[
name|bytesPerDim
index|]
decl_stmt|;
name|long
name|valueCount
init|=
literal|0
decl_stmt|;
comment|// Buffer up each leaf block's docs and values
name|int
index|[]
name|leafBlockDocIDs
init|=
operator|new
name|int
index|[
name|maxPointsInLeafNode
index|]
decl_stmt|;
name|byte
index|[]
index|[]
name|leafBlockPackedValues
init|=
operator|new
name|byte
index|[
name|maxPointsInLeafNode
index|]
index|[]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|maxPointsInLeafNode
condition|;
name|i
operator|++
control|)
block|{
name|leafBlockPackedValues
index|[
name|i
index|]
operator|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
expr_stmt|;
block|}
name|Arrays
operator|.
name|fill
argument_list|(
name|commonPrefixLengths
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
while|while
condition|(
name|queue
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|MergeReader
name|reader
init|=
name|queue
operator|.
name|top
argument_list|()
decl_stmt|;
comment|// System.out.println("iter reader=" + reader);
comment|// NOTE: doesn't work with subclasses (e.g. SimpleText!)
name|int
name|docID
init|=
name|reader
operator|.
name|docIDBase
operator|+
name|reader
operator|.
name|docID
decl_stmt|;
name|leafBlockDocIDs
index|[
name|leafCount
index|]
operator|=
name|docID
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|,
name|leafBlockPackedValues
index|[
name|leafCount
index|]
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|docsSeen
operator|.
name|set
argument_list|(
name|docID
argument_list|)
expr_stmt|;
if|if
condition|(
name|valueCount
operator|==
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|,
name|minPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
block|}
name|System
operator|.
name|arraycopy
argument_list|(
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|,
name|maxPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
assert|assert
name|numDims
operator|>
literal|1
operator|||
name|valueInOrder
argument_list|(
name|valueCount
argument_list|,
name|lastPackedValue
argument_list|,
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|)
assert|;
name|valueCount
operator|++
expr_stmt|;
if|if
condition|(
name|pointCount
operator|>
name|totalPointCount
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"totalPointCount="
operator|+
name|totalPointCount
operator|+
literal|" was passed when we were created, but we just hit "
operator|+
name|pointCount
operator|+
literal|" values"
argument_list|)
throw|;
block|}
if|if
condition|(
name|leafCount
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|leafBlockFPs
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// Save the first (minimum) value in each leaf block except the first, to build the split value index in the end:
name|leafBlockStartValues
operator|.
name|add
argument_list|(
name|Arrays
operator|.
name|copyOf
argument_list|(
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
name|bytesPerDim
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Arrays
operator|.
name|fill
argument_list|(
name|commonPrefixLengths
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
argument_list|,
literal|0
argument_list|,
name|firstPackedValue
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Find per-dim common prefix:
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|int
name|offset
init|=
name|dim
operator|*
name|bytesPerDim
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|commonPrefixLengths
index|[
name|dim
index|]
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|firstPackedValue
index|[
name|offset
operator|+
name|j
index|]
operator|!=
name|reader
operator|.
name|state
operator|.
name|scratchPackedValue
index|[
name|offset
operator|+
name|j
index|]
condition|)
block|{
name|commonPrefixLengths
index|[
name|dim
index|]
operator|=
name|j
expr_stmt|;
break|break;
block|}
block|}
block|}
block|}
name|leafCount
operator|++
expr_stmt|;
if|if
condition|(
name|reader
operator|.
name|next
argument_list|()
condition|)
block|{
name|queue
operator|.
name|updateTop
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// This segment was exhausted
name|queue
operator|.
name|pop
argument_list|()
expr_stmt|;
block|}
comment|// We write a block once we hit exactly the max count ... this is different from
comment|// when we flush a new segment, where we write between max/2 and max per leaf block,
comment|// so merged segments will behave differently from newly flushed segments:
if|if
condition|(
name|leafCount
operator|==
name|pointsPerLeafBlock
operator|||
name|queue
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|leafBlockFPs
operator|.
name|add
argument_list|(
name|out
operator|.
name|getFilePointer
argument_list|()
argument_list|)
expr_stmt|;
name|checkMaxLeafNodeCount
argument_list|(
name|leafBlockFPs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|writeLeafBlockDocs
argument_list|(
name|out
argument_list|,
name|leafBlockDocIDs
argument_list|,
literal|0
argument_list|,
name|leafCount
argument_list|)
expr_stmt|;
name|writeCommonPrefixes
argument_list|(
name|out
argument_list|,
name|commonPrefixLengths
argument_list|,
name|firstPackedValue
argument_list|)
expr_stmt|;
comment|// Write the full values:
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|leafCount
condition|;
name|i
operator|++
control|)
block|{
name|writeLeafBlockPackedValue
argument_list|(
name|out
argument_list|,
name|commonPrefixLengths
argument_list|,
name|leafBlockPackedValues
index|[
name|i
index|]
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|leafCount
operator|=
literal|0
expr_stmt|;
block|}
block|}
name|pointCount
operator|=
name|valueCount
expr_stmt|;
name|long
name|indexFP
init|=
name|out
operator|.
name|getFilePointer
argument_list|()
decl_stmt|;
name|int
name|numInnerNodes
init|=
name|leafBlockStartValues
operator|.
name|size
argument_list|()
decl_stmt|;
comment|//System.out.println("BKDW: now rotate numInnerNodes=" + numInnerNodes + " leafBlockStarts=" + leafBlockStartValues.size());
name|byte
index|[]
name|index
init|=
operator|new
name|byte
index|[
operator|(
literal|1
operator|+
name|numInnerNodes
operator|)
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
index|]
decl_stmt|;
name|rotateToTree
argument_list|(
literal|1
argument_list|,
literal|0
argument_list|,
name|numInnerNodes
argument_list|,
name|index
argument_list|,
name|leafBlockStartValues
argument_list|)
expr_stmt|;
name|long
index|[]
name|arr
init|=
operator|new
name|long
index|[
name|leafBlockFPs
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|leafBlockFPs
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|arr
index|[
name|i
index|]
operator|=
name|leafBlockFPs
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
name|writeIndex
argument_list|(
name|out
argument_list|,
name|arr
argument_list|,
name|index
argument_list|)
expr_stmt|;
return|return
name|indexFP
return|;
block|}
comment|// TODO: there must be a simpler way?
DECL|method|rotateToTree
specifier|private
name|void
name|rotateToTree
parameter_list|(
name|int
name|nodeID
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|count
parameter_list|,
name|byte
index|[]
name|index
parameter_list|,
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|leafBlockStartValues
parameter_list|)
block|{
comment|//System.out.println("ROTATE: nodeID=" + nodeID + " offset=" + offset + " count=" + count + " bpd=" + bytesPerDim + " index.length=" + index.length);
if|if
condition|(
name|count
operator|==
literal|1
condition|)
block|{
comment|// Leaf index node
comment|//System.out.println("  leaf index node");
comment|//System.out.println("  index[" + nodeID + "] = blockStartValues[" + offset + "]");
name|System
operator|.
name|arraycopy
argument_list|(
name|leafBlockStartValues
operator|.
name|get
argument_list|(
name|offset
argument_list|)
argument_list|,
literal|0
argument_list|,
name|index
argument_list|,
name|nodeID
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
operator|+
literal|1
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|count
operator|>
literal|1
condition|)
block|{
comment|// Internal index node: binary partition of count
name|int
name|countAtLevel
init|=
literal|1
decl_stmt|;
name|int
name|totalCount
init|=
literal|0
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|int
name|countLeft
init|=
name|count
operator|-
name|totalCount
decl_stmt|;
comment|//System.out.println("    cycle countLeft=" + countLeft + " coutAtLevel=" + countAtLevel);
if|if
condition|(
name|countLeft
operator|<=
name|countAtLevel
condition|)
block|{
comment|// This is the last level, possibly partially filled:
name|int
name|lastLeftCount
init|=
name|Math
operator|.
name|min
argument_list|(
name|countAtLevel
operator|/
literal|2
argument_list|,
name|countLeft
argument_list|)
decl_stmt|;
assert|assert
name|lastLeftCount
operator|>=
literal|0
assert|;
name|int
name|leftHalf
init|=
operator|(
name|totalCount
operator|-
literal|1
operator|)
operator|/
literal|2
operator|+
name|lastLeftCount
decl_stmt|;
name|int
name|rootOffset
init|=
name|offset
operator|+
name|leftHalf
decl_stmt|;
comment|/*           System.out.println("  last left count " + lastLeftCount);           System.out.println("  leftHalf " + leftHalf + " rightHalf=" + (count-leftHalf-1));           System.out.println("  rootOffset=" + rootOffset);           */
name|System
operator|.
name|arraycopy
argument_list|(
name|leafBlockStartValues
operator|.
name|get
argument_list|(
name|rootOffset
argument_list|)
argument_list|,
literal|0
argument_list|,
name|index
argument_list|,
name|nodeID
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
operator|+
literal|1
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
comment|//System.out.println("  index[" + nodeID + "] = blockStartValues[" + rootOffset + "]");
comment|// TODO: we could optimize/specialize, when we know it's simply fully balanced binary tree
comment|// under here, to save this while loop on each recursion
comment|// Recurse left
name|rotateToTree
argument_list|(
literal|2
operator|*
name|nodeID
argument_list|,
name|offset
argument_list|,
name|leftHalf
argument_list|,
name|index
argument_list|,
name|leafBlockStartValues
argument_list|)
expr_stmt|;
comment|// Recurse right
name|rotateToTree
argument_list|(
literal|2
operator|*
name|nodeID
operator|+
literal|1
argument_list|,
name|rootOffset
operator|+
literal|1
argument_list|,
name|count
operator|-
name|leftHalf
operator|-
literal|1
argument_list|,
name|index
argument_list|,
name|leafBlockStartValues
argument_list|)
expr_stmt|;
return|return;
block|}
name|totalCount
operator|+=
name|countAtLevel
expr_stmt|;
name|countAtLevel
operator|*=
literal|2
expr_stmt|;
block|}
block|}
else|else
block|{
assert|assert
name|count
operator|==
literal|0
assert|;
block|}
block|}
comment|// TODO: if we fixed each partition step to just record the file offset at the "split point", we could probably handle variable length
comment|// encoding and not have our own ByteSequencesReader/Writer
comment|/** Sort the heap writer by the specified dim */
DECL|method|sortHeapPointWriter
specifier|private
name|void
name|sortHeapPointWriter
parameter_list|(
specifier|final
name|HeapPointWriter
name|writer
parameter_list|,
name|int
name|dim
parameter_list|)
block|{
assert|assert
name|pointCount
operator|<
name|Integer
operator|.
name|MAX_VALUE
assert|;
comment|//int[] swapCount = new int[1];
comment|//int[] cmpCount = new int[1];
comment|// System.out.println("SORT length=" + length);
comment|// All buffered points are still in heap; just do in-place sort:
operator|new
name|IntroSorter
argument_list|()
block|{
specifier|private
specifier|final
name|byte
index|[]
name|pivotPackedValue
init|=
operator|new
name|byte
index|[
name|bytesPerDim
index|]
decl_stmt|;
specifier|private
name|int
name|pivotDocID
decl_stmt|;
annotation|@
name|Override
specifier|protected
name|void
name|setPivot
parameter_list|(
name|int
name|i
parameter_list|)
block|{
name|pivotDocID
operator|=
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
expr_stmt|;
name|int
name|block
init|=
name|i
operator|/
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|int
name|index
init|=
name|i
operator|%
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|writer
operator|.
name|blocks
operator|.
name|get
argument_list|(
name|block
argument_list|)
argument_list|,
name|index
operator|*
name|packedBytesLength
operator|+
name|dim
operator|*
name|bytesPerDim
argument_list|,
name|pivotPackedValue
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|comparePivot
parameter_list|(
name|int
name|j
parameter_list|)
block|{
comment|//cmpCount[0]++;
name|int
name|block
init|=
name|j
operator|/
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|int
name|index
init|=
name|j
operator|%
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
assert|assert
name|index
operator|>=
literal|0
operator|:
literal|"index="
operator|+
name|index
operator|+
literal|" j="
operator|+
name|j
assert|;
name|int
name|cmp
init|=
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|pivotPackedValue
argument_list|,
literal|0
argument_list|,
name|writer
operator|.
name|blocks
operator|.
name|get
argument_list|(
name|block
argument_list|)
argument_list|,
name|bytesPerDim
operator|*
operator|(
name|index
operator|*
name|numDims
operator|+
name|dim
operator|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// Tie-break
return|return
name|Integer
operator|.
name|compare
argument_list|(
name|pivotDocID
argument_list|,
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|swap
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
name|int
name|docID
init|=
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
decl_stmt|;
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
operator|=
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
expr_stmt|;
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
operator|=
name|docID
expr_stmt|;
if|if
condition|(
name|singleValuePerDoc
operator|==
literal|false
condition|)
block|{
if|if
condition|(
name|longOrds
condition|)
block|{
name|long
name|ord
init|=
name|writer
operator|.
name|ordsLong
index|[
name|i
index|]
decl_stmt|;
name|writer
operator|.
name|ordsLong
index|[
name|i
index|]
operator|=
name|writer
operator|.
name|ordsLong
index|[
name|j
index|]
expr_stmt|;
name|writer
operator|.
name|ordsLong
index|[
name|j
index|]
operator|=
name|ord
expr_stmt|;
block|}
else|else
block|{
name|int
name|ord
init|=
name|writer
operator|.
name|ords
index|[
name|i
index|]
decl_stmt|;
name|writer
operator|.
name|ords
index|[
name|i
index|]
operator|=
name|writer
operator|.
name|ords
index|[
name|j
index|]
expr_stmt|;
name|writer
operator|.
name|ords
index|[
name|j
index|]
operator|=
name|ord
expr_stmt|;
block|}
block|}
name|byte
index|[]
name|blockI
init|=
name|writer
operator|.
name|blocks
operator|.
name|get
argument_list|(
name|i
operator|/
name|writer
operator|.
name|valuesPerBlock
argument_list|)
decl_stmt|;
name|int
name|indexI
init|=
operator|(
name|i
operator|%
name|writer
operator|.
name|valuesPerBlock
operator|)
operator|*
name|packedBytesLength
decl_stmt|;
name|byte
index|[]
name|blockJ
init|=
name|writer
operator|.
name|blocks
operator|.
name|get
argument_list|(
name|j
operator|/
name|writer
operator|.
name|valuesPerBlock
argument_list|)
decl_stmt|;
name|int
name|indexJ
init|=
operator|(
name|j
operator|%
name|writer
operator|.
name|valuesPerBlock
operator|)
operator|*
name|packedBytesLength
decl_stmt|;
comment|// scratch1 = values[i]
name|System
operator|.
name|arraycopy
argument_list|(
name|blockI
argument_list|,
name|indexI
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
comment|// values[i] = values[j]
name|System
operator|.
name|arraycopy
argument_list|(
name|blockJ
argument_list|,
name|indexJ
argument_list|,
name|blockI
argument_list|,
name|indexI
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
comment|// values[j] = scratch1
name|System
operator|.
name|arraycopy
argument_list|(
name|scratch1
argument_list|,
literal|0
argument_list|,
name|blockJ
argument_list|,
name|indexJ
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|compare
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
comment|//cmpCount[0]++;
name|int
name|blockI
init|=
name|i
operator|/
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|int
name|dimI
init|=
name|i
operator|%
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|int
name|blockJ
init|=
name|j
operator|/
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|int
name|dimJ
init|=
name|j
operator|%
name|writer
operator|.
name|valuesPerBlock
decl_stmt|;
name|int
name|cmp
init|=
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|writer
operator|.
name|blocks
operator|.
name|get
argument_list|(
name|blockI
argument_list|)
argument_list|,
name|bytesPerDim
operator|*
operator|(
name|dimI
operator|*
name|numDims
operator|+
name|dim
operator|)
argument_list|,
name|writer
operator|.
name|blocks
operator|.
name|get
argument_list|(
name|blockJ
argument_list|)
argument_list|,
name|bytesPerDim
operator|*
operator|(
name|dimJ
operator|*
name|numDims
operator|+
name|dim
operator|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// Tie-break by docID:
comment|// No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it
comment|// can't matter at search time since we don't write ords into the index:
return|return
name|Integer
operator|.
name|compare
argument_list|(
name|writer
operator|.
name|docIDs
index|[
name|i
index|]
argument_list|,
name|writer
operator|.
name|docIDs
index|[
name|j
index|]
argument_list|)
return|;
block|}
block|}
operator|.
name|sort
argument_list|(
literal|0
argument_list|,
name|Math
operator|.
name|toIntExact
argument_list|(
name|pointCount
argument_list|)
argument_list|)
expr_stmt|;
comment|//System.out.println("LEN=" + length + " SWAP=" + swapCount[0] + " CMP=" + cmpCount[0]);
block|}
DECL|method|sort
specifier|private
name|PointWriter
name|sort
parameter_list|(
name|int
name|dim
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|heapPointWriter
operator|!=
literal|null
condition|)
block|{
assert|assert
name|tempInput
operator|==
literal|null
assert|;
comment|// We never spilled the incoming points to disk, so now we sort in heap:
name|HeapPointWriter
name|sorted
decl_stmt|;
if|if
condition|(
name|dim
operator|==
literal|0
condition|)
block|{
comment|// First dim can re-use the current heap writer
name|sorted
operator|=
name|heapPointWriter
expr_stmt|;
block|}
else|else
block|{
comment|// Subsequent dims need a private copy
name|sorted
operator|=
operator|new
name|HeapPointWriter
argument_list|(
operator|(
name|int
operator|)
name|pointCount
argument_list|,
operator|(
name|int
operator|)
name|pointCount
argument_list|,
name|packedBytesLength
argument_list|,
name|longOrds
argument_list|,
name|singleValuePerDoc
argument_list|)
expr_stmt|;
name|sorted
operator|.
name|copyFrom
argument_list|(
name|heapPointWriter
argument_list|)
expr_stmt|;
block|}
comment|//long t0 = System.nanoTime();
name|sortHeapPointWriter
argument_list|(
name|sorted
argument_list|,
name|dim
argument_list|)
expr_stmt|;
comment|//long t1 = System.nanoTime();
comment|//System.out.println("BKD: sort took " + ((t1-t0)/1000000.0) + " msec");
name|sorted
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|sorted
return|;
block|}
else|else
block|{
comment|// Offline sort:
assert|assert
name|tempInput
operator|!=
literal|null
assert|;
name|Comparator
argument_list|<
name|BytesRef
argument_list|>
name|cmp
init|=
operator|new
name|Comparator
argument_list|<
name|BytesRef
argument_list|>
argument_list|()
block|{
specifier|final
name|ByteArrayDataInput
name|reader
init|=
operator|new
name|ByteArrayDataInput
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|BytesRef
name|a
parameter_list|,
name|BytesRef
name|b
parameter_list|)
block|{
comment|// First compare by the requested dimension we are sorting by:
name|int
name|cmp
init|=
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|a
operator|.
name|bytes
argument_list|,
name|a
operator|.
name|offset
operator|+
name|bytesPerDim
operator|*
name|dim
argument_list|,
name|b
operator|.
name|bytes
argument_list|,
name|b
operator|.
name|offset
operator|+
name|bytesPerDim
operator|*
name|dim
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// Tie-break by docID ... no need to tie break on ord, for the case where the same doc has
comment|// the same value in a given dimension indexed more than once: it can't matter at search
comment|// time since we don't write ords into the index:
return|return
name|StringHelper
operator|.
name|compare
argument_list|(
name|Integer
operator|.
name|BYTES
argument_list|,
name|a
operator|.
name|bytes
argument_list|,
name|a
operator|.
name|offset
operator|+
name|packedBytesLength
argument_list|,
name|b
operator|.
name|bytes
argument_list|,
name|b
operator|.
name|offset
operator|+
name|packedBytesLength
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|// TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:
name|IndexOutput
index|[]
name|lastWriter
init|=
operator|new
name|IndexOutput
index|[
literal|1
index|]
decl_stmt|;
specifier|final
name|BytesRef
name|scratch
init|=
operator|new
name|BytesRef
argument_list|(
operator|new
name|byte
index|[
name|bytesPerDoc
index|]
argument_list|)
decl_stmt|;
name|OfflineSorter
name|sorter
init|=
operator|new
name|OfflineSorter
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
operator|+
literal|"_bkd"
operator|+
name|dim
argument_list|,
name|cmp
argument_list|,
name|OfflineSorter
operator|.
name|BufferSize
operator|.
name|megabytes
argument_list|(
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
operator|(
name|long
operator|)
name|maxMBSortInHeap
argument_list|)
argument_list|)
argument_list|,
name|OfflineSorter
operator|.
name|MAX_TEMPFILES
argument_list|)
block|{
comment|/** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */
annotation|@
name|Override
specifier|protected
name|ByteSequencesWriter
name|getWriter
parameter_list|(
name|IndexOutput
name|out
parameter_list|)
block|{
name|lastWriter
index|[
literal|0
index|]
operator|=
name|out
expr_stmt|;
return|return
operator|new
name|ByteSequencesWriter
argument_list|(
name|out
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|byte
index|[]
name|bytes
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|len
operator|==
name|bytesPerDoc
operator|:
literal|"len="
operator|+
name|len
operator|+
literal|" bytesPerDoc="
operator|+
name|bytesPerDoc
assert|;
name|out
operator|.
name|writeBytes
argument_list|(
name|bytes
argument_list|,
name|off
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
block|}
return|;
block|}
comment|/** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */
annotation|@
name|Override
specifier|protected
name|ByteSequencesReader
name|getReader
parameter_list|(
name|ChecksumIndexInput
name|in
parameter_list|,
name|String
name|name
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|ByteSequencesReader
argument_list|(
name|in
argument_list|,
name|name
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|BytesRef
name|next
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|in
operator|.
name|getFilePointer
argument_list|()
operator|>=
name|end
condition|)
block|{
return|return
literal|null
return|;
block|}
name|in
operator|.
name|readBytes
argument_list|(
name|scratch
operator|.
name|bytes
argument_list|,
literal|0
argument_list|,
name|bytesPerDoc
argument_list|)
expr_stmt|;
return|return
name|scratch
return|;
block|}
block|}
return|;
block|}
block|}
decl_stmt|;
name|sorter
operator|.
name|sort
argument_list|(
name|tempInput
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
assert|assert
name|lastWriter
index|[
literal|0
index|]
operator|!=
literal|null
assert|;
return|return
operator|new
name|OfflinePointWriter
argument_list|(
name|tempDir
argument_list|,
name|lastWriter
index|[
literal|0
index|]
argument_list|,
name|packedBytesLength
argument_list|,
name|pointCount
argument_list|,
name|longOrds
argument_list|,
name|singleValuePerDoc
argument_list|)
return|;
block|}
block|}
DECL|method|checkMaxLeafNodeCount
specifier|private
name|void
name|checkMaxLeafNodeCount
parameter_list|(
name|int
name|numLeaves
parameter_list|)
block|{
if|if
condition|(
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
operator|*
operator|(
name|long
operator|)
name|numLeaves
operator|>
name|ArrayUtil
operator|.
name|MAX_ARRAY_LENGTH
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"too many nodes; increase maxPointsInLeafNode (currently "
operator|+
name|maxPointsInLeafNode
operator|+
literal|") and reindex"
argument_list|)
throw|;
block|}
block|}
comment|/** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */
DECL|method|finish
specifier|public
name|long
name|finish
parameter_list|(
name|IndexOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
comment|// System.out.println("\nBKDTreeWriter.finish pointCount=" + pointCount + " out=" + out + " heapWriter=" + heapPointWriter);
comment|// TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)
comment|// Catch user silliness:
if|if
condition|(
name|heapPointWriter
operator|==
literal|null
operator|&&
name|tempInput
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"already finished"
argument_list|)
throw|;
block|}
if|if
condition|(
name|offlinePointWriter
operator|!=
literal|null
condition|)
block|{
name|offlinePointWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|pointCount
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"must index at least one point"
argument_list|)
throw|;
block|}
name|LongBitSet
name|ordBitSet
decl_stmt|;
if|if
condition|(
name|numDims
operator|>
literal|1
condition|)
block|{
if|if
condition|(
name|singleValuePerDoc
condition|)
block|{
name|ordBitSet
operator|=
operator|new
name|LongBitSet
argument_list|(
name|maxDoc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ordBitSet
operator|=
operator|new
name|LongBitSet
argument_list|(
name|pointCount
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|ordBitSet
operator|=
literal|null
expr_stmt|;
block|}
name|long
name|countPerLeaf
init|=
name|pointCount
decl_stmt|;
name|long
name|innerNodeCount
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|countPerLeaf
operator|>
name|maxPointsInLeafNode
condition|)
block|{
name|countPerLeaf
operator|=
operator|(
name|countPerLeaf
operator|+
literal|1
operator|)
operator|/
literal|2
expr_stmt|;
name|innerNodeCount
operator|*=
literal|2
expr_stmt|;
block|}
name|int
name|numLeaves
init|=
operator|(
name|int
operator|)
name|innerNodeCount
decl_stmt|;
name|checkMaxLeafNodeCount
argument_list|(
name|numLeaves
argument_list|)
expr_stmt|;
comment|// NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each
comment|// step of the recursion to recompute the split dim:
comment|// Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.
name|byte
index|[]
name|splitPackedValues
init|=
operator|new
name|byte
index|[
name|Math
operator|.
name|toIntExact
argument_list|(
name|numLeaves
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
argument_list|)
index|]
decl_stmt|;
comment|// +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)
name|long
index|[]
name|leafBlockFPs
init|=
operator|new
name|long
index|[
name|numLeaves
index|]
decl_stmt|;
comment|// Make sure the math above "worked":
assert|assert
name|pointCount
operator|/
name|numLeaves
operator|<=
name|maxPointsInLeafNode
operator|:
literal|"pointCount="
operator|+
name|pointCount
operator|+
literal|" numLeaves="
operator|+
name|numLeaves
operator|+
literal|" maxPointsInLeafNode="
operator|+
name|maxPointsInLeafNode
assert|;
comment|// Sort all docs once by each dimension:
name|PathSlice
index|[]
name|sortedPointWriters
init|=
operator|new
name|PathSlice
index|[
name|numDims
index|]
decl_stmt|;
comment|// This is only used on exception; on normal code paths we close all files we opened:
name|List
argument_list|<
name|Closeable
argument_list|>
name|toCloseHeroically
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|//long t0 = System.nanoTime();
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|sortedPointWriters
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|sort
argument_list|(
name|dim
argument_list|)
argument_list|,
literal|0
argument_list|,
name|pointCount
argument_list|)
expr_stmt|;
block|}
comment|//long t1 = System.nanoTime();
comment|//System.out.println("sort time: " + ((t1-t0)/1000000.0) + " msec");
if|if
condition|(
name|tempInput
operator|!=
literal|null
condition|)
block|{
name|tempDir
operator|.
name|deleteFile
argument_list|(
name|tempInput
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tempInput
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
assert|assert
name|heapPointWriter
operator|!=
literal|null
assert|;
name|heapPointWriter
operator|=
literal|null
expr_stmt|;
block|}
name|build
argument_list|(
literal|1
argument_list|,
name|numLeaves
argument_list|,
name|sortedPointWriters
argument_list|,
name|ordBitSet
argument_list|,
name|out
argument_list|,
name|minPackedValue
argument_list|,
name|maxPackedValue
argument_list|,
name|splitPackedValues
argument_list|,
name|leafBlockFPs
argument_list|,
name|toCloseHeroically
argument_list|)
expr_stmt|;
for|for
control|(
name|PathSlice
name|slice
range|:
name|sortedPointWriters
control|)
block|{
name|slice
operator|.
name|writer
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
comment|// If no exception, we should have cleaned everything up:
assert|assert
name|tempDir
operator|.
name|getCreatedFiles
argument_list|()
operator|.
name|isEmpty
argument_list|()
assert|;
comment|//long t2 = System.nanoTime();
comment|//System.out.println("write time: " + ((t2-t1)/1000000.0) + " msec");
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|success
operator|==
literal|false
condition|)
block|{
name|IOUtils
operator|.
name|deleteFilesIgnoringExceptions
argument_list|(
name|tempDir
argument_list|,
name|tempDir
operator|.
name|getCreatedFiles
argument_list|()
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|toCloseHeroically
argument_list|)
expr_stmt|;
block|}
block|}
comment|//System.out.println("Total nodes: " + innerNodeCount);
comment|// Write index:
name|long
name|indexFP
init|=
name|out
operator|.
name|getFilePointer
argument_list|()
decl_stmt|;
name|writeIndex
argument_list|(
name|out
argument_list|,
name|leafBlockFPs
argument_list|,
name|splitPackedValues
argument_list|)
expr_stmt|;
return|return
name|indexFP
return|;
block|}
comment|/** Subclass can change how it writes the index. */
DECL|method|writeIndex
specifier|protected
name|void
name|writeIndex
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|long
index|[]
name|leafBlockFPs
parameter_list|,
name|byte
index|[]
name|splitPackedValues
parameter_list|)
throws|throws
name|IOException
block|{
name|CodecUtil
operator|.
name|writeHeader
argument_list|(
name|out
argument_list|,
name|CODEC_NAME
argument_list|,
name|VERSION_CURRENT
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|numDims
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|maxPointsInLeafNode
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|bytesPerDim
argument_list|)
expr_stmt|;
assert|assert
name|leafBlockFPs
operator|.
name|length
operator|>
literal|0
assert|;
name|out
operator|.
name|writeVInt
argument_list|(
name|leafBlockFPs
operator|.
name|length
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeBytes
argument_list|(
name|minPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeBytes
argument_list|(
name|maxPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVLong
argument_list|(
name|pointCount
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeVInt
argument_list|(
name|docsSeen
operator|.
name|cardinality
argument_list|()
argument_list|)
expr_stmt|;
comment|// TODO: for 1D case, don't waste the first byte of each split value (it's always 0)
comment|// NOTE: splitPackedValues[0] is unused, because nodeID is 1-based:
name|out
operator|.
name|writeBytes
argument_list|(
name|splitPackedValues
argument_list|,
literal|0
argument_list|,
name|splitPackedValues
operator|.
name|length
argument_list|)
expr_stmt|;
name|long
name|lastFP
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|leafBlockFPs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|long
name|delta
init|=
name|leafBlockFPs
index|[
name|i
index|]
operator|-
name|lastFP
decl_stmt|;
name|out
operator|.
name|writeVLong
argument_list|(
name|delta
argument_list|)
expr_stmt|;
name|lastFP
operator|=
name|leafBlockFPs
index|[
name|i
index|]
expr_stmt|;
block|}
block|}
DECL|method|writeLeafBlockDocs
specifier|protected
name|void
name|writeLeafBlockDocs
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|int
index|[]
name|docIDs
parameter_list|,
name|int
name|start
parameter_list|,
name|int
name|count
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|count
operator|>
literal|0
operator|:
literal|"maxPointsInLeafNode="
operator|+
name|maxPointsInLeafNode
assert|;
name|out
operator|.
name|writeVInt
argument_list|(
name|count
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|out
operator|.
name|writeInt
argument_list|(
name|docIDs
index|[
name|start
operator|+
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|writeLeafBlockPackedValue
specifier|protected
name|void
name|writeLeafBlockPackedValue
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|int
index|[]
name|commonPrefixLengths
parameter_list|,
name|byte
index|[]
name|bytes
parameter_list|,
name|int
name|offset
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|int
name|prefix
init|=
name|commonPrefixLengths
index|[
name|dim
index|]
decl_stmt|;
name|out
operator|.
name|writeBytes
argument_list|(
name|bytes
argument_list|,
name|offset
operator|+
name|dim
operator|*
name|bytesPerDim
operator|+
name|prefix
argument_list|,
name|bytesPerDim
operator|-
name|prefix
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|writeCommonPrefixes
specifier|protected
name|void
name|writeCommonPrefixes
parameter_list|(
name|IndexOutput
name|out
parameter_list|,
name|int
index|[]
name|commonPrefixes
parameter_list|,
name|byte
index|[]
name|packedValue
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|out
operator|.
name|writeVInt
argument_list|(
name|commonPrefixes
index|[
name|dim
index|]
argument_list|)
expr_stmt|;
comment|//System.out.println(commonPrefixes[dim] + " of " + bytesPerDim);
name|out
operator|.
name|writeBytes
argument_list|(
name|packedValue
argument_list|,
name|dim
operator|*
name|bytesPerDim
argument_list|,
name|commonPrefixes
index|[
name|dim
index|]
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|close
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|tempInput
operator|!=
literal|null
condition|)
block|{
comment|// NOTE: this should only happen on exception, e.g. caller calls close w/o calling finish:
try|try
block|{
name|tempInput
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|tempDir
operator|.
name|deleteFile
argument_list|(
name|tempInput
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|tempInput
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/** Sliced reference to points in an OfflineSorter.ByteSequencesWriter file. */
DECL|class|PathSlice
specifier|private
specifier|static
specifier|final
class|class
name|PathSlice
block|{
DECL|field|writer
specifier|final
name|PointWriter
name|writer
decl_stmt|;
DECL|field|start
specifier|final
name|long
name|start
decl_stmt|;
DECL|field|count
specifier|final
name|long
name|count
decl_stmt|;
DECL|method|PathSlice
specifier|public
name|PathSlice
parameter_list|(
name|PointWriter
name|writer
parameter_list|,
name|long
name|start
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|this
operator|.
name|writer
operator|=
name|writer
expr_stmt|;
name|this
operator|.
name|start
operator|=
name|start
expr_stmt|;
name|this
operator|.
name|count
operator|=
name|count
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|toString
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"PathSlice(start="
operator|+
name|start
operator|+
literal|" count="
operator|+
name|count
operator|+
literal|" writer="
operator|+
name|writer
operator|+
literal|")"
return|;
block|}
block|}
comment|/** Called on exception, to check whether the checksum is also corrupt in this source, and add that     *  information (checksum matched or didn't) as a suppressed exception. */
DECL|method|verifyChecksum
specifier|private
name|void
name|verifyChecksum
parameter_list|(
name|Throwable
name|priorException
parameter_list|,
name|PointWriter
name|writer
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: we could improve this, to always validate checksum as we recurse, if we shared left and
comment|// right reader after recursing to children, and possibly within recursed children,
comment|// since all together they make a single pass through the file.  But this is a sizable re-org,
comment|// and would mean leaving readers (IndexInputs) open for longer:
if|if
condition|(
name|writer
operator|instanceof
name|OfflinePointWriter
condition|)
block|{
comment|// We are reading from a temp file; go verify the checksum:
name|String
name|tempFileName
init|=
operator|(
operator|(
name|OfflinePointWriter
operator|)
name|writer
operator|)
operator|.
name|out
operator|.
name|getName
argument_list|()
decl_stmt|;
try|try
init|(
name|ChecksumIndexInput
name|in
init|=
name|tempDir
operator|.
name|openChecksumInput
argument_list|(
name|tempFileName
argument_list|,
name|IOContext
operator|.
name|READONCE
argument_list|)
init|)
block|{
name|CodecUtil
operator|.
name|checkFooter
argument_list|(
name|in
argument_list|,
name|priorException
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// We are reading from heap; nothing to add:
name|IOUtils
operator|.
name|reThrow
argument_list|(
name|priorException
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Marks bits for the ords (points) that belong in the right sub tree (those docs that have values>= the splitValue). */
DECL|method|markRightTree
specifier|private
name|byte
index|[]
name|markRightTree
parameter_list|(
name|long
name|rightCount
parameter_list|,
name|int
name|splitDim
parameter_list|,
name|PathSlice
name|source
parameter_list|,
name|LongBitSet
name|ordBitSet
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Now we mark ords that fall into the right half, so we can partition on all other dims that are not the split dim:
comment|// Read the split value, then mark all ords in the right tree (larger than the split value):
comment|// TODO: find a way to also checksum this reader?  If we changed to markLeftTree, and scanned the final chunk, it could work?
try|try
init|(
name|PointReader
name|reader
init|=
name|source
operator|.
name|writer
operator|.
name|getReader
argument_list|(
name|source
operator|.
name|start
operator|+
name|source
operator|.
name|count
operator|-
name|rightCount
argument_list|,
name|rightCount
argument_list|)
init|)
block|{
name|boolean
name|result
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|result
assert|;
name|System
operator|.
name|arraycopy
argument_list|(
name|reader
operator|.
name|packedValue
argument_list|()
argument_list|,
name|splitDim
operator|*
name|bytesPerDim
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
if|if
condition|(
name|numDims
operator|>
literal|1
condition|)
block|{
assert|assert
name|ordBitSet
operator|.
name|get
argument_list|(
name|reader
operator|.
name|ord
argument_list|()
argument_list|)
operator|==
literal|false
assert|;
name|ordBitSet
operator|.
name|set
argument_list|(
name|reader
operator|.
name|ord
argument_list|()
argument_list|)
expr_stmt|;
comment|// Subtract 1 from rightCount because we already did the first value above (so we could record the split value):
name|reader
operator|.
name|markOrds
argument_list|(
name|rightCount
operator|-
literal|1
argument_list|,
name|ordBitSet
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|verifyChecksum
argument_list|(
name|t
argument_list|,
name|source
operator|.
name|writer
argument_list|)
expr_stmt|;
block|}
return|return
name|scratch1
return|;
block|}
comment|/** Called only in assert */
DECL|method|valueInBounds
specifier|private
name|boolean
name|valueInBounds
parameter_list|(
name|BytesRef
name|packedValue
parameter_list|,
name|byte
index|[]
name|minPackedValue
parameter_list|,
name|byte
index|[]
name|maxPackedValue
parameter_list|)
block|{
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|int
name|offset
init|=
name|bytesPerDim
operator|*
name|dim
decl_stmt|;
if|if
condition|(
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|packedValue
operator|.
name|bytes
argument_list|,
name|packedValue
operator|.
name|offset
operator|+
name|offset
argument_list|,
name|minPackedValue
argument_list|,
name|offset
argument_list|)
operator|<
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|packedValue
operator|.
name|bytes
argument_list|,
name|packedValue
operator|.
name|offset
operator|+
name|offset
argument_list|,
name|maxPackedValue
argument_list|,
name|offset
argument_list|)
operator|>
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
DECL|method|split
specifier|protected
name|int
name|split
parameter_list|(
name|byte
index|[]
name|minPackedValue
parameter_list|,
name|byte
index|[]
name|maxPackedValue
parameter_list|)
block|{
comment|// Find which dim has the largest span so we can split on it:
name|int
name|splitDim
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
name|NumericUtils
operator|.
name|subtract
argument_list|(
name|bytesPerDim
argument_list|,
name|dim
argument_list|,
name|maxPackedValue
argument_list|,
name|minPackedValue
argument_list|,
name|scratchDiff
argument_list|)
expr_stmt|;
if|if
condition|(
name|splitDim
operator|==
operator|-
literal|1
operator|||
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|scratchDiff
argument_list|,
literal|0
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|)
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|scratchDiff
argument_list|,
literal|0
argument_list|,
name|scratch1
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
name|splitDim
operator|=
name|dim
expr_stmt|;
block|}
block|}
comment|//System.out.println("SPLIT: " + splitDim);
return|return
name|splitDim
return|;
block|}
comment|/** Pull a partition back into heap once the point count is low enough while recursing. */
DECL|method|switchToHeap
specifier|private
name|PathSlice
name|switchToHeap
parameter_list|(
name|PathSlice
name|source
parameter_list|,
name|List
argument_list|<
name|Closeable
argument_list|>
name|toCloseHeroically
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|count
init|=
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|count
argument_list|)
decl_stmt|;
comment|// Not inside the try because we don't want to close it here:
name|PointReader
name|reader
init|=
name|source
operator|.
name|writer
operator|.
name|getSharedReader
argument_list|(
name|source
operator|.
name|start
argument_list|,
name|source
operator|.
name|count
argument_list|,
name|toCloseHeroically
argument_list|)
decl_stmt|;
try|try
init|(
name|PointWriter
name|writer
init|=
operator|new
name|HeapPointWriter
argument_list|(
name|count
argument_list|,
name|count
argument_list|,
name|packedBytesLength
argument_list|,
name|longOrds
argument_list|,
name|singleValuePerDoc
argument_list|)
init|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|boolean
name|hasNext
init|=
name|reader
operator|.
name|next
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
assert|;
name|writer
operator|.
name|append
argument_list|(
name|reader
operator|.
name|packedValue
argument_list|()
argument_list|,
name|reader
operator|.
name|ord
argument_list|()
argument_list|,
name|reader
operator|.
name|docID
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|PathSlice
argument_list|(
name|writer
argument_list|,
literal|0
argument_list|,
name|count
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|verifyChecksum
argument_list|(
name|t
argument_list|,
name|source
operator|.
name|writer
argument_list|)
expr_stmt|;
comment|// Dead code but javac disagrees:
return|return
literal|null
return|;
block|}
block|}
comment|/** The array (sized numDims) of PathSlice describe the cell we have currently recursed to. */
DECL|method|build
specifier|private
name|void
name|build
parameter_list|(
name|int
name|nodeID
parameter_list|,
name|int
name|leafNodeOffset
parameter_list|,
name|PathSlice
index|[]
name|slices
parameter_list|,
name|LongBitSet
name|ordBitSet
parameter_list|,
name|IndexOutput
name|out
parameter_list|,
name|byte
index|[]
name|minPackedValue
parameter_list|,
name|byte
index|[]
name|maxPackedValue
parameter_list|,
name|byte
index|[]
name|splitPackedValues
parameter_list|,
name|long
index|[]
name|leafBlockFPs
parameter_list|,
name|List
argument_list|<
name|Closeable
argument_list|>
name|toCloseHeroically
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|PathSlice
name|slice
range|:
name|slices
control|)
block|{
assert|assert
name|slice
operator|.
name|count
operator|==
name|slices
index|[
literal|0
index|]
operator|.
name|count
assert|;
block|}
if|if
condition|(
name|numDims
operator|==
literal|1
operator|&&
name|slices
index|[
literal|0
index|]
operator|.
name|writer
operator|instanceof
name|OfflinePointWriter
operator|&&
name|slices
index|[
literal|0
index|]
operator|.
name|count
operator|<=
name|maxPointsSortInHeap
condition|)
block|{
comment|// Special case for 1D, to cutover to heap once we recurse deeply enough:
name|slices
index|[
literal|0
index|]
operator|=
name|switchToHeap
argument_list|(
name|slices
index|[
literal|0
index|]
argument_list|,
name|toCloseHeroically
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nodeID
operator|>=
name|leafNodeOffset
condition|)
block|{
comment|// Leaf node: write block
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
if|if
condition|(
name|slices
index|[
name|dim
index|]
operator|.
name|writer
operator|instanceof
name|HeapPointWriter
operator|==
literal|false
condition|)
block|{
comment|// Adversarial cases can cause this, e.g. very lopsided data, all equal points, such that we started
comment|// offline, but then kept splitting only in one dimension, and so never had to rewrite into heap writer
name|slices
index|[
name|dim
index|]
operator|=
name|switchToHeap
argument_list|(
name|slices
index|[
name|dim
index|]
argument_list|,
name|toCloseHeroically
argument_list|)
expr_stmt|;
block|}
name|PathSlice
name|source
init|=
name|slices
index|[
name|dim
index|]
decl_stmt|;
name|HeapPointWriter
name|heapSource
init|=
operator|(
name|HeapPointWriter
operator|)
name|source
operator|.
name|writer
decl_stmt|;
comment|// Find common prefix by comparing first and last values, already sorted in this dimension:
name|heapSource
operator|.
name|readPackedValue
argument_list|(
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|start
argument_list|)
argument_list|,
name|scratch1
argument_list|)
expr_stmt|;
name|heapSource
operator|.
name|readPackedValue
argument_list|(
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|start
operator|+
name|source
operator|.
name|count
operator|-
literal|1
argument_list|)
argument_list|,
name|scratch2
argument_list|)
expr_stmt|;
name|int
name|offset
init|=
name|dim
operator|*
name|bytesPerDim
decl_stmt|;
name|commonPrefixLengths
index|[
name|dim
index|]
operator|=
name|bytesPerDim
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|bytesPerDim
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|scratch1
index|[
name|offset
operator|+
name|j
index|]
operator|!=
name|scratch2
index|[
name|offset
operator|+
name|j
index|]
condition|)
block|{
name|commonPrefixLengths
index|[
name|dim
index|]
operator|=
name|j
expr_stmt|;
break|break;
block|}
block|}
block|}
name|PathSlice
name|source
init|=
name|slices
index|[
literal|0
index|]
decl_stmt|;
comment|// We ensured that maxPointsSortInHeap was>= maxPointsInLeafNode, so we better be in heap at this point:
name|HeapPointWriter
name|heapSource
init|=
operator|(
name|HeapPointWriter
operator|)
name|source
operator|.
name|writer
decl_stmt|;
comment|// Save the block file pointer:
name|leafBlockFPs
index|[
name|nodeID
operator|-
name|leafNodeOffset
index|]
operator|=
name|out
operator|.
name|getFilePointer
argument_list|()
expr_stmt|;
comment|//System.out.println("  write leaf block @ fp=" + out.getFilePointer());
comment|// Write docIDs first, as their own chunk, so that at intersect time we can add all docIDs w/o
comment|// loading the values:
name|int
name|count
init|=
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|count
argument_list|)
decl_stmt|;
assert|assert
name|count
operator|>
literal|0
operator|:
literal|"nodeID="
operator|+
name|nodeID
operator|+
literal|" leafNodeOffset="
operator|+
name|leafNodeOffset
assert|;
name|writeLeafBlockDocs
argument_list|(
name|out
argument_list|,
name|heapSource
operator|.
name|docIDs
argument_list|,
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|start
argument_list|)
argument_list|,
name|count
argument_list|)
expr_stmt|;
comment|// TODO: minor opto: we don't really have to write the actual common prefixes, because BKDReader on recursing can regenerate it for us
comment|// from the index, much like how terms dict does so from the FST:
comment|// Write the common prefixes:
name|writeCommonPrefixes
argument_list|(
name|out
argument_list|,
name|commonPrefixLengths
argument_list|,
name|scratch1
argument_list|)
expr_stmt|;
comment|// Write the full values:
name|byte
index|[]
name|lastPackedValue
init|=
operator|new
name|byte
index|[
name|bytesPerDim
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|heapSource
operator|.
name|getPackedValueSlice
argument_list|(
name|Math
operator|.
name|toIntExact
argument_list|(
name|source
operator|.
name|start
operator|+
name|i
argument_list|)
argument_list|,
name|scratchBytesRef
argument_list|)
expr_stmt|;
assert|assert
name|numDims
operator|!=
literal|1
operator|||
name|valueInOrder
argument_list|(
name|i
argument_list|,
name|lastPackedValue
argument_list|,
name|scratchBytesRef
operator|.
name|bytes
argument_list|,
name|scratchBytesRef
operator|.
name|offset
argument_list|)
assert|;
comment|// Make sure this value does in fact fall within this leaf cell:
assert|assert
name|valueInBounds
argument_list|(
name|scratchBytesRef
argument_list|,
name|minPackedValue
argument_list|,
name|maxPackedValue
argument_list|)
assert|;
name|writeLeafBlockPackedValue
argument_list|(
name|out
argument_list|,
name|commonPrefixLengths
argument_list|,
name|scratchBytesRef
operator|.
name|bytes
argument_list|,
name|scratchBytesRef
operator|.
name|offset
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Inner node: partition/recurse
name|int
name|splitDim
decl_stmt|;
if|if
condition|(
name|numDims
operator|>
literal|1
condition|)
block|{
name|splitDim
operator|=
name|split
argument_list|(
name|minPackedValue
argument_list|,
name|maxPackedValue
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|splitDim
operator|=
literal|0
expr_stmt|;
block|}
name|PathSlice
name|source
init|=
name|slices
index|[
name|splitDim
index|]
decl_stmt|;
assert|assert
name|nodeID
operator|<
name|splitPackedValues
operator|.
name|length
operator|:
literal|"nodeID="
operator|+
name|nodeID
operator|+
literal|" splitValues.length="
operator|+
name|splitPackedValues
operator|.
name|length
assert|;
comment|// How many points will be in the left tree:
name|long
name|rightCount
init|=
name|source
operator|.
name|count
operator|/
literal|2
decl_stmt|;
name|long
name|leftCount
init|=
name|source
operator|.
name|count
operator|-
name|rightCount
decl_stmt|;
name|byte
index|[]
name|splitValue
init|=
name|markRightTree
argument_list|(
name|rightCount
argument_list|,
name|splitDim
argument_list|,
name|source
argument_list|,
name|ordBitSet
argument_list|)
decl_stmt|;
name|int
name|address
init|=
name|nodeID
operator|*
operator|(
literal|1
operator|+
name|bytesPerDim
operator|)
decl_stmt|;
name|splitPackedValues
index|[
name|address
index|]
operator|=
operator|(
name|byte
operator|)
name|splitDim
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|splitValue
argument_list|,
literal|0
argument_list|,
name|splitPackedValues
argument_list|,
name|address
operator|+
literal|1
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
comment|// Partition all PathSlice that are not the split dim into sorted left and right sets, so we can recurse:
name|PathSlice
index|[]
name|leftSlices
init|=
operator|new
name|PathSlice
index|[
name|numDims
index|]
decl_stmt|;
name|PathSlice
index|[]
name|rightSlices
init|=
operator|new
name|PathSlice
index|[
name|numDims
index|]
decl_stmt|;
name|byte
index|[]
name|minSplitPackedValue
init|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|minPackedValue
argument_list|,
literal|0
argument_list|,
name|minSplitPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
name|byte
index|[]
name|maxSplitPackedValue
init|=
operator|new
name|byte
index|[
name|packedBytesLength
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|maxPackedValue
argument_list|,
literal|0
argument_list|,
name|maxSplitPackedValue
argument_list|,
literal|0
argument_list|,
name|packedBytesLength
argument_list|)
expr_stmt|;
comment|// When we are on this dim, below, we clear the ordBitSet:
name|int
name|dimToClear
decl_stmt|;
if|if
condition|(
name|numDims
operator|-
literal|1
operator|==
name|splitDim
condition|)
block|{
name|dimToClear
operator|=
name|numDims
operator|-
literal|2
expr_stmt|;
block|}
else|else
block|{
name|dimToClear
operator|=
name|numDims
operator|-
literal|1
expr_stmt|;
block|}
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
if|if
condition|(
name|dim
operator|==
name|splitDim
condition|)
block|{
comment|// No need to partition on this dim since it's a simple slice of the incoming already sorted slice, and we
comment|// will re-use its shared reader when visiting it as we recurse:
name|leftSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|source
operator|.
name|writer
argument_list|,
name|source
operator|.
name|start
argument_list|,
name|leftCount
argument_list|)
expr_stmt|;
name|rightSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|source
operator|.
name|writer
argument_list|,
name|source
operator|.
name|start
operator|+
name|leftCount
argument_list|,
name|rightCount
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|splitValue
argument_list|,
literal|0
argument_list|,
name|minSplitPackedValue
argument_list|,
name|dim
operator|*
name|bytesPerDim
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|splitValue
argument_list|,
literal|0
argument_list|,
name|maxSplitPackedValue
argument_list|,
name|dim
operator|*
name|bytesPerDim
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// Not inside the try because we don't want to close this one now, so that after recursion is done,
comment|// we will have done a singel full sweep of the file:
name|PointReader
name|reader
init|=
name|slices
index|[
name|dim
index|]
operator|.
name|writer
operator|.
name|getSharedReader
argument_list|(
name|slices
index|[
name|dim
index|]
operator|.
name|start
argument_list|,
name|slices
index|[
name|dim
index|]
operator|.
name|count
argument_list|,
name|toCloseHeroically
argument_list|)
decl_stmt|;
try|try
init|(
name|PointWriter
name|leftPointWriter
init|=
name|getPointWriter
argument_list|(
name|leftCount
argument_list|,
literal|"left"
operator|+
name|dim
argument_list|)
init|;              PointWriter rightPointWriter = getPointWriter(source.count - leftCount
operator|,
init|"right" + dim)
block|)
block|{
name|long
name|nextRightCount
init|=
name|reader
operator|.
name|split
argument_list|(
name|source
operator|.
name|count
argument_list|,
name|ordBitSet
argument_list|,
name|leftPointWriter
argument_list|,
name|rightPointWriter
argument_list|,
name|dim
operator|==
name|dimToClear
argument_list|)
decl_stmt|;
if|if
condition|(
name|rightCount
operator|!=
name|nextRightCount
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"wrong number of points in split: expected="
operator|+
name|rightCount
operator|+
literal|" but actual="
operator|+
name|nextRightCount
argument_list|)
throw|;
block|}
name|leftSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|leftPointWriter
argument_list|,
literal|0
argument_list|,
name|leftCount
argument_list|)
expr_stmt|;
name|rightSlices
index|[
name|dim
index|]
operator|=
operator|new
name|PathSlice
argument_list|(
name|rightPointWriter
argument_list|,
literal|0
argument_list|,
name|rightCount
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|verifyChecksum
argument_list|(
name|t
argument_list|,
name|slices
index|[
name|dim
index|]
operator|.
name|writer
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Recurse on left tree:
name|build
argument_list|(
literal|2
operator|*
name|nodeID
argument_list|,
name|leafNodeOffset
argument_list|,
name|leftSlices
argument_list|,
name|ordBitSet
argument_list|,
name|out
argument_list|,
name|minPackedValue
argument_list|,
name|maxSplitPackedValue
argument_list|,
name|splitPackedValues
argument_list|,
name|leafBlockFPs
argument_list|,
name|toCloseHeroically
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
comment|// Don't destroy the dim we split on because we just re-used what our caller above gave us for that dim:
if|if
condition|(
name|dim
operator|!=
name|splitDim
condition|)
block|{
name|leftSlices
index|[
name|dim
index|]
operator|.
name|writer
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
block|}
comment|// TODO: we could "tail recurse" here?  have our parent discard its refs as we recurse right?
comment|// Recurse on right tree:
name|build
argument_list|(
literal|2
operator|*
name|nodeID
operator|+
literal|1
argument_list|,
name|leafNodeOffset
argument_list|,
name|rightSlices
argument_list|,
name|ordBitSet
argument_list|,
name|out
argument_list|,
name|minSplitPackedValue
argument_list|,
name|maxPackedValue
argument_list|,
name|splitPackedValues
argument_list|,
name|leafBlockFPs
argument_list|,
name|toCloseHeroically
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|dim
init|=
literal|0
init|;
name|dim
operator|<
name|numDims
condition|;
name|dim
operator|++
control|)
block|{
comment|// Don't destroy the dim we split on because we just re-used what our caller above gave us for that dim:
if|if
condition|(
name|dim
operator|!=
name|splitDim
condition|)
block|{
name|rightSlices
index|[
name|dim
index|]
operator|.
name|writer
operator|.
name|destroy
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class
begin_comment
comment|// only called from assert
end_comment
begin_function
DECL|method|valueInOrder
specifier|private
name|boolean
name|valueInOrder
parameter_list|(
name|long
name|ord
parameter_list|,
name|byte
index|[]
name|lastPackedValue
parameter_list|,
name|byte
index|[]
name|packedValue
parameter_list|,
name|int
name|packedValueOffset
parameter_list|)
block|{
if|if
condition|(
name|ord
operator|>
literal|0
operator|&&
name|StringHelper
operator|.
name|compare
argument_list|(
name|bytesPerDim
argument_list|,
name|lastPackedValue
argument_list|,
literal|0
argument_list|,
name|packedValue
argument_list|,
name|packedValueOffset
argument_list|)
operator|>
literal|0
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"values out of order: last value="
operator|+
operator|new
name|BytesRef
argument_list|(
name|lastPackedValue
argument_list|)
operator|+
literal|" current value="
operator|+
operator|new
name|BytesRef
argument_list|(
name|packedValue
argument_list|,
name|packedValueOffset
argument_list|,
name|packedBytesLength
argument_list|)
operator|+
literal|" ord="
operator|+
name|ord
argument_list|)
throw|;
block|}
name|System
operator|.
name|arraycopy
argument_list|(
name|packedValue
argument_list|,
name|packedValueOffset
argument_list|,
name|lastPackedValue
argument_list|,
literal|0
argument_list|,
name|bytesPerDim
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
end_function
begin_function
DECL|method|getPointWriter
name|PointWriter
name|getPointWriter
parameter_list|(
name|long
name|count
parameter_list|,
name|String
name|desc
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|count
operator|<=
name|maxPointsSortInHeap
condition|)
block|{
name|int
name|size
init|=
name|Math
operator|.
name|toIntExact
argument_list|(
name|count
argument_list|)
decl_stmt|;
return|return
operator|new
name|HeapPointWriter
argument_list|(
name|size
argument_list|,
name|size
argument_list|,
name|packedBytesLength
argument_list|,
name|longOrds
argument_list|,
name|singleValuePerDoc
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|OfflinePointWriter
argument_list|(
name|tempDir
argument_list|,
name|tempFileNamePrefix
argument_list|,
name|packedBytesLength
argument_list|,
name|longOrds
argument_list|,
name|desc
argument_list|,
name|count
argument_list|,
name|singleValuePerDoc
argument_list|)
return|;
block|}
block|}
end_function
unit|}
end_unit
