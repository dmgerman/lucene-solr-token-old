begin_unit
begin_package
DECL|package|org.apache.lucene.search.similarities
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|similarities
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInvertState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReaderContext
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|NumericDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|CollectionStatistics
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Explanation
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|PhraseQuery
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TermStatistics
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_comment
comment|/**  * Implementation of {@link Similarity} with the Vector Space Model.  *<p>  * Expert: Scoring API.  *<p>TFIDFSimilarity defines the components of Lucene scoring.  * Overriding computation of these components is a convenient  * way to alter Lucene scoring.  *  *<p>Suggested reading:  *<a href="http://nlp.stanford.edu/IR-book/html/htmledition/queries-as-vectors-1.html">  * Introduction To Information Retrieval, Chapter 6</a>.  *  *<p>The following describes how Lucene scoring evolves from  * underlying information retrieval models to (efficient) implementation.  * We first brief on<i>VSM Score</i>,   * then derive from it<i>Lucene's Conceptual Scoring Formula</i>,  * from which, finally, evolves<i>Lucene's Practical Scoring Function</i>   * (the latter is connected directly with Lucene classes and methods).      *  *<p>Lucene combines  *<a href="http://en.wikipedia.org/wiki/Standard_Boolean_model">  * Boolean model (BM) of Information Retrieval</a>  * with  *<a href="http://en.wikipedia.org/wiki/Vector_Space_Model">  * Vector Space Model (VSM) of Information Retrieval</a> -  * documents "approved" by BM are scored by VSM.  *  *<p>In VSM, documents and queries are represented as  * weighted vectors in a multi-dimensional space,  * where each distinct index term is a dimension,  * and weights are  *<a href="http://en.wikipedia.org/wiki/Tfidf">Tf-idf</a> values.  *  *<p>VSM does not require weights to be<i>Tf-idf</i> values,  * but<i>Tf-idf</i> values are believed to produce search results of high quality,  * and so Lucene is using<i>Tf-idf</i>.  *<i>Tf</i> and<i>Idf</i> are described in more detail below,  * but for now, for completion, let's just say that  * for given term<i>t</i> and document (or query)<i>x</i>,  *<i>Tf(t,x)</i> varies with the number of occurrences of term<i>t</i> in<i>x</i>  * (when one increases so does the other) and  *<i>idf(t)</i> similarly varies with the inverse of the  * number of index documents containing term<i>t</i>.  *  *<p><i>VSM score</i> of document<i>d</i> for query<i>q</i> is the  *<a href="http://en.wikipedia.org/wiki/Cosine_similarity">  * Cosine Similarity</a>  * of the weighted query vectors<i>V(q)</i> and<i>V(d)</i>:  *  *<br>&nbsp;<br>  *<table cellpadding="2" cellspacing="2" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="formatting only">  *<tr><td>  *<table cellpadding="1" cellspacing="0" border="1" style="margin-left:auto; margin-right:auto" summary="formatting only">  *<tr><td>  *<table cellpadding="2" cellspacing="2" border="0" style="margin-left:auto; margin-right:auto" summary="cosine similarity formula">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *            cosine-similarity(q,d)&nbsp; =&nbsp;  *</td>  *<td valign="middle" align="center">  *<table summary="cosine similarity formula">  *<tr><td align="center" style="text-align: center"><small>V(q)&nbsp;&middot;&nbsp;V(d)</small></td></tr>  *<tr><td align="center" style="text-align: center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>  *<tr><td align="center" style="text-align: center"><small>|V(q)|&nbsp;|V(d)|</small></td></tr>  *</table>  *</td>  *</tr>  *</table>  *</td></tr>  *</table>  *</td></tr>  *<tr><td>  *<center><u>VSM Score</u></center>  *</td></tr>  *</table>  *<br>&nbsp;<br>  *     *  * Where<i>V(q)</i>&middot;<i>V(d)</i> is the  *<a href="http://en.wikipedia.org/wiki/Dot_product">dot product</a>  * of the weighted vectors,  * and<i>|V(q)|</i> and<i>|V(d)|</i> are their  *<a href="http://en.wikipedia.org/wiki/Euclidean_norm#Euclidean_norm">Euclidean norms</a>.  *  *<p>Note: the above equation can be viewed as the dot product of  * the normalized weighted vectors, in the sense that dividing  *<i>V(q)</i> by its euclidean norm is normalizing it to a unit vector.  *  *<p>Lucene refines<i>VSM score</i> for both search quality and usability:  *<ul>  *<li>Normalizing<i>V(d)</i> to the unit vector is known to be problematic in that   *  it removes all document length information.   *  For some documents removing this info is probably ok,   *  e.g. a document made by duplicating a certain paragraph<i>10</i> times,  *  especially if that paragraph is made of distinct terms.   *  But for a document which contains no duplicated paragraphs,   *  this might be wrong.   *  To avoid this problem, a different document length normalization   *  factor is used, which normalizes to a vector equal to or larger   *  than the unit vector:<i>doc-len-norm(d)</i>.  *</li>  *  *<li>At indexing, users can specify that certain documents are more  *  important than others, by assigning a document boost.  *  For this, the score of each document is also multiplied by its boost value  *<i>doc-boost(d)</i>.  *</li>  *  *<li>Lucene is field based, hence each query term applies to a single  *  field, document length normalization is by the length of the certain field,  *  and in addition to document boost there are also document fields boosts.  *</li>  *  *<li>The same field can be added to a document during indexing several times,  *  and so the boost of that field is the multiplication of the boosts of  *  the separate additions (or parts) of that field within the document.  *</li>  *  *<li>At search time users can specify boosts to each query, sub-query, and  *  each query term, hence the contribution of a query term to the score of  *  a document is multiplied by the boost of that query term<i>query-boost(q)</i>.  *</li>  *  *<li>A document may match a multi term query without containing all  *  the terms of that query (this is correct for some of the queries),  *  and users can further reward documents matching more query terms  *  through a coordination factor, which is usually larger when  *  more terms are matched:<i>coord-factor(q,d)</i>.  *</li>  *</ul>  *  *<p>Under the simplifying assumption of a single field in the index,  * we get<i>Lucene's Conceptual scoring formula</i>:  *  *<br>&nbsp;<br>  *<table cellpadding="2" cellspacing="2" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="formatting only">  *<tr><td>  *<table cellpadding="1" cellspacing="0" border="1" style="margin-left:auto; margin-right:auto" summary="formatting only">  *<tr><td>  *<table cellpadding="2" cellspacing="2" border="0" style="margin-left:auto; margin-right:auto" summary="formatting only">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *            score(q,d)&nbsp; =&nbsp;  *<span style="color: #FF9933">coord-factor(q,d)</span>&middot;&nbsp;  *<span style="color: #CCCC00">query-boost(q)</span>&middot;&nbsp;  *</td>  *<td valign="middle" align="center">  *<table summary="Lucene conceptual scoring formula">  *<tr><td align="center" style="text-align: center"><small><span style="color: #993399">V(q)&nbsp;&middot;&nbsp;V(d)</span></small></td></tr>  *<tr><td align="center" style="text-align: center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>  *<tr><td align="center" style="text-align: center"><small><span style="color: #FF33CC">|V(q)|</span></small></td></tr>  *</table>  *</td>  *<td valign="middle" align="right" rowspan="1">  *&nbsp;&middot;&nbsp;<span style="color: #3399FF">doc-len-norm(d)</span>  *&nbsp;&middot;&nbsp;<span style="color: #3399FF">doc-boost(d)</span>  *</td>  *</tr>  *</table>  *</td></tr>  *</table>  *</td></tr>  *<tr><td>  *<center><u>Lucene Conceptual Scoring Formula</u></center>  *</td></tr>  *</table>  *<br>&nbsp;<br>  *  *<p>The conceptual formula is a simplification in the sense that (1) terms and documents  * are fielded and (2) boosts are usually per query term rather than per query.  *  *<p>We now describe how Lucene implements this conceptual scoring formula, and  * derive from it<i>Lucene's Practical Scoring Function</i>.  *    *<p>For efficient score computation some scoring components  * are computed and aggregated in advance:  *  *<ul>  *<li><i>Query-boost</i> for the query (actually for each query term)  *  is known when search starts.  *</li>  *  *<li>Query Euclidean norm<i>|V(q)|</i> can be computed when search starts,  *  as it is independent of the document being scored.  *  From search optimization perspective, it is a valid question  *  why bother to normalize the query at all, because all  *  scored documents will be multiplied by the same<i>|V(q)|</i>,  *  and hence documents ranks (their order by score) will not  *  be affected by this normalization.  *  There are two good reasons to keep this normalization:  *<ul>  *<li>Recall that  *<a href="http://en.wikipedia.org/wiki/Cosine_similarity">  *   Cosine Similarity</a> can be used find how similar  *   two documents are. One can use Lucene for e.g.  *   clustering, and use a document as a query to compute  *   its similarity to other documents.  *   In this use case it is important that the score of document<i>d3</i>  *   for query<i>d1</i> is comparable to the score of document<i>d3</i>  *   for query<i>d2</i>. In other words, scores of a document for two  *   distinct queries should be comparable.  *   There are other applications that may require this.  *   And this is exactly what normalizing the query vector<i>V(q)</i>  *   provides: comparability (to a certain extent) of two or more queries.  *</li>  *  *<li>Applying query normalization on the scores helps to keep the  *   scores around the unit vector, hence preventing loss of score data  *   because of floating point precision limitations.  *</li>  *</ul>  *</li>  *  *<li>Document length norm<i>doc-len-norm(d)</i> and document  *  boost<i>doc-boost(d)</i> are known at indexing time.  *  They are computed in advance and their multiplication  *  is saved as a single value in the index:<i>norm(d)</i>.  *  (In the equations below,<i>norm(t in d)</i> means<i>norm(field(t) in doc d)</i>  *  where<i>field(t)</i> is the field associated with term<i>t</i>.)  *</li>  *</ul>  *  *<p><i>Lucene's Practical Scoring Function</i> is derived from the above.  * The color codes demonstrate how it relates  * to those of the<i>conceptual</i> formula:  *  *<table cellpadding="2" cellspacing="2" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="formatting only">  *<tr><td>  *<table cellpadding="" cellspacing="2" border="2" style="margin-left:auto; margin-right:auto" summary="formatting only">  *<tr><td>  *<table cellpadding="2" cellspacing="2" border="0" style="margin-left:auto; margin-right:auto" summary="Lucene conceptual scoring formula">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *       score(q,d)&nbsp; =&nbsp;  *<A HREF="#formula_coord"><span style="color: #FF9933">coord(q,d)</span></A>&nbsp;&middot;&nbsp;  *<A HREF="#formula_queryNorm"><span style="color: #FF33CC">queryNorm(q)</span></A>&nbsp;&middot;&nbsp;  *</td>  *<td valign="bottom" align="center" rowspan="1" style="text-align: center">  *<big><big><big>&sum;</big></big></big>  *</td>  *<td valign="middle" align="right" rowspan="1">  *<big><big>(</big></big>  *<A HREF="#formula_tf"><span style="color: #993399">tf(t in d)</span></A>&nbsp;&middot;&nbsp;  *<A HREF="#formula_idf"><span style="color: #993399">idf(t)</span></A><sup>2</sup>&nbsp;&middot;&nbsp;  *<A HREF="#formula_termBoost"><span style="color: #CCCC00">t.getBoost()</span></A>&nbsp;&middot;&nbsp;  *<A HREF="#formula_norm"><span style="color: #3399FF">norm(t,d)</span></A>  *<big><big>)</big></big>  *</td>  *</tr>  *<tr valign="top">  *<td></td>  *<td align="center" style="text-align: center"><small>t in q</small></td>  *<td></td>  *</tr>  *</table>  *</td></tr>  *</table>  *</td></tr>  *<tr><td>  *<center><u>Lucene Practical Scoring Function</u></center>  *</td></tr>  *</table>  *  *<p> where  *<ol>  *<li>  *<A NAME="formula_tf"></A>  *<b><i>tf(t in d)</i></b>  *      correlates to the term's<i>frequency</i>,  *      defined as the number of times term<i>t</i> appears in the currently scored document<i>d</i>.  *      Documents that have more occurrences of a given term receive a higher score.  *      Note that<i>tf(t in q)</i> is assumed to be<i>1</i> and therefore it does not appear in this equation,  *      However if a query contains twice the same term, there will be  *      two term-queries with that same term and hence the computation would still be correct (although  *      not very efficient).  *      The default computation for<i>tf(t in d)</i> in  *      {@link org.apache.lucene.search.similarities.DefaultSimilarity#tf(float) DefaultSimilarity} is:  *  *<br>&nbsp;<br>  *<table cellpadding="2" cellspacing="2" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="term frequency computation">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *            {@link org.apache.lucene.search.similarities.DefaultSimilarity#tf(float) tf(t in d)}&nbsp; =&nbsp;  *</td>  *<td valign="top" align="center" rowspan="1">  *               frequency<sup><big>&frac12;</big></sup>  *</td>  *</tr>  *</table>  *<br>&nbsp;<br>  *</li>  *  *<li>  *<A NAME="formula_idf"></A>  *<b><i>idf(t)</i></b> stands for Inverse Document Frequency. This value  *      correlates to the inverse of<i>docFreq</i>  *      (the number of documents in which the term<i>t</i> appears).  *      This means rarer terms give higher contribution to the total score.  *<i>idf(t)</i> appears for<i>t</i> in both the query and the document,  *      hence it is squared in the equation.  *      The default computation for<i>idf(t)</i> in  *      {@link org.apache.lucene.search.similarities.DefaultSimilarity#idf(long, long) DefaultSimilarity} is:  *  *<br>&nbsp;<br>  *<table cellpadding="2" cellspacing="2" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="inverse document frequency computation">  *<tr>  *<td valign="middle" align="right">  *            {@link org.apache.lucene.search.similarities.DefaultSimilarity#idf(long, long) idf(t)}&nbsp; =&nbsp;  *</td>  *<td valign="middle" align="center">  *            1 + log<big>(</big>  *</td>  *<td valign="middle" align="center">  *<table summary="inverse document frequency computation">  *<tr><td align="center" style="text-align: center"><small>docCount</small></td></tr>  *<tr><td align="center" style="text-align: center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>  *<tr><td align="center" style="text-align: center"><small>docFreq+1</small></td></tr>  *</table>  *</td>  *<td valign="middle" align="center">  *<big>)</big>  *</td>  *</tr>  *</table>  *<br>&nbsp;<br>  *</li>  *  *<li>  *<A NAME="formula_coord"></A>  *<b><i>coord(q,d)</i></b>  *      is a score factor based on how many of the query terms are found in the specified document.  *      Typically, a document that contains more of the query's terms will receive a higher score  *      than another document with fewer query terms.  *      This is a search time factor computed in  *      {@link #coord(int, int) coord(q,d)}  *      by the Similarity in effect at search time.  *<br>&nbsp;<br>  *</li>  *  *<li><b>  *<A NAME="formula_queryNorm"></A>  *<i>queryNorm(q)</i>  *</b>  *      is a normalizing factor used to make scores between queries comparable.  *      This factor does not affect document ranking (since all ranked documents are multiplied by the same factor),  *      but rather just attempts to make scores from different queries (or even different indexes) comparable.  *      This is a search time factor computed by the Similarity in effect at search time.  *  *      The default computation in  *      {@link org.apache.lucene.search.similarities.DefaultSimilarity#queryNorm(float) DefaultSimilarity}  *      produces a<a href="http://en.wikipedia.org/wiki/Euclidean_norm#Euclidean_norm">Euclidean norm</a>:  *<br>&nbsp;<br>  *<table cellpadding="1" cellspacing="0" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="query normalization computation">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *            queryNorm(q)&nbsp; =&nbsp;  *            {@link org.apache.lucene.search.similarities.DefaultSimilarity#queryNorm(float) queryNorm(sumOfSquaredWeights)}  *&nbsp; =&nbsp;  *</td>  *<td valign="middle" align="center" rowspan="1">  *<table summary="query normalization computation">  *<tr><td align="center" style="text-align: center"><big>1</big></td></tr>  *<tr><td align="center" style="text-align: center"><big>  *&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;  *</big></td></tr>  *<tr><td align="center" style="text-align: center">sumOfSquaredWeights<sup><big>&frac12;</big></sup></td></tr>  *</table>  *</td>  *</tr>  *</table>  *<br>&nbsp;<br>  *  *      The sum of squared weights (of the query terms) is  *      computed by the query {@link org.apache.lucene.search.Weight} object.  *      For example, a {@link org.apache.lucene.search.BooleanQuery}  *      computes this value as:  *  *<br>&nbsp;<br>  *<table cellpadding="1" cellspacing="0" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="sum of squared weights computation">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *            {@link org.apache.lucene.search.Weight#getValueForNormalization() sumOfSquaredWeights}&nbsp; =&nbsp;  *            {@link org.apache.lucene.search.BoostQuery#getBoost() q.getBoost()}<sup><big>2</big></sup>  *&nbsp;&middot;&nbsp;  *</td>  *<td valign="bottom" align="center" rowspan="1" style="text-align: center">  *<big><big><big>&sum;</big></big></big>  *</td>  *<td valign="middle" align="right" rowspan="1">  *<big><big>(</big></big>  *<A HREF="#formula_idf">idf(t)</A>&nbsp;&middot;&nbsp;  *<A HREF="#formula_termBoost">t.getBoost()</A>  *<big><big>)<sup>2</sup></big></big>  *</td>  *</tr>  *<tr valign="top">  *<td></td>  *<td align="center" style="text-align: center"><small>t in q</small></td>  *<td></td>  *</tr>  *</table>  *<br>&nbsp;<br>  *  *</li>  *  *<li>  *<A NAME="formula_termBoost"></A>  *<b><i>t.getBoost()</i></b>  *      is a search time boost of term<i>t</i> in the query<i>q</i> as  *      specified in the query text  *      (see<A HREF="{@docRoot}/../queryparser/org/apache/lucene/queryparser/classic/package-summary.html#Boosting_a_Term">query syntax</A>),  *      or as set by wrapping with  *      {@link org.apache.lucene.search.BoostQuery#BoostQuery(org.apache.lucene.search.Query, float) BoostQuery}.  *      Notice that there is really no direct API for accessing a boost of one term in a multi term query,  *      but rather multi terms are represented in a query as multi  *      {@link org.apache.lucene.search.TermQuery TermQuery} objects,  *      and so the boost of a term in the query is accessible by calling the sub-query  *      {@link org.apache.lucene.search.BoostQuery#getBoost() getBoost()}.  *<br>&nbsp;<br>  *</li>  *  *<li>  *<A NAME="formula_norm"></A>  *<b><i>norm(t,d)</i></b> encapsulates a few (indexing time) boost and length factors:  *  *<ul>  *<li><b>Field boost</b> - set by calling  *        {@link org.apache.lucene.document.Field#setBoost(float) field.setBoost()}  *        before adding the field to a document.  *</li>  *<li><b>lengthNorm</b> - computed  *        when the document is added to the index in accordance with the number of tokens  *        of this field in the document, so that shorter fields contribute more to the score.  *        LengthNorm is computed by the Similarity class in effect at indexing.  *</li>  *</ul>  *      The {@link #computeNorm} method is responsible for  *      combining all of these factors into a single float.  *  *<p>  *      When a document is added to the index, all the above factors are multiplied.  *      If the document has multiple fields with the same name, all their boosts are multiplied together:  *  *<br>&nbsp;<br>  *<table cellpadding="1" cellspacing="0" border="0" style="width:auto; margin-left:auto; margin-right:auto" summary="index-time normalization">  *<tr>  *<td valign="middle" align="right" rowspan="1">  *            norm(t,d)&nbsp; =&nbsp;  *            lengthNorm  *&nbsp;&middot;&nbsp;  *</td>  *<td valign="bottom" align="center" rowspan="1" style="text-align: center">  *<big><big><big>&prod;</big></big></big>  *</td>  *<td valign="middle" align="right" rowspan="1">  *            {@link org.apache.lucene.index.IndexableField#boost() f.boost}()  *</td>  *</tr>  *<tr valign="top">  *<td></td>  *<td align="center" style="text-align: center"><small>field<i><b>f</b></i> in<i>d</i> named as<i><b>t</b></i></small></td>  *<td></td>  *</tr>  *</table>  *      Note that search time is too late to modify this<i>norm</i> part of scoring,   *      e.g. by using a different {@link Similarity} for search.  *</li>  *</ol>  *  * @see org.apache.lucene.index.IndexWriterConfig#setSimilarity(Similarity)  * @see IndexSearcher#setSimilarity(Similarity)  */
end_comment
begin_class
DECL|class|TFIDFSimilarity
specifier|public
specifier|abstract
class|class
name|TFIDFSimilarity
extends|extends
name|Similarity
block|{
comment|/**    * Sole constructor. (For invocation by subclass     * constructors, typically implicit.)    */
DECL|method|TFIDFSimilarity
specifier|public
name|TFIDFSimilarity
parameter_list|()
block|{}
comment|/** Computes a score factor based on the fraction of all query terms that a    * document contains.  This value is multiplied into scores.    *    *<p>The presence of a large portion of the query terms indicates a better    * match with the query, so implementations of this method usually return    * larger values when the ratio between these parameters is large and smaller    * values when the ratio between them is small.    *    * @param overlap the number of query terms matched in the document    * @param maxOverlap the total number of terms in the query    * @return a score factor based on term overlap with the query    */
annotation|@
name|Override
DECL|method|coord
specifier|public
specifier|abstract
name|float
name|coord
parameter_list|(
name|int
name|overlap
parameter_list|,
name|int
name|maxOverlap
parameter_list|)
function_decl|;
comment|/** Computes the normalization value for a query given the sum of the squared    * weights of each of the query terms.  This value is multiplied into the    * weight of each query term. While the classic query normalization factor is    * computed as 1/sqrt(sumOfSquaredWeights), other implementations might    * completely ignore sumOfSquaredWeights (ie return 1).    *    *<p>This does not affect ranking, but the default implementation does make scores    * from different queries more comparable than they would be by eliminating the    * magnitude of the Query vector as a factor in the score.    *    * @param sumOfSquaredWeights the sum of the squares of query term weights    * @return a normalization factor for query weights    */
annotation|@
name|Override
DECL|method|queryNorm
specifier|public
specifier|abstract
name|float
name|queryNorm
parameter_list|(
name|float
name|sumOfSquaredWeights
parameter_list|)
function_decl|;
comment|/** Computes a score factor based on a term or phrase's frequency in a    * document.  This value is multiplied by the {@link #idf(long, long)}    * factor for each term in the query and these products are then summed to    * form the initial score for a document.    *    *<p>Terms and phrases repeated in a document indicate the topic of the    * document, so implementations of this method usually return larger values    * when<code>freq</code> is large, and smaller values when<code>freq</code>    * is small.    *    * @param freq the frequency of a term within a document    * @return a score factor based on a term's within-document frequency    */
DECL|method|tf
specifier|public
specifier|abstract
name|float
name|tf
parameter_list|(
name|float
name|freq
parameter_list|)
function_decl|;
comment|/**    * Computes a score factor for a simple term and returns an explanation    * for that score factor.    *     *<p>    * The default implementation uses:    *     *<pre class="prettyprint">    * idf(docFreq, docCount);    *</pre>    *     * Note that {@link CollectionStatistics#docCount()} is used instead of    * {@link org.apache.lucene.index.IndexReader#numDocs() IndexReader#numDocs()} because also     * {@link TermStatistics#docFreq()} is used, and when the latter     * is inaccurate, so is {@link CollectionStatistics#docCount()}, and in the same direction.    * In addition, {@link CollectionStatistics#docCount()} does not skew when fields are sparse.    *       * @param collectionStats collection-level statistics    * @param termStats term-level statistics for the term    * @return an Explain object that includes both an idf score factor               and an explanation for the term.    */
DECL|method|idfExplain
specifier|public
name|Explanation
name|idfExplain
parameter_list|(
name|CollectionStatistics
name|collectionStats
parameter_list|,
name|TermStatistics
name|termStats
parameter_list|)
block|{
specifier|final
name|long
name|df
init|=
name|termStats
operator|.
name|docFreq
argument_list|()
decl_stmt|;
specifier|final
name|long
name|docCount
init|=
name|collectionStats
operator|.
name|docCount
argument_list|()
operator|==
operator|-
literal|1
condition|?
name|collectionStats
operator|.
name|maxDoc
argument_list|()
else|:
name|collectionStats
operator|.
name|docCount
argument_list|()
decl_stmt|;
specifier|final
name|float
name|idf
init|=
name|idf
argument_list|(
name|df
argument_list|,
name|docCount
argument_list|)
decl_stmt|;
return|return
name|Explanation
operator|.
name|match
argument_list|(
name|idf
argument_list|,
literal|"idf(docFreq="
operator|+
name|df
operator|+
literal|", docCount="
operator|+
name|docCount
operator|+
literal|")"
argument_list|)
return|;
block|}
comment|/**    * Computes a score factor for a phrase.    *     *<p>    * The default implementation sums the idf factor for    * each term in the phrase.    *     * @param collectionStats collection-level statistics    * @param termStats term-level statistics for the terms in the phrase    * @return an Explain object that includes both an idf     *         score factor for the phrase and an explanation     *         for each term.    */
DECL|method|idfExplain
specifier|public
name|Explanation
name|idfExplain
parameter_list|(
name|CollectionStatistics
name|collectionStats
parameter_list|,
name|TermStatistics
name|termStats
index|[]
parameter_list|)
block|{
specifier|final
name|long
name|docCount
init|=
name|collectionStats
operator|.
name|docCount
argument_list|()
operator|==
operator|-
literal|1
condition|?
name|collectionStats
operator|.
name|maxDoc
argument_list|()
else|:
name|collectionStats
operator|.
name|docCount
argument_list|()
decl_stmt|;
name|float
name|idf
init|=
literal|0.0f
decl_stmt|;
name|List
argument_list|<
name|Explanation
argument_list|>
name|subs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
specifier|final
name|TermStatistics
name|stat
range|:
name|termStats
control|)
block|{
specifier|final
name|long
name|df
init|=
name|stat
operator|.
name|docFreq
argument_list|()
decl_stmt|;
specifier|final
name|float
name|termIdf
init|=
name|idf
argument_list|(
name|df
argument_list|,
name|docCount
argument_list|)
decl_stmt|;
name|subs
operator|.
name|add
argument_list|(
name|Explanation
operator|.
name|match
argument_list|(
name|termIdf
argument_list|,
literal|"idf(docFreq="
operator|+
name|df
operator|+
literal|", docCount="
operator|+
name|docCount
operator|+
literal|")"
argument_list|)
argument_list|)
expr_stmt|;
name|idf
operator|+=
name|termIdf
expr_stmt|;
block|}
return|return
name|Explanation
operator|.
name|match
argument_list|(
name|idf
argument_list|,
literal|"idf(), sum of:"
argument_list|,
name|subs
argument_list|)
return|;
block|}
comment|/** Computes a score factor based on a term's document frequency (the number    * of documents which contain the term).  This value is multiplied by the    * {@link #tf(float)} factor for each term in the query and these products are    * then summed to form the initial score for a document.    *    *<p>Terms that occur in fewer documents are better indicators of topic, so    * implementations of this method usually return larger values for rare terms,    * and smaller values for common terms.    *    * @param docFreq the number of documents which contain the term    * @param docCount the total number of documents in the collection    * @return a score factor based on the term's document frequency    */
DECL|method|idf
specifier|public
specifier|abstract
name|float
name|idf
parameter_list|(
name|long
name|docFreq
parameter_list|,
name|long
name|docCount
parameter_list|)
function_decl|;
comment|/**    * Compute an index-time normalization value for this field instance.    *<p>    * This value will be stored in a single byte lossy representation by     * {@link #encodeNormValue(float)}.    *     * @param state statistics of the current field (such as length, boost, etc)    * @return an index-time normalization value    */
DECL|method|lengthNorm
specifier|public
specifier|abstract
name|float
name|lengthNorm
parameter_list|(
name|FieldInvertState
name|state
parameter_list|)
function_decl|;
annotation|@
name|Override
DECL|method|computeNorm
specifier|public
specifier|final
name|long
name|computeNorm
parameter_list|(
name|FieldInvertState
name|state
parameter_list|)
block|{
name|float
name|normValue
init|=
name|lengthNorm
argument_list|(
name|state
argument_list|)
decl_stmt|;
return|return
name|encodeNormValue
argument_list|(
name|normValue
argument_list|)
return|;
block|}
comment|/**    * Decodes a normalization factor stored in an index.    *     * @see #encodeNormValue(float)    */
DECL|method|decodeNormValue
specifier|public
specifier|abstract
name|float
name|decodeNormValue
parameter_list|(
name|long
name|norm
parameter_list|)
function_decl|;
comment|/** Encodes a normalization factor for storage in an index. */
DECL|method|encodeNormValue
specifier|public
specifier|abstract
name|long
name|encodeNormValue
parameter_list|(
name|float
name|f
parameter_list|)
function_decl|;
comment|/** Computes the amount of a sloppy phrase match, based on an edit distance.    * This value is summed for each sloppy phrase match in a document to form    * the frequency to be used in scoring instead of the exact term count.    *    *<p>A phrase match with a small edit distance to a document passage more    * closely matches the document, so implementations of this method usually    * return larger values when the edit distance is small and smaller values    * when it is large.    *    * @see PhraseQuery#getSlop()    * @param distance the edit distance of this sloppy phrase match    * @return the frequency increment for this match    */
DECL|method|sloppyFreq
specifier|public
specifier|abstract
name|float
name|sloppyFreq
parameter_list|(
name|int
name|distance
parameter_list|)
function_decl|;
comment|/**    * Calculate a scoring factor based on the data in the payload.  Implementations    * are responsible for interpreting what is in the payload.  Lucene makes no assumptions about    * what is in the byte array.    *    * @param doc The docId currently being scored.    * @param start The start position of the payload    * @param end The end position of the payload    * @param payload The payload byte array to be scored    * @return An implementation dependent float to be used as a scoring factor    */
DECL|method|scorePayload
specifier|public
specifier|abstract
name|float
name|scorePayload
parameter_list|(
name|int
name|doc
parameter_list|,
name|int
name|start
parameter_list|,
name|int
name|end
parameter_list|,
name|BytesRef
name|payload
parameter_list|)
function_decl|;
annotation|@
name|Override
DECL|method|computeWeight
specifier|public
specifier|final
name|SimWeight
name|computeWeight
parameter_list|(
name|CollectionStatistics
name|collectionStats
parameter_list|,
name|TermStatistics
modifier|...
name|termStats
parameter_list|)
block|{
specifier|final
name|Explanation
name|idf
init|=
name|termStats
operator|.
name|length
operator|==
literal|1
condition|?
name|idfExplain
argument_list|(
name|collectionStats
argument_list|,
name|termStats
index|[
literal|0
index|]
argument_list|)
else|:
name|idfExplain
argument_list|(
name|collectionStats
argument_list|,
name|termStats
argument_list|)
decl_stmt|;
return|return
operator|new
name|IDFStats
argument_list|(
name|collectionStats
operator|.
name|field
argument_list|()
argument_list|,
name|idf
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|simScorer
specifier|public
specifier|final
name|SimScorer
name|simScorer
parameter_list|(
name|SimWeight
name|stats
parameter_list|,
name|LeafReaderContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
name|IDFStats
name|idfstats
init|=
operator|(
name|IDFStats
operator|)
name|stats
decl_stmt|;
return|return
operator|new
name|TFIDFSimScorer
argument_list|(
name|idfstats
argument_list|,
name|context
operator|.
name|reader
argument_list|()
operator|.
name|getNormValues
argument_list|(
name|idfstats
operator|.
name|field
argument_list|)
argument_list|)
return|;
block|}
DECL|class|TFIDFSimScorer
specifier|private
specifier|final
class|class
name|TFIDFSimScorer
extends|extends
name|SimScorer
block|{
DECL|field|stats
specifier|private
specifier|final
name|IDFStats
name|stats
decl_stmt|;
DECL|field|weightValue
specifier|private
specifier|final
name|float
name|weightValue
decl_stmt|;
DECL|field|norms
specifier|private
specifier|final
name|NumericDocValues
name|norms
decl_stmt|;
DECL|method|TFIDFSimScorer
name|TFIDFSimScorer
parameter_list|(
name|IDFStats
name|stats
parameter_list|,
name|NumericDocValues
name|norms
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|stats
operator|=
name|stats
expr_stmt|;
name|this
operator|.
name|weightValue
operator|=
name|stats
operator|.
name|value
expr_stmt|;
name|this
operator|.
name|norms
operator|=
name|norms
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|score
specifier|public
name|float
name|score
parameter_list|(
name|int
name|doc
parameter_list|,
name|float
name|freq
parameter_list|)
block|{
specifier|final
name|float
name|raw
init|=
name|tf
argument_list|(
name|freq
argument_list|)
operator|*
name|weightValue
decl_stmt|;
comment|// compute tf(f)*weight
return|return
name|norms
operator|==
literal|null
condition|?
name|raw
else|:
name|raw
operator|*
name|decodeNormValue
argument_list|(
name|norms
operator|.
name|get
argument_list|(
name|doc
argument_list|)
argument_list|)
return|;
comment|// normalize for field
block|}
annotation|@
name|Override
DECL|method|computeSlopFactor
specifier|public
name|float
name|computeSlopFactor
parameter_list|(
name|int
name|distance
parameter_list|)
block|{
return|return
name|sloppyFreq
argument_list|(
name|distance
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|computePayloadFactor
specifier|public
name|float
name|computePayloadFactor
parameter_list|(
name|int
name|doc
parameter_list|,
name|int
name|start
parameter_list|,
name|int
name|end
parameter_list|,
name|BytesRef
name|payload
parameter_list|)
block|{
return|return
name|scorePayload
argument_list|(
name|doc
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|payload
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|explain
specifier|public
name|Explanation
name|explain
parameter_list|(
name|int
name|doc
parameter_list|,
name|Explanation
name|freq
parameter_list|)
block|{
return|return
name|explainScore
argument_list|(
name|doc
argument_list|,
name|freq
argument_list|,
name|stats
argument_list|,
name|norms
argument_list|)
return|;
block|}
block|}
comment|/** Collection statistics for the TF-IDF model. The only statistic of interest    * to this model is idf. */
DECL|class|IDFStats
specifier|private
specifier|static
class|class
name|IDFStats
extends|extends
name|SimWeight
block|{
DECL|field|field
specifier|private
specifier|final
name|String
name|field
decl_stmt|;
comment|/** The idf and its explanation */
DECL|field|idf
specifier|private
specifier|final
name|Explanation
name|idf
decl_stmt|;
DECL|field|queryNorm
specifier|private
name|float
name|queryNorm
decl_stmt|;
DECL|field|boost
specifier|private
name|float
name|boost
decl_stmt|;
DECL|field|queryWeight
specifier|private
name|float
name|queryWeight
decl_stmt|;
DECL|field|value
specifier|private
name|float
name|value
decl_stmt|;
DECL|method|IDFStats
specifier|public
name|IDFStats
parameter_list|(
name|String
name|field
parameter_list|,
name|Explanation
name|idf
parameter_list|)
block|{
comment|// TODO: Validate?
name|this
operator|.
name|field
operator|=
name|field
expr_stmt|;
name|this
operator|.
name|idf
operator|=
name|idf
expr_stmt|;
name|normalize
argument_list|(
literal|1f
argument_list|,
literal|1f
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getValueForNormalization
specifier|public
name|float
name|getValueForNormalization
parameter_list|()
block|{
comment|// TODO: (sorta LUCENE-1907) make non-static class and expose this squaring via a nice method to subclasses?
return|return
name|queryWeight
operator|*
name|queryWeight
return|;
comment|// sum of squared weights
block|}
annotation|@
name|Override
DECL|method|normalize
specifier|public
name|void
name|normalize
parameter_list|(
name|float
name|queryNorm
parameter_list|,
name|float
name|boost
parameter_list|)
block|{
name|this
operator|.
name|boost
operator|=
name|boost
expr_stmt|;
name|this
operator|.
name|queryNorm
operator|=
name|queryNorm
expr_stmt|;
name|queryWeight
operator|=
name|queryNorm
operator|*
name|boost
operator|*
name|idf
operator|.
name|getValue
argument_list|()
expr_stmt|;
name|value
operator|=
name|queryWeight
operator|*
name|idf
operator|.
name|getValue
argument_list|()
expr_stmt|;
comment|// idf for document
block|}
block|}
DECL|method|explainQuery
specifier|private
name|Explanation
name|explainQuery
parameter_list|(
name|IDFStats
name|stats
parameter_list|)
block|{
name|List
argument_list|<
name|Explanation
argument_list|>
name|subs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Explanation
name|boostExpl
init|=
name|Explanation
operator|.
name|match
argument_list|(
name|stats
operator|.
name|boost
argument_list|,
literal|"boost"
argument_list|)
decl_stmt|;
if|if
condition|(
name|stats
operator|.
name|boost
operator|!=
literal|1.0f
condition|)
name|subs
operator|.
name|add
argument_list|(
name|boostExpl
argument_list|)
expr_stmt|;
name|subs
operator|.
name|add
argument_list|(
name|stats
operator|.
name|idf
argument_list|)
expr_stmt|;
name|Explanation
name|queryNormExpl
init|=
name|Explanation
operator|.
name|match
argument_list|(
name|stats
operator|.
name|queryNorm
argument_list|,
literal|"queryNorm"
argument_list|)
decl_stmt|;
name|subs
operator|.
name|add
argument_list|(
name|queryNormExpl
argument_list|)
expr_stmt|;
return|return
name|Explanation
operator|.
name|match
argument_list|(
name|boostExpl
operator|.
name|getValue
argument_list|()
operator|*
name|stats
operator|.
name|idf
operator|.
name|getValue
argument_list|()
operator|*
name|queryNormExpl
operator|.
name|getValue
argument_list|()
argument_list|,
literal|"queryWeight, product of:"
argument_list|,
name|subs
argument_list|)
return|;
block|}
DECL|method|explainField
specifier|private
name|Explanation
name|explainField
parameter_list|(
name|int
name|doc
parameter_list|,
name|Explanation
name|freq
parameter_list|,
name|IDFStats
name|stats
parameter_list|,
name|NumericDocValues
name|norms
parameter_list|)
block|{
name|Explanation
name|tfExplanation
init|=
name|Explanation
operator|.
name|match
argument_list|(
name|tf
argument_list|(
name|freq
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|,
literal|"tf(freq="
operator|+
name|freq
operator|.
name|getValue
argument_list|()
operator|+
literal|"), with freq of:"
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|Explanation
name|fieldNormExpl
init|=
name|Explanation
operator|.
name|match
argument_list|(
name|norms
operator|!=
literal|null
condition|?
name|decodeNormValue
argument_list|(
name|norms
operator|.
name|get
argument_list|(
name|doc
argument_list|)
argument_list|)
else|:
literal|1.0f
argument_list|,
literal|"fieldNorm(doc="
operator|+
name|doc
operator|+
literal|")"
argument_list|)
decl_stmt|;
return|return
name|Explanation
operator|.
name|match
argument_list|(
name|tfExplanation
operator|.
name|getValue
argument_list|()
operator|*
name|stats
operator|.
name|idf
operator|.
name|getValue
argument_list|()
operator|*
name|fieldNormExpl
operator|.
name|getValue
argument_list|()
argument_list|,
literal|"fieldWeight in "
operator|+
name|doc
operator|+
literal|", product of:"
argument_list|,
name|tfExplanation
argument_list|,
name|stats
operator|.
name|idf
argument_list|,
name|fieldNormExpl
argument_list|)
return|;
block|}
DECL|method|explainScore
specifier|private
name|Explanation
name|explainScore
parameter_list|(
name|int
name|doc
parameter_list|,
name|Explanation
name|freq
parameter_list|,
name|IDFStats
name|stats
parameter_list|,
name|NumericDocValues
name|norms
parameter_list|)
block|{
name|Explanation
name|queryExpl
init|=
name|explainQuery
argument_list|(
name|stats
argument_list|)
decl_stmt|;
name|Explanation
name|fieldExpl
init|=
name|explainField
argument_list|(
name|doc
argument_list|,
name|freq
argument_list|,
name|stats
argument_list|,
name|norms
argument_list|)
decl_stmt|;
if|if
condition|(
name|queryExpl
operator|.
name|getValue
argument_list|()
operator|==
literal|1f
condition|)
block|{
return|return
name|fieldExpl
return|;
block|}
return|return
name|Explanation
operator|.
name|match
argument_list|(
name|queryExpl
operator|.
name|getValue
argument_list|()
operator|*
name|fieldExpl
operator|.
name|getValue
argument_list|()
argument_list|,
literal|"score(doc="
operator|+
name|doc
operator|+
literal|",freq="
operator|+
name|freq
operator|.
name|getValue
argument_list|()
operator|+
literal|"), product of:"
argument_list|,
name|queryExpl
argument_list|,
name|fieldExpl
argument_list|)
return|;
block|}
block|}
end_class
end_unit
