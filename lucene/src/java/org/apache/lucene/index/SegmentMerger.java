begin_unit
begin_package
DECL|package|org.apache.lucene.index
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
package|;
end_package
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Document
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
operator|.
name|FieldOption
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MergePolicy
operator|.
name|MergeAbortedException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|codecs
operator|.
name|CodecProvider
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|codecs
operator|.
name|Codec
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|codecs
operator|.
name|MergeState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|codecs
operator|.
name|FieldsConsumer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|IndexOutput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Bits
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ReaderUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|MultiBits
import|;
end_import
begin_comment
comment|/**  * The SegmentMerger class combines two or more Segments, represented by an IndexReader ({@link #add},  * into a single Segment.  After adding the appropriate readers, call the merge method to combine the   * segments.  *   * @see #merge  * @see #add  */
end_comment
begin_class
DECL|class|SegmentMerger
specifier|final
class|class
name|SegmentMerger
block|{
comment|/** norms header placeholder */
DECL|field|NORMS_HEADER
specifier|static
specifier|final
name|byte
index|[]
name|NORMS_HEADER
init|=
operator|new
name|byte
index|[]
block|{
literal|'N'
block|,
literal|'R'
block|,
literal|'M'
block|,
operator|-
literal|1
block|}
decl_stmt|;
DECL|field|directory
specifier|private
name|Directory
name|directory
decl_stmt|;
DECL|field|segment
specifier|private
name|String
name|segment
decl_stmt|;
DECL|field|termIndexInterval
specifier|private
name|int
name|termIndexInterval
init|=
name|IndexWriterConfig
operator|.
name|DEFAULT_TERM_INDEX_INTERVAL
decl_stmt|;
DECL|field|readers
specifier|private
name|List
argument_list|<
name|IndexReader
argument_list|>
name|readers
init|=
operator|new
name|ArrayList
argument_list|<
name|IndexReader
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|fieldInfos
specifier|private
name|FieldInfos
name|fieldInfos
decl_stmt|;
DECL|field|mergedDocs
specifier|private
name|int
name|mergedDocs
decl_stmt|;
DECL|field|checkAbort
specifier|private
specifier|final
name|CheckAbort
name|checkAbort
decl_stmt|;
comment|// Whether we should merge doc stores (stored fields and
comment|// vectors files).  When all segments we are merging
comment|// already share the same doc store files, we don't need
comment|// to merge the doc stores.
DECL|field|mergeDocStores
specifier|private
name|boolean
name|mergeDocStores
decl_stmt|;
comment|/** Maximum number of contiguous documents to bulk-copy       when merging stored fields */
DECL|field|MAX_RAW_MERGE_DOCS
specifier|private
specifier|final
specifier|static
name|int
name|MAX_RAW_MERGE_DOCS
init|=
literal|4192
decl_stmt|;
DECL|field|codecs
specifier|private
specifier|final
name|CodecProvider
name|codecs
decl_stmt|;
DECL|field|codec
specifier|private
name|Codec
name|codec
decl_stmt|;
DECL|field|segmentWriteState
specifier|private
name|SegmentWriteState
name|segmentWriteState
decl_stmt|;
DECL|field|payloadProcessorProvider
specifier|private
name|PayloadProcessorProvider
name|payloadProcessorProvider
decl_stmt|;
DECL|method|SegmentMerger
name|SegmentMerger
parameter_list|(
name|Directory
name|dir
parameter_list|,
name|int
name|termIndexInterval
parameter_list|,
name|String
name|name
parameter_list|,
name|MergePolicy
operator|.
name|OneMerge
name|merge
parameter_list|,
name|CodecProvider
name|codecs
parameter_list|,
name|PayloadProcessorProvider
name|payloadProcessorProvider
parameter_list|)
block|{
name|this
operator|.
name|payloadProcessorProvider
operator|=
name|payloadProcessorProvider
expr_stmt|;
name|directory
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|codecs
operator|=
name|codecs
expr_stmt|;
name|segment
operator|=
name|name
expr_stmt|;
if|if
condition|(
name|merge
operator|!=
literal|null
condition|)
block|{
name|checkAbort
operator|=
operator|new
name|CheckAbort
argument_list|(
name|merge
argument_list|,
name|directory
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|checkAbort
operator|=
operator|new
name|CheckAbort
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|void
name|work
parameter_list|(
name|double
name|units
parameter_list|)
throws|throws
name|MergeAbortedException
block|{
comment|// do nothing
block|}
block|}
expr_stmt|;
block|}
name|this
operator|.
name|termIndexInterval
operator|=
name|termIndexInterval
expr_stmt|;
block|}
DECL|method|fieldInfos
specifier|public
name|FieldInfos
name|fieldInfos
parameter_list|()
block|{
return|return
name|fieldInfos
return|;
block|}
comment|/**    * Add an IndexReader to the collection of readers that are to be merged    * @param reader    */
DECL|method|add
specifier|final
name|void
name|add
parameter_list|(
name|IndexReader
name|reader
parameter_list|)
block|{
name|ReaderUtil
operator|.
name|gatherSubReaders
argument_list|(
name|readers
argument_list|,
name|reader
argument_list|)
expr_stmt|;
block|}
comment|/**    * Merges the readers specified by the {@link #add} method into the directory passed to the constructor    * @return The number of documents that were merged    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|merge
specifier|final
name|int
name|merge
parameter_list|()
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
return|return
name|merge
argument_list|(
literal|true
argument_list|)
return|;
block|}
comment|/**    * Merges the readers specified by the {@link #add} method    * into the directory passed to the constructor.    * @param mergeDocStores if false, we will not merge the    * stored fields nor vectors files    * @return The number of documents that were merged    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|merge
specifier|final
name|int
name|merge
parameter_list|(
name|boolean
name|mergeDocStores
parameter_list|)
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
name|this
operator|.
name|mergeDocStores
operator|=
name|mergeDocStores
expr_stmt|;
comment|// NOTE: it's important to add calls to
comment|// checkAbort.work(...) if you make any changes to this
comment|// method that will spend alot of time.  The frequency
comment|// of this check impacts how long
comment|// IndexWriter.close(false) takes to actually stop the
comment|// threads.
name|mergedDocs
operator|=
name|mergeFields
argument_list|()
expr_stmt|;
name|mergeTerms
argument_list|()
expr_stmt|;
name|mergeNorms
argument_list|()
expr_stmt|;
if|if
condition|(
name|mergeDocStores
operator|&&
name|fieldInfos
operator|.
name|hasVectors
argument_list|()
condition|)
block|{
name|mergeVectors
argument_list|()
expr_stmt|;
block|}
return|return
name|mergedDocs
return|;
block|}
DECL|method|getMergedFiles
specifier|final
name|Collection
argument_list|<
name|String
argument_list|>
name|getMergedFiles
parameter_list|(
specifier|final
name|SegmentInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|fileSet
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
comment|// Basic files
for|for
control|(
name|String
name|ext
range|:
name|IndexFileNames
operator|.
name|COMPOUND_EXTENSIONS_NOT_CODEC
control|)
block|{
if|if
condition|(
name|mergeDocStores
operator|||
operator|(
operator|!
name|ext
operator|.
name|equals
argument_list|(
name|IndexFileNames
operator|.
name|FIELDS_EXTENSION
argument_list|)
operator|&&
operator|!
name|ext
operator|.
name|equals
argument_list|(
name|IndexFileNames
operator|.
name|FIELDS_INDEX_EXTENSION
argument_list|)
operator|)
condition|)
name|fileSet
operator|.
name|add
argument_list|(
name|IndexFileNames
operator|.
name|segmentFileName
argument_list|(
name|segment
argument_list|,
literal|""
argument_list|,
name|ext
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|segmentWriteState
operator|.
name|segmentCodecs
operator|.
name|files
argument_list|(
name|directory
argument_list|,
name|info
argument_list|,
name|fileSet
argument_list|)
expr_stmt|;
comment|// Fieldable norm files
name|int
name|numFIs
init|=
name|fieldInfos
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numFIs
condition|;
name|i
operator|++
control|)
block|{
name|FieldInfo
name|fi
init|=
name|fieldInfos
operator|.
name|fieldInfo
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|fi
operator|.
name|isIndexed
operator|&&
operator|!
name|fi
operator|.
name|omitNorms
condition|)
block|{
name|fileSet
operator|.
name|add
argument_list|(
name|IndexFileNames
operator|.
name|segmentFileName
argument_list|(
name|segment
argument_list|,
literal|""
argument_list|,
name|IndexFileNames
operator|.
name|NORMS_EXTENSION
argument_list|)
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
comment|// Vector files
if|if
condition|(
name|fieldInfos
operator|.
name|hasVectors
argument_list|()
operator|&&
name|mergeDocStores
condition|)
block|{
for|for
control|(
name|String
name|ext
range|:
name|IndexFileNames
operator|.
name|VECTOR_EXTENSIONS
control|)
block|{
name|fileSet
operator|.
name|add
argument_list|(
name|IndexFileNames
operator|.
name|segmentFileName
argument_list|(
name|segment
argument_list|,
literal|""
argument_list|,
name|ext
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|fileSet
return|;
block|}
DECL|method|createCompoundFile
specifier|final
name|Collection
argument_list|<
name|String
argument_list|>
name|createCompoundFile
parameter_list|(
name|String
name|fileName
parameter_list|,
specifier|final
name|SegmentInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Now merge all added files
name|Collection
argument_list|<
name|String
argument_list|>
name|files
init|=
name|getMergedFiles
argument_list|(
name|info
argument_list|)
decl_stmt|;
name|CompoundFileWriter
name|cfsWriter
init|=
operator|new
name|CompoundFileWriter
argument_list|(
name|directory
argument_list|,
name|fileName
argument_list|,
name|checkAbort
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|file
range|:
name|files
control|)
block|{
name|cfsWriter
operator|.
name|addFile
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
comment|// Perform the merge
name|cfsWriter
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|files
return|;
block|}
DECL|method|addIndexed
specifier|private
specifier|static
name|void
name|addIndexed
parameter_list|(
name|IndexReader
name|reader
parameter_list|,
name|FieldInfos
name|fInfos
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|names
parameter_list|,
name|boolean
name|storeTermVectors
parameter_list|,
name|boolean
name|storePositionWithTermVector
parameter_list|,
name|boolean
name|storeOffsetWithTermVector
parameter_list|,
name|boolean
name|storePayloads
parameter_list|,
name|boolean
name|omitTFAndPositions
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|String
name|field
range|:
name|names
control|)
block|{
name|fInfos
operator|.
name|add
argument_list|(
name|field
argument_list|,
literal|true
argument_list|,
name|storeTermVectors
argument_list|,
name|storePositionWithTermVector
argument_list|,
name|storeOffsetWithTermVector
argument_list|,
operator|!
name|reader
operator|.
name|hasNorms
argument_list|(
name|field
argument_list|)
argument_list|,
name|storePayloads
argument_list|,
name|omitTFAndPositions
argument_list|)
expr_stmt|;
block|}
block|}
DECL|field|matchingSegmentReaders
specifier|private
name|SegmentReader
index|[]
name|matchingSegmentReaders
decl_stmt|;
DECL|field|rawDocLengths
specifier|private
name|int
index|[]
name|rawDocLengths
decl_stmt|;
DECL|field|rawDocLengths2
specifier|private
name|int
index|[]
name|rawDocLengths2
decl_stmt|;
DECL|method|setMatchingSegmentReaders
specifier|private
name|void
name|setMatchingSegmentReaders
parameter_list|()
block|{
comment|// If the i'th reader is a SegmentReader and has
comment|// identical fieldName -> number mapping, then this
comment|// array will be non-null at position i:
name|int
name|numReaders
init|=
name|readers
operator|.
name|size
argument_list|()
decl_stmt|;
name|matchingSegmentReaders
operator|=
operator|new
name|SegmentReader
index|[
name|numReaders
index|]
expr_stmt|;
comment|// If this reader is a SegmentReader, and all of its
comment|// field name -> number mappings match the "merged"
comment|// FieldInfos, then we can do a bulk copy of the
comment|// stored fields:
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numReaders
condition|;
name|i
operator|++
control|)
block|{
name|IndexReader
name|reader
init|=
name|readers
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|instanceof
name|SegmentReader
condition|)
block|{
name|SegmentReader
name|segmentReader
init|=
operator|(
name|SegmentReader
operator|)
name|reader
decl_stmt|;
name|boolean
name|same
init|=
literal|true
decl_stmt|;
name|FieldInfos
name|segmentFieldInfos
init|=
name|segmentReader
operator|.
name|fieldInfos
argument_list|()
decl_stmt|;
name|int
name|numFieldInfos
init|=
name|segmentFieldInfos
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|same
operator|&&
name|j
operator|<
name|numFieldInfos
condition|;
name|j
operator|++
control|)
block|{
name|same
operator|=
name|fieldInfos
operator|.
name|fieldName
argument_list|(
name|j
argument_list|)
operator|.
name|equals
argument_list|(
name|segmentFieldInfos
operator|.
name|fieldName
argument_list|(
name|j
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|same
condition|)
block|{
name|matchingSegmentReaders
index|[
name|i
index|]
operator|=
name|segmentReader
expr_stmt|;
block|}
block|}
block|}
comment|// Used for bulk-reading raw bytes for stored fields
name|rawDocLengths
operator|=
operator|new
name|int
index|[
name|MAX_RAW_MERGE_DOCS
index|]
expr_stmt|;
name|rawDocLengths2
operator|=
operator|new
name|int
index|[
name|MAX_RAW_MERGE_DOCS
index|]
expr_stmt|;
block|}
comment|/**    *     * @return The number of documents in all of the readers    * @throws CorruptIndexException if the index is corrupt    * @throws IOException if there is a low-level IO error    */
DECL|method|mergeFields
specifier|private
specifier|final
name|int
name|mergeFields
parameter_list|()
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
if|if
condition|(
operator|!
name|mergeDocStores
condition|)
block|{
comment|// When we are not merging by doc stores, their field
comment|// name -> number mapping are the same.  So, we start
comment|// with the fieldInfos of the last segment in this
comment|// case, to keep that numbering.
specifier|final
name|SegmentReader
name|sr
init|=
operator|(
name|SegmentReader
operator|)
name|readers
operator|.
name|get
argument_list|(
name|readers
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|fieldInfos
operator|=
operator|(
name|FieldInfos
operator|)
name|sr
operator|.
name|core
operator|.
name|fieldInfos
operator|.
name|clone
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|fieldInfos
operator|=
operator|new
name|FieldInfos
argument_list|()
expr_stmt|;
comment|// merge field names
block|}
for|for
control|(
name|IndexReader
name|reader
range|:
name|readers
control|)
block|{
if|if
condition|(
name|reader
operator|instanceof
name|SegmentReader
condition|)
block|{
name|SegmentReader
name|segmentReader
init|=
operator|(
name|SegmentReader
operator|)
name|reader
decl_stmt|;
name|FieldInfos
name|readerFieldInfos
init|=
name|segmentReader
operator|.
name|fieldInfos
argument_list|()
decl_stmt|;
name|int
name|numReaderFieldInfos
init|=
name|readerFieldInfos
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|numReaderFieldInfos
condition|;
name|j
operator|++
control|)
block|{
name|FieldInfo
name|fi
init|=
name|readerFieldInfos
operator|.
name|fieldInfo
argument_list|(
name|j
argument_list|)
decl_stmt|;
name|fieldInfos
operator|.
name|add
argument_list|(
name|fi
operator|.
name|name
argument_list|,
name|fi
operator|.
name|isIndexed
argument_list|,
name|fi
operator|.
name|storeTermVector
argument_list|,
name|fi
operator|.
name|storePositionWithTermVector
argument_list|,
name|fi
operator|.
name|storeOffsetWithTermVector
argument_list|,
operator|!
name|reader
operator|.
name|hasNorms
argument_list|(
name|fi
operator|.
name|name
argument_list|)
argument_list|,
name|fi
operator|.
name|storePayloads
argument_list|,
name|fi
operator|.
name|omitTermFreqAndPositions
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR_WITH_POSITION_OFFSET
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR_WITH_POSITION
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR_WITH_OFFSET
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|TERMVECTOR
argument_list|)
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|OMIT_TERM_FREQ_AND_POSITIONS
argument_list|)
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|STORES_PAYLOADS
argument_list|)
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|addIndexed
argument_list|(
name|reader
argument_list|,
name|fieldInfos
argument_list|,
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|INDEXED
argument_list|)
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|fieldInfos
operator|.
name|add
argument_list|(
name|reader
operator|.
name|getFieldNames
argument_list|(
name|FieldOption
operator|.
name|UNINDEXED
argument_list|)
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
specifier|final
name|SegmentCodecs
name|codecInfo
init|=
name|SegmentCodecs
operator|.
name|build
argument_list|(
name|fieldInfos
argument_list|,
name|this
operator|.
name|codecs
argument_list|)
decl_stmt|;
name|fieldInfos
operator|.
name|write
argument_list|(
name|directory
argument_list|,
name|segment
operator|+
literal|".fnm"
argument_list|)
expr_stmt|;
name|int
name|docCount
init|=
literal|0
decl_stmt|;
name|setMatchingSegmentReaders
argument_list|()
expr_stmt|;
if|if
condition|(
name|mergeDocStores
condition|)
block|{
comment|// merge field values
specifier|final
name|FieldsWriter
name|fieldsWriter
init|=
operator|new
name|FieldsWriter
argument_list|(
name|directory
argument_list|,
name|segment
argument_list|,
name|fieldInfos
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|idx
init|=
literal|0
decl_stmt|;
for|for
control|(
name|IndexReader
name|reader
range|:
name|readers
control|)
block|{
specifier|final
name|SegmentReader
name|matchingSegmentReader
init|=
name|matchingSegmentReaders
index|[
name|idx
operator|++
index|]
decl_stmt|;
name|FieldsReader
name|matchingFieldsReader
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|matchingSegmentReader
operator|!=
literal|null
condition|)
block|{
specifier|final
name|FieldsReader
name|fieldsReader
init|=
name|matchingSegmentReader
operator|.
name|getFieldsReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|fieldsReader
operator|!=
literal|null
condition|)
block|{
name|matchingFieldsReader
operator|=
name|fieldsReader
expr_stmt|;
block|}
block|}
if|if
condition|(
name|reader
operator|.
name|hasDeletions
argument_list|()
condition|)
block|{
name|docCount
operator|+=
name|copyFieldsWithDeletions
argument_list|(
name|fieldsWriter
argument_list|,
name|reader
argument_list|,
name|matchingFieldsReader
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|docCount
operator|+=
name|copyFieldsNoDeletions
argument_list|(
name|fieldsWriter
argument_list|,
name|reader
argument_list|,
name|matchingFieldsReader
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|fieldsWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
specifier|final
name|String
name|fileName
init|=
name|IndexFileNames
operator|.
name|segmentFileName
argument_list|(
name|segment
argument_list|,
literal|""
argument_list|,
name|IndexFileNames
operator|.
name|FIELDS_INDEX_EXTENSION
argument_list|)
decl_stmt|;
specifier|final
name|long
name|fdxFileLength
init|=
name|directory
operator|.
name|fileLength
argument_list|(
name|fileName
argument_list|)
decl_stmt|;
if|if
condition|(
literal|4
operator|+
operator|(
operator|(
name|long
operator|)
name|docCount
operator|)
operator|*
literal|8
operator|!=
name|fdxFileLength
condition|)
comment|// This is most likely a bug in Sun JRE 1.6.0_04/_05;
comment|// we detect that the bug has struck, here, and
comment|// throw an exception to prevent the corruption from
comment|// entering the index.  See LUCENE-1282 for
comment|// details.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"mergeFields produced an invalid result: docCount is "
operator|+
name|docCount
operator|+
literal|" but fdx file size is "
operator|+
name|fdxFileLength
operator|+
literal|" file="
operator|+
name|fileName
operator|+
literal|" file exists?="
operator|+
name|directory
operator|.
name|fileExists
argument_list|(
name|fileName
argument_list|)
operator|+
literal|"; now aborting this merge to prevent index corruption"
argument_list|)
throw|;
block|}
else|else
block|{
comment|// If we are skipping the doc stores, that means there
comment|// are no deletions in any of these segments, so we
comment|// just sum numDocs() of each segment to get total docCount
for|for
control|(
specifier|final
name|IndexReader
name|reader
range|:
name|readers
control|)
block|{
name|docCount
operator|+=
name|reader
operator|.
name|numDocs
argument_list|()
expr_stmt|;
block|}
block|}
name|segmentWriteState
operator|=
operator|new
name|SegmentWriteState
argument_list|(
literal|null
argument_list|,
name|directory
argument_list|,
name|segment
argument_list|,
name|fieldInfos
argument_list|,
literal|null
argument_list|,
name|docCount
argument_list|,
literal|0
argument_list|,
name|termIndexInterval
argument_list|,
name|codecInfo
argument_list|)
expr_stmt|;
return|return
name|docCount
return|;
block|}
DECL|method|copyFieldsWithDeletions
specifier|private
name|int
name|copyFieldsWithDeletions
parameter_list|(
specifier|final
name|FieldsWriter
name|fieldsWriter
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|,
specifier|final
name|FieldsReader
name|matchingFieldsReader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
throws|,
name|CorruptIndexException
block|{
name|int
name|docCount
init|=
literal|0
decl_stmt|;
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
specifier|final
name|Bits
name|delDocs
init|=
name|reader
operator|.
name|getDeletedDocs
argument_list|()
decl_stmt|;
if|if
condition|(
name|matchingFieldsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|maxDoc
condition|;
control|)
block|{
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|j
argument_list|)
condition|)
block|{
comment|// skip deleted docs
operator|++
name|j
expr_stmt|;
continue|continue;
block|}
comment|// We can optimize this case (doing a bulk byte copy) since the field
comment|// numbers are identical
name|int
name|start
init|=
name|j
decl_stmt|,
name|numDocs
init|=
literal|0
decl_stmt|;
do|do
block|{
name|j
operator|++
expr_stmt|;
name|numDocs
operator|++
expr_stmt|;
if|if
condition|(
name|j
operator|>=
name|maxDoc
condition|)
break|break;
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|j
argument_list|)
condition|)
block|{
name|j
operator|++
expr_stmt|;
break|break;
block|}
block|}
do|while
condition|(
name|numDocs
operator|<
name|MAX_RAW_MERGE_DOCS
condition|)
do|;
name|IndexInput
name|stream
init|=
name|matchingFieldsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|start
argument_list|,
name|numDocs
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addRawDocuments
argument_list|(
name|stream
argument_list|,
name|rawDocLengths
argument_list|,
name|numDocs
argument_list|)
expr_stmt|;
name|docCount
operator|+=
name|numDocs
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|numDocs
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|maxDoc
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|j
argument_list|)
condition|)
block|{
comment|// skip deleted docs
continue|continue;
block|}
comment|// NOTE: it's very important to first assign to doc then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|Document
name|doc
init|=
name|reader
operator|.
name|document
argument_list|(
name|j
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|docCount
operator|++
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|docCount
return|;
block|}
DECL|method|copyFieldsNoDeletions
specifier|private
name|int
name|copyFieldsNoDeletions
parameter_list|(
specifier|final
name|FieldsWriter
name|fieldsWriter
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|,
specifier|final
name|FieldsReader
name|matchingFieldsReader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
throws|,
name|CorruptIndexException
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
name|int
name|docCount
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|matchingFieldsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
while|while
condition|(
name|docCount
operator|<
name|maxDoc
condition|)
block|{
name|int
name|len
init|=
name|Math
operator|.
name|min
argument_list|(
name|MAX_RAW_MERGE_DOCS
argument_list|,
name|maxDoc
operator|-
name|docCount
argument_list|)
decl_stmt|;
name|IndexInput
name|stream
init|=
name|matchingFieldsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|docCount
argument_list|,
name|len
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addRawDocuments
argument_list|(
name|stream
argument_list|,
name|rawDocLengths
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|docCount
operator|+=
name|len
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|len
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
init|;
name|docCount
operator|<
name|maxDoc
condition|;
name|docCount
operator|++
control|)
block|{
comment|// NOTE: it's very important to first assign to doc then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|Document
name|doc
init|=
name|reader
operator|.
name|document
argument_list|(
name|docCount
argument_list|)
decl_stmt|;
name|fieldsWriter
operator|.
name|addDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|docCount
return|;
block|}
comment|/**    * Merge the TermVectors from each of the segments into the new one.    * @throws IOException    */
DECL|method|mergeVectors
specifier|private
specifier|final
name|void
name|mergeVectors
parameter_list|()
throws|throws
name|IOException
block|{
name|TermVectorsWriter
name|termVectorsWriter
init|=
operator|new
name|TermVectorsWriter
argument_list|(
name|directory
argument_list|,
name|segment
argument_list|,
name|fieldInfos
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|idx
init|=
literal|0
decl_stmt|;
for|for
control|(
specifier|final
name|IndexReader
name|reader
range|:
name|readers
control|)
block|{
specifier|final
name|SegmentReader
name|matchingSegmentReader
init|=
name|matchingSegmentReaders
index|[
name|idx
operator|++
index|]
decl_stmt|;
name|TermVectorsReader
name|matchingVectorsReader
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|matchingSegmentReader
operator|!=
literal|null
condition|)
block|{
name|TermVectorsReader
name|vectorsReader
init|=
name|matchingSegmentReader
operator|.
name|getTermVectorsReader
argument_list|()
decl_stmt|;
comment|// If the TV* files are an older format then they cannot read raw docs:
if|if
condition|(
name|vectorsReader
operator|!=
literal|null
operator|&&
name|vectorsReader
operator|.
name|canReadRawDocs
argument_list|()
condition|)
block|{
name|matchingVectorsReader
operator|=
name|vectorsReader
expr_stmt|;
block|}
block|}
if|if
condition|(
name|reader
operator|.
name|hasDeletions
argument_list|()
condition|)
block|{
name|copyVectorsWithDeletions
argument_list|(
name|termVectorsWriter
argument_list|,
name|matchingVectorsReader
argument_list|,
name|reader
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|copyVectorsNoDeletions
argument_list|(
name|termVectorsWriter
argument_list|,
name|matchingVectorsReader
argument_list|,
name|reader
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|termVectorsWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
specifier|final
name|String
name|fileName
init|=
name|IndexFileNames
operator|.
name|segmentFileName
argument_list|(
name|segment
argument_list|,
literal|""
argument_list|,
name|IndexFileNames
operator|.
name|VECTORS_INDEX_EXTENSION
argument_list|)
decl_stmt|;
specifier|final
name|long
name|tvxSize
init|=
name|directory
operator|.
name|fileLength
argument_list|(
name|fileName
argument_list|)
decl_stmt|;
if|if
condition|(
literal|4
operator|+
operator|(
operator|(
name|long
operator|)
name|mergedDocs
operator|)
operator|*
literal|16
operator|!=
name|tvxSize
condition|)
comment|// This is most likely a bug in Sun JRE 1.6.0_04/_05;
comment|// we detect that the bug has struck, here, and
comment|// throw an exception to prevent the corruption from
comment|// entering the index.  See LUCENE-1282 for
comment|// details.
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"mergeVectors produced an invalid result: mergedDocs is "
operator|+
name|mergedDocs
operator|+
literal|" but tvx size is "
operator|+
name|tvxSize
operator|+
literal|" file="
operator|+
name|fileName
operator|+
literal|" file exists?="
operator|+
name|directory
operator|.
name|fileExists
argument_list|(
name|fileName
argument_list|)
operator|+
literal|"; now aborting this merge to prevent index corruption"
argument_list|)
throw|;
block|}
DECL|method|copyVectorsWithDeletions
specifier|private
name|void
name|copyVectorsWithDeletions
parameter_list|(
specifier|final
name|TermVectorsWriter
name|termVectorsWriter
parameter_list|,
specifier|final
name|TermVectorsReader
name|matchingVectorsReader
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
specifier|final
name|Bits
name|delDocs
init|=
name|reader
operator|.
name|getDeletedDocs
argument_list|()
decl_stmt|;
if|if
condition|(
name|matchingVectorsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
for|for
control|(
name|int
name|docNum
init|=
literal|0
init|;
name|docNum
operator|<
name|maxDoc
condition|;
control|)
block|{
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|docNum
argument_list|)
condition|)
block|{
comment|// skip deleted docs
operator|++
name|docNum
expr_stmt|;
continue|continue;
block|}
comment|// We can optimize this case (doing a bulk byte copy) since the field
comment|// numbers are identical
name|int
name|start
init|=
name|docNum
decl_stmt|,
name|numDocs
init|=
literal|0
decl_stmt|;
do|do
block|{
name|docNum
operator|++
expr_stmt|;
name|numDocs
operator|++
expr_stmt|;
if|if
condition|(
name|docNum
operator|>=
name|maxDoc
condition|)
break|break;
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|docNum
argument_list|)
condition|)
block|{
name|docNum
operator|++
expr_stmt|;
break|break;
block|}
block|}
do|while
condition|(
name|numDocs
operator|<
name|MAX_RAW_MERGE_DOCS
condition|)
do|;
name|matchingVectorsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|start
argument_list|,
name|numDocs
argument_list|)
expr_stmt|;
name|termVectorsWriter
operator|.
name|addRawDocuments
argument_list|(
name|matchingVectorsReader
argument_list|,
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|numDocs
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|numDocs
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|docNum
init|=
literal|0
init|;
name|docNum
operator|<
name|maxDoc
condition|;
name|docNum
operator|++
control|)
block|{
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|docNum
argument_list|)
condition|)
block|{
comment|// skip deleted docs
continue|continue;
block|}
comment|// NOTE: it's very important to first assign to vectors then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|TermFreqVector
index|[]
name|vectors
init|=
name|reader
operator|.
name|getTermFreqVectors
argument_list|(
name|docNum
argument_list|)
decl_stmt|;
name|termVectorsWriter
operator|.
name|addAllDocVectors
argument_list|(
name|vectors
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|copyVectorsNoDeletions
specifier|private
name|void
name|copyVectorsNoDeletions
parameter_list|(
specifier|final
name|TermVectorsWriter
name|termVectorsWriter
parameter_list|,
specifier|final
name|TermVectorsReader
name|matchingVectorsReader
parameter_list|,
specifier|final
name|IndexReader
name|reader
parameter_list|)
throws|throws
name|IOException
throws|,
name|MergeAbortedException
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|matchingVectorsReader
operator|!=
literal|null
condition|)
block|{
comment|// We can bulk-copy because the fieldInfos are "congruent"
name|int
name|docCount
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|docCount
operator|<
name|maxDoc
condition|)
block|{
name|int
name|len
init|=
name|Math
operator|.
name|min
argument_list|(
name|MAX_RAW_MERGE_DOCS
argument_list|,
name|maxDoc
operator|-
name|docCount
argument_list|)
decl_stmt|;
name|matchingVectorsReader
operator|.
name|rawDocs
argument_list|(
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|docCount
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|termVectorsWriter
operator|.
name|addRawDocuments
argument_list|(
name|matchingVectorsReader
argument_list|,
name|rawDocLengths
argument_list|,
name|rawDocLengths2
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|docCount
operator|+=
name|len
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
operator|*
name|len
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|int
name|docNum
init|=
literal|0
init|;
name|docNum
operator|<
name|maxDoc
condition|;
name|docNum
operator|++
control|)
block|{
comment|// NOTE: it's very important to first assign to vectors then pass it to
comment|// termVectorsWriter.addAllDocVectors; see LUCENE-1282
name|TermFreqVector
index|[]
name|vectors
init|=
name|reader
operator|.
name|getTermFreqVectors
argument_list|(
name|docNum
argument_list|)
decl_stmt|;
name|termVectorsWriter
operator|.
name|addAllDocVectors
argument_list|(
name|vectors
argument_list|)
expr_stmt|;
name|checkAbort
operator|.
name|work
argument_list|(
literal|300
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|getSegmentCodecs
name|SegmentCodecs
name|getSegmentCodecs
parameter_list|()
block|{
assert|assert
name|segmentWriteState
operator|!=
literal|null
assert|;
return|return
name|segmentWriteState
operator|.
name|segmentCodecs
return|;
block|}
DECL|method|mergeTerms
specifier|private
specifier|final
name|void
name|mergeTerms
parameter_list|()
throws|throws
name|CorruptIndexException
throws|,
name|IOException
block|{
comment|// Let CodecProvider decide which codec will be used to write
comment|// the new segment:
name|int
name|docBase
init|=
literal|0
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Fields
argument_list|>
name|fields
init|=
operator|new
name|ArrayList
argument_list|<
name|Fields
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|ReaderUtil
operator|.
name|Slice
argument_list|>
name|slices
init|=
operator|new
name|ArrayList
argument_list|<
name|ReaderUtil
operator|.
name|Slice
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Bits
argument_list|>
name|bits
init|=
operator|new
name|ArrayList
argument_list|<
name|Bits
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Integer
argument_list|>
name|bitsStarts
init|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|IndexReader
name|r
range|:
name|readers
control|)
block|{
specifier|final
name|Fields
name|f
init|=
name|r
operator|.
name|fields
argument_list|()
decl_stmt|;
specifier|final
name|int
name|maxDoc
init|=
name|r
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|f
operator|!=
literal|null
condition|)
block|{
name|slices
operator|.
name|add
argument_list|(
operator|new
name|ReaderUtil
operator|.
name|Slice
argument_list|(
name|docBase
argument_list|,
name|maxDoc
argument_list|,
name|fields
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|fields
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
name|bits
operator|.
name|add
argument_list|(
name|r
operator|.
name|getDeletedDocs
argument_list|()
argument_list|)
expr_stmt|;
name|bitsStarts
operator|.
name|add
argument_list|(
name|docBase
argument_list|)
expr_stmt|;
block|}
name|docBase
operator|+=
name|maxDoc
expr_stmt|;
block|}
name|bitsStarts
operator|.
name|add
argument_list|(
name|docBase
argument_list|)
expr_stmt|;
comment|// we may gather more readers than mergeState.readerCount
name|mergeState
operator|=
operator|new
name|MergeState
argument_list|()
expr_stmt|;
name|mergeState
operator|.
name|readers
operator|=
name|readers
expr_stmt|;
name|mergeState
operator|.
name|readerCount
operator|=
name|readers
operator|.
name|size
argument_list|()
expr_stmt|;
name|mergeState
operator|.
name|fieldInfos
operator|=
name|fieldInfos
expr_stmt|;
name|mergeState
operator|.
name|mergedDocCount
operator|=
name|mergedDocs
expr_stmt|;
comment|// Remap docIDs
name|mergeState
operator|.
name|delCounts
operator|=
operator|new
name|int
index|[
name|mergeState
operator|.
name|readerCount
index|]
expr_stmt|;
name|mergeState
operator|.
name|docMaps
operator|=
operator|new
name|int
index|[
name|mergeState
operator|.
name|readerCount
index|]
index|[]
expr_stmt|;
name|mergeState
operator|.
name|docBase
operator|=
operator|new
name|int
index|[
name|mergeState
operator|.
name|readerCount
index|]
expr_stmt|;
name|mergeState
operator|.
name|hasPayloadProcessorProvider
operator|=
name|payloadProcessorProvider
operator|!=
literal|null
expr_stmt|;
name|mergeState
operator|.
name|dirPayloadProcessor
operator|=
operator|new
name|PayloadProcessorProvider
operator|.
name|DirPayloadProcessor
index|[
name|mergeState
operator|.
name|readerCount
index|]
expr_stmt|;
name|mergeState
operator|.
name|currentPayloadProcessor
operator|=
operator|new
name|PayloadProcessorProvider
operator|.
name|PayloadProcessor
index|[
name|mergeState
operator|.
name|readerCount
index|]
expr_stmt|;
name|docBase
operator|=
literal|0
expr_stmt|;
name|int
name|inputDocBase
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|mergeState
operator|.
name|readerCount
condition|;
name|i
operator|++
control|)
block|{
specifier|final
name|IndexReader
name|reader
init|=
name|readers
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|mergeState
operator|.
name|delCounts
index|[
name|i
index|]
operator|=
name|reader
operator|.
name|numDeletedDocs
argument_list|()
expr_stmt|;
name|mergeState
operator|.
name|docBase
index|[
name|i
index|]
operator|=
name|docBase
expr_stmt|;
name|docBase
operator|+=
name|reader
operator|.
name|numDocs
argument_list|()
expr_stmt|;
name|inputDocBase
operator|+=
name|reader
operator|.
name|maxDoc
argument_list|()
expr_stmt|;
if|if
condition|(
name|mergeState
operator|.
name|delCounts
index|[
name|i
index|]
operator|!=
literal|0
condition|)
block|{
name|int
name|delCount
init|=
literal|0
decl_stmt|;
specifier|final
name|Bits
name|delDocs
init|=
name|reader
operator|.
name|getDeletedDocs
argument_list|()
decl_stmt|;
assert|assert
name|delDocs
operator|!=
literal|null
assert|;
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
specifier|final
name|int
index|[]
name|docMap
init|=
name|mergeState
operator|.
name|docMaps
index|[
name|i
index|]
operator|=
operator|new
name|int
index|[
name|maxDoc
index|]
decl_stmt|;
name|int
name|newDocID
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|maxDoc
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|delDocs
operator|.
name|get
argument_list|(
name|j
argument_list|)
condition|)
block|{
name|docMap
index|[
name|j
index|]
operator|=
operator|-
literal|1
expr_stmt|;
name|delCount
operator|++
expr_stmt|;
comment|// only for assert
block|}
else|else
block|{
name|docMap
index|[
name|j
index|]
operator|=
name|newDocID
operator|++
expr_stmt|;
block|}
block|}
assert|assert
name|delCount
operator|==
name|mergeState
operator|.
name|delCounts
index|[
name|i
index|]
operator|:
literal|"reader delCount="
operator|+
name|mergeState
operator|.
name|delCounts
index|[
name|i
index|]
operator|+
literal|" vs recomputed delCount="
operator|+
name|delCount
assert|;
block|}
if|if
condition|(
name|payloadProcessorProvider
operator|!=
literal|null
condition|)
block|{
name|mergeState
operator|.
name|dirPayloadProcessor
index|[
name|i
index|]
operator|=
name|payloadProcessorProvider
operator|.
name|getDirProcessor
argument_list|(
name|reader
operator|.
name|directory
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|codec
operator|=
name|segmentWriteState
operator|.
name|segmentCodecs
operator|.
name|codec
argument_list|()
expr_stmt|;
specifier|final
name|FieldsConsumer
name|consumer
init|=
name|codec
operator|.
name|fieldsConsumer
argument_list|(
name|segmentWriteState
argument_list|)
decl_stmt|;
comment|// NOTE: this is silly, yet, necessary -- we create a
comment|// MultiBits as our skip docs only to have it broken
comment|// apart when we step through the docs enums in
comment|// MultiDocsEnum.
name|mergeState
operator|.
name|multiDeletedDocs
operator|=
operator|new
name|MultiBits
argument_list|(
name|bits
argument_list|,
name|bitsStarts
argument_list|)
expr_stmt|;
try|try
block|{
name|consumer
operator|.
name|merge
argument_list|(
name|mergeState
argument_list|,
operator|new
name|MultiFields
argument_list|(
name|fields
operator|.
name|toArray
argument_list|(
name|Fields
operator|.
name|EMPTY_ARRAY
argument_list|)
argument_list|,
name|slices
operator|.
name|toArray
argument_list|(
name|ReaderUtil
operator|.
name|Slice
operator|.
name|EMPTY_ARRAY
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|consumer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
DECL|field|mergeState
specifier|private
name|MergeState
name|mergeState
decl_stmt|;
DECL|method|getDocMaps
name|int
index|[]
index|[]
name|getDocMaps
parameter_list|()
block|{
return|return
name|mergeState
operator|.
name|docMaps
return|;
block|}
DECL|method|getDelCounts
name|int
index|[]
name|getDelCounts
parameter_list|()
block|{
return|return
name|mergeState
operator|.
name|delCounts
return|;
block|}
DECL|method|mergeNorms
specifier|private
name|void
name|mergeNorms
parameter_list|()
throws|throws
name|IOException
block|{
comment|// get needed buffer size by finding the largest segment
name|int
name|bufferSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|IndexReader
name|reader
range|:
name|readers
control|)
block|{
name|bufferSize
operator|=
name|Math
operator|.
name|max
argument_list|(
name|bufferSize
argument_list|,
name|reader
operator|.
name|maxDoc
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|byte
index|[]
name|normBuffer
init|=
literal|null
decl_stmt|;
name|IndexOutput
name|output
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|,
name|numFieldInfos
init|=
name|fieldInfos
operator|.
name|size
argument_list|()
init|;
name|i
operator|<
name|numFieldInfos
condition|;
name|i
operator|++
control|)
block|{
specifier|final
name|FieldInfo
name|fi
init|=
name|fieldInfos
operator|.
name|fieldInfo
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|fi
operator|.
name|isIndexed
operator|&&
operator|!
name|fi
operator|.
name|omitNorms
condition|)
block|{
if|if
condition|(
name|output
operator|==
literal|null
condition|)
block|{
name|output
operator|=
name|directory
operator|.
name|createOutput
argument_list|(
name|IndexFileNames
operator|.
name|segmentFileName
argument_list|(
name|segment
argument_list|,
literal|""
argument_list|,
name|IndexFileNames
operator|.
name|NORMS_EXTENSION
argument_list|)
argument_list|)
expr_stmt|;
name|output
operator|.
name|writeBytes
argument_list|(
name|NORMS_HEADER
argument_list|,
name|NORMS_HEADER
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|normBuffer
operator|==
literal|null
condition|)
block|{
name|normBuffer
operator|=
operator|new
name|byte
index|[
name|bufferSize
index|]
expr_stmt|;
block|}
for|for
control|(
name|IndexReader
name|reader
range|:
name|readers
control|)
block|{
specifier|final
name|int
name|maxDoc
init|=
name|reader
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
name|reader
operator|.
name|norms
argument_list|(
name|fi
operator|.
name|name
argument_list|,
name|normBuffer
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|reader
operator|.
name|hasDeletions
argument_list|()
condition|)
block|{
comment|//optimized case for segments without deleted docs
name|output
operator|.
name|writeBytes
argument_list|(
name|normBuffer
argument_list|,
name|maxDoc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// this segment has deleted docs, so we have to
comment|// check for every doc if it is deleted or not
specifier|final
name|Bits
name|delDocs
init|=
name|reader
operator|.
name|getDeletedDocs
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|maxDoc
condition|;
name|k
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|delDocs
operator|.
name|get
argument_list|(
name|k
argument_list|)
condition|)
block|{
name|output
operator|.
name|writeByte
argument_list|(
name|normBuffer
index|[
name|k
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|checkAbort
operator|.
name|work
argument_list|(
name|maxDoc
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|output
operator|!=
literal|null
condition|)
block|{
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|class|CheckAbort
specifier|static
class|class
name|CheckAbort
block|{
DECL|field|workCount
specifier|private
name|double
name|workCount
decl_stmt|;
DECL|field|merge
specifier|private
name|MergePolicy
operator|.
name|OneMerge
name|merge
decl_stmt|;
DECL|field|dir
specifier|private
name|Directory
name|dir
decl_stmt|;
DECL|method|CheckAbort
specifier|public
name|CheckAbort
parameter_list|(
name|MergePolicy
operator|.
name|OneMerge
name|merge
parameter_list|,
name|Directory
name|dir
parameter_list|)
block|{
name|this
operator|.
name|merge
operator|=
name|merge
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
block|}
comment|/**      * Records the fact that roughly units amount of work      * have been done since this method was last called.      * When adding time-consuming code into SegmentMerger,      * you should test different values for units to ensure      * that the time in between calls to merge.checkAborted      * is up to ~ 1 second.      */
DECL|method|work
specifier|public
name|void
name|work
parameter_list|(
name|double
name|units
parameter_list|)
throws|throws
name|MergePolicy
operator|.
name|MergeAbortedException
block|{
name|workCount
operator|+=
name|units
expr_stmt|;
if|if
condition|(
name|workCount
operator|>=
literal|10000.0
condition|)
block|{
name|merge
operator|.
name|checkAborted
argument_list|(
name|dir
argument_list|)
expr_stmt|;
name|workCount
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
block|}
end_class
end_unit
