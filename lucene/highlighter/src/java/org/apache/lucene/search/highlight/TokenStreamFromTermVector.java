begin_unit
begin_package
DECL|package|org.apache.lucene.search.highlight
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|highlight
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PackedTokenAttributeImpl
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PayloadAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|PostingsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Terms
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|TermsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|AttributeFactory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefArray
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|CharsRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Counter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|UnicodeUtil
import|;
end_import
begin_comment
comment|/**  * TokenStream created from a term vector field. The term vector requires positions and/or offsets (either). If you  * want payloads add PayloadAttributeImpl (as you would normally) but don't assume the attribute is already added just  * because you know the term vector has payloads, since the first call to incrementToken() will observe if you asked  * for them and if not then won't get them.  This TokenStream supports an efficient {@link #reset()}, so there's  * no need to wrap with a caching impl.  *<p>  * The implementation will create an array of tokens indexed by token position.  As long as there aren't massive jumps  * in positions, this is fine.  And it assumes there aren't large numbers of tokens at the same position, since it adds  * them to a linked-list per position in O(N^2) complexity.  When there aren't positions in the term vector, it divides  * the startOffset by 8 to use as a temporary substitute. In that case, tokens with the same startOffset will occupy  * the same final position; otherwise tokens become adjacent.  *  * @lucene.internal  */
end_comment
begin_class
DECL|class|TokenStreamFromTermVector
specifier|public
specifier|final
class|class
name|TokenStreamFromTermVector
extends|extends
name|TokenStream
block|{
comment|//This attribute factory uses less memory when captureState() is called.
DECL|field|ATTRIBUTE_FACTORY
specifier|public
specifier|static
specifier|final
name|AttributeFactory
name|ATTRIBUTE_FACTORY
init|=
name|AttributeFactory
operator|.
name|getStaticImplementation
argument_list|(
name|AttributeFactory
operator|.
name|DEFAULT_ATTRIBUTE_FACTORY
argument_list|,
name|PackedTokenAttributeImpl
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|vector
specifier|private
specifier|final
name|Terms
name|vector
decl_stmt|;
DECL|field|termAttribute
specifier|private
specifier|final
name|CharTermAttribute
name|termAttribute
decl_stmt|;
DECL|field|positionIncrementAttribute
specifier|private
specifier|final
name|PositionIncrementAttribute
name|positionIncrementAttribute
decl_stmt|;
DECL|field|maxStartOffset
specifier|private
specifier|final
name|int
name|maxStartOffset
decl_stmt|;
DECL|field|offsetAttribute
specifier|private
name|OffsetAttribute
name|offsetAttribute
decl_stmt|;
comment|//maybe null
DECL|field|payloadAttribute
specifier|private
name|PayloadAttribute
name|payloadAttribute
decl_stmt|;
comment|//maybe null
DECL|field|termCharsBuilder
specifier|private
name|CharsRefBuilder
name|termCharsBuilder
decl_stmt|;
comment|//term data here
DECL|field|payloadsBytesRefArray
specifier|private
name|BytesRefArray
name|payloadsBytesRefArray
decl_stmt|;
comment|//only used when payloadAttribute is non-null
DECL|field|spareBytesRefBuilder
specifier|private
name|BytesRefBuilder
name|spareBytesRefBuilder
decl_stmt|;
comment|//only used when payloadAttribute is non-null
DECL|field|firstToken
specifier|private
name|TokenLL
name|firstToken
init|=
literal|null
decl_stmt|;
comment|// the head of a linked-list
DECL|field|incrementToken
specifier|private
name|TokenLL
name|incrementToken
init|=
literal|null
decl_stmt|;
DECL|field|initialized
specifier|private
name|boolean
name|initialized
init|=
literal|false
decl_stmt|;
comment|//lazy
comment|/**    * Constructor. The uninversion doesn't happen here; it's delayed till the first call to    * {@link #incrementToken}.    *    * @param vector Terms that contains the data for    *        creating the TokenStream. Must have positions and/or offsets.    * @param maxStartOffset if a token's start offset exceeds this then the token is not added. -1 disables the limit.    */
DECL|method|TokenStreamFromTermVector
specifier|public
name|TokenStreamFromTermVector
parameter_list|(
name|Terms
name|vector
parameter_list|,
name|int
name|maxStartOffset
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|ATTRIBUTE_FACTORY
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxStartOffset
operator|=
name|maxStartOffset
operator|<
literal|0
condition|?
name|Integer
operator|.
name|MAX_VALUE
else|:
name|maxStartOffset
expr_stmt|;
assert|assert
operator|!
name|hasAttribute
argument_list|(
name|PayloadAttribute
operator|.
name|class
argument_list|)
operator|:
literal|"AttributeFactory shouldn't have payloads *yet*"
assert|;
if|if
condition|(
operator|!
name|vector
operator|.
name|hasPositions
argument_list|()
operator|&&
operator|!
name|vector
operator|.
name|hasOffsets
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The term vector needs positions and/or offsets."
argument_list|)
throw|;
block|}
assert|assert
name|vector
operator|.
name|hasFreqs
argument_list|()
assert|;
name|this
operator|.
name|vector
operator|=
name|vector
expr_stmt|;
name|termAttribute
operator|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
name|positionIncrementAttribute
operator|=
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
DECL|method|getTermVectorTerms
specifier|public
name|Terms
name|getTermVectorTerms
parameter_list|()
block|{
return|return
name|vector
return|;
block|}
annotation|@
name|Override
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|incrementToken
operator|=
literal|null
expr_stmt|;
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
comment|//We delay initialization because we can see which attributes the consumer wants, particularly payloads
DECL|method|init
specifier|private
name|void
name|init
parameter_list|()
throws|throws
name|IOException
block|{
assert|assert
operator|!
name|initialized
assert|;
name|short
name|dpEnumFlags
init|=
name|PostingsEnum
operator|.
name|POSITIONS
decl_stmt|;
if|if
condition|(
name|vector
operator|.
name|hasOffsets
argument_list|()
condition|)
block|{
name|dpEnumFlags
operator||=
name|PostingsEnum
operator|.
name|OFFSETS
expr_stmt|;
name|offsetAttribute
operator|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|vector
operator|.
name|hasPayloads
argument_list|()
operator|&&
name|hasAttribute
argument_list|(
name|PayloadAttribute
operator|.
name|class
argument_list|)
condition|)
block|{
name|dpEnumFlags
operator||=
operator|(
name|PostingsEnum
operator|.
name|OFFSETS
operator||
name|PostingsEnum
operator|.
name|PAYLOADS
operator|)
expr_stmt|;
comment|//must ask for offsets too
name|payloadAttribute
operator|=
name|getAttribute
argument_list|(
name|PayloadAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
name|payloadsBytesRefArray
operator|=
operator|new
name|BytesRefArray
argument_list|(
name|Counter
operator|.
name|newCounter
argument_list|()
argument_list|)
expr_stmt|;
name|spareBytesRefBuilder
operator|=
operator|new
name|BytesRefBuilder
argument_list|()
expr_stmt|;
block|}
comment|// We put term data here
name|termCharsBuilder
operator|=
operator|new
name|CharsRefBuilder
argument_list|()
expr_stmt|;
name|termCharsBuilder
operator|.
name|grow
argument_list|(
call|(
name|int
call|)
argument_list|(
name|vector
operator|.
name|size
argument_list|()
operator|*
literal|7
argument_list|)
argument_list|)
expr_stmt|;
comment|//7 is over-estimate of average term len
comment|// Step 1: iterate termsEnum and create a token, placing into an array of tokens by position
name|TokenLL
index|[]
name|positionedTokens
init|=
name|initTokensArray
argument_list|()
decl_stmt|;
name|int
name|lastPosition
init|=
operator|-
literal|1
decl_stmt|;
specifier|final
name|TermsEnum
name|termsEnum
init|=
name|vector
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|BytesRef
name|termBytesRef
decl_stmt|;
name|PostingsEnum
name|dpEnum
init|=
literal|null
decl_stmt|;
name|CharsRefBuilder
name|tempCharsRefBuilder
init|=
operator|new
name|CharsRefBuilder
argument_list|()
decl_stmt|;
comment|//only for UTF8->UTF16 call
comment|//int sumFreq = 0;
while|while
condition|(
operator|(
name|termBytesRef
operator|=
name|termsEnum
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
comment|//Grab the term (in same way as BytesRef.utf8ToString() but we don't want a String obj)
comment|// note: if term vectors supported seek by ord then we might just keep an int and seek by ord on-demand
name|tempCharsRefBuilder
operator|.
name|grow
argument_list|(
name|termBytesRef
operator|.
name|length
argument_list|)
expr_stmt|;
specifier|final
name|int
name|termCharsLen
init|=
name|UnicodeUtil
operator|.
name|UTF8toUTF16
argument_list|(
name|termBytesRef
argument_list|,
name|tempCharsRefBuilder
operator|.
name|chars
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|int
name|termCharsOff
init|=
name|termCharsBuilder
operator|.
name|length
argument_list|()
decl_stmt|;
name|termCharsBuilder
operator|.
name|append
argument_list|(
name|tempCharsRefBuilder
operator|.
name|chars
argument_list|()
argument_list|,
literal|0
argument_list|,
name|termCharsLen
argument_list|)
expr_stmt|;
name|dpEnum
operator|=
name|termsEnum
operator|.
name|postings
argument_list|(
name|dpEnum
argument_list|,
name|dpEnumFlags
argument_list|)
expr_stmt|;
assert|assert
name|dpEnum
operator|!=
literal|null
assert|;
comment|// presumably checked by TokenSources.hasPositions earlier
name|dpEnum
operator|.
name|nextDoc
argument_list|()
expr_stmt|;
specifier|final
name|int
name|freq
init|=
name|dpEnum
operator|.
name|freq
argument_list|()
decl_stmt|;
comment|//sumFreq += freq;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|freq
condition|;
name|j
operator|++
control|)
block|{
name|int
name|pos
init|=
name|dpEnum
operator|.
name|nextPosition
argument_list|()
decl_stmt|;
name|TokenLL
name|token
init|=
operator|new
name|TokenLL
argument_list|()
decl_stmt|;
name|token
operator|.
name|termCharsOff
operator|=
name|termCharsOff
expr_stmt|;
name|token
operator|.
name|termCharsLen
operator|=
operator|(
name|short
operator|)
name|Math
operator|.
name|min
argument_list|(
name|termCharsLen
argument_list|,
name|Short
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
if|if
condition|(
name|offsetAttribute
operator|!=
literal|null
condition|)
block|{
name|token
operator|.
name|startOffset
operator|=
name|dpEnum
operator|.
name|startOffset
argument_list|()
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|startOffset
operator|>
name|maxStartOffset
condition|)
block|{
continue|continue;
comment|//filter this token out; exceeds threshold
block|}
name|token
operator|.
name|endOffsetInc
operator|=
operator|(
name|short
operator|)
name|Math
operator|.
name|min
argument_list|(
name|dpEnum
operator|.
name|endOffset
argument_list|()
operator|-
name|token
operator|.
name|startOffset
argument_list|,
name|Short
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
if|if
condition|(
name|pos
operator|==
operator|-
literal|1
condition|)
block|{
name|pos
operator|=
name|token
operator|.
name|startOffset
operator|>>
literal|3
expr_stmt|;
comment|//divide by 8
block|}
block|}
if|if
condition|(
name|payloadAttribute
operator|!=
literal|null
condition|)
block|{
specifier|final
name|BytesRef
name|payload
init|=
name|dpEnum
operator|.
name|getPayload
argument_list|()
decl_stmt|;
name|token
operator|.
name|payloadIndex
operator|=
name|payload
operator|==
literal|null
condition|?
operator|-
literal|1
else|:
name|payloadsBytesRefArray
operator|.
name|append
argument_list|(
name|payload
argument_list|)
expr_stmt|;
block|}
comment|//Add token to an array indexed by position
if|if
condition|(
name|positionedTokens
operator|.
name|length
operator|<=
name|pos
condition|)
block|{
comment|//grow, but not 2x since we think our original length estimate is close
name|TokenLL
index|[]
name|newPositionedTokens
init|=
operator|new
name|TokenLL
index|[
call|(
name|int
call|)
argument_list|(
operator|(
name|pos
operator|+
literal|1
operator|)
operator|*
literal|1.5f
argument_list|)
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|positionedTokens
argument_list|,
literal|0
argument_list|,
name|newPositionedTokens
argument_list|,
literal|0
argument_list|,
name|lastPosition
operator|+
literal|1
argument_list|)
expr_stmt|;
name|positionedTokens
operator|=
name|newPositionedTokens
expr_stmt|;
block|}
name|positionedTokens
index|[
name|pos
index|]
operator|=
name|token
operator|.
name|insertIntoSortedLinkedList
argument_list|(
name|positionedTokens
index|[
name|pos
index|]
argument_list|)
expr_stmt|;
name|lastPosition
operator|=
name|Math
operator|.
name|max
argument_list|(
name|lastPosition
argument_list|,
name|pos
argument_list|)
expr_stmt|;
block|}
block|}
comment|//    System.out.println(String.format(
comment|//        "SumFreq: %5d Size: %4d SumFreq/size: %3.3f MaxPos: %4d MaxPos/SumFreq: %3.3f WastePct: %3.3f",
comment|//        sumFreq, vector.size(), (sumFreq / (float)vector.size()), lastPosition, ((float)lastPosition)/sumFreq,
comment|//        (originalPositionEstimate/(lastPosition + 1.0f))));
comment|// Step 2:  Link all Tokens into a linked-list and set position increments as we go
name|int
name|prevTokenPos
init|=
operator|-
literal|1
decl_stmt|;
name|TokenLL
name|prevToken
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|pos
init|=
literal|0
init|;
name|pos
operator|<=
name|lastPosition
condition|;
name|pos
operator|++
control|)
block|{
name|TokenLL
name|token
init|=
name|positionedTokens
index|[
name|pos
index|]
decl_stmt|;
if|if
condition|(
name|token
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|//link
if|if
condition|(
name|prevToken
operator|!=
literal|null
condition|)
block|{
assert|assert
name|prevToken
operator|.
name|next
operator|==
literal|null
assert|;
name|prevToken
operator|.
name|next
operator|=
name|token
expr_stmt|;
comment|//concatenate linked-list
block|}
else|else
block|{
assert|assert
name|firstToken
operator|==
literal|null
assert|;
name|firstToken
operator|=
name|token
expr_stmt|;
block|}
comment|//set increments
if|if
condition|(
name|vector
operator|.
name|hasPositions
argument_list|()
condition|)
block|{
name|token
operator|.
name|positionIncrement
operator|=
name|pos
operator|-
name|prevTokenPos
expr_stmt|;
while|while
condition|(
name|token
operator|.
name|next
operator|!=
literal|null
condition|)
block|{
name|token
operator|=
name|token
operator|.
name|next
expr_stmt|;
name|token
operator|.
name|positionIncrement
operator|=
literal|0
expr_stmt|;
block|}
block|}
else|else
block|{
name|token
operator|.
name|positionIncrement
operator|=
literal|1
expr_stmt|;
while|while
condition|(
name|token
operator|.
name|next
operator|!=
literal|null
condition|)
block|{
name|prevToken
operator|=
name|token
expr_stmt|;
name|token
operator|=
name|token
operator|.
name|next
expr_stmt|;
if|if
condition|(
name|prevToken
operator|.
name|startOffset
operator|==
name|token
operator|.
name|startOffset
condition|)
block|{
name|token
operator|.
name|positionIncrement
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|token
operator|.
name|positionIncrement
operator|=
literal|1
expr_stmt|;
block|}
block|}
block|}
name|prevTokenPos
operator|=
name|pos
expr_stmt|;
name|prevToken
operator|=
name|token
expr_stmt|;
block|}
name|initialized
operator|=
literal|true
expr_stmt|;
block|}
DECL|method|initTokensArray
specifier|private
name|TokenLL
index|[]
name|initTokensArray
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Estimate the number of position slots we need from term stats.  We use some estimation factors taken from
comment|//  Wikipedia that reduce the likelihood of needing to expand the array.
name|int
name|sumTotalTermFreq
init|=
operator|(
name|int
operator|)
name|vector
operator|.
name|getSumTotalTermFreq
argument_list|()
decl_stmt|;
if|if
condition|(
name|sumTotalTermFreq
operator|==
operator|-
literal|1
condition|)
block|{
comment|//unfortunately term vectors seem to not have this stat
name|int
name|size
init|=
operator|(
name|int
operator|)
name|vector
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|size
operator|==
operator|-
literal|1
condition|)
block|{
comment|//doesn't happen with term vectors, it seems, but pick a default any way
name|size
operator|=
literal|128
expr_stmt|;
block|}
name|sumTotalTermFreq
operator|=
call|(
name|int
call|)
argument_list|(
name|size
operator|*
literal|2.4
argument_list|)
expr_stmt|;
block|}
specifier|final
name|int
name|originalPositionEstimate
init|=
call|(
name|int
call|)
argument_list|(
name|sumTotalTermFreq
operator|*
literal|1.5
argument_list|)
decl_stmt|;
comment|//less than 1 in 10 docs exceed this
comment|// This estimate is based on maxStartOffset. Err on the side of this being larger than needed.
specifier|final
name|int
name|offsetLimitPositionEstimate
init|=
call|(
name|int
call|)
argument_list|(
name|maxStartOffset
operator|/
literal|5.0
argument_list|)
decl_stmt|;
comment|// Take the smaller of the two estimates, but no smaller than 64
return|return
operator|new
name|TokenLL
index|[
name|Math
operator|.
name|max
argument_list|(
literal|64
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|originalPositionEstimate
argument_list|,
name|offsetLimitPositionEstimate
argument_list|)
argument_list|)
index|]
return|;
block|}
annotation|@
name|Override
DECL|method|incrementToken
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|incrementToken
operator|==
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|initialized
condition|)
block|{
name|init
argument_list|()
expr_stmt|;
assert|assert
name|initialized
assert|;
block|}
name|incrementToken
operator|=
name|firstToken
expr_stmt|;
if|if
condition|(
name|incrementToken
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
elseif|else
if|if
condition|(
name|incrementToken
operator|.
name|next
operator|!=
literal|null
condition|)
block|{
name|incrementToken
operator|=
name|incrementToken
operator|.
name|next
expr_stmt|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
name|clearAttributes
argument_list|()
expr_stmt|;
name|termAttribute
operator|.
name|copyBuffer
argument_list|(
name|termCharsBuilder
operator|.
name|chars
argument_list|()
argument_list|,
name|incrementToken
operator|.
name|termCharsOff
argument_list|,
name|incrementToken
operator|.
name|termCharsLen
argument_list|)
expr_stmt|;
name|positionIncrementAttribute
operator|.
name|setPositionIncrement
argument_list|(
name|incrementToken
operator|.
name|positionIncrement
argument_list|)
expr_stmt|;
if|if
condition|(
name|offsetAttribute
operator|!=
literal|null
condition|)
block|{
name|offsetAttribute
operator|.
name|setOffset
argument_list|(
name|incrementToken
operator|.
name|startOffset
argument_list|,
name|incrementToken
operator|.
name|startOffset
operator|+
name|incrementToken
operator|.
name|endOffsetInc
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|payloadAttribute
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|incrementToken
operator|.
name|payloadIndex
operator|==
operator|-
literal|1
condition|)
block|{
name|payloadAttribute
operator|.
name|setPayload
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|payloadAttribute
operator|.
name|setPayload
argument_list|(
name|payloadsBytesRefArray
operator|.
name|get
argument_list|(
name|spareBytesRefBuilder
argument_list|,
name|incrementToken
operator|.
name|payloadIndex
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|true
return|;
block|}
DECL|class|TokenLL
specifier|private
specifier|static
class|class
name|TokenLL
block|{
comment|// This class should weigh 32 bytes, including object header
DECL|field|termCharsOff
name|int
name|termCharsOff
decl_stmt|;
comment|// see termCharsBuilder
DECL|field|termCharsLen
name|short
name|termCharsLen
decl_stmt|;
DECL|field|positionIncrement
name|int
name|positionIncrement
decl_stmt|;
DECL|field|startOffset
name|int
name|startOffset
decl_stmt|;
DECL|field|endOffsetInc
name|short
name|endOffsetInc
decl_stmt|;
comment|// add to startOffset to get endOffset
DECL|field|payloadIndex
name|int
name|payloadIndex
decl_stmt|;
DECL|field|next
name|TokenLL
name|next
decl_stmt|;
comment|/** Given the head of a linked-list (possibly null) this inserts the token at the correct      * spot to maintain the desired order, and returns the head (which could be this token if it's the smallest).      * O(N^2) complexity but N should be a handful at most.      */
DECL|method|insertIntoSortedLinkedList
name|TokenLL
name|insertIntoSortedLinkedList
parameter_list|(
specifier|final
name|TokenLL
name|head
parameter_list|)
block|{
assert|assert
name|next
operator|==
literal|null
assert|;
if|if
condition|(
name|head
operator|==
literal|null
condition|)
block|{
return|return
name|this
return|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|compareOffsets
argument_list|(
name|head
argument_list|)
operator|<=
literal|0
condition|)
block|{
name|this
operator|.
name|next
operator|=
name|head
expr_stmt|;
return|return
name|this
return|;
block|}
name|TokenLL
name|prev
init|=
name|head
decl_stmt|;
while|while
condition|(
name|prev
operator|.
name|next
operator|!=
literal|null
operator|&&
name|this
operator|.
name|compareOffsets
argument_list|(
name|prev
operator|.
name|next
argument_list|)
operator|>
literal|0
condition|)
block|{
name|prev
operator|=
name|prev
operator|.
name|next
expr_stmt|;
block|}
name|this
operator|.
name|next
operator|=
name|prev
operator|.
name|next
expr_stmt|;
name|prev
operator|.
name|next
operator|=
name|this
expr_stmt|;
return|return
name|head
return|;
block|}
comment|/** by startOffset then endOffset */
DECL|method|compareOffsets
name|int
name|compareOffsets
parameter_list|(
name|TokenLL
name|tokenB
parameter_list|)
block|{
name|int
name|cmp
init|=
name|Integer
operator|.
name|compare
argument_list|(
name|this
operator|.
name|startOffset
argument_list|,
name|tokenB
operator|.
name|startOffset
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|==
literal|0
condition|)
block|{
name|cmp
operator|=
name|Short
operator|.
name|compare
argument_list|(
name|this
operator|.
name|endOffsetInc
argument_list|,
name|tokenB
operator|.
name|endOffsetInc
argument_list|)
expr_stmt|;
block|}
return|return
name|cmp
return|;
block|}
block|}
block|}
end_class
end_unit
