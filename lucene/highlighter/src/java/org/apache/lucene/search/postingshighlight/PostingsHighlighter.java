begin_unit
begin_package
DECL|package|org.apache.lucene.search.postingshighlight
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|postingshighlight
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import
begin_import
import|import
name|java
operator|.
name|text
operator|.
name|BreakIterator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|PriorityQueue
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInfo
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexOptions
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReaderContext
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReaderContext
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MultiReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|PostingsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|ReaderUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|StoredFieldVisitor
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Term
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Terms
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|TermsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Query
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|ScoreDoc
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TopDocs
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|InPlaceMergeSorter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|UnicodeUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|CharacterRunAutomaton
import|;
end_import
begin_comment
comment|/**  * Simple highlighter that does not analyze fields nor use  * term vectors. Instead it requires   * {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}.  *<p>  * PostingsHighlighter treats the single original document as the whole corpus, and then scores individual  * passages as if they were documents in this corpus. It uses a {@link BreakIterator} to find   * passages in the text; by default it breaks using {@link BreakIterator#getSentenceInstance(Locale)   * getSentenceInstance(Locale.ROOT)}. It then iterates in parallel (merge sorting by offset) through   * the positions of all terms from the query, coalescing those hits that occur in a single passage   * into a {@link Passage}, and then scores each Passage using a separate {@link PassageScorer}.   * Passages are finally formatted into highlighted snippets with a {@link PassageFormatter}.  *<p>  * You can customize the behavior by subclassing this highlighter, some important hooks:  *<ul>  *<li>{@link #getBreakIterator(String)}: Customize how the text is divided into passages.  *<li>{@link #getScorer(String)}: Customize how passages are ranked.  *<li>{@link #getFormatter(String)}: Customize how snippets are formatted.  *<li>{@link #getIndexAnalyzer(String)}: Enable highlighting of MultiTermQuerys such as {@code WildcardQuery}.  *</ul>  *<p>  *<b>WARNING</b>: The code is very new and probably still has some exciting bugs!  *<p>  * Example usage:  *<pre class="prettyprint">  *   // configure field with offsets at index time  *   FieldType offsetsType = new FieldType(TextField.TYPE_STORED);  *   offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);  *   Field body = new Field("body", "foobar", offsetsType);  *  *   // retrieve highlights at query time   *   PostingsHighlighter highlighter = new PostingsHighlighter();  *   Query query = new TermQuery(new Term("body", "highlighting"));  *   TopDocs topDocs = searcher.search(query, n);  *   String highlights[] = highlighter.highlight("body", query, searcher, topDocs);  *</pre>  *<p>  * This is thread-safe, and can be used across different readers.  * @lucene.experimental  */
end_comment
begin_class
DECL|class|PostingsHighlighter
specifier|public
class|class
name|PostingsHighlighter
block|{
comment|// TODO: maybe allow re-analysis for tiny fields? currently we require offsets,
comment|// but if the analyzer is really fast and the field is tiny, this might really be
comment|// unnecessary.
comment|/** for rewriting: we don't want slow processing from MTQs */
DECL|field|EMPTY_INDEXSEARCHER
specifier|private
specifier|static
specifier|final
name|IndexSearcher
name|EMPTY_INDEXSEARCHER
decl_stmt|;
static|static
block|{
try|try
block|{
name|IndexReader
name|emptyReader
init|=
operator|new
name|MultiReader
argument_list|()
decl_stmt|;
name|EMPTY_INDEXSEARCHER
operator|=
operator|new
name|IndexSearcher
argument_list|(
name|emptyReader
argument_list|)
expr_stmt|;
name|EMPTY_INDEXSEARCHER
operator|.
name|setQueryCache
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|bogus
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|bogus
argument_list|)
throw|;
block|}
block|}
comment|/** Default maximum content size to process. Typically snippets    *  closer to the beginning of the document better summarize its content */
DECL|field|DEFAULT_MAX_LENGTH
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_LENGTH
init|=
literal|10000
decl_stmt|;
DECL|field|maxLength
specifier|private
specifier|final
name|int
name|maxLength
decl_stmt|;
comment|/** Set the first time {@link #getFormatter} is called,    *  and then reused. */
DECL|field|defaultFormatter
specifier|private
name|PassageFormatter
name|defaultFormatter
decl_stmt|;
comment|/** Set the first time {@link #getScorer} is called,    *  and then reused. */
DECL|field|defaultScorer
specifier|private
name|PassageScorer
name|defaultScorer
decl_stmt|;
comment|/**    * Creates a new highlighter with {@link #DEFAULT_MAX_LENGTH}.    */
DECL|method|PostingsHighlighter
specifier|public
name|PostingsHighlighter
parameter_list|()
block|{
name|this
argument_list|(
name|DEFAULT_MAX_LENGTH
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates a new highlighter, specifying maximum content length.    * @param maxLength maximum content size to process.    * @throws IllegalArgumentException if<code>maxLength</code> is negative or<code>Integer.MAX_VALUE</code>    */
DECL|method|PostingsHighlighter
specifier|public
name|PostingsHighlighter
parameter_list|(
name|int
name|maxLength
parameter_list|)
block|{
if|if
condition|(
name|maxLength
operator|<
literal|0
operator|||
name|maxLength
operator|==
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
comment|// two reasons: no overflow problems in BreakIterator.preceding(offset+1),
comment|// our sentinel in the offsets queue uses this value to terminate.
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxLength must be< Integer.MAX_VALUE"
argument_list|)
throw|;
block|}
name|this
operator|.
name|maxLength
operator|=
name|maxLength
expr_stmt|;
block|}
comment|/** Returns the {@link BreakIterator} to use for    *  dividing text into passages.  This returns     *  {@link BreakIterator#getSentenceInstance(Locale)} by default;    *  subclasses can override to customize. */
DECL|method|getBreakIterator
specifier|protected
name|BreakIterator
name|getBreakIterator
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|BreakIterator
operator|.
name|getSentenceInstance
argument_list|(
name|Locale
operator|.
name|ROOT
argument_list|)
return|;
block|}
comment|/** Returns the {@link PassageFormatter} to use for    *  formatting passages into highlighted snippets.  This    *  returns a new {@code PassageFormatter} by default;    *  subclasses can override to customize. */
DECL|method|getFormatter
specifier|protected
name|PassageFormatter
name|getFormatter
parameter_list|(
name|String
name|field
parameter_list|)
block|{
if|if
condition|(
name|defaultFormatter
operator|==
literal|null
condition|)
block|{
name|defaultFormatter
operator|=
operator|new
name|DefaultPassageFormatter
argument_list|()
expr_stmt|;
block|}
return|return
name|defaultFormatter
return|;
block|}
comment|/** Returns the {@link PassageScorer} to use for    *  ranking passages.  This    *  returns a new {@code PassageScorer} by default;    *  subclasses can override to customize. */
DECL|method|getScorer
specifier|protected
name|PassageScorer
name|getScorer
parameter_list|(
name|String
name|field
parameter_list|)
block|{
if|if
condition|(
name|defaultScorer
operator|==
literal|null
condition|)
block|{
name|defaultScorer
operator|=
operator|new
name|PassageScorer
argument_list|()
expr_stmt|;
block|}
return|return
name|defaultScorer
return|;
block|}
comment|/**    * Highlights the top passages from a single field.    *     * @param field field name to highlight.     *        Must have a stored string value and also be indexed with offsets.    * @param query query to highlight.    * @param searcher searcher that was previously used to execute the query.    * @param topDocs TopDocs containing the summary result documents to highlight.    * @return Array of formatted snippets corresponding to the documents in<code>topDocs</code>.     *         If no highlights were found for a document, the    *         first sentence for the field will be returned.    * @throws IOException if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without     *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlight
specifier|public
name|String
index|[]
name|highlight
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|IndexSearcher
name|searcher
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|highlight
argument_list|(
name|field
argument_list|,
name|query
argument_list|,
name|searcher
argument_list|,
name|topDocs
argument_list|,
literal|1
argument_list|)
return|;
block|}
comment|/**    * Highlights the top-N passages from a single field.    *     * @param field field name to highlight.     *        Must have a stored string value and also be indexed with offsets.    * @param query query to highlight.    * @param searcher searcher that was previously used to execute the query.    * @param topDocs TopDocs containing the summary result documents to highlight.    * @param maxPassages The maximum number of top-N ranked passages used to     *        form the highlighted snippets.    * @return Array of formatted snippets corresponding to the documents in<code>topDocs</code>.     *         If no highlights were found for a document, the    *         first {@code maxPassages} sentences from the    *         field will be returned.    * @throws IOException if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without     *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlight
specifier|public
name|String
index|[]
name|highlight
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|IndexSearcher
name|searcher
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|,
name|int
name|maxPassages
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|res
init|=
name|highlightFields
argument_list|(
operator|new
name|String
index|[]
block|{
name|field
block|}
argument_list|,
name|query
argument_list|,
name|searcher
argument_list|,
name|topDocs
argument_list|,
operator|new
name|int
index|[]
block|{
name|maxPassages
block|}
argument_list|)
decl_stmt|;
return|return
name|res
operator|.
name|get
argument_list|(
name|field
argument_list|)
return|;
block|}
comment|/**    * Highlights the top passages from multiple fields.    *<p>    * Conceptually, this behaves as a more efficient form of:    *<pre class="prettyprint">    * Map m = new HashMap();    * for (String field : fields) {    *   m.put(field, highlight(field, query, searcher, topDocs));    * }    * return m;    *</pre>    *     * @param fields field names to highlight.     *        Must have a stored string value and also be indexed with offsets.    * @param query query to highlight.    * @param searcher searcher that was previously used to execute the query.    * @param topDocs TopDocs containing the summary result documents to highlight.    * @return Map keyed on field name, containing the array of formatted snippets     *         corresponding to the documents in<code>topDocs</code>.     *         If no highlights were found for a document, the    *         first sentence from the field will be returned.    * @throws IOException if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without     *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFields
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|highlightFields
parameter_list|(
name|String
name|fields
index|[]
parameter_list|,
name|Query
name|query
parameter_list|,
name|IndexSearcher
name|searcher
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|maxPassages
index|[]
init|=
operator|new
name|int
index|[
name|fields
operator|.
name|length
index|]
decl_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|maxPassages
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
name|highlightFields
argument_list|(
name|fields
argument_list|,
name|query
argument_list|,
name|searcher
argument_list|,
name|topDocs
argument_list|,
name|maxPassages
argument_list|)
return|;
block|}
comment|/**    * Highlights the top-N passages from multiple fields.    *<p>    * Conceptually, this behaves as a more efficient form of:    *<pre class="prettyprint">    * Map m = new HashMap();    * for (String field : fields) {    *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));    * }    * return m;    *</pre>    *     * @param fields field names to highlight.     *        Must have a stored string value and also be indexed with offsets.    * @param query query to highlight.    * @param searcher searcher that was previously used to execute the query.    * @param topDocs TopDocs containing the summary result documents to highlight.    * @param maxPassages The maximum number of top-N ranked passages per-field used to     *        form the highlighted snippets.    * @return Map keyed on field name, containing the array of formatted snippets     *         corresponding to the documents in<code>topDocs</code>.     *         If no highlights were found for a document, the    *         first {@code maxPassages} sentences from the    *         field will be returned.    * @throws IOException if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without     *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFields
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|highlightFields
parameter_list|(
name|String
name|fields
index|[]
parameter_list|,
name|Query
name|query
parameter_list|,
name|IndexSearcher
name|searcher
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|,
name|int
name|maxPassages
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|ScoreDoc
name|scoreDocs
index|[]
init|=
name|topDocs
operator|.
name|scoreDocs
decl_stmt|;
name|int
name|docids
index|[]
init|=
operator|new
name|int
index|[
name|scoreDocs
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|docids
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|docids
index|[
name|i
index|]
operator|=
name|scoreDocs
index|[
name|i
index|]
operator|.
name|doc
expr_stmt|;
block|}
return|return
name|highlightFields
argument_list|(
name|fields
argument_list|,
name|query
argument_list|,
name|searcher
argument_list|,
name|docids
argument_list|,
name|maxPassages
argument_list|)
return|;
block|}
comment|/**    * Highlights the top-N passages from multiple fields,    * for the provided int[] docids.    *     * @param fieldsIn field names to highlight.     *        Must have a stored string value and also be indexed with offsets.    * @param query query to highlight.    * @param searcher searcher that was previously used to execute the query.    * @param docidsIn containing the document IDs to highlight.    * @param maxPassagesIn The maximum number of top-N ranked passages per-field used to     *        form the highlighted snippets.    * @return Map keyed on field name, containing the array of formatted snippets     *         corresponding to the documents in<code>docidsIn</code>.     *         If no highlights were found for a document, the    *         first {@code maxPassages} from the field will    *         be returned.    * @throws IOException if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without     *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFields
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|highlightFields
parameter_list|(
name|String
name|fieldsIn
index|[]
parameter_list|,
name|Query
name|query
parameter_list|,
name|IndexSearcher
name|searcher
parameter_list|,
name|int
index|[]
name|docidsIn
parameter_list|,
name|int
name|maxPassagesIn
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|snippets
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Object
index|[]
argument_list|>
name|ent
range|:
name|highlightFieldsAsObjects
argument_list|(
name|fieldsIn
argument_list|,
name|query
argument_list|,
name|searcher
argument_list|,
name|docidsIn
argument_list|,
name|maxPassagesIn
argument_list|)
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Object
index|[]
name|snippetObjects
init|=
name|ent
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|String
index|[]
name|snippetStrings
init|=
operator|new
name|String
index|[
name|snippetObjects
operator|.
name|length
index|]
decl_stmt|;
name|snippets
operator|.
name|put
argument_list|(
name|ent
operator|.
name|getKey
argument_list|()
argument_list|,
name|snippetStrings
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|snippetObjects
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Object
name|snippet
init|=
name|snippetObjects
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|snippet
operator|!=
literal|null
condition|)
block|{
name|snippetStrings
index|[
name|i
index|]
operator|=
name|snippet
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
block|}
block|}
return|return
name|snippets
return|;
block|}
comment|/**    * Expert: highlights the top-N passages from multiple fields,    * for the provided int[] docids, to custom Object as    * returned by the {@link PassageFormatter}.  Use    * this API to render to something other than String.    *     * @param fieldsIn field names to highlight.     *        Must have a stored string value and also be indexed with offsets.    * @param query query to highlight.    * @param searcher searcher that was previously used to execute the query.    * @param docidsIn containing the document IDs to highlight.    * @param maxPassagesIn The maximum number of top-N ranked passages per-field used to     *        form the highlighted snippets.    * @return Map keyed on field name, containing the array of formatted snippets     *         corresponding to the documents in<code>docidsIn</code>.     *         If no highlights were found for a document, the    *         first {@code maxPassages} from the field will    *         be returned.    * @throws IOException if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without     *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFieldsAsObjects
specifier|protected
name|Map
argument_list|<
name|String
argument_list|,
name|Object
index|[]
argument_list|>
name|highlightFieldsAsObjects
parameter_list|(
name|String
name|fieldsIn
index|[]
parameter_list|,
name|Query
name|query
parameter_list|,
name|IndexSearcher
name|searcher
parameter_list|,
name|int
index|[]
name|docidsIn
parameter_list|,
name|int
name|maxPassagesIn
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fieldsIn
operator|.
name|length
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"fieldsIn must not be empty"
argument_list|)
throw|;
block|}
if|if
condition|(
name|fieldsIn
operator|.
name|length
operator|!=
name|maxPassagesIn
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"invalid number of maxPassagesIn"
argument_list|)
throw|;
block|}
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|queryTerms
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
decl_stmt|;
name|EMPTY_INDEXSEARCHER
operator|.
name|createNormalizedWeight
argument_list|(
name|query
argument_list|,
literal|false
argument_list|)
operator|.
name|extractTerms
argument_list|(
name|queryTerms
argument_list|)
expr_stmt|;
name|IndexReaderContext
name|readerContext
init|=
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|.
name|getContext
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|LeafReaderContext
argument_list|>
name|leaves
init|=
name|readerContext
operator|.
name|leaves
argument_list|()
decl_stmt|;
comment|// Make our own copies because we sort in-place:
name|int
index|[]
name|docids
init|=
operator|new
name|int
index|[
name|docidsIn
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|docidsIn
argument_list|,
literal|0
argument_list|,
name|docids
argument_list|,
literal|0
argument_list|,
name|docidsIn
operator|.
name|length
argument_list|)
expr_stmt|;
specifier|final
name|String
name|fields
index|[]
init|=
operator|new
name|String
index|[
name|fieldsIn
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|fieldsIn
argument_list|,
literal|0
argument_list|,
name|fields
argument_list|,
literal|0
argument_list|,
name|fieldsIn
operator|.
name|length
argument_list|)
expr_stmt|;
specifier|final
name|int
name|maxPassages
index|[]
init|=
operator|new
name|int
index|[
name|maxPassagesIn
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|maxPassagesIn
argument_list|,
literal|0
argument_list|,
name|maxPassages
argument_list|,
literal|0
argument_list|,
name|maxPassagesIn
operator|.
name|length
argument_list|)
expr_stmt|;
comment|// sort for sequential io
name|Arrays
operator|.
name|sort
argument_list|(
name|docids
argument_list|)
expr_stmt|;
operator|new
name|InPlaceMergeSorter
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|void
name|swap
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
name|String
name|tmp
init|=
name|fields
index|[
name|i
index|]
decl_stmt|;
name|fields
index|[
name|i
index|]
operator|=
name|fields
index|[
name|j
index|]
expr_stmt|;
name|fields
index|[
name|j
index|]
operator|=
name|tmp
expr_stmt|;
name|int
name|tmp2
init|=
name|maxPassages
index|[
name|i
index|]
decl_stmt|;
name|maxPassages
index|[
name|i
index|]
operator|=
name|maxPassages
index|[
name|j
index|]
expr_stmt|;
name|maxPassages
index|[
name|j
index|]
operator|=
name|tmp2
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|compare
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
return|return
name|fields
index|[
name|i
index|]
operator|.
name|compareTo
argument_list|(
name|fields
index|[
name|j
index|]
argument_list|)
return|;
block|}
block|}
operator|.
name|sort
argument_list|(
literal|0
argument_list|,
name|fields
operator|.
name|length
argument_list|)
expr_stmt|;
comment|// pull stored data:
name|String
index|[]
index|[]
name|contents
init|=
name|loadFieldValues
argument_list|(
name|searcher
argument_list|,
name|fields
argument_list|,
name|docids
argument_list|,
name|maxLength
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Object
index|[]
argument_list|>
name|highlights
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fields
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|field
init|=
name|fields
index|[
name|i
index|]
decl_stmt|;
name|int
name|numPassages
init|=
name|maxPassages
index|[
name|i
index|]
decl_stmt|;
name|Term
name|floor
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
literal|""
argument_list|)
decl_stmt|;
name|Term
name|ceiling
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|UnicodeUtil
operator|.
name|BIG_TERM
argument_list|)
decl_stmt|;
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|fieldTerms
init|=
name|queryTerms
operator|.
name|subSet
argument_list|(
name|floor
argument_list|,
name|ceiling
argument_list|)
decl_stmt|;
comment|// TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)
comment|// Strip off the redundant field:
name|BytesRef
name|terms
index|[]
init|=
operator|new
name|BytesRef
index|[
name|fieldTerms
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|termUpto
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Term
name|term
range|:
name|fieldTerms
control|)
block|{
name|terms
index|[
name|termUpto
operator|++
index|]
operator|=
name|term
operator|.
name|bytes
argument_list|()
expr_stmt|;
block|}
name|Map
argument_list|<
name|Integer
argument_list|,
name|Object
argument_list|>
name|fieldHighlights
init|=
name|highlightField
argument_list|(
name|field
argument_list|,
name|contents
index|[
name|i
index|]
argument_list|,
name|getBreakIterator
argument_list|(
name|field
argument_list|)
argument_list|,
name|terms
argument_list|,
name|docids
argument_list|,
name|leaves
argument_list|,
name|numPassages
argument_list|,
name|query
argument_list|)
decl_stmt|;
name|Object
index|[]
name|result
init|=
operator|new
name|Object
index|[
name|docids
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|docidsIn
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
name|result
index|[
name|j
index|]
operator|=
name|fieldHighlights
operator|.
name|get
argument_list|(
name|docidsIn
index|[
name|j
index|]
argument_list|)
expr_stmt|;
block|}
name|highlights
operator|.
name|put
argument_list|(
name|field
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|highlights
return|;
block|}
comment|/** Loads the String values for each field X docID to be    *  highlighted.  By default this loads from stored    *  fields, but a subclass can change the source.  This    *  method should allocate the String[fields.length][docids.length]    *  and fill all values.  The returned Strings must be    *  identical to what was indexed. */
DECL|method|loadFieldValues
specifier|protected
name|String
index|[]
index|[]
name|loadFieldValues
parameter_list|(
name|IndexSearcher
name|searcher
parameter_list|,
name|String
index|[]
name|fields
parameter_list|,
name|int
index|[]
name|docids
parameter_list|,
name|int
name|maxLength
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|contents
index|[]
index|[]
init|=
operator|new
name|String
index|[
name|fields
operator|.
name|length
index|]
index|[
name|docids
operator|.
name|length
index|]
decl_stmt|;
name|char
name|valueSeparators
index|[]
init|=
operator|new
name|char
index|[
name|fields
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fields
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|valueSeparators
index|[
name|i
index|]
operator|=
name|getMultiValuedSeparator
argument_list|(
name|fields
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|LimitedStoredFieldVisitor
name|visitor
init|=
operator|new
name|LimitedStoredFieldVisitor
argument_list|(
name|fields
argument_list|,
name|valueSeparators
argument_list|,
name|maxLength
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|docids
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|searcher
operator|.
name|doc
argument_list|(
name|docids
index|[
name|i
index|]
argument_list|,
name|visitor
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|fields
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
name|contents
index|[
name|j
index|]
index|[
name|i
index|]
operator|=
name|visitor
operator|.
name|getValue
argument_list|(
name|j
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
name|visitor
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
return|return
name|contents
return|;
block|}
comment|/**     * Returns the logical separator between values for multi-valued fields.    * The default value is a space character, which means passages can span across values,    * but a subclass can override, for example with {@code U+2029 PARAGRAPH SEPARATOR (PS)}    * if each value holds a discrete passage for highlighting.    */
DECL|method|getMultiValuedSeparator
specifier|protected
name|char
name|getMultiValuedSeparator
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|' '
return|;
block|}
comment|/**     * Returns the analyzer originally used to index the content for {@code field}.    *<p>    * This is used to highlight some MultiTermQueries.    * @return Analyzer or null (the default, meaning no special multi-term processing)    */
DECL|method|getIndexAnalyzer
specifier|protected
name|Analyzer
name|getIndexAnalyzer
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
DECL|method|highlightField
specifier|private
name|Map
argument_list|<
name|Integer
argument_list|,
name|Object
argument_list|>
name|highlightField
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|contents
index|[]
parameter_list|,
name|BreakIterator
name|bi
parameter_list|,
name|BytesRef
name|terms
index|[]
parameter_list|,
name|int
index|[]
name|docids
parameter_list|,
name|List
argument_list|<
name|LeafReaderContext
argument_list|>
name|leaves
parameter_list|,
name|int
name|maxPassages
parameter_list|,
name|Query
name|query
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|Integer
argument_list|,
name|Object
argument_list|>
name|highlights
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|PassageFormatter
name|fieldFormatter
init|=
name|getFormatter
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|fieldFormatter
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"PassageFormatter cannot be null"
argument_list|)
throw|;
block|}
comment|// check if we should do any multiterm processing
name|Analyzer
name|analyzer
init|=
name|getIndexAnalyzer
argument_list|(
name|field
argument_list|)
decl_stmt|;
name|CharacterRunAutomaton
name|automata
index|[]
init|=
operator|new
name|CharacterRunAutomaton
index|[
literal|0
index|]
decl_stmt|;
if|if
condition|(
name|analyzer
operator|!=
literal|null
condition|)
block|{
name|automata
operator|=
name|MultiTermHighlighting
operator|.
name|extractAutomata
argument_list|(
name|query
argument_list|,
name|field
argument_list|)
expr_stmt|;
block|}
comment|// resize 'terms', where the last term is the multiterm matcher
if|if
condition|(
name|automata
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|BytesRef
name|newTerms
index|[]
init|=
operator|new
name|BytesRef
index|[
name|terms
operator|.
name|length
operator|+
literal|1
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|terms
argument_list|,
literal|0
argument_list|,
name|newTerms
argument_list|,
literal|0
argument_list|,
name|terms
operator|.
name|length
argument_list|)
expr_stmt|;
name|terms
operator|=
name|newTerms
expr_stmt|;
block|}
comment|// we are processing in increasing docid order, so we only need to reinitialize stuff on segment changes
comment|// otherwise, we will just advance() existing enums to the new document in the same segment.
name|PostingsEnum
name|postings
index|[]
init|=
literal|null
decl_stmt|;
name|TermsEnum
name|termsEnum
init|=
literal|null
decl_stmt|;
name|int
name|lastLeaf
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|docids
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|content
init|=
name|contents
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|content
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
continue|continue;
comment|// nothing to do
block|}
name|bi
operator|.
name|setText
argument_list|(
name|content
argument_list|)
expr_stmt|;
name|int
name|doc
init|=
name|docids
index|[
name|i
index|]
decl_stmt|;
name|int
name|leaf
init|=
name|ReaderUtil
operator|.
name|subIndex
argument_list|(
name|doc
argument_list|,
name|leaves
argument_list|)
decl_stmt|;
name|LeafReaderContext
name|subContext
init|=
name|leaves
operator|.
name|get
argument_list|(
name|leaf
argument_list|)
decl_stmt|;
name|LeafReader
name|r
init|=
name|subContext
operator|.
name|reader
argument_list|()
decl_stmt|;
assert|assert
name|leaf
operator|>=
name|lastLeaf
assert|;
comment|// increasing order
comment|// if the segment has changed, we must initialize new enums.
if|if
condition|(
name|leaf
operator|!=
name|lastLeaf
condition|)
block|{
name|Terms
name|t
init|=
name|r
operator|.
name|terms
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|t
operator|.
name|hasOffsets
argument_list|()
condition|)
block|{
comment|// no offsets available
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"field '"
operator|+
name|field
operator|+
literal|"' was indexed without offsets, cannot highlight"
argument_list|)
throw|;
block|}
name|termsEnum
operator|=
name|t
operator|.
name|iterator
argument_list|()
expr_stmt|;
name|postings
operator|=
operator|new
name|PostingsEnum
index|[
name|terms
operator|.
name|length
index|]
expr_stmt|;
block|}
else|else
block|{
name|termsEnum
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|termsEnum
operator|==
literal|null
condition|)
block|{
continue|continue;
comment|// no terms for this field, nothing to do
block|}
comment|// if there are multi-term matches, we have to initialize the "fake" enum for each document
if|if
condition|(
name|automata
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|PostingsEnum
name|dp
init|=
name|MultiTermHighlighting
operator|.
name|getDocsEnum
argument_list|(
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|field
argument_list|,
name|content
argument_list|)
argument_list|,
name|automata
argument_list|)
decl_stmt|;
name|dp
operator|.
name|advance
argument_list|(
name|doc
operator|-
name|subContext
operator|.
name|docBase
argument_list|)
expr_stmt|;
name|postings
index|[
name|terms
operator|.
name|length
operator|-
literal|1
index|]
operator|=
name|dp
expr_stmt|;
comment|// last term is the multiterm matcher
block|}
name|Passage
name|passages
index|[]
init|=
name|highlightDoc
argument_list|(
name|field
argument_list|,
name|terms
argument_list|,
name|content
operator|.
name|length
argument_list|()
argument_list|,
name|bi
argument_list|,
name|doc
operator|-
name|subContext
operator|.
name|docBase
argument_list|,
name|termsEnum
argument_list|,
name|postings
argument_list|,
name|maxPassages
argument_list|)
decl_stmt|;
if|if
condition|(
name|passages
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|// no passages were returned, so ask for a default summary
name|passages
operator|=
name|getEmptyHighlight
argument_list|(
name|field
argument_list|,
name|bi
argument_list|,
name|maxPassages
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|passages
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|highlights
operator|.
name|put
argument_list|(
name|doc
argument_list|,
name|fieldFormatter
operator|.
name|format
argument_list|(
name|passages
argument_list|,
name|content
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|lastLeaf
operator|=
name|leaf
expr_stmt|;
block|}
return|return
name|highlights
return|;
block|}
comment|// algorithm: treat sentence snippets as miniature documents
comment|// we can intersect these with the postings lists via BreakIterator.preceding(offset),s
comment|// score each sentence as norm(sentenceStartOffset) * sum(weight * tf(freq))
DECL|method|highlightDoc
specifier|private
name|Passage
index|[]
name|highlightDoc
parameter_list|(
name|String
name|field
parameter_list|,
name|BytesRef
name|terms
index|[]
parameter_list|,
name|int
name|contentLength
parameter_list|,
name|BreakIterator
name|bi
parameter_list|,
name|int
name|doc
parameter_list|,
name|TermsEnum
name|termsEnum
parameter_list|,
name|PostingsEnum
index|[]
name|postings
parameter_list|,
name|int
name|n
parameter_list|)
throws|throws
name|IOException
block|{
name|PassageScorer
name|scorer
init|=
name|getScorer
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|scorer
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"PassageScorer cannot be null"
argument_list|)
throw|;
block|}
name|PriorityQueue
argument_list|<
name|OffsetsEnum
argument_list|>
name|pq
init|=
operator|new
name|PriorityQueue
argument_list|<>
argument_list|()
decl_stmt|;
name|float
name|weights
index|[]
init|=
operator|new
name|float
index|[
name|terms
operator|.
name|length
index|]
decl_stmt|;
comment|// initialize postings
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|terms
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|PostingsEnum
name|de
init|=
name|postings
index|[
name|i
index|]
decl_stmt|;
name|int
name|pDoc
decl_stmt|;
if|if
condition|(
name|de
operator|==
name|EMPTY
condition|)
block|{
continue|continue;
block|}
elseif|else
if|if
condition|(
name|de
operator|==
literal|null
condition|)
block|{
name|postings
index|[
name|i
index|]
operator|=
name|EMPTY
expr_stmt|;
comment|// initially
if|if
condition|(
operator|!
name|termsEnum
operator|.
name|seekExact
argument_list|(
name|terms
index|[
name|i
index|]
argument_list|)
condition|)
block|{
continue|continue;
comment|// term not found
block|}
name|de
operator|=
name|postings
index|[
name|i
index|]
operator|=
name|termsEnum
operator|.
name|postings
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
name|PostingsEnum
operator|.
name|OFFSETS
argument_list|)
expr_stmt|;
assert|assert
name|de
operator|!=
literal|null
assert|;
name|pDoc
operator|=
name|de
operator|.
name|advance
argument_list|(
name|doc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pDoc
operator|=
name|de
operator|.
name|docID
argument_list|()
expr_stmt|;
if|if
condition|(
name|pDoc
operator|<
name|doc
condition|)
block|{
name|pDoc
operator|=
name|de
operator|.
name|advance
argument_list|(
name|doc
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|doc
operator|==
name|pDoc
condition|)
block|{
name|weights
index|[
name|i
index|]
operator|=
name|scorer
operator|.
name|weight
argument_list|(
name|contentLength
argument_list|,
name|de
operator|.
name|freq
argument_list|()
argument_list|)
expr_stmt|;
name|de
operator|.
name|nextPosition
argument_list|()
expr_stmt|;
name|pq
operator|.
name|add
argument_list|(
operator|new
name|OffsetsEnum
argument_list|(
name|de
argument_list|,
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|pq
operator|.
name|add
argument_list|(
operator|new
name|OffsetsEnum
argument_list|(
name|EMPTY
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
argument_list|)
expr_stmt|;
comment|// a sentinel for termination
name|PriorityQueue
argument_list|<
name|Passage
argument_list|>
name|passageQueue
init|=
operator|new
name|PriorityQueue
argument_list|<>
argument_list|(
name|n
argument_list|,
operator|new
name|Comparator
argument_list|<
name|Passage
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Passage
name|left
parameter_list|,
name|Passage
name|right
parameter_list|)
block|{
if|if
condition|(
name|left
operator|.
name|score
operator|<
name|right
operator|.
name|score
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
elseif|else
if|if
condition|(
name|left
operator|.
name|score
operator|>
name|right
operator|.
name|score
condition|)
block|{
return|return
literal|1
return|;
block|}
else|else
block|{
return|return
name|left
operator|.
name|startOffset
operator|-
name|right
operator|.
name|startOffset
return|;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|Passage
name|current
init|=
operator|new
name|Passage
argument_list|()
decl_stmt|;
name|OffsetsEnum
name|off
decl_stmt|;
while|while
condition|(
operator|(
name|off
operator|=
name|pq
operator|.
name|poll
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
specifier|final
name|PostingsEnum
name|dp
init|=
name|off
operator|.
name|dp
decl_stmt|;
name|int
name|start
init|=
name|dp
operator|.
name|startOffset
argument_list|()
decl_stmt|;
assert|assert
name|start
operator|>=
literal|0
assert|;
name|int
name|end
init|=
name|dp
operator|.
name|endOffset
argument_list|()
decl_stmt|;
comment|// LUCENE-5166: this hit would span the content limit... however more valid
comment|// hits may exist (they are sorted by start). so we pretend like we never
comment|// saw this term, it won't cause a passage to be added to passageQueue or anything.
assert|assert
name|EMPTY
operator|.
name|startOffset
argument_list|()
operator|==
name|Integer
operator|.
name|MAX_VALUE
assert|;
if|if
condition|(
name|start
argument_list|<
name|contentLength
operator|&&
name|end
argument_list|>
name|contentLength
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|start
operator|>=
name|current
operator|.
name|endOffset
condition|)
block|{
if|if
condition|(
name|current
operator|.
name|startOffset
operator|>=
literal|0
condition|)
block|{
comment|// finalize current
name|current
operator|.
name|score
operator|*=
name|scorer
operator|.
name|norm
argument_list|(
name|current
operator|.
name|startOffset
argument_list|)
expr_stmt|;
comment|// new sentence: first add 'current' to queue
if|if
condition|(
name|passageQueue
operator|.
name|size
argument_list|()
operator|==
name|n
operator|&&
name|current
operator|.
name|score
operator|<
name|passageQueue
operator|.
name|peek
argument_list|()
operator|.
name|score
condition|)
block|{
name|current
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// can't compete, just reset it
block|}
else|else
block|{
name|passageQueue
operator|.
name|offer
argument_list|(
name|current
argument_list|)
expr_stmt|;
if|if
condition|(
name|passageQueue
operator|.
name|size
argument_list|()
operator|>
name|n
condition|)
block|{
name|current
operator|=
name|passageQueue
operator|.
name|poll
argument_list|()
expr_stmt|;
name|current
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|current
operator|=
operator|new
name|Passage
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// if we exceed limit, we are done
if|if
condition|(
name|start
operator|>=
name|contentLength
condition|)
block|{
name|Passage
name|passages
index|[]
init|=
operator|new
name|Passage
index|[
name|passageQueue
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|passageQueue
operator|.
name|toArray
argument_list|(
name|passages
argument_list|)
expr_stmt|;
for|for
control|(
name|Passage
name|p
range|:
name|passages
control|)
block|{
name|p
operator|.
name|sort
argument_list|()
expr_stmt|;
block|}
comment|// sort in ascending order
name|Arrays
operator|.
name|sort
argument_list|(
name|passages
argument_list|,
operator|new
name|Comparator
argument_list|<
name|Passage
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Passage
name|left
parameter_list|,
name|Passage
name|right
parameter_list|)
block|{
return|return
name|left
operator|.
name|startOffset
operator|-
name|right
operator|.
name|startOffset
return|;
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|passages
return|;
block|}
comment|// advance breakiterator
assert|assert
name|BreakIterator
operator|.
name|DONE
operator|<
literal|0
assert|;
name|current
operator|.
name|startOffset
operator|=
name|Math
operator|.
name|max
argument_list|(
name|bi
operator|.
name|preceding
argument_list|(
name|start
operator|+
literal|1
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|current
operator|.
name|endOffset
operator|=
name|Math
operator|.
name|min
argument_list|(
name|bi
operator|.
name|next
argument_list|()
argument_list|,
name|contentLength
argument_list|)
expr_stmt|;
block|}
name|int
name|tf
init|=
literal|0
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|tf
operator|++
expr_stmt|;
name|BytesRef
name|term
init|=
name|terms
index|[
name|off
operator|.
name|id
index|]
decl_stmt|;
if|if
condition|(
name|term
operator|==
literal|null
condition|)
block|{
comment|// multitermquery match, pull from payload
name|term
operator|=
name|off
operator|.
name|dp
operator|.
name|getPayload
argument_list|()
expr_stmt|;
assert|assert
name|term
operator|!=
literal|null
assert|;
block|}
name|current
operator|.
name|addMatch
argument_list|(
name|start
argument_list|,
name|end
argument_list|,
name|term
argument_list|)
expr_stmt|;
if|if
condition|(
name|off
operator|.
name|pos
operator|==
name|dp
operator|.
name|freq
argument_list|()
condition|)
block|{
break|break;
comment|// removed from pq
block|}
else|else
block|{
name|off
operator|.
name|pos
operator|++
expr_stmt|;
name|dp
operator|.
name|nextPosition
argument_list|()
expr_stmt|;
name|start
operator|=
name|dp
operator|.
name|startOffset
argument_list|()
expr_stmt|;
name|end
operator|=
name|dp
operator|.
name|endOffset
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|start
operator|>=
name|current
operator|.
name|endOffset
operator|||
name|end
operator|>
name|contentLength
condition|)
block|{
name|pq
operator|.
name|offer
argument_list|(
name|off
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|current
operator|.
name|score
operator|+=
name|weights
index|[
name|off
operator|.
name|id
index|]
operator|*
name|scorer
operator|.
name|tf
argument_list|(
name|tf
argument_list|,
name|current
operator|.
name|endOffset
operator|-
name|current
operator|.
name|startOffset
argument_list|)
expr_stmt|;
block|}
comment|// Dead code but compiler disagrees:
assert|assert
literal|false
assert|;
return|return
literal|null
return|;
block|}
comment|/** Called to summarize a document when no hits were    *  found.  By default this just returns the first    *  {@code maxPassages} sentences; subclasses can override    *  to customize. */
DECL|method|getEmptyHighlight
specifier|protected
name|Passage
index|[]
name|getEmptyHighlight
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|BreakIterator
name|bi
parameter_list|,
name|int
name|maxPassages
parameter_list|)
block|{
comment|// BreakIterator should be un-next'd:
name|List
argument_list|<
name|Passage
argument_list|>
name|passages
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|int
name|pos
init|=
name|bi
operator|.
name|current
argument_list|()
decl_stmt|;
assert|assert
name|pos
operator|==
literal|0
assert|;
while|while
condition|(
name|passages
operator|.
name|size
argument_list|()
operator|<
name|maxPassages
condition|)
block|{
name|int
name|next
init|=
name|bi
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|next
operator|==
name|BreakIterator
operator|.
name|DONE
condition|)
block|{
break|break;
block|}
name|Passage
name|passage
init|=
operator|new
name|Passage
argument_list|()
decl_stmt|;
name|passage
operator|.
name|score
operator|=
name|Float
operator|.
name|NaN
expr_stmt|;
name|passage
operator|.
name|startOffset
operator|=
name|pos
expr_stmt|;
name|passage
operator|.
name|endOffset
operator|=
name|next
expr_stmt|;
name|passages
operator|.
name|add
argument_list|(
name|passage
argument_list|)
expr_stmt|;
name|pos
operator|=
name|next
expr_stmt|;
block|}
return|return
name|passages
operator|.
name|toArray
argument_list|(
operator|new
name|Passage
index|[
name|passages
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
DECL|class|OffsetsEnum
specifier|private
specifier|static
class|class
name|OffsetsEnum
implements|implements
name|Comparable
argument_list|<
name|OffsetsEnum
argument_list|>
block|{
DECL|field|dp
name|PostingsEnum
name|dp
decl_stmt|;
DECL|field|pos
name|int
name|pos
decl_stmt|;
DECL|field|id
name|int
name|id
decl_stmt|;
DECL|method|OffsetsEnum
name|OffsetsEnum
parameter_list|(
name|PostingsEnum
name|dp
parameter_list|,
name|int
name|id
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|dp
operator|=
name|dp
expr_stmt|;
name|this
operator|.
name|id
operator|=
name|id
expr_stmt|;
name|this
operator|.
name|pos
operator|=
literal|1
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|compareTo
specifier|public
name|int
name|compareTo
parameter_list|(
name|OffsetsEnum
name|other
parameter_list|)
block|{
try|try
block|{
name|int
name|off
init|=
name|dp
operator|.
name|startOffset
argument_list|()
decl_stmt|;
name|int
name|otherOff
init|=
name|other
operator|.
name|dp
operator|.
name|startOffset
argument_list|()
decl_stmt|;
if|if
condition|(
name|off
operator|==
name|otherOff
condition|)
block|{
return|return
name|id
operator|-
name|other
operator|.
name|id
return|;
block|}
else|else
block|{
return|return
name|Integer
operator|.
name|compare
argument_list|(
name|off
argument_list|,
name|otherOff
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
DECL|field|EMPTY
specifier|private
specifier|static
specifier|final
name|PostingsEnum
name|EMPTY
init|=
operator|new
name|PostingsEnum
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|nextPosition
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|-
literal|1
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|startOffset
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|Integer
operator|.
name|MAX_VALUE
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|endOffset
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|Integer
operator|.
name|MAX_VALUE
return|;
block|}
annotation|@
name|Override
specifier|public
name|BytesRef
name|getPayload
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|freq
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|docID
parameter_list|()
block|{
return|return
name|NO_MORE_DOCS
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|nextDoc
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|NO_MORE_DOCS
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|advance
parameter_list|(
name|int
name|target
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|NO_MORE_DOCS
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|cost
parameter_list|()
block|{
return|return
literal|0
return|;
block|}
block|}
decl_stmt|;
DECL|class|LimitedStoredFieldVisitor
specifier|private
specifier|static
class|class
name|LimitedStoredFieldVisitor
extends|extends
name|StoredFieldVisitor
block|{
DECL|field|fields
specifier|private
specifier|final
name|String
name|fields
index|[]
decl_stmt|;
DECL|field|valueSeparators
specifier|private
specifier|final
name|char
name|valueSeparators
index|[]
decl_stmt|;
DECL|field|maxLength
specifier|private
specifier|final
name|int
name|maxLength
decl_stmt|;
DECL|field|builders
specifier|private
specifier|final
name|StringBuilder
name|builders
index|[]
decl_stmt|;
DECL|field|currentField
specifier|private
name|int
name|currentField
init|=
operator|-
literal|1
decl_stmt|;
DECL|method|LimitedStoredFieldVisitor
specifier|public
name|LimitedStoredFieldVisitor
parameter_list|(
name|String
name|fields
index|[]
parameter_list|,
name|char
name|valueSeparators
index|[]
parameter_list|,
name|int
name|maxLength
parameter_list|)
block|{
assert|assert
name|fields
operator|.
name|length
operator|==
name|valueSeparators
operator|.
name|length
assert|;
name|this
operator|.
name|fields
operator|=
name|fields
expr_stmt|;
name|this
operator|.
name|valueSeparators
operator|=
name|valueSeparators
expr_stmt|;
name|this
operator|.
name|maxLength
operator|=
name|maxLength
expr_stmt|;
name|builders
operator|=
operator|new
name|StringBuilder
index|[
name|fields
operator|.
name|length
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|builders
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|builders
index|[
name|i
index|]
operator|=
operator|new
name|StringBuilder
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|stringField
specifier|public
name|void
name|stringField
parameter_list|(
name|FieldInfo
name|fieldInfo
parameter_list|,
name|byte
index|[]
name|bytes
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|value
init|=
operator|new
name|String
argument_list|(
name|bytes
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
argument_list|)
decl_stmt|;
assert|assert
name|currentField
operator|>=
literal|0
assert|;
name|StringBuilder
name|builder
init|=
name|builders
index|[
name|currentField
index|]
decl_stmt|;
if|if
condition|(
name|builder
operator|.
name|length
argument_list|()
operator|>
literal|0
operator|&&
name|builder
operator|.
name|length
argument_list|()
operator|<
name|maxLength
condition|)
block|{
name|builder
operator|.
name|append
argument_list|(
name|valueSeparators
index|[
name|currentField
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|builder
operator|.
name|length
argument_list|()
operator|+
name|value
operator|.
name|length
argument_list|()
operator|>
name|maxLength
condition|)
block|{
name|builder
operator|.
name|append
argument_list|(
name|value
argument_list|,
literal|0
argument_list|,
name|maxLength
operator|-
name|builder
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|builder
operator|.
name|append
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|needsField
specifier|public
name|Status
name|needsField
parameter_list|(
name|FieldInfo
name|fieldInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|currentField
operator|=
name|Arrays
operator|.
name|binarySearch
argument_list|(
name|fields
argument_list|,
name|fieldInfo
operator|.
name|name
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentField
operator|<
literal|0
condition|)
block|{
return|return
name|Status
operator|.
name|NO
return|;
block|}
elseif|else
if|if
condition|(
name|builders
index|[
name|currentField
index|]
operator|.
name|length
argument_list|()
operator|>
name|maxLength
condition|)
block|{
return|return
name|fields
operator|.
name|length
operator|==
literal|1
condition|?
name|Status
operator|.
name|STOP
else|:
name|Status
operator|.
name|NO
return|;
block|}
return|return
name|Status
operator|.
name|YES
return|;
block|}
DECL|method|getValue
name|String
name|getValue
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|builders
index|[
name|i
index|]
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|method|reset
name|void
name|reset
parameter_list|()
block|{
name|currentField
operator|=
operator|-
literal|1
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|fields
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|builders
index|[
name|i
index|]
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class
end_unit
