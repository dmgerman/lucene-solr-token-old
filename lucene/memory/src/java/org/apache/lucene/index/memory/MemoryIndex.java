begin_unit
begin_package
DECL|package|org.apache.lucene.index.memory
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|memory
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PayloadAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TermToBytesRefAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|BinaryDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|DocValuesType
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|PostingsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInfo
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInfos
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInvertState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Fields
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexOptions
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|NumericDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|OrdTermState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SortedDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SortedNumericDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SortedSetDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|StoredFieldVisitor
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|TermState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Terms
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|TermsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Query
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Scorer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|SimpleCollector
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|similarities
operator|.
name|Similarity
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|RAMDirectory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ArrayUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Bits
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ByteBlockPool
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefArray
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefHash
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefHash
operator|.
name|DirectBytesStartArray
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Counter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntBlockPool
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntBlockPool
operator|.
name|SliceReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntBlockPool
operator|.
name|SliceWriter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RamUsageEstimator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RecyclingByteBlockAllocator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RecyclingIntBlockAllocator
import|;
end_import
begin_comment
comment|/**  * High-performance single-document main memory Apache Lucene fulltext search index.   *<p>  *<b>Overview</b>  *<p>  * This class is a replacement/substitute for a large subset of  * {@link RAMDirectory} functionality. It is designed to  * enable maximum efficiency for on-the-fly matchmaking combining structured and   * fuzzy fulltext search in realtime streaming applications such as Nux XQuery based XML   * message queues, publish-subscribe systems for Blogs/newsfeeds, text chat, data acquisition and   * distribution systems, application level routers, firewalls, classifiers, etc.   * Rather than targeting fulltext search of infrequent queries over huge persistent   * data archives (historic search), this class targets fulltext search of huge   * numbers of queries over comparatively small transient realtime data (prospective   * search).   * For example as in   *<pre class="prettyprint">  * float score = search(String text, Query query)  *</pre>  *<p>  * Each instance can hold at most one Lucene "document", with a document containing  * zero or more "fields", each field having a name and a fulltext value. The  * fulltext value is tokenized (split and transformed) into zero or more index terms   * (aka words) on<code>addField()</code>, according to the policy implemented by an  * Analyzer. For example, Lucene analyzers can split on whitespace, normalize to lower case  * for case insensitivity, ignore common terms with little discriminatory value such as "he", "in", "and" (stop  * words), reduce the terms to their natural linguistic root form such as "fishing"  * being reduced to "fish" (stemming), resolve synonyms/inflexions/thesauri   * (upon indexing and/or querying), etc. For details, see  *<a target="_blank" href="http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html">Lucene Analyzer Intro</a>.  *<p>  * Arbitrary Lucene queries can be run against this class - see<a target="_blank"   * href="{@docRoot}/../queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description">  * Lucene Query Syntax</a>  * as well as<a target="_blank"   * href="http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html">Query Parser Rules</a>.  * Note that a Lucene query selects on the field names and associated (indexed)   * tokenized terms, not on the original fulltext(s) - the latter are not stored   * but rather thrown away immediately after tokenization.  *<p>  * For some interesting background information on search technology, see Bob Wyman's  *<a target="_blank"   * href="http://bobwyman.pubsub.com/main/2005/05/mary_hodder_poi.html">Prospective Search</a>,   * Jim Gray's  *<a target="_blank" href="http://www.acmqueue.org/modules.php?name=Content&pa=showpage&pid=293&page=4">  * A Call to Arms - Custom subscriptions</a>, and Tim Bray's  *<a target="_blank"   * href="http://www.tbray.org/ongoing/When/200x/2003/07/30/OnSearchTOC">On Search, the Series</a>.  *   *<p>  *<b>Example Usage</b>   *<br>  *<pre class="prettyprint">  * Analyzer analyzer = new SimpleAnalyzer(version);  * MemoryIndex index = new MemoryIndex();  * index.addField("content", "Readings about Salmons and other select Alaska fishing Manuals", analyzer);  * index.addField("author", "Tales of James", analyzer);  * QueryParser parser = new QueryParser(version, "content", analyzer);  * float score = index.search(parser.parse("+author:james +salmon~ +fish* manual~"));  * if (score&gt; 0.0f) {  *     System.out.println("it's a match");  * } else {  *     System.out.println("no match found");  * }  * System.out.println("indexData=" + index.toString());  *</pre>  *   *<p>  *<b>Example XQuery Usage</b>   *   *<pre class="prettyprint">  * (: An XQuery that finds all books authored by James that have something to do with "salmon fishing manuals", sorted by relevance :)  * declare namespace lucene = "java:nux.xom.pool.FullTextUtil";  * declare variable $query := "+salmon~ +fish* manual~"; (: any arbitrary Lucene query can go here :)  *   * for $book in /books/book[author="James" and lucene:match(abstract, $query)&gt; 0.0]  * let $score := lucene:match($book/abstract, $query)  * order by $score descending  * return $book  *</pre>  *   *<p>  *<b>Thread safety guarantees</b>  *<p>  * MemoryIndex is not normally thread-safe for adds or queries.  However, queries  * are thread-safe after {@code freeze()} has been called.  *  *<p>  *<b>Performance Notes</b>  *<p>  * Internally there's a new data structure geared towards efficient indexing   * and searching, plus the necessary support code to seamlessly plug into the Lucene   * framework.  *<p>  * This class performs very well for very small texts (e.g. 10 chars)   * as well as for large texts (e.g. 10 MB) and everything in between.   * Typically, it is about 10-100 times faster than<code>RAMDirectory</code>.  * Note that<code>RAMDirectory</code> has particularly   * large efficiency overheads for small to medium sized texts, both in time and space.  * Indexing a field with N tokens takes O(N) in the best case, and O(N logN) in the worst   * case. Memory consumption is probably larger than for<code>RAMDirectory</code>.  *<p>  * Example throughput of many simple term queries over a single MemoryIndex:   * ~500000 queries/sec on a MacBook Pro, jdk 1.5.0_06, server VM.   * As always, your mileage may vary.  *<p>  * If you're curious about  * the whereabouts of bottlenecks, run java 1.5 with the non-perturbing '-server  * -agentlib:hprof=cpu=samples,depth=10' flags, then study the trace log and  * correlate its hotspot trailer with its call stack headers (see<a  * target="_blank"  * href="http://java.sun.com/developer/technicalArticles/Programming/HPROF.html">  * hprof tracing</a>).  *  */
end_comment
begin_class
DECL|class|MemoryIndex
specifier|public
class|class
name|MemoryIndex
block|{
DECL|field|DEBUG
specifier|private
specifier|static
specifier|final
name|boolean
name|DEBUG
init|=
literal|false
decl_stmt|;
comment|/** info for each field: Map&lt;String fieldName, Info field&gt; */
DECL|field|fields
specifier|private
specifier|final
name|SortedMap
argument_list|<
name|String
argument_list|,
name|Info
argument_list|>
name|fields
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
DECL|field|storeOffsets
specifier|private
specifier|final
name|boolean
name|storeOffsets
decl_stmt|;
DECL|field|storePayloads
specifier|private
specifier|final
name|boolean
name|storePayloads
decl_stmt|;
DECL|field|byteBlockPool
specifier|private
specifier|final
name|ByteBlockPool
name|byteBlockPool
decl_stmt|;
DECL|field|intBlockPool
specifier|private
specifier|final
name|IntBlockPool
name|intBlockPool
decl_stmt|;
comment|//  private final IntBlockPool.SliceReader postingsReader;
DECL|field|postingsWriter
specifier|private
specifier|final
name|IntBlockPool
operator|.
name|SliceWriter
name|postingsWriter
decl_stmt|;
DECL|field|payloadsBytesRefs
specifier|private
specifier|final
name|BytesRefArray
name|payloadsBytesRefs
decl_stmt|;
comment|//non null only when storePayloads
DECL|field|bytesUsed
specifier|private
name|Counter
name|bytesUsed
decl_stmt|;
DECL|field|frozen
specifier|private
name|boolean
name|frozen
init|=
literal|false
decl_stmt|;
DECL|field|normSimilarity
specifier|private
name|Similarity
name|normSimilarity
init|=
name|IndexSearcher
operator|.
name|getDefaultSimilarity
argument_list|()
decl_stmt|;
comment|/**    * Constructs an empty instance that will not store offsets or payloads.    */
DECL|method|MemoryIndex
specifier|public
name|MemoryIndex
parameter_list|()
block|{
name|this
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructs an empty instance that can optionally store the start and end    * character offset of each token term in the text. This can be useful for    * highlighting of hit locations with the Lucene highlighter package.  But    * it will not store payloads; use another constructor for that.    *     * @param storeOffsets    *            whether or not to store the start and end character offset of    *            each token term in the text    */
DECL|method|MemoryIndex
specifier|public
name|MemoryIndex
parameter_list|(
name|boolean
name|storeOffsets
parameter_list|)
block|{
name|this
argument_list|(
name|storeOffsets
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructs an empty instance with the option of storing offsets and payloads.    *    * @param storeOffsets store term offsets at each position    * @param storePayloads store term payloads at each position    */
DECL|method|MemoryIndex
specifier|public
name|MemoryIndex
parameter_list|(
name|boolean
name|storeOffsets
parameter_list|,
name|boolean
name|storePayloads
parameter_list|)
block|{
name|this
argument_list|(
name|storeOffsets
argument_list|,
name|storePayloads
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/**    * Expert: This constructor accepts an upper limit for the number of bytes that should be reused if this instance is {@link #reset()}.    * The payload storage, if used, is unaffected by maxReusuedBytes, however.    * @param storeOffsets<code>true</code> if offsets should be stored    * @param storePayloads<code>true</code> if payloads should be stored    * @param maxReusedBytes the number of bytes that should remain in the internal memory pools after {@link #reset()} is called    */
DECL|method|MemoryIndex
name|MemoryIndex
parameter_list|(
name|boolean
name|storeOffsets
parameter_list|,
name|boolean
name|storePayloads
parameter_list|,
name|long
name|maxReusedBytes
parameter_list|)
block|{
name|this
operator|.
name|storeOffsets
operator|=
name|storeOffsets
expr_stmt|;
name|this
operator|.
name|storePayloads
operator|=
name|storePayloads
expr_stmt|;
name|this
operator|.
name|bytesUsed
operator|=
name|Counter
operator|.
name|newCounter
argument_list|()
expr_stmt|;
specifier|final
name|int
name|maxBufferedByteBlocks
init|=
call|(
name|int
call|)
argument_list|(
operator|(
name|maxReusedBytes
operator|/
literal|2
operator|)
operator|/
name|ByteBlockPool
operator|.
name|BYTE_BLOCK_SIZE
argument_list|)
decl_stmt|;
specifier|final
name|int
name|maxBufferedIntBlocks
init|=
call|(
name|int
call|)
argument_list|(
operator|(
name|maxReusedBytes
operator|-
operator|(
name|maxBufferedByteBlocks
operator|*
name|ByteBlockPool
operator|.
name|BYTE_BLOCK_SIZE
operator|)
operator|)
operator|/
operator|(
name|IntBlockPool
operator|.
name|INT_BLOCK_SIZE
operator|*
name|RamUsageEstimator
operator|.
name|NUM_BYTES_INT
operator|)
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|maxBufferedByteBlocks
operator|*
name|ByteBlockPool
operator|.
name|BYTE_BLOCK_SIZE
operator|)
operator|+
operator|(
name|maxBufferedIntBlocks
operator|*
name|IntBlockPool
operator|.
name|INT_BLOCK_SIZE
operator|*
name|RamUsageEstimator
operator|.
name|NUM_BYTES_INT
operator|)
operator|<=
name|maxReusedBytes
assert|;
name|byteBlockPool
operator|=
operator|new
name|ByteBlockPool
argument_list|(
operator|new
name|RecyclingByteBlockAllocator
argument_list|(
name|ByteBlockPool
operator|.
name|BYTE_BLOCK_SIZE
argument_list|,
name|maxBufferedByteBlocks
argument_list|,
name|bytesUsed
argument_list|)
argument_list|)
expr_stmt|;
name|intBlockPool
operator|=
operator|new
name|IntBlockPool
argument_list|(
operator|new
name|RecyclingIntBlockAllocator
argument_list|(
name|IntBlockPool
operator|.
name|INT_BLOCK_SIZE
argument_list|,
name|maxBufferedIntBlocks
argument_list|,
name|bytesUsed
argument_list|)
argument_list|)
expr_stmt|;
name|postingsWriter
operator|=
operator|new
name|SliceWriter
argument_list|(
name|intBlockPool
argument_list|)
expr_stmt|;
comment|//TODO refactor BytesRefArray to allow us to apply maxReusedBytes option
name|payloadsBytesRefs
operator|=
name|storePayloads
condition|?
operator|new
name|BytesRefArray
argument_list|(
name|bytesUsed
argument_list|)
else|:
literal|null
expr_stmt|;
block|}
comment|/**    * Convenience method; Tokenizes the given field text and adds the resulting    * terms to the index; Equivalent to adding an indexed non-keyword Lucene    * {@link org.apache.lucene.document.Field} that is tokenized, not stored,    * termVectorStored with positions (or termVectorStored with positions and offsets),    *     * @param fieldName    *            a name to be associated with the text    * @param text    *            the text to tokenize and index.    * @param analyzer    *            the analyzer to use for tokenization    */
DECL|method|addField
specifier|public
name|void
name|addField
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|String
name|text
parameter_list|,
name|Analyzer
name|analyzer
parameter_list|)
block|{
if|if
condition|(
name|fieldName
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"fieldName must not be null"
argument_list|)
throw|;
if|if
condition|(
name|text
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"text must not be null"
argument_list|)
throw|;
if|if
condition|(
name|analyzer
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"analyzer must not be null"
argument_list|)
throw|;
name|TokenStream
name|stream
decl_stmt|;
try|try
block|{
name|stream
operator|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|fieldName
argument_list|,
name|text
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
name|addField
argument_list|(
name|fieldName
argument_list|,
name|stream
argument_list|,
literal|1.0f
argument_list|,
name|analyzer
operator|.
name|getPositionIncrementGap
argument_list|(
name|fieldName
argument_list|)
argument_list|,
name|analyzer
operator|.
name|getOffsetGap
argument_list|(
name|fieldName
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Convenience method; Creates and returns a token stream that generates a    * token for each keyword in the given collection, "as is", without any    * transforming text analysis. The resulting token stream can be fed into    * {@link #addField(String, TokenStream)}, perhaps wrapped into another    * {@link org.apache.lucene.analysis.TokenFilter}, as desired.    *     * @param keywords    *            the keywords to generate tokens for    * @return the corresponding token stream    */
DECL|method|keywordTokenStream
specifier|public
parameter_list|<
name|T
parameter_list|>
name|TokenStream
name|keywordTokenStream
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|T
argument_list|>
name|keywords
parameter_list|)
block|{
comment|// TODO: deprecate& move this method into AnalyzerUtil?
if|if
condition|(
name|keywords
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"keywords must not be null"
argument_list|)
throw|;
return|return
operator|new
name|TokenStream
argument_list|()
block|{
specifier|private
name|Iterator
argument_list|<
name|T
argument_list|>
name|iter
init|=
name|keywords
operator|.
name|iterator
argument_list|()
decl_stmt|;
specifier|private
name|int
name|start
init|=
literal|0
decl_stmt|;
specifier|private
specifier|final
name|CharTermAttribute
name|termAtt
init|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|OffsetAttribute
name|offsetAtt
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|incrementToken
parameter_list|()
block|{
if|if
condition|(
operator|!
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
return|return
literal|false
return|;
name|T
name|obj
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|obj
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"keyword must not be null"
argument_list|)
throw|;
name|String
name|term
init|=
name|obj
operator|.
name|toString
argument_list|()
decl_stmt|;
name|clearAttributes
argument_list|()
expr_stmt|;
name|termAtt
operator|.
name|setEmpty
argument_list|()
operator|.
name|append
argument_list|(
name|term
argument_list|)
expr_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|start
argument_list|,
name|start
operator|+
name|termAtt
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|start
operator|+=
name|term
operator|.
name|length
argument_list|()
operator|+
literal|1
expr_stmt|;
comment|// separate words by 1 (blank) character
return|return
literal|true
return|;
block|}
block|}
return|;
block|}
comment|/**    * Equivalent to<code>addField(fieldName, stream, 1.0f)</code>.    *    * @param fieldName    *            a name to be associated with the text    * @param stream    *            the token stream to retrieve tokens from    */
DECL|method|addField
specifier|public
name|void
name|addField
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TokenStream
name|stream
parameter_list|)
block|{
name|addField
argument_list|(
name|fieldName
argument_list|,
name|stream
argument_list|,
literal|1.0f
argument_list|)
expr_stmt|;
block|}
comment|/**    * Iterates over the given token stream and adds the resulting terms to the index;    * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,    * Lucene {@link org.apache.lucene.document.Field}.    * Finally closes the token stream. Note that untokenized keywords can be added with this method via     * {@link #keywordTokenStream(Collection)}, the Lucene<code>KeywordTokenizer</code> or similar utilities.    *     * @param fieldName    *            a name to be associated with the text    * @param stream    *            the token stream to retrieve tokens from.    * @param boost    *            the boost factor for hits for this field    *      * @see org.apache.lucene.document.Field#setBoost(float)    */
DECL|method|addField
specifier|public
name|void
name|addField
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TokenStream
name|stream
parameter_list|,
name|float
name|boost
parameter_list|)
block|{
name|addField
argument_list|(
name|fieldName
argument_list|,
name|stream
argument_list|,
name|boost
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/**    * Iterates over the given token stream and adds the resulting terms to the index;    * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,    * Lucene {@link org.apache.lucene.document.Field}.    * Finally closes the token stream. Note that untokenized keywords can be added with this method via    * {@link #keywordTokenStream(Collection)}, the Lucene<code>KeywordTokenizer</code> or similar utilities.    *    * @param fieldName    *            a name to be associated with the text    * @param stream    *            the token stream to retrieve tokens from.    * @param boost    *            the boost factor for hits for this field    *    * @param positionIncrementGap    *            the position increment gap if fields with the same name are added more than once    *    *    * @see org.apache.lucene.document.Field#setBoost(float)    */
DECL|method|addField
specifier|public
name|void
name|addField
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TokenStream
name|stream
parameter_list|,
name|float
name|boost
parameter_list|,
name|int
name|positionIncrementGap
parameter_list|)
block|{
name|addField
argument_list|(
name|fieldName
argument_list|,
name|stream
argument_list|,
name|boost
argument_list|,
name|positionIncrementGap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Iterates over the given token stream and adds the resulting terms to the index;    * Equivalent to adding a tokenized, indexed, termVectorStored, unstored,    * Lucene {@link org.apache.lucene.document.Field}.    * Finally closes the token stream. Note that untokenized keywords can be added with this method via     * {@link #keywordTokenStream(Collection)}, the Lucene<code>KeywordTokenizer</code> or similar utilities.    *     *    * @param fieldName    *            a name to be associated with the text    * @param tokenStream    *            the token stream to retrieve tokens from. It's guaranteed to be closed no matter what.    * @param boost    *            the boost factor for hits for this field    * @param positionIncrementGap    *            the position increment gap if fields with the same name are added more than once    * @param offsetGap    *            the offset gap if fields with the same name are added more than once    * @see org.apache.lucene.document.Field#setBoost(float)    */
DECL|method|addField
specifier|public
name|void
name|addField
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TokenStream
name|tokenStream
parameter_list|,
name|float
name|boost
parameter_list|,
name|int
name|positionIncrementGap
parameter_list|,
name|int
name|offsetGap
parameter_list|)
block|{
try|try
init|(
name|TokenStream
name|stream
init|=
name|tokenStream
init|)
block|{
if|if
condition|(
name|frozen
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Cannot call addField() when MemoryIndex is frozen"
argument_list|)
throw|;
if|if
condition|(
name|fieldName
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"fieldName must not be null"
argument_list|)
throw|;
if|if
condition|(
name|stream
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"token stream must not be null"
argument_list|)
throw|;
if|if
condition|(
name|boost
operator|<=
literal|0.0f
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"boost factor must be greater than 0.0"
argument_list|)
throw|;
name|int
name|numTokens
init|=
literal|0
decl_stmt|;
name|int
name|numOverlapTokens
init|=
literal|0
decl_stmt|;
name|int
name|pos
init|=
operator|-
literal|1
decl_stmt|;
specifier|final
name|BytesRefHash
name|terms
decl_stmt|;
specifier|final
name|SliceByteStartArray
name|sliceArray
decl_stmt|;
name|Info
name|info
decl_stmt|;
name|long
name|sumTotalTermFreq
init|=
literal|0
decl_stmt|;
name|int
name|offset
init|=
literal|0
decl_stmt|;
name|FieldInfo
name|fieldInfo
decl_stmt|;
if|if
condition|(
operator|(
name|info
operator|=
name|fields
operator|.
name|get
argument_list|(
name|fieldName
argument_list|)
operator|)
operator|!=
literal|null
condition|)
block|{
name|fieldInfo
operator|=
name|info
operator|.
name|fieldInfo
expr_stmt|;
name|numTokens
operator|=
name|info
operator|.
name|numTokens
expr_stmt|;
name|numOverlapTokens
operator|=
name|info
operator|.
name|numOverlapTokens
expr_stmt|;
name|pos
operator|=
name|info
operator|.
name|lastPosition
operator|+
name|positionIncrementGap
expr_stmt|;
name|offset
operator|=
name|info
operator|.
name|lastOffset
operator|+
name|offsetGap
expr_stmt|;
name|terms
operator|=
name|info
operator|.
name|terms
expr_stmt|;
name|boost
operator|*=
name|info
operator|.
name|boost
expr_stmt|;
name|sliceArray
operator|=
name|info
operator|.
name|sliceArray
expr_stmt|;
name|sumTotalTermFreq
operator|=
name|info
operator|.
name|sumTotalTermFreq
expr_stmt|;
block|}
else|else
block|{
name|fieldInfo
operator|=
operator|new
name|FieldInfo
argument_list|(
name|fieldName
argument_list|,
name|fields
operator|.
name|size
argument_list|()
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
name|this
operator|.
name|storePayloads
argument_list|,
name|this
operator|.
name|storeOffsets
condition|?
name|IndexOptions
operator|.
name|DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS
else|:
name|IndexOptions
operator|.
name|DOCS_AND_FREQS_AND_POSITIONS
argument_list|,
name|DocValuesType
operator|.
name|NONE
argument_list|,
operator|-
literal|1
argument_list|,
name|Collections
operator|.
name|emptyMap
argument_list|()
argument_list|)
expr_stmt|;
name|sliceArray
operator|=
operator|new
name|SliceByteStartArray
argument_list|(
name|BytesRefHash
operator|.
name|DEFAULT_CAPACITY
argument_list|)
expr_stmt|;
name|terms
operator|=
operator|new
name|BytesRefHash
argument_list|(
name|byteBlockPool
argument_list|,
name|BytesRefHash
operator|.
name|DEFAULT_CAPACITY
argument_list|,
name|sliceArray
argument_list|)
expr_stmt|;
block|}
name|TermToBytesRefAttribute
name|termAtt
init|=
name|stream
operator|.
name|getAttribute
argument_list|(
name|TermToBytesRefAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|PositionIncrementAttribute
name|posIncrAttribute
init|=
name|stream
operator|.
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|OffsetAttribute
name|offsetAtt
init|=
name|stream
operator|.
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|PayloadAttribute
name|payloadAtt
init|=
name|storePayloads
condition|?
name|stream
operator|.
name|addAttribute
argument_list|(
name|PayloadAttribute
operator|.
name|class
argument_list|)
else|:
literal|null
decl_stmt|;
name|stream
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|stream
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
comment|//        if (DEBUG) System.err.println("token='" + term + "'");
name|numTokens
operator|++
expr_stmt|;
specifier|final
name|int
name|posIncr
init|=
name|posIncrAttribute
operator|.
name|getPositionIncrement
argument_list|()
decl_stmt|;
if|if
condition|(
name|posIncr
operator|==
literal|0
condition|)
name|numOverlapTokens
operator|++
expr_stmt|;
name|pos
operator|+=
name|posIncr
expr_stmt|;
name|int
name|ord
init|=
name|terms
operator|.
name|add
argument_list|(
name|termAtt
operator|.
name|getBytesRef
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|ord
operator|<
literal|0
condition|)
block|{
name|ord
operator|=
operator|(
operator|-
name|ord
operator|)
operator|-
literal|1
expr_stmt|;
name|postingsWriter
operator|.
name|reset
argument_list|(
name|sliceArray
operator|.
name|end
index|[
name|ord
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sliceArray
operator|.
name|start
index|[
name|ord
index|]
operator|=
name|postingsWriter
operator|.
name|startNewSlice
argument_list|()
expr_stmt|;
block|}
name|sliceArray
operator|.
name|freq
index|[
name|ord
index|]
operator|++
expr_stmt|;
name|sumTotalTermFreq
operator|++
expr_stmt|;
name|postingsWriter
operator|.
name|writeInt
argument_list|(
name|pos
argument_list|)
expr_stmt|;
if|if
condition|(
name|storeOffsets
condition|)
block|{
name|postingsWriter
operator|.
name|writeInt
argument_list|(
name|offsetAtt
operator|.
name|startOffset
argument_list|()
operator|+
name|offset
argument_list|)
expr_stmt|;
name|postingsWriter
operator|.
name|writeInt
argument_list|(
name|offsetAtt
operator|.
name|endOffset
argument_list|()
operator|+
name|offset
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|storePayloads
condition|)
block|{
specifier|final
name|BytesRef
name|payload
init|=
name|payloadAtt
operator|.
name|getPayload
argument_list|()
decl_stmt|;
specifier|final
name|int
name|pIndex
decl_stmt|;
if|if
condition|(
name|payload
operator|==
literal|null
operator|||
name|payload
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|pIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
name|pIndex
operator|=
name|payloadsBytesRefs
operator|.
name|append
argument_list|(
name|payload
argument_list|)
expr_stmt|;
block|}
name|postingsWriter
operator|.
name|writeInt
argument_list|(
name|pIndex
argument_list|)
expr_stmt|;
block|}
name|sliceArray
operator|.
name|end
index|[
name|ord
index|]
operator|=
name|postingsWriter
operator|.
name|getCurrentOffset
argument_list|()
expr_stmt|;
block|}
name|stream
operator|.
name|end
argument_list|()
expr_stmt|;
comment|// ensure infos.numTokens> 0 invariant; needed for correct operation of terms()
if|if
condition|(
name|numTokens
operator|>
literal|0
condition|)
block|{
name|fields
operator|.
name|put
argument_list|(
name|fieldName
argument_list|,
operator|new
name|Info
argument_list|(
name|fieldInfo
argument_list|,
name|terms
argument_list|,
name|sliceArray
argument_list|,
name|numTokens
argument_list|,
name|numOverlapTokens
argument_list|,
name|boost
argument_list|,
name|pos
argument_list|,
name|offsetAtt
operator|.
name|endOffset
argument_list|()
operator|+
name|offset
argument_list|,
name|sumTotalTermFreq
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Set the Similarity to be used for calculating field norms    */
DECL|method|setSimilarity
specifier|public
name|void
name|setSimilarity
parameter_list|(
name|Similarity
name|similarity
parameter_list|)
block|{
if|if
condition|(
name|frozen
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Cannot set Similarity when MemoryIndex is frozen"
argument_list|)
throw|;
if|if
condition|(
name|this
operator|.
name|normSimilarity
operator|==
name|similarity
condition|)
return|return;
name|this
operator|.
name|normSimilarity
operator|=
name|similarity
expr_stmt|;
comment|//invalidate any cached norms that may exist
for|for
control|(
name|Info
name|info
range|:
name|fields
operator|.
name|values
argument_list|()
control|)
block|{
name|info
operator|.
name|norms
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Creates and returns a searcher that can be used to execute arbitrary    * Lucene queries and to collect the resulting query results as hits.    *     * @return a searcher    */
DECL|method|createSearcher
specifier|public
name|IndexSearcher
name|createSearcher
parameter_list|()
block|{
name|MemoryIndexReader
name|reader
init|=
operator|new
name|MemoryIndexReader
argument_list|()
decl_stmt|;
name|IndexSearcher
name|searcher
init|=
operator|new
name|IndexSearcher
argument_list|(
name|reader
argument_list|)
decl_stmt|;
comment|// ensures no auto-close !!
name|searcher
operator|.
name|setSimilarity
argument_list|(
name|normSimilarity
argument_list|)
expr_stmt|;
return|return
name|searcher
return|;
block|}
comment|/**    * Prepares the MemoryIndex for querying in a non-lazy way.    *<p>    * After calling this you can query the MemoryIndex from multiple threads, but you    * cannot subsequently add new data.    */
DECL|method|freeze
specifier|public
name|void
name|freeze
parameter_list|()
block|{
name|this
operator|.
name|frozen
operator|=
literal|true
expr_stmt|;
for|for
control|(
name|Info
name|info
range|:
name|fields
operator|.
name|values
argument_list|()
control|)
block|{
name|info
operator|.
name|sortTerms
argument_list|()
expr_stmt|;
name|info
operator|.
name|getNormDocValues
argument_list|()
expr_stmt|;
comment|//lazily computed
block|}
block|}
comment|/**    * Convenience method that efficiently returns the relevance score by    * matching this index against the given Lucene query expression.    *     * @param query    *            an arbitrary Lucene query to run against this index    * @return the relevance score of the matchmaking; A number in the range    *         [0.0 .. 1.0], with 0.0 indicating no match. The higher the number    *         the better the match.    *    */
DECL|method|search
specifier|public
name|float
name|search
parameter_list|(
name|Query
name|query
parameter_list|)
block|{
if|if
condition|(
name|query
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"query must not be null"
argument_list|)
throw|;
name|IndexSearcher
name|searcher
init|=
name|createSearcher
argument_list|()
decl_stmt|;
try|try
block|{
specifier|final
name|float
index|[]
name|scores
init|=
operator|new
name|float
index|[
literal|1
index|]
decl_stmt|;
comment|// inits to 0.0f (no match)
name|searcher
operator|.
name|search
argument_list|(
name|query
argument_list|,
operator|new
name|SimpleCollector
argument_list|()
block|{
specifier|private
name|Scorer
name|scorer
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|collect
parameter_list|(
name|int
name|doc
parameter_list|)
throws|throws
name|IOException
block|{
name|scores
index|[
literal|0
index|]
operator|=
name|scorer
operator|.
name|score
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setScorer
parameter_list|(
name|Scorer
name|scorer
parameter_list|)
block|{
name|this
operator|.
name|scorer
operator|=
name|scorer
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|needsScores
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|float
name|score
init|=
name|scores
index|[
literal|0
index|]
decl_stmt|;
return|return
name|score
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// can never happen (RAMDirectory)
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
comment|// searcher.close();
comment|/*        * Note that it is harmless and important for good performance to        * NOT close the index reader!!! This avoids all sorts of        * unnecessary baggage and locking in the Lucene IndexReader        * superclass, all of which is completely unnecessary for this main        * memory index data structure.        *         * Wishing IndexReader would be an interface...        *         * Actually with the new tight createSearcher() API auto-closing is now        * made impossible, hence searcher.close() would be harmless and also         * would not degrade performance...        */
block|}
block|}
comment|/**    * Returns a String representation of the index data for debugging purposes.    *     * @return the string representation    */
annotation|@
name|Override
DECL|method|toString
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|result
init|=
operator|new
name|StringBuilder
argument_list|(
literal|256
argument_list|)
decl_stmt|;
name|int
name|sumPositions
init|=
literal|0
decl_stmt|;
name|int
name|sumTerms
init|=
literal|0
decl_stmt|;
specifier|final
name|BytesRef
name|spare
init|=
operator|new
name|BytesRef
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Info
argument_list|>
name|entry
range|:
name|fields
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|fieldName
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Info
name|info
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|info
operator|.
name|sortTerms
argument_list|()
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
name|fieldName
operator|+
literal|":\n"
argument_list|)
expr_stmt|;
name|SliceByteStartArray
name|sliceArray
init|=
name|info
operator|.
name|sliceArray
decl_stmt|;
name|int
name|numPositions
init|=
literal|0
decl_stmt|;
name|SliceReader
name|postingsReader
init|=
operator|new
name|SliceReader
argument_list|(
name|intBlockPool
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
condition|;
name|j
operator|++
control|)
block|{
name|int
name|ord
init|=
name|info
operator|.
name|sortedTerms
index|[
name|j
index|]
decl_stmt|;
name|info
operator|.
name|terms
operator|.
name|get
argument_list|(
name|ord
argument_list|,
name|spare
argument_list|)
expr_stmt|;
name|int
name|freq
init|=
name|sliceArray
operator|.
name|freq
index|[
name|ord
index|]
decl_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|"\t'"
operator|+
name|spare
operator|+
literal|"':"
operator|+
name|freq
operator|+
literal|":"
argument_list|)
expr_stmt|;
name|postingsReader
operator|.
name|reset
argument_list|(
name|sliceArray
operator|.
name|start
index|[
name|ord
index|]
argument_list|,
name|sliceArray
operator|.
name|end
index|[
name|ord
index|]
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|" ["
argument_list|)
expr_stmt|;
specifier|final
name|int
name|iters
init|=
name|storeOffsets
condition|?
literal|3
else|:
literal|1
decl_stmt|;
while|while
condition|(
operator|!
name|postingsReader
operator|.
name|endOfSlice
argument_list|()
condition|)
block|{
name|result
operator|.
name|append
argument_list|(
literal|"("
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|iters
condition|;
name|k
operator|++
control|)
block|{
name|result
operator|.
name|append
argument_list|(
name|postingsReader
operator|.
name|readInt
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|k
operator|<
name|iters
operator|-
literal|1
condition|)
block|{
name|result
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
block|}
name|result
operator|.
name|append
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|postingsReader
operator|.
name|endOfSlice
argument_list|()
condition|)
block|{
name|result
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
block|}
name|result
operator|.
name|append
argument_list|(
literal|"]"
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|numPositions
operator|+=
name|freq
expr_stmt|;
block|}
name|result
operator|.
name|append
argument_list|(
literal|"\tterms="
operator|+
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|", positions="
operator|+
name|numPositions
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|sumPositions
operator|+=
name|numPositions
expr_stmt|;
name|sumTerms
operator|+=
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
name|result
operator|.
name|append
argument_list|(
literal|"\nfields="
operator|+
name|fields
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|", terms="
operator|+
name|sumTerms
argument_list|)
expr_stmt|;
name|result
operator|.
name|append
argument_list|(
literal|", positions="
operator|+
name|sumPositions
argument_list|)
expr_stmt|;
return|return
name|result
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Index data structure for a field; contains the tokenized term texts and    * their positions.    */
DECL|class|Info
specifier|private
specifier|final
class|class
name|Info
block|{
DECL|field|fieldInfo
specifier|private
specifier|final
name|FieldInfo
name|fieldInfo
decl_stmt|;
comment|/** The norms for this field; computed on demand. */
DECL|field|norms
specifier|private
specifier|transient
name|NumericDocValues
name|norms
decl_stmt|;
comment|/**      * Term strings and their positions for this field: Map&lt;String      * termText, ArrayIntList positions&gt;      */
DECL|field|terms
specifier|private
specifier|final
name|BytesRefHash
name|terms
decl_stmt|;
comment|// note unfortunate variable name class with Terms type
DECL|field|sliceArray
specifier|private
specifier|final
name|SliceByteStartArray
name|sliceArray
decl_stmt|;
comment|/** Terms sorted ascending by term text; computed on demand */
DECL|field|sortedTerms
specifier|private
specifier|transient
name|int
index|[]
name|sortedTerms
decl_stmt|;
comment|/** Number of added tokens for this field */
DECL|field|numTokens
specifier|private
specifier|final
name|int
name|numTokens
decl_stmt|;
comment|/** Number of overlapping tokens for this field */
DECL|field|numOverlapTokens
specifier|private
specifier|final
name|int
name|numOverlapTokens
decl_stmt|;
comment|/** Boost factor for hits for this field */
DECL|field|boost
specifier|private
specifier|final
name|float
name|boost
decl_stmt|;
DECL|field|sumTotalTermFreq
specifier|private
specifier|final
name|long
name|sumTotalTermFreq
decl_stmt|;
comment|/** the last position encountered in this field for multi field support*/
DECL|field|lastPosition
specifier|private
specifier|final
name|int
name|lastPosition
decl_stmt|;
comment|/** the last offset encountered in this field for multi field support*/
DECL|field|lastOffset
specifier|private
specifier|final
name|int
name|lastOffset
decl_stmt|;
DECL|method|Info
specifier|public
name|Info
parameter_list|(
name|FieldInfo
name|fieldInfo
parameter_list|,
name|BytesRefHash
name|terms
parameter_list|,
name|SliceByteStartArray
name|sliceArray
parameter_list|,
name|int
name|numTokens
parameter_list|,
name|int
name|numOverlapTokens
parameter_list|,
name|float
name|boost
parameter_list|,
name|int
name|lastPosition
parameter_list|,
name|int
name|lastOffset
parameter_list|,
name|long
name|sumTotalTermFreq
parameter_list|)
block|{
name|this
operator|.
name|fieldInfo
operator|=
name|fieldInfo
expr_stmt|;
name|this
operator|.
name|terms
operator|=
name|terms
expr_stmt|;
name|this
operator|.
name|sliceArray
operator|=
name|sliceArray
expr_stmt|;
name|this
operator|.
name|numTokens
operator|=
name|numTokens
expr_stmt|;
name|this
operator|.
name|numOverlapTokens
operator|=
name|numOverlapTokens
expr_stmt|;
name|this
operator|.
name|boost
operator|=
name|boost
expr_stmt|;
name|this
operator|.
name|sumTotalTermFreq
operator|=
name|sumTotalTermFreq
expr_stmt|;
name|this
operator|.
name|lastPosition
operator|=
name|lastPosition
expr_stmt|;
name|this
operator|.
name|lastOffset
operator|=
name|lastOffset
expr_stmt|;
block|}
comment|/**      * Sorts hashed terms into ascending order, reusing memory along the      * way. Note that sorting is lazily delayed until required (often it's      * not required at all). If a sorted view is required then hashing +      * sort + binary search is still faster and smaller than TreeMap usage      * (which would be an alternative and somewhat more elegant approach,      * apart from more sophisticated Tries / prefix trees).      */
DECL|method|sortTerms
specifier|public
name|void
name|sortTerms
parameter_list|()
block|{
if|if
condition|(
name|sortedTerms
operator|==
literal|null
condition|)
block|{
name|sortedTerms
operator|=
name|terms
operator|.
name|sort
argument_list|(
name|BytesRef
operator|.
name|getUTF8SortedAsUnicodeComparator
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|getNormDocValues
specifier|public
name|NumericDocValues
name|getNormDocValues
parameter_list|()
block|{
if|if
condition|(
name|norms
operator|==
literal|null
condition|)
block|{
name|FieldInvertState
name|invertState
init|=
operator|new
name|FieldInvertState
argument_list|(
name|fieldInfo
operator|.
name|name
argument_list|,
name|fieldInfo
operator|.
name|number
argument_list|,
name|numTokens
argument_list|,
name|numOverlapTokens
argument_list|,
literal|0
argument_list|,
name|boost
argument_list|)
decl_stmt|;
specifier|final
name|long
name|value
init|=
name|normSimilarity
operator|.
name|computeNorm
argument_list|(
name|invertState
argument_list|)
decl_stmt|;
if|if
condition|(
name|DEBUG
condition|)
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"MemoryIndexReader.norms: "
operator|+
name|fieldInfo
operator|.
name|name
operator|+
literal|":"
operator|+
name|value
operator|+
literal|":"
operator|+
name|numTokens
argument_list|)
expr_stmt|;
name|norms
operator|=
operator|new
name|NumericDocValues
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|long
name|get
parameter_list|(
name|int
name|docID
parameter_list|)
block|{
if|if
condition|(
name|docID
operator|!=
literal|0
condition|)
throw|throw
operator|new
name|IndexOutOfBoundsException
argument_list|()
throw|;
else|else
return|return
name|value
return|;
block|}
block|}
expr_stmt|;
block|}
return|return
name|norms
return|;
block|}
block|}
comment|///////////////////////////////////////////////////////////////////////////////
comment|// Nested classes:
comment|///////////////////////////////////////////////////////////////////////////////
comment|/**    * Search support for Lucene framework integration; implements all methods    * required by the Lucene IndexReader contracts.    */
DECL|class|MemoryIndexReader
specifier|private
specifier|final
class|class
name|MemoryIndexReader
extends|extends
name|LeafReader
block|{
DECL|method|MemoryIndexReader
specifier|private
name|MemoryIndexReader
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
comment|// avoid as much superclass baggage as possible
block|}
annotation|@
name|Override
DECL|method|addCoreClosedListener
specifier|public
name|void
name|addCoreClosedListener
parameter_list|(
name|CoreClosedListener
name|listener
parameter_list|)
block|{
name|addCoreClosedListenerAsReaderClosedListener
argument_list|(
name|this
argument_list|,
name|listener
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|removeCoreClosedListener
specifier|public
name|void
name|removeCoreClosedListener
parameter_list|(
name|CoreClosedListener
name|listener
parameter_list|)
block|{
name|removeCoreClosedListenerAsReaderClosedListener
argument_list|(
name|this
argument_list|,
name|listener
argument_list|)
expr_stmt|;
block|}
DECL|method|getInfo
specifier|private
name|Info
name|getInfo
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
return|return
name|fields
operator|.
name|get
argument_list|(
name|fieldName
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|getLiveDocs
specifier|public
name|Bits
name|getLiveDocs
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getFieldInfos
specifier|public
name|FieldInfos
name|getFieldInfos
parameter_list|()
block|{
name|FieldInfo
index|[]
name|fieldInfos
init|=
operator|new
name|FieldInfo
index|[
name|fields
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Info
name|info
range|:
name|fields
operator|.
name|values
argument_list|()
control|)
block|{
name|fieldInfos
index|[
name|i
operator|++
index|]
operator|=
name|info
operator|.
name|fieldInfo
expr_stmt|;
block|}
return|return
operator|new
name|FieldInfos
argument_list|(
name|fieldInfos
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|getNumericDocValues
specifier|public
name|NumericDocValues
name|getNumericDocValues
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getBinaryDocValues
specifier|public
name|BinaryDocValues
name|getBinaryDocValues
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getSortedDocValues
specifier|public
name|SortedDocValues
name|getSortedDocValues
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getSortedNumericDocValues
specifier|public
name|SortedNumericDocValues
name|getSortedNumericDocValues
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getSortedSetDocValues
specifier|public
name|SortedSetDocValues
name|getSortedSetDocValues
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getDocsWithField
specifier|public
name|Bits
name|getDocsWithField
parameter_list|(
name|String
name|field
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|checkIntegrity
specifier|public
name|void
name|checkIntegrity
parameter_list|()
throws|throws
name|IOException
block|{
comment|// no-op
block|}
DECL|class|MemoryFields
specifier|private
class|class
name|MemoryFields
extends|extends
name|Fields
block|{
annotation|@
name|Override
DECL|method|iterator
specifier|public
name|Iterator
argument_list|<
name|String
argument_list|>
name|iterator
parameter_list|()
block|{
return|return
name|fields
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|terms
specifier|public
name|Terms
name|terms
parameter_list|(
specifier|final
name|String
name|field
parameter_list|)
block|{
specifier|final
name|Info
name|info
init|=
name|fields
operator|.
name|get
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|info
operator|==
literal|null
condition|)
return|return
literal|null
return|;
return|return
operator|new
name|Terms
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|TermsEnum
name|iterator
parameter_list|()
block|{
return|return
operator|new
name|MemoryTermsEnum
argument_list|(
name|info
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|size
parameter_list|()
block|{
return|return
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSumTotalTermFreq
parameter_list|()
block|{
return|return
name|info
operator|.
name|sumTotalTermFreq
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSumDocFreq
parameter_list|()
block|{
comment|// each term has df=1
return|return
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getDocCount
parameter_list|()
block|{
return|return
name|size
argument_list|()
operator|>
literal|0
condition|?
literal|1
else|:
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasFreqs
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasOffsets
parameter_list|()
block|{
return|return
name|storeOffsets
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPositions
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPayloads
parameter_list|()
block|{
return|return
name|storePayloads
return|;
block|}
block|}
return|;
block|}
annotation|@
name|Override
DECL|method|size
specifier|public
name|int
name|size
parameter_list|()
block|{
return|return
name|fields
operator|.
name|size
argument_list|()
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|fields
specifier|public
name|Fields
name|fields
parameter_list|()
block|{
return|return
operator|new
name|MemoryFields
argument_list|()
return|;
block|}
DECL|class|MemoryTermsEnum
specifier|private
class|class
name|MemoryTermsEnum
extends|extends
name|TermsEnum
block|{
DECL|field|info
specifier|private
specifier|final
name|Info
name|info
decl_stmt|;
DECL|field|br
specifier|private
specifier|final
name|BytesRef
name|br
init|=
operator|new
name|BytesRef
argument_list|()
decl_stmt|;
DECL|field|termUpto
name|int
name|termUpto
init|=
operator|-
literal|1
decl_stmt|;
DECL|method|MemoryTermsEnum
specifier|public
name|MemoryTermsEnum
parameter_list|(
name|Info
name|info
parameter_list|)
block|{
name|this
operator|.
name|info
operator|=
name|info
expr_stmt|;
name|info
operator|.
name|sortTerms
argument_list|()
expr_stmt|;
block|}
DECL|method|binarySearch
specifier|private
specifier|final
name|int
name|binarySearch
parameter_list|(
name|BytesRef
name|b
parameter_list|,
name|BytesRef
name|bytesRef
parameter_list|,
name|int
name|low
parameter_list|,
name|int
name|high
parameter_list|,
name|BytesRefHash
name|hash
parameter_list|,
name|int
index|[]
name|ords
parameter_list|,
name|Comparator
argument_list|<
name|BytesRef
argument_list|>
name|comparator
parameter_list|)
block|{
name|int
name|mid
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|low
operator|<=
name|high
condition|)
block|{
name|mid
operator|=
operator|(
name|low
operator|+
name|high
operator|)
operator|>>>
literal|1
expr_stmt|;
name|hash
operator|.
name|get
argument_list|(
name|ords
index|[
name|mid
index|]
argument_list|,
name|bytesRef
argument_list|)
expr_stmt|;
specifier|final
name|int
name|cmp
init|=
name|comparator
operator|.
name|compare
argument_list|(
name|bytesRef
argument_list|,
name|b
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|<
literal|0
condition|)
block|{
name|low
operator|=
name|mid
operator|+
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmp
operator|>
literal|0
condition|)
block|{
name|high
operator|=
name|mid
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
return|return
name|mid
return|;
block|}
block|}
assert|assert
name|comparator
operator|.
name|compare
argument_list|(
name|bytesRef
argument_list|,
name|b
argument_list|)
operator|!=
literal|0
assert|;
return|return
operator|-
operator|(
name|low
operator|+
literal|1
operator|)
return|;
block|}
annotation|@
name|Override
DECL|method|seekExact
specifier|public
name|boolean
name|seekExact
parameter_list|(
name|BytesRef
name|text
parameter_list|)
block|{
name|termUpto
operator|=
name|binarySearch
argument_list|(
name|text
argument_list|,
name|br
argument_list|,
literal|0
argument_list|,
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|,
name|info
operator|.
name|terms
argument_list|,
name|info
operator|.
name|sortedTerms
argument_list|,
name|BytesRef
operator|.
name|getUTF8SortedAsUnicodeComparator
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|termUpto
operator|>=
literal|0
return|;
block|}
annotation|@
name|Override
DECL|method|seekCeil
specifier|public
name|SeekStatus
name|seekCeil
parameter_list|(
name|BytesRef
name|text
parameter_list|)
block|{
name|termUpto
operator|=
name|binarySearch
argument_list|(
name|text
argument_list|,
name|br
argument_list|,
literal|0
argument_list|,
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|,
name|info
operator|.
name|terms
argument_list|,
name|info
operator|.
name|sortedTerms
argument_list|,
name|BytesRef
operator|.
name|getUTF8SortedAsUnicodeComparator
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|termUpto
operator|<
literal|0
condition|)
block|{
comment|// not found; choose successor
name|termUpto
operator|=
operator|-
name|termUpto
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|termUpto
operator|>=
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
name|SeekStatus
operator|.
name|END
return|;
block|}
else|else
block|{
name|info
operator|.
name|terms
operator|.
name|get
argument_list|(
name|info
operator|.
name|sortedTerms
index|[
name|termUpto
index|]
argument_list|,
name|br
argument_list|)
expr_stmt|;
return|return
name|SeekStatus
operator|.
name|NOT_FOUND
return|;
block|}
block|}
else|else
block|{
return|return
name|SeekStatus
operator|.
name|FOUND
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|seekExact
specifier|public
name|void
name|seekExact
parameter_list|(
name|long
name|ord
parameter_list|)
block|{
assert|assert
name|ord
operator|<
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
assert|;
name|termUpto
operator|=
operator|(
name|int
operator|)
name|ord
expr_stmt|;
name|info
operator|.
name|terms
operator|.
name|get
argument_list|(
name|info
operator|.
name|sortedTerms
index|[
name|termUpto
index|]
argument_list|,
name|br
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|next
specifier|public
name|BytesRef
name|next
parameter_list|()
block|{
name|termUpto
operator|++
expr_stmt|;
if|if
condition|(
name|termUpto
operator|>=
name|info
operator|.
name|terms
operator|.
name|size
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
name|info
operator|.
name|terms
operator|.
name|get
argument_list|(
name|info
operator|.
name|sortedTerms
index|[
name|termUpto
index|]
argument_list|,
name|br
argument_list|)
expr_stmt|;
return|return
name|br
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|term
specifier|public
name|BytesRef
name|term
parameter_list|()
block|{
return|return
name|br
return|;
block|}
annotation|@
name|Override
DECL|method|ord
specifier|public
name|long
name|ord
parameter_list|()
block|{
return|return
name|termUpto
return|;
block|}
annotation|@
name|Override
DECL|method|docFreq
specifier|public
name|int
name|docFreq
parameter_list|()
block|{
return|return
literal|1
return|;
block|}
annotation|@
name|Override
DECL|method|totalTermFreq
specifier|public
name|long
name|totalTermFreq
parameter_list|()
block|{
return|return
name|info
operator|.
name|sliceArray
operator|.
name|freq
index|[
name|info
operator|.
name|sortedTerms
index|[
name|termUpto
index|]
index|]
return|;
block|}
annotation|@
name|Override
DECL|method|postings
specifier|public
name|PostingsEnum
name|postings
parameter_list|(
name|PostingsEnum
name|reuse
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
if|if
condition|(
name|reuse
operator|==
literal|null
operator|||
operator|!
operator|(
name|reuse
operator|instanceof
name|MemoryPostingsEnum
operator|)
condition|)
block|{
name|reuse
operator|=
operator|new
name|MemoryPostingsEnum
argument_list|()
expr_stmt|;
block|}
specifier|final
name|int
name|ord
init|=
name|info
operator|.
name|sortedTerms
index|[
name|termUpto
index|]
decl_stmt|;
return|return
operator|(
operator|(
name|MemoryPostingsEnum
operator|)
name|reuse
operator|)
operator|.
name|reset
argument_list|(
name|info
operator|.
name|sliceArray
operator|.
name|start
index|[
name|ord
index|]
argument_list|,
name|info
operator|.
name|sliceArray
operator|.
name|end
index|[
name|ord
index|]
argument_list|,
name|info
operator|.
name|sliceArray
operator|.
name|freq
index|[
name|ord
index|]
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|seekExact
specifier|public
name|void
name|seekExact
parameter_list|(
name|BytesRef
name|term
parameter_list|,
name|TermState
name|state
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|state
operator|!=
literal|null
assert|;
name|this
operator|.
name|seekExact
argument_list|(
operator|(
operator|(
name|OrdTermState
operator|)
name|state
operator|)
operator|.
name|ord
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|termState
specifier|public
name|TermState
name|termState
parameter_list|()
throws|throws
name|IOException
block|{
name|OrdTermState
name|ts
init|=
operator|new
name|OrdTermState
argument_list|()
decl_stmt|;
name|ts
operator|.
name|ord
operator|=
name|termUpto
expr_stmt|;
return|return
name|ts
return|;
block|}
block|}
DECL|class|MemoryPostingsEnum
specifier|private
class|class
name|MemoryPostingsEnum
extends|extends
name|PostingsEnum
block|{
DECL|field|sliceReader
specifier|private
specifier|final
name|SliceReader
name|sliceReader
decl_stmt|;
DECL|field|posUpto
specifier|private
name|int
name|posUpto
decl_stmt|;
comment|// for assert
DECL|field|hasNext
specifier|private
name|boolean
name|hasNext
decl_stmt|;
DECL|field|doc
specifier|private
name|int
name|doc
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|freq
specifier|private
name|int
name|freq
decl_stmt|;
DECL|field|pos
specifier|private
name|int
name|pos
decl_stmt|;
DECL|field|startOffset
specifier|private
name|int
name|startOffset
decl_stmt|;
DECL|field|endOffset
specifier|private
name|int
name|endOffset
decl_stmt|;
DECL|field|payloadIndex
specifier|private
name|int
name|payloadIndex
decl_stmt|;
DECL|field|payloadBuilder
specifier|private
specifier|final
name|BytesRefBuilder
name|payloadBuilder
decl_stmt|;
comment|//only non-null when storePayloads
DECL|method|MemoryPostingsEnum
specifier|public
name|MemoryPostingsEnum
parameter_list|()
block|{
name|this
operator|.
name|sliceReader
operator|=
operator|new
name|SliceReader
argument_list|(
name|intBlockPool
argument_list|)
expr_stmt|;
name|this
operator|.
name|payloadBuilder
operator|=
name|storePayloads
condition|?
operator|new
name|BytesRefBuilder
argument_list|()
else|:
literal|null
expr_stmt|;
block|}
DECL|method|reset
specifier|public
name|PostingsEnum
name|reset
parameter_list|(
name|int
name|start
parameter_list|,
name|int
name|end
parameter_list|,
name|int
name|freq
parameter_list|)
block|{
name|this
operator|.
name|sliceReader
operator|.
name|reset
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
expr_stmt|;
name|posUpto
operator|=
literal|0
expr_stmt|;
comment|// for assert
name|hasNext
operator|=
literal|true
expr_stmt|;
name|doc
operator|=
operator|-
literal|1
expr_stmt|;
name|this
operator|.
name|freq
operator|=
name|freq
expr_stmt|;
return|return
name|this
return|;
block|}
annotation|@
name|Override
DECL|method|docID
specifier|public
name|int
name|docID
parameter_list|()
block|{
return|return
name|doc
return|;
block|}
annotation|@
name|Override
DECL|method|nextDoc
specifier|public
name|int
name|nextDoc
parameter_list|()
block|{
name|pos
operator|=
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|hasNext
condition|)
block|{
name|hasNext
operator|=
literal|false
expr_stmt|;
return|return
name|doc
operator|=
literal|0
return|;
block|}
else|else
block|{
return|return
name|doc
operator|=
name|NO_MORE_DOCS
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|advance
specifier|public
name|int
name|advance
parameter_list|(
name|int
name|target
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|slowAdvance
argument_list|(
name|target
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|freq
specifier|public
name|int
name|freq
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|freq
return|;
block|}
annotation|@
name|Override
DECL|method|nextPosition
specifier|public
name|int
name|nextPosition
parameter_list|()
block|{
name|posUpto
operator|++
expr_stmt|;
assert|assert
name|posUpto
operator|<=
name|freq
assert|;
assert|assert
operator|!
name|sliceReader
operator|.
name|endOfSlice
argument_list|()
operator|:
literal|" stores offsets : "
operator|+
name|startOffset
assert|;
name|int
name|pos
init|=
name|sliceReader
operator|.
name|readInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeOffsets
condition|)
block|{
comment|//pos = sliceReader.readInt();
name|startOffset
operator|=
name|sliceReader
operator|.
name|readInt
argument_list|()
expr_stmt|;
name|endOffset
operator|=
name|sliceReader
operator|.
name|readInt
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|storePayloads
condition|)
block|{
name|payloadIndex
operator|=
name|sliceReader
operator|.
name|readInt
argument_list|()
expr_stmt|;
block|}
return|return
name|pos
return|;
block|}
annotation|@
name|Override
DECL|method|startOffset
specifier|public
name|int
name|startOffset
parameter_list|()
block|{
return|return
name|startOffset
return|;
block|}
annotation|@
name|Override
DECL|method|endOffset
specifier|public
name|int
name|endOffset
parameter_list|()
block|{
return|return
name|endOffset
return|;
block|}
annotation|@
name|Override
DECL|method|getPayload
specifier|public
name|BytesRef
name|getPayload
parameter_list|()
block|{
if|if
condition|(
name|payloadBuilder
operator|==
literal|null
operator|||
name|payloadIndex
operator|==
operator|-
literal|1
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|payloadsBytesRefs
operator|.
name|get
argument_list|(
name|payloadBuilder
argument_list|,
name|payloadIndex
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|cost
specifier|public
name|long
name|cost
parameter_list|()
block|{
return|return
literal|1
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|getTermVectors
specifier|public
name|Fields
name|getTermVectors
parameter_list|(
name|int
name|docID
parameter_list|)
block|{
if|if
condition|(
name|docID
operator|==
literal|0
condition|)
block|{
return|return
name|fields
argument_list|()
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|numDocs
specifier|public
name|int
name|numDocs
parameter_list|()
block|{
if|if
condition|(
name|DEBUG
condition|)
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"MemoryIndexReader.numDocs"
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
annotation|@
name|Override
DECL|method|maxDoc
specifier|public
name|int
name|maxDoc
parameter_list|()
block|{
if|if
condition|(
name|DEBUG
condition|)
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"MemoryIndexReader.maxDoc"
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
annotation|@
name|Override
DECL|method|document
specifier|public
name|void
name|document
parameter_list|(
name|int
name|docID
parameter_list|,
name|StoredFieldVisitor
name|visitor
parameter_list|)
block|{
if|if
condition|(
name|DEBUG
condition|)
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"MemoryIndexReader.document"
argument_list|)
expr_stmt|;
comment|// no-op: there are no stored fields
block|}
annotation|@
name|Override
DECL|method|doClose
specifier|protected
name|void
name|doClose
parameter_list|()
block|{
if|if
condition|(
name|DEBUG
condition|)
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"MemoryIndexReader.doClose"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getNormValues
specifier|public
name|NumericDocValues
name|getNormValues
parameter_list|(
name|String
name|field
parameter_list|)
block|{
name|Info
name|info
init|=
name|fields
operator|.
name|get
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|info
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|info
operator|.
name|getNormDocValues
argument_list|()
return|;
block|}
block|}
comment|/**    * Resets the {@link MemoryIndex} to its initial state and recycles all internal buffers.    */
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
block|{
name|fields
operator|.
name|clear
argument_list|()
expr_stmt|;
name|this
operator|.
name|normSimilarity
operator|=
name|IndexSearcher
operator|.
name|getDefaultSimilarity
argument_list|()
expr_stmt|;
name|byteBlockPool
operator|.
name|reset
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// no need to 0-fill the buffers
name|intBlockPool
operator|.
name|reset
argument_list|(
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// here must must 0-fill since we use slices
if|if
condition|(
name|payloadsBytesRefs
operator|!=
literal|null
condition|)
block|{
name|payloadsBytesRefs
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|frozen
operator|=
literal|false
expr_stmt|;
block|}
DECL|class|SliceByteStartArray
specifier|private
specifier|static
specifier|final
class|class
name|SliceByteStartArray
extends|extends
name|DirectBytesStartArray
block|{
DECL|field|start
name|int
index|[]
name|start
decl_stmt|;
comment|// the start offset in the IntBlockPool per term
DECL|field|end
name|int
index|[]
name|end
decl_stmt|;
comment|// the end pointer in the IntBlockPool for the postings slice per term
DECL|field|freq
name|int
index|[]
name|freq
decl_stmt|;
comment|// the term frequency
DECL|method|SliceByteStartArray
specifier|public
name|SliceByteStartArray
parameter_list|(
name|int
name|initSize
parameter_list|)
block|{
name|super
argument_list|(
name|initSize
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|init
specifier|public
name|int
index|[]
name|init
parameter_list|()
block|{
specifier|final
name|int
index|[]
name|ord
init|=
name|super
operator|.
name|init
argument_list|()
decl_stmt|;
name|start
operator|=
operator|new
name|int
index|[
name|ArrayUtil
operator|.
name|oversize
argument_list|(
name|ord
operator|.
name|length
argument_list|,
name|RamUsageEstimator
operator|.
name|NUM_BYTES_INT
argument_list|)
index|]
expr_stmt|;
name|end
operator|=
operator|new
name|int
index|[
name|ArrayUtil
operator|.
name|oversize
argument_list|(
name|ord
operator|.
name|length
argument_list|,
name|RamUsageEstimator
operator|.
name|NUM_BYTES_INT
argument_list|)
index|]
expr_stmt|;
name|freq
operator|=
operator|new
name|int
index|[
name|ArrayUtil
operator|.
name|oversize
argument_list|(
name|ord
operator|.
name|length
argument_list|,
name|RamUsageEstimator
operator|.
name|NUM_BYTES_INT
argument_list|)
index|]
expr_stmt|;
assert|assert
name|start
operator|.
name|length
operator|>=
name|ord
operator|.
name|length
assert|;
assert|assert
name|end
operator|.
name|length
operator|>=
name|ord
operator|.
name|length
assert|;
assert|assert
name|freq
operator|.
name|length
operator|>=
name|ord
operator|.
name|length
assert|;
return|return
name|ord
return|;
block|}
annotation|@
name|Override
DECL|method|grow
specifier|public
name|int
index|[]
name|grow
parameter_list|()
block|{
specifier|final
name|int
index|[]
name|ord
init|=
name|super
operator|.
name|grow
argument_list|()
decl_stmt|;
if|if
condition|(
name|start
operator|.
name|length
operator|<
name|ord
operator|.
name|length
condition|)
block|{
name|start
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|start
argument_list|,
name|ord
operator|.
name|length
argument_list|)
expr_stmt|;
name|end
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|end
argument_list|,
name|ord
operator|.
name|length
argument_list|)
expr_stmt|;
name|freq
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|freq
argument_list|,
name|ord
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
assert|assert
name|start
operator|.
name|length
operator|>=
name|ord
operator|.
name|length
assert|;
assert|assert
name|end
operator|.
name|length
operator|>=
name|ord
operator|.
name|length
assert|;
assert|assert
name|freq
operator|.
name|length
operator|>=
name|ord
operator|.
name|length
assert|;
return|return
name|ord
return|;
block|}
annotation|@
name|Override
DECL|method|clear
specifier|public
name|int
index|[]
name|clear
parameter_list|()
block|{
name|start
operator|=
name|end
operator|=
literal|null
expr_stmt|;
return|return
name|super
operator|.
name|clear
argument_list|()
return|;
block|}
block|}
block|}
end_class
end_unit
