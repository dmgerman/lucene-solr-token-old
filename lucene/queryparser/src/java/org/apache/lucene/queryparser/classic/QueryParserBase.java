begin_unit
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.lucene.queryparser.classic
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|queryparser
operator|.
name|classic
package|;
end_package
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|text
operator|.
name|DateFormat
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|CachingTokenFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TermToBytesRefAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|DateTools
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Term
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|queryparser
operator|.
name|classic
operator|.
name|QueryParser
operator|.
name|Operator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|*
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Version
import|;
end_import
begin_comment
comment|/** This class is overridden by QueryParser in QueryParser.jj  * and acts to separate the majority of the Java code from the .jj grammar file.   */
end_comment
begin_class
DECL|class|QueryParserBase
specifier|public
specifier|abstract
class|class
name|QueryParserBase
block|{
comment|/** Do not catch this exception in your code, it means you are using methods that you should no longer use. */
DECL|class|MethodRemovedUseAnother
specifier|public
specifier|static
class|class
name|MethodRemovedUseAnother
extends|extends
name|Throwable
block|{}
DECL|field|CONJ_NONE
specifier|static
specifier|final
name|int
name|CONJ_NONE
init|=
literal|0
decl_stmt|;
DECL|field|CONJ_AND
specifier|static
specifier|final
name|int
name|CONJ_AND
init|=
literal|1
decl_stmt|;
DECL|field|CONJ_OR
specifier|static
specifier|final
name|int
name|CONJ_OR
init|=
literal|2
decl_stmt|;
DECL|field|MOD_NONE
specifier|static
specifier|final
name|int
name|MOD_NONE
init|=
literal|0
decl_stmt|;
DECL|field|MOD_NOT
specifier|static
specifier|final
name|int
name|MOD_NOT
init|=
literal|10
decl_stmt|;
DECL|field|MOD_REQ
specifier|static
specifier|final
name|int
name|MOD_REQ
init|=
literal|11
decl_stmt|;
comment|// make it possible to call setDefaultOperator() without accessing
comment|// the nested class:
comment|/** Alternative form of QueryParser.Operator.AND */
DECL|field|AND_OPERATOR
specifier|public
specifier|static
specifier|final
name|Operator
name|AND_OPERATOR
init|=
name|Operator
operator|.
name|AND
decl_stmt|;
comment|/** Alternative form of QueryParser.Operator.OR */
DECL|field|OR_OPERATOR
specifier|public
specifier|static
specifier|final
name|Operator
name|OR_OPERATOR
init|=
name|Operator
operator|.
name|OR
decl_stmt|;
comment|/** The actual operator that parser uses to combine query terms */
DECL|field|operator
name|Operator
name|operator
init|=
name|OR_OPERATOR
decl_stmt|;
DECL|field|lowercaseExpandedTerms
name|boolean
name|lowercaseExpandedTerms
init|=
literal|true
decl_stmt|;
DECL|field|multiTermRewriteMethod
name|MultiTermQuery
operator|.
name|RewriteMethod
name|multiTermRewriteMethod
init|=
name|MultiTermQuery
operator|.
name|CONSTANT_SCORE_AUTO_REWRITE_DEFAULT
decl_stmt|;
DECL|field|allowLeadingWildcard
name|boolean
name|allowLeadingWildcard
init|=
literal|false
decl_stmt|;
DECL|field|enablePositionIncrements
name|boolean
name|enablePositionIncrements
init|=
literal|true
decl_stmt|;
DECL|field|analyzer
name|Analyzer
name|analyzer
decl_stmt|;
DECL|field|field
name|String
name|field
decl_stmt|;
DECL|field|phraseSlop
name|int
name|phraseSlop
init|=
literal|0
decl_stmt|;
DECL|field|fuzzyMinSim
name|float
name|fuzzyMinSim
init|=
name|FuzzyQuery
operator|.
name|defaultMinSimilarity
decl_stmt|;
DECL|field|fuzzyPrefixLength
name|int
name|fuzzyPrefixLength
init|=
name|FuzzyQuery
operator|.
name|defaultPrefixLength
decl_stmt|;
DECL|field|locale
name|Locale
name|locale
init|=
name|Locale
operator|.
name|getDefault
argument_list|()
decl_stmt|;
comment|// the default date resolution
DECL|field|dateResolution
name|DateTools
operator|.
name|Resolution
name|dateResolution
init|=
literal|null
decl_stmt|;
comment|// maps field names to date resolutions
DECL|field|fieldToDateResolution
name|Map
argument_list|<
name|String
argument_list|,
name|DateTools
operator|.
name|Resolution
argument_list|>
name|fieldToDateResolution
init|=
literal|null
decl_stmt|;
comment|//Whether or not to analyze range terms when constructing RangeQuerys
comment|// (For example, analyzing terms into collation keys for locale-sensitive RangeQuery)
DECL|field|analyzeRangeTerms
name|boolean
name|analyzeRangeTerms
init|=
literal|false
decl_stmt|;
DECL|field|autoGeneratePhraseQueries
name|boolean
name|autoGeneratePhraseQueries
decl_stmt|;
comment|// So the generated QueryParser(CharStream) won't error out
DECL|method|QueryParserBase
specifier|protected
name|QueryParserBase
parameter_list|()
block|{   }
comment|/** Initializes a query parser.  Called by the QueryParser constructor    *  @param matchVersion  Lucene version to match.    *  @param f  the default field for query terms.    *  @param a   used to find terms in the query text.    */
DECL|method|init
specifier|public
name|void
name|init
parameter_list|(
name|Version
name|matchVersion
parameter_list|,
name|String
name|f
parameter_list|,
name|Analyzer
name|a
parameter_list|)
block|{
name|analyzer
operator|=
name|a
expr_stmt|;
name|field
operator|=
name|f
expr_stmt|;
name|setAutoGeneratePhraseQueries
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// the generated parser will create these in QueryParser
DECL|method|ReInit
specifier|public
specifier|abstract
name|void
name|ReInit
parameter_list|(
name|CharStream
name|stream
parameter_list|)
function_decl|;
DECL|method|TopLevelQuery
specifier|public
specifier|abstract
name|Query
name|TopLevelQuery
parameter_list|(
name|String
name|field
parameter_list|)
throws|throws
name|ParseException
function_decl|;
comment|/** Parses a query string, returning a {@link org.apache.lucene.search.Query}.    *  @param query  the query string to be parsed.    *  @throws ParseException if the parsing fails    */
DECL|method|parse
specifier|public
name|Query
name|parse
parameter_list|(
name|String
name|query
parameter_list|)
throws|throws
name|ParseException
block|{
name|ReInit
argument_list|(
operator|new
name|FastCharStream
argument_list|(
operator|new
name|StringReader
argument_list|(
name|query
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
comment|// TopLevelQuery is a Query followed by the end-of-input (EOF)
name|Query
name|res
init|=
name|TopLevelQuery
argument_list|(
name|field
argument_list|)
decl_stmt|;
return|return
name|res
operator|!=
literal|null
condition|?
name|res
else|:
name|newBooleanQuery
argument_list|(
literal|false
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|ParseException
name|tme
parameter_list|)
block|{
comment|// rethrow to include the original query:
name|ParseException
name|e
init|=
operator|new
name|ParseException
argument_list|(
literal|"Cannot parse '"
operator|+
name|query
operator|+
literal|"': "
operator|+
name|tme
operator|.
name|getMessage
argument_list|()
argument_list|)
decl_stmt|;
name|e
operator|.
name|initCause
argument_list|(
name|tme
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|TokenMgrError
name|tme
parameter_list|)
block|{
name|ParseException
name|e
init|=
operator|new
name|ParseException
argument_list|(
literal|"Cannot parse '"
operator|+
name|query
operator|+
literal|"': "
operator|+
name|tme
operator|.
name|getMessage
argument_list|()
argument_list|)
decl_stmt|;
name|e
operator|.
name|initCause
argument_list|(
name|tme
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|BooleanQuery
operator|.
name|TooManyClauses
name|tmc
parameter_list|)
block|{
name|ParseException
name|e
init|=
operator|new
name|ParseException
argument_list|(
literal|"Cannot parse '"
operator|+
name|query
operator|+
literal|"': too many boolean clauses"
argument_list|)
decl_stmt|;
name|e
operator|.
name|initCause
argument_list|(
name|tmc
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * @return Returns the analyzer.    */
DECL|method|getAnalyzer
specifier|public
name|Analyzer
name|getAnalyzer
parameter_list|()
block|{
return|return
name|analyzer
return|;
block|}
comment|/**    * @return Returns the default field.    */
DECL|method|getField
specifier|public
name|String
name|getField
parameter_list|()
block|{
return|return
name|field
return|;
block|}
comment|/**    * @see #setAutoGeneratePhraseQueries(boolean)    */
DECL|method|getAutoGeneratePhraseQueries
specifier|public
specifier|final
name|boolean
name|getAutoGeneratePhraseQueries
parameter_list|()
block|{
return|return
name|autoGeneratePhraseQueries
return|;
block|}
comment|/**    * Set to true if phrase queries will be automatically generated    * when the analyzer returns more than one term from whitespace    * delimited text.    * NOTE: this behavior may not be suitable for all languages.    *<p>    * Set to false if phrase queries should only be generated when    * surrounded by double quotes.    */
DECL|method|setAutoGeneratePhraseQueries
specifier|public
specifier|final
name|void
name|setAutoGeneratePhraseQueries
parameter_list|(
name|boolean
name|value
parameter_list|)
block|{
name|this
operator|.
name|autoGeneratePhraseQueries
operator|=
name|value
expr_stmt|;
block|}
comment|/**    * Get the minimal similarity for fuzzy queries.    */
DECL|method|getFuzzyMinSim
specifier|public
name|float
name|getFuzzyMinSim
parameter_list|()
block|{
return|return
name|fuzzyMinSim
return|;
block|}
comment|/**    * Set the minimum similarity for fuzzy queries.    * Default is 2f.    */
DECL|method|setFuzzyMinSim
specifier|public
name|void
name|setFuzzyMinSim
parameter_list|(
name|float
name|fuzzyMinSim
parameter_list|)
block|{
name|this
operator|.
name|fuzzyMinSim
operator|=
name|fuzzyMinSim
expr_stmt|;
block|}
comment|/**    * Get the prefix length for fuzzy queries.    * @return Returns the fuzzyPrefixLength.    */
DECL|method|getFuzzyPrefixLength
specifier|public
name|int
name|getFuzzyPrefixLength
parameter_list|()
block|{
return|return
name|fuzzyPrefixLength
return|;
block|}
comment|/**    * Set the prefix length for fuzzy queries. Default is 0.    * @param fuzzyPrefixLength The fuzzyPrefixLength to set.    */
DECL|method|setFuzzyPrefixLength
specifier|public
name|void
name|setFuzzyPrefixLength
parameter_list|(
name|int
name|fuzzyPrefixLength
parameter_list|)
block|{
name|this
operator|.
name|fuzzyPrefixLength
operator|=
name|fuzzyPrefixLength
expr_stmt|;
block|}
comment|/**    * Sets the default slop for phrases.  If zero, then exact phrase matches    * are required.  Default value is zero.    */
DECL|method|setPhraseSlop
specifier|public
name|void
name|setPhraseSlop
parameter_list|(
name|int
name|phraseSlop
parameter_list|)
block|{
name|this
operator|.
name|phraseSlop
operator|=
name|phraseSlop
expr_stmt|;
block|}
comment|/**    * Gets the default slop for phrases.    */
DECL|method|getPhraseSlop
specifier|public
name|int
name|getPhraseSlop
parameter_list|()
block|{
return|return
name|phraseSlop
return|;
block|}
comment|/**    * Set to<code>true</code> to allow leading wildcard characters.    *<p>    * When set,<code>*</code> or<code>?</code> are allowed as    * the first character of a PrefixQuery and WildcardQuery.    * Note that this can produce very slow    * queries on big indexes.    *<p>    * Default: false.    */
DECL|method|setAllowLeadingWildcard
specifier|public
name|void
name|setAllowLeadingWildcard
parameter_list|(
name|boolean
name|allowLeadingWildcard
parameter_list|)
block|{
name|this
operator|.
name|allowLeadingWildcard
operator|=
name|allowLeadingWildcard
expr_stmt|;
block|}
comment|/**    * @see #setAllowLeadingWildcard(boolean)    */
DECL|method|getAllowLeadingWildcard
specifier|public
name|boolean
name|getAllowLeadingWildcard
parameter_list|()
block|{
return|return
name|allowLeadingWildcard
return|;
block|}
comment|/**    * Set to<code>true</code> to enable position increments in result query.    *<p>    * When set, result phrase and multi-phrase queries will    * be aware of position increments.    * Useful when e.g. a StopFilter increases the position increment of    * the token that follows an omitted token.    *<p>    * Default: true.    */
DECL|method|setEnablePositionIncrements
specifier|public
name|void
name|setEnablePositionIncrements
parameter_list|(
name|boolean
name|enable
parameter_list|)
block|{
name|this
operator|.
name|enablePositionIncrements
operator|=
name|enable
expr_stmt|;
block|}
comment|/**    * @see #setEnablePositionIncrements(boolean)    */
DECL|method|getEnablePositionIncrements
specifier|public
name|boolean
name|getEnablePositionIncrements
parameter_list|()
block|{
return|return
name|enablePositionIncrements
return|;
block|}
comment|/**    * Sets the boolean operator of the QueryParser.    * In default mode (<code>OR_OPERATOR</code>) terms without any modifiers    * are considered optional: for example<code>capital of Hungary</code> is equal to    *<code>capital OR of OR Hungary</code>.<br/>    * In<code>AND_OPERATOR</code> mode terms are considered to be in conjunction: the    * above mentioned query is parsed as<code>capital AND of AND Hungary</code>    */
DECL|method|setDefaultOperator
specifier|public
name|void
name|setDefaultOperator
parameter_list|(
name|Operator
name|op
parameter_list|)
block|{
name|this
operator|.
name|operator
operator|=
name|op
expr_stmt|;
block|}
comment|/**    * Gets implicit operator setting, which will be either AND_OPERATOR    * or OR_OPERATOR.    */
DECL|method|getDefaultOperator
specifier|public
name|Operator
name|getDefaultOperator
parameter_list|()
block|{
return|return
name|operator
return|;
block|}
comment|/**    * Whether terms of wildcard, prefix, fuzzy and range queries are to be automatically    * lower-cased or not.  Default is<code>true</code>.    */
DECL|method|setLowercaseExpandedTerms
specifier|public
name|void
name|setLowercaseExpandedTerms
parameter_list|(
name|boolean
name|lowercaseExpandedTerms
parameter_list|)
block|{
name|this
operator|.
name|lowercaseExpandedTerms
operator|=
name|lowercaseExpandedTerms
expr_stmt|;
block|}
comment|/**    * @see #setLowercaseExpandedTerms(boolean)    */
DECL|method|getLowercaseExpandedTerms
specifier|public
name|boolean
name|getLowercaseExpandedTerms
parameter_list|()
block|{
return|return
name|lowercaseExpandedTerms
return|;
block|}
comment|/**    * By default QueryParser uses {@link org.apache.lucene.search.MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}    * when creating a PrefixQuery, WildcardQuery or RangeQuery. This implementation is generally preferable because it    * a) Runs faster b) Does not have the scarcity of terms unduly influence score    * c) avoids any "TooManyBooleanClauses" exception.    * However, if your application really needs to use the    * old-fashioned BooleanQuery expansion rewriting and the above    * points are not relevant then use this to change    * the rewrite method.    */
DECL|method|setMultiTermRewriteMethod
specifier|public
name|void
name|setMultiTermRewriteMethod
parameter_list|(
name|MultiTermQuery
operator|.
name|RewriteMethod
name|method
parameter_list|)
block|{
name|multiTermRewriteMethod
operator|=
name|method
expr_stmt|;
block|}
comment|/**    * @see #setMultiTermRewriteMethod    */
DECL|method|getMultiTermRewriteMethod
specifier|public
name|MultiTermQuery
operator|.
name|RewriteMethod
name|getMultiTermRewriteMethod
parameter_list|()
block|{
return|return
name|multiTermRewriteMethod
return|;
block|}
comment|/**    * Set locale used by date range parsing.    */
DECL|method|setLocale
specifier|public
name|void
name|setLocale
parameter_list|(
name|Locale
name|locale
parameter_list|)
block|{
name|this
operator|.
name|locale
operator|=
name|locale
expr_stmt|;
block|}
comment|/**    * Returns current locale, allowing access by subclasses.    */
DECL|method|getLocale
specifier|public
name|Locale
name|getLocale
parameter_list|()
block|{
return|return
name|locale
return|;
block|}
comment|/**    * Sets the default date resolution used by RangeQueries for fields for which no    * specific date resolutions has been set. Field specific resolutions can be set    * with {@link #setDateResolution(String, org.apache.lucene.document.DateTools.Resolution)}.    *    * @param dateResolution the default date resolution to set    */
DECL|method|setDateResolution
specifier|public
name|void
name|setDateResolution
parameter_list|(
name|DateTools
operator|.
name|Resolution
name|dateResolution
parameter_list|)
block|{
name|this
operator|.
name|dateResolution
operator|=
name|dateResolution
expr_stmt|;
block|}
comment|/**    * Sets the date resolution used by RangeQueries for a specific field.    *    * @param fieldName field for which the date resolution is to be set    * @param dateResolution date resolution to set    */
DECL|method|setDateResolution
specifier|public
name|void
name|setDateResolution
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|DateTools
operator|.
name|Resolution
name|dateResolution
parameter_list|)
block|{
if|if
condition|(
name|fieldName
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Field cannot be null."
argument_list|)
throw|;
block|}
if|if
condition|(
name|fieldToDateResolution
operator|==
literal|null
condition|)
block|{
comment|// lazily initialize HashMap
name|fieldToDateResolution
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|DateTools
operator|.
name|Resolution
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|fieldToDateResolution
operator|.
name|put
argument_list|(
name|fieldName
argument_list|,
name|dateResolution
argument_list|)
expr_stmt|;
block|}
comment|/**    * Returns the date resolution that is used by RangeQueries for the given field.    * Returns null, if no default or field specific date resolution has been set    * for the given field.    *    */
DECL|method|getDateResolution
specifier|public
name|DateTools
operator|.
name|Resolution
name|getDateResolution
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
if|if
condition|(
name|fieldName
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Field cannot be null."
argument_list|)
throw|;
block|}
if|if
condition|(
name|fieldToDateResolution
operator|==
literal|null
condition|)
block|{
comment|// no field specific date resolutions set; return default date resolution instead
return|return
name|this
operator|.
name|dateResolution
return|;
block|}
name|DateTools
operator|.
name|Resolution
name|resolution
init|=
name|fieldToDateResolution
operator|.
name|get
argument_list|(
name|fieldName
argument_list|)
decl_stmt|;
if|if
condition|(
name|resolution
operator|==
literal|null
condition|)
block|{
comment|// no date resolutions set for the given field; return default date resolution instead
name|resolution
operator|=
name|this
operator|.
name|dateResolution
expr_stmt|;
block|}
return|return
name|resolution
return|;
block|}
comment|/**    * Set whether or not to analyze range terms when constructing RangeQuerys.    * For example, setting this to true can enable analyzing terms into     * collation keys for locale-sensitive RangeQuery.    *     * @param analyzeRangeTerms whether or not terms should be analyzed for RangeQuerys    */
DECL|method|setAnalyzeRangeTerms
specifier|public
name|void
name|setAnalyzeRangeTerms
parameter_list|(
name|boolean
name|analyzeRangeTerms
parameter_list|)
block|{
name|this
operator|.
name|analyzeRangeTerms
operator|=
name|analyzeRangeTerms
expr_stmt|;
block|}
comment|/**    * @return whether or not to analyze range terms when constructing RangeQuerys.    */
DECL|method|getAnalyzeRangeTerms
specifier|public
name|boolean
name|getAnalyzeRangeTerms
parameter_list|()
block|{
return|return
name|analyzeRangeTerms
return|;
block|}
DECL|method|addClause
specifier|protected
name|void
name|addClause
parameter_list|(
name|List
argument_list|<
name|BooleanClause
argument_list|>
name|clauses
parameter_list|,
name|int
name|conj
parameter_list|,
name|int
name|mods
parameter_list|,
name|Query
name|q
parameter_list|)
block|{
name|boolean
name|required
decl_stmt|,
name|prohibited
decl_stmt|;
comment|// If this term is introduced by AND, make the preceding term required,
comment|// unless it's already prohibited
if|if
condition|(
name|clauses
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|conj
operator|==
name|CONJ_AND
condition|)
block|{
name|BooleanClause
name|c
init|=
name|clauses
operator|.
name|get
argument_list|(
name|clauses
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|c
operator|.
name|isProhibited
argument_list|()
condition|)
name|c
operator|.
name|setOccur
argument_list|(
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|clauses
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|operator
operator|==
name|AND_OPERATOR
operator|&&
name|conj
operator|==
name|CONJ_OR
condition|)
block|{
comment|// If this term is introduced by OR, make the preceding term optional,
comment|// unless it's prohibited (that means we leave -a OR b but +a OR b-->a OR b)
comment|// notice if the input is a OR b, first term is parsed as required; without
comment|// this modification a OR b would parsed as +a OR b
name|BooleanClause
name|c
init|=
name|clauses
operator|.
name|get
argument_list|(
name|clauses
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|c
operator|.
name|isProhibited
argument_list|()
condition|)
name|c
operator|.
name|setOccur
argument_list|(
name|BooleanClause
operator|.
name|Occur
operator|.
name|SHOULD
argument_list|)
expr_stmt|;
block|}
comment|// We might have been passed a null query; the term might have been
comment|// filtered away by the analyzer.
if|if
condition|(
name|q
operator|==
literal|null
condition|)
return|return;
if|if
condition|(
name|operator
operator|==
name|OR_OPERATOR
condition|)
block|{
comment|// We set REQUIRED if we're introduced by AND or +; PROHIBITED if
comment|// introduced by NOT or -; make sure not to set both.
name|prohibited
operator|=
operator|(
name|mods
operator|==
name|MOD_NOT
operator|)
expr_stmt|;
name|required
operator|=
operator|(
name|mods
operator|==
name|MOD_REQ
operator|)
expr_stmt|;
if|if
condition|(
name|conj
operator|==
name|CONJ_AND
operator|&&
operator|!
name|prohibited
condition|)
block|{
name|required
operator|=
literal|true
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// We set PROHIBITED if we're introduced by NOT or -; We set REQUIRED
comment|// if not PROHIBITED and not introduced by OR
name|prohibited
operator|=
operator|(
name|mods
operator|==
name|MOD_NOT
operator|)
expr_stmt|;
name|required
operator|=
operator|(
operator|!
name|prohibited
operator|&&
name|conj
operator|!=
name|CONJ_OR
operator|)
expr_stmt|;
block|}
if|if
condition|(
name|required
operator|&&
operator|!
name|prohibited
condition|)
name|clauses
operator|.
name|add
argument_list|(
name|newBooleanClause
argument_list|(
name|q
argument_list|,
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST
argument_list|)
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|required
operator|&&
operator|!
name|prohibited
condition|)
name|clauses
operator|.
name|add
argument_list|(
name|newBooleanClause
argument_list|(
name|q
argument_list|,
name|BooleanClause
operator|.
name|Occur
operator|.
name|SHOULD
argument_list|)
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|required
operator|&&
name|prohibited
condition|)
name|clauses
operator|.
name|add
argument_list|(
name|newBooleanClause
argument_list|(
name|q
argument_list|,
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST_NOT
argument_list|)
argument_list|)
expr_stmt|;
else|else
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Clause cannot be both required and prohibited"
argument_list|)
throw|;
block|}
comment|/**    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getFieldQuery
specifier|protected
name|Query
name|getFieldQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|queryText
parameter_list|,
name|boolean
name|quoted
parameter_list|)
throws|throws
name|ParseException
block|{
return|return
name|newFieldQuery
argument_list|(
name|analyzer
argument_list|,
name|field
argument_list|,
name|queryText
argument_list|,
name|quoted
argument_list|)
return|;
block|}
comment|/**    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|newFieldQuery
specifier|protected
name|Query
name|newFieldQuery
parameter_list|(
name|Analyzer
name|analyzer
parameter_list|,
name|String
name|field
parameter_list|,
name|String
name|queryText
parameter_list|,
name|boolean
name|quoted
parameter_list|)
throws|throws
name|ParseException
block|{
comment|// Use the analyzer to get all the tokens, and then build a TermQuery,
comment|// PhraseQuery, or nothing based on the term count
name|TokenStream
name|source
decl_stmt|;
try|try
block|{
name|source
operator|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|field
argument_list|,
operator|new
name|StringReader
argument_list|(
name|queryText
argument_list|)
argument_list|)
expr_stmt|;
name|source
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Unable to initialize TokenStream to analyze query text"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|CachingTokenFilter
name|buffer
init|=
operator|new
name|CachingTokenFilter
argument_list|(
name|source
argument_list|)
decl_stmt|;
name|TermToBytesRefAttribute
name|termAtt
init|=
literal|null
decl_stmt|;
name|PositionIncrementAttribute
name|posIncrAtt
init|=
literal|null
decl_stmt|;
name|int
name|numTokens
init|=
literal|0
decl_stmt|;
try|try
block|{
name|buffer
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Unable to initialize TokenStream to analyze query text"
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|buffer
operator|.
name|hasAttribute
argument_list|(
name|TermToBytesRefAttribute
operator|.
name|class
argument_list|)
condition|)
block|{
name|termAtt
operator|=
name|buffer
operator|.
name|getAttribute
argument_list|(
name|TermToBytesRefAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|buffer
operator|.
name|hasAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
condition|)
block|{
name|posIncrAtt
operator|=
name|buffer
operator|.
name|getAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
name|int
name|positionCount
init|=
literal|0
decl_stmt|;
name|boolean
name|severalTokensAtSamePosition
init|=
literal|false
decl_stmt|;
name|boolean
name|hasMoreTokens
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|termAtt
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|hasMoreTokens
operator|=
name|buffer
operator|.
name|incrementToken
argument_list|()
expr_stmt|;
while|while
condition|(
name|hasMoreTokens
condition|)
block|{
name|numTokens
operator|++
expr_stmt|;
name|int
name|positionIncrement
init|=
operator|(
name|posIncrAtt
operator|!=
literal|null
operator|)
condition|?
name|posIncrAtt
operator|.
name|getPositionIncrement
argument_list|()
else|:
literal|1
decl_stmt|;
if|if
condition|(
name|positionIncrement
operator|!=
literal|0
condition|)
block|{
name|positionCount
operator|+=
name|positionIncrement
expr_stmt|;
block|}
else|else
block|{
name|severalTokensAtSamePosition
operator|=
literal|true
expr_stmt|;
block|}
name|hasMoreTokens
operator|=
name|buffer
operator|.
name|incrementToken
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
block|}
try|try
block|{
comment|// rewind the buffer stream
name|buffer
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// close original stream - all tokens buffered
name|source
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Cannot close TokenStream analyzing query text"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|BytesRef
name|bytes
init|=
name|termAtt
operator|==
literal|null
condition|?
literal|null
else|:
name|termAtt
operator|.
name|getBytesRef
argument_list|()
decl_stmt|;
if|if
condition|(
name|numTokens
operator|==
literal|0
condition|)
return|return
literal|null
return|;
elseif|else
if|if
condition|(
name|numTokens
operator|==
literal|1
condition|)
block|{
try|try
block|{
name|boolean
name|hasNext
init|=
name|buffer
operator|.
name|incrementToken
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
operator|==
literal|true
assert|;
name|termAtt
operator|.
name|fillBytesRef
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// safe to ignore, because we know the number of tokens
block|}
return|return
name|newTermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|bytes
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
if|if
condition|(
name|severalTokensAtSamePosition
operator|||
operator|(
operator|!
name|quoted
operator|&&
operator|!
name|autoGeneratePhraseQueries
operator|)
condition|)
block|{
if|if
condition|(
name|positionCount
operator|==
literal|1
operator|||
operator|(
operator|!
name|quoted
operator|&&
operator|!
name|autoGeneratePhraseQueries
operator|)
condition|)
block|{
comment|// no phrase query:
name|BooleanQuery
name|q
init|=
name|newBooleanQuery
argument_list|(
name|positionCount
operator|==
literal|1
argument_list|)
decl_stmt|;
name|BooleanClause
operator|.
name|Occur
name|occur
init|=
name|positionCount
operator|>
literal|1
operator|&&
name|operator
operator|==
name|AND_OPERATOR
condition|?
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST
else|:
name|BooleanClause
operator|.
name|Occur
operator|.
name|SHOULD
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numTokens
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|boolean
name|hasNext
init|=
name|buffer
operator|.
name|incrementToken
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
operator|==
literal|true
assert|;
name|termAtt
operator|.
name|fillBytesRef
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// safe to ignore, because we know the number of tokens
block|}
name|Query
name|currentQuery
init|=
name|newTermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|bytes
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|q
operator|.
name|add
argument_list|(
name|currentQuery
argument_list|,
name|occur
argument_list|)
expr_stmt|;
block|}
return|return
name|q
return|;
block|}
else|else
block|{
comment|// phrase query:
name|MultiPhraseQuery
name|mpq
init|=
name|newMultiPhraseQuery
argument_list|()
decl_stmt|;
name|mpq
operator|.
name|setSlop
argument_list|(
name|phraseSlop
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Term
argument_list|>
name|multiTerms
init|=
operator|new
name|ArrayList
argument_list|<
name|Term
argument_list|>
argument_list|()
decl_stmt|;
name|int
name|position
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numTokens
condition|;
name|i
operator|++
control|)
block|{
name|int
name|positionIncrement
init|=
literal|1
decl_stmt|;
try|try
block|{
name|boolean
name|hasNext
init|=
name|buffer
operator|.
name|incrementToken
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
operator|==
literal|true
assert|;
name|termAtt
operator|.
name|fillBytesRef
argument_list|()
expr_stmt|;
if|if
condition|(
name|posIncrAtt
operator|!=
literal|null
condition|)
block|{
name|positionIncrement
operator|=
name|posIncrAtt
operator|.
name|getPositionIncrement
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// safe to ignore, because we know the number of tokens
block|}
if|if
condition|(
name|positionIncrement
operator|>
literal|0
operator|&&
name|multiTerms
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|enablePositionIncrements
condition|)
block|{
name|mpq
operator|.
name|add
argument_list|(
name|multiTerms
operator|.
name|toArray
argument_list|(
operator|new
name|Term
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|position
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mpq
operator|.
name|add
argument_list|(
name|multiTerms
operator|.
name|toArray
argument_list|(
operator|new
name|Term
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|multiTerms
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|position
operator|+=
name|positionIncrement
expr_stmt|;
name|multiTerms
operator|.
name|add
argument_list|(
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|bytes
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|enablePositionIncrements
condition|)
block|{
name|mpq
operator|.
name|add
argument_list|(
name|multiTerms
operator|.
name|toArray
argument_list|(
operator|new
name|Term
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|position
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mpq
operator|.
name|add
argument_list|(
name|multiTerms
operator|.
name|toArray
argument_list|(
operator|new
name|Term
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|mpq
return|;
block|}
block|}
else|else
block|{
name|PhraseQuery
name|pq
init|=
name|newPhraseQuery
argument_list|()
decl_stmt|;
name|pq
operator|.
name|setSlop
argument_list|(
name|phraseSlop
argument_list|)
expr_stmt|;
name|int
name|position
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numTokens
condition|;
name|i
operator|++
control|)
block|{
name|int
name|positionIncrement
init|=
literal|1
decl_stmt|;
try|try
block|{
name|boolean
name|hasNext
init|=
name|buffer
operator|.
name|incrementToken
argument_list|()
decl_stmt|;
assert|assert
name|hasNext
operator|==
literal|true
assert|;
name|termAtt
operator|.
name|fillBytesRef
argument_list|()
expr_stmt|;
if|if
condition|(
name|posIncrAtt
operator|!=
literal|null
condition|)
block|{
name|positionIncrement
operator|=
name|posIncrAtt
operator|.
name|getPositionIncrement
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// safe to ignore, because we know the number of tokens
block|}
if|if
condition|(
name|enablePositionIncrements
condition|)
block|{
name|position
operator|+=
name|positionIncrement
expr_stmt|;
name|pq
operator|.
name|add
argument_list|(
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|bytes
argument_list|)
argument_list|)
argument_list|,
name|position
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pq
operator|.
name|add
argument_list|(
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|bytes
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|pq
return|;
block|}
block|}
block|}
comment|/**    * Base implementation delegates to {@link #getFieldQuery(String,String,boolean)}.    * This method may be overridden, for example, to return    * a SpanNearQuery instead of a PhraseQuery.    *    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getFieldQuery
specifier|protected
name|Query
name|getFieldQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|queryText
parameter_list|,
name|int
name|slop
parameter_list|)
throws|throws
name|ParseException
block|{
name|Query
name|query
init|=
name|getFieldQuery
argument_list|(
name|field
argument_list|,
name|queryText
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|query
operator|instanceof
name|PhraseQuery
condition|)
block|{
operator|(
operator|(
name|PhraseQuery
operator|)
name|query
operator|)
operator|.
name|setSlop
argument_list|(
name|slop
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|query
operator|instanceof
name|MultiPhraseQuery
condition|)
block|{
operator|(
operator|(
name|MultiPhraseQuery
operator|)
name|query
operator|)
operator|.
name|setSlop
argument_list|(
name|slop
argument_list|)
expr_stmt|;
block|}
return|return
name|query
return|;
block|}
comment|/**    *    * @exception org.apache.lucene.queryparser.classic.ParseException    */
DECL|method|getRangeQuery
specifier|protected
name|Query
name|getRangeQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|part1
parameter_list|,
name|String
name|part2
parameter_list|,
name|boolean
name|startInclusive
parameter_list|,
name|boolean
name|endInclusive
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
name|lowercaseExpandedTerms
condition|)
block|{
name|part1
operator|=
name|part1
operator|==
literal|null
condition|?
literal|null
else|:
name|part1
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
name|part2
operator|=
name|part2
operator|==
literal|null
condition|?
literal|null
else|:
name|part2
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
block|}
name|DateFormat
name|df
init|=
name|DateFormat
operator|.
name|getDateInstance
argument_list|(
name|DateFormat
operator|.
name|SHORT
argument_list|,
name|locale
argument_list|)
decl_stmt|;
name|df
operator|.
name|setLenient
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|DateTools
operator|.
name|Resolution
name|resolution
init|=
name|getDateResolution
argument_list|(
name|field
argument_list|)
decl_stmt|;
try|try
block|{
name|part1
operator|=
name|DateTools
operator|.
name|dateToString
argument_list|(
name|df
operator|.
name|parse
argument_list|(
name|part1
argument_list|)
argument_list|,
name|resolution
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{ }
try|try
block|{
name|Date
name|d2
init|=
name|df
operator|.
name|parse
argument_list|(
name|part2
argument_list|)
decl_stmt|;
if|if
condition|(
name|endInclusive
condition|)
block|{
comment|// The user can only specify the date, not the time, so make sure
comment|// the time is set to the latest possible time of that date to really
comment|// include all documents:
name|Calendar
name|cal
init|=
name|Calendar
operator|.
name|getInstance
argument_list|(
name|locale
argument_list|)
decl_stmt|;
name|cal
operator|.
name|setTime
argument_list|(
name|d2
argument_list|)
expr_stmt|;
name|cal
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|HOUR_OF_DAY
argument_list|,
literal|23
argument_list|)
expr_stmt|;
name|cal
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|MINUTE
argument_list|,
literal|59
argument_list|)
expr_stmt|;
name|cal
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|SECOND
argument_list|,
literal|59
argument_list|)
expr_stmt|;
name|cal
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|MILLISECOND
argument_list|,
literal|999
argument_list|)
expr_stmt|;
name|d2
operator|=
name|cal
operator|.
name|getTime
argument_list|()
expr_stmt|;
block|}
name|part2
operator|=
name|DateTools
operator|.
name|dateToString
argument_list|(
name|d2
argument_list|,
name|resolution
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{ }
return|return
name|newRangeQuery
argument_list|(
name|field
argument_list|,
name|part1
argument_list|,
name|part2
argument_list|,
name|startInclusive
argument_list|,
name|endInclusive
argument_list|)
return|;
block|}
comment|/**   * Builds a new BooleanQuery instance   * @param disableCoord disable coord   * @return new BooleanQuery instance   */
DECL|method|newBooleanQuery
specifier|protected
name|BooleanQuery
name|newBooleanQuery
parameter_list|(
name|boolean
name|disableCoord
parameter_list|)
block|{
return|return
operator|new
name|BooleanQuery
argument_list|(
name|disableCoord
argument_list|)
return|;
block|}
comment|/**   * Builds a new BooleanClause instance   * @param q sub query   * @param occur how this clause should occur when matching documents   * @return new BooleanClause instance   */
DECL|method|newBooleanClause
specifier|protected
name|BooleanClause
name|newBooleanClause
parameter_list|(
name|Query
name|q
parameter_list|,
name|BooleanClause
operator|.
name|Occur
name|occur
parameter_list|)
block|{
return|return
operator|new
name|BooleanClause
argument_list|(
name|q
argument_list|,
name|occur
argument_list|)
return|;
block|}
comment|/**    * Builds a new TermQuery instance    * @param term term    * @return new TermQuery instance    */
DECL|method|newTermQuery
specifier|protected
name|Query
name|newTermQuery
parameter_list|(
name|Term
name|term
parameter_list|)
block|{
return|return
operator|new
name|TermQuery
argument_list|(
name|term
argument_list|)
return|;
block|}
comment|/**    * Builds a new PhraseQuery instance    * @return new PhraseQuery instance    */
DECL|method|newPhraseQuery
specifier|protected
name|PhraseQuery
name|newPhraseQuery
parameter_list|()
block|{
return|return
operator|new
name|PhraseQuery
argument_list|()
return|;
block|}
comment|/**    * Builds a new MultiPhraseQuery instance    * @return new MultiPhraseQuery instance    */
DECL|method|newMultiPhraseQuery
specifier|protected
name|MultiPhraseQuery
name|newMultiPhraseQuery
parameter_list|()
block|{
return|return
operator|new
name|MultiPhraseQuery
argument_list|()
return|;
block|}
comment|/**    * Builds a new PrefixQuery instance    * @param prefix Prefix term    * @return new PrefixQuery instance    */
DECL|method|newPrefixQuery
specifier|protected
name|Query
name|newPrefixQuery
parameter_list|(
name|Term
name|prefix
parameter_list|)
block|{
name|PrefixQuery
name|query
init|=
operator|new
name|PrefixQuery
argument_list|(
name|prefix
argument_list|)
decl_stmt|;
name|query
operator|.
name|setRewriteMethod
argument_list|(
name|multiTermRewriteMethod
argument_list|)
expr_stmt|;
return|return
name|query
return|;
block|}
comment|/**    * Builds a new RegexpQuery instance    * @param regexp Regexp term    * @return new RegexpQuery instance    */
DECL|method|newRegexpQuery
specifier|protected
name|Query
name|newRegexpQuery
parameter_list|(
name|Term
name|regexp
parameter_list|)
block|{
name|RegexpQuery
name|query
init|=
operator|new
name|RegexpQuery
argument_list|(
name|regexp
argument_list|)
decl_stmt|;
name|query
operator|.
name|setRewriteMethod
argument_list|(
name|multiTermRewriteMethod
argument_list|)
expr_stmt|;
return|return
name|query
return|;
block|}
comment|/**    * Builds a new FuzzyQuery instance    * @param term Term    * @param minimumSimilarity minimum similarity    * @param prefixLength prefix length    * @return new FuzzyQuery Instance    */
DECL|method|newFuzzyQuery
specifier|protected
name|Query
name|newFuzzyQuery
parameter_list|(
name|Term
name|term
parameter_list|,
name|float
name|minimumSimilarity
parameter_list|,
name|int
name|prefixLength
parameter_list|)
block|{
comment|// FuzzyQuery doesn't yet allow constant score rewrite
name|String
name|text
init|=
name|term
operator|.
name|text
argument_list|()
decl_stmt|;
name|int
name|numEdits
init|=
name|FuzzyQuery
operator|.
name|floatToEdits
argument_list|(
name|minimumSimilarity
argument_list|,
name|text
operator|.
name|codePointCount
argument_list|(
literal|0
argument_list|,
name|text
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|FuzzyQuery
argument_list|(
name|term
argument_list|,
name|numEdits
argument_list|,
name|prefixLength
argument_list|)
return|;
block|}
comment|// TODO: Should this be protected instead?
DECL|method|analyzeMultitermTerm
specifier|private
name|BytesRef
name|analyzeMultitermTerm
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|part
parameter_list|)
block|{
return|return
name|analyzeMultitermTerm
argument_list|(
name|field
argument_list|,
name|part
argument_list|,
name|analyzer
argument_list|)
return|;
block|}
DECL|method|analyzeMultitermTerm
specifier|protected
name|BytesRef
name|analyzeMultitermTerm
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|part
parameter_list|,
name|Analyzer
name|analyzerIn
parameter_list|)
block|{
name|TokenStream
name|source
decl_stmt|;
if|if
condition|(
name|analyzerIn
operator|==
literal|null
condition|)
name|analyzerIn
operator|=
name|analyzer
expr_stmt|;
try|try
block|{
name|source
operator|=
name|analyzerIn
operator|.
name|tokenStream
argument_list|(
name|field
argument_list|,
operator|new
name|StringReader
argument_list|(
name|part
argument_list|)
argument_list|)
expr_stmt|;
name|source
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unable to initialize TokenStream to analyze multiTerm term: "
operator|+
name|part
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|TermToBytesRefAttribute
name|termAtt
init|=
name|source
operator|.
name|getAttribute
argument_list|(
name|TermToBytesRefAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|BytesRef
name|bytes
init|=
name|termAtt
operator|.
name|getBytesRef
argument_list|()
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|source
operator|.
name|incrementToken
argument_list|()
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"analyzer returned no terms for multiTerm term: "
operator|+
name|part
argument_list|)
throw|;
name|termAtt
operator|.
name|fillBytesRef
argument_list|()
expr_stmt|;
if|if
condition|(
name|source
operator|.
name|incrementToken
argument_list|()
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"analyzer returned too many terms for multiTerm term: "
operator|+
name|part
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"error analyzing range part: "
operator|+
name|part
argument_list|,
name|e
argument_list|)
throw|;
block|}
try|try
block|{
name|source
operator|.
name|end
argument_list|()
expr_stmt|;
name|source
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unable to end& close TokenStream after analyzing multiTerm term: "
operator|+
name|part
argument_list|,
name|e
argument_list|)
throw|;
block|}
return|return
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|bytes
argument_list|)
return|;
block|}
comment|/**    * Builds a new TermRangeQuery instance    * @param field Field    * @param part1 min    * @param part2 max    * @param startInclusive true if the start of the range is inclusive    * @param endInclusive true if the end of the range is inclusive    * @return new TermRangeQuery instance    */
DECL|method|newRangeQuery
specifier|protected
name|Query
name|newRangeQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|part1
parameter_list|,
name|String
name|part2
parameter_list|,
name|boolean
name|startInclusive
parameter_list|,
name|boolean
name|endInclusive
parameter_list|)
block|{
specifier|final
name|BytesRef
name|start
decl_stmt|;
specifier|final
name|BytesRef
name|end
decl_stmt|;
if|if
condition|(
name|part1
operator|==
literal|null
condition|)
block|{
name|start
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|start
operator|=
name|analyzeRangeTerms
condition|?
name|analyzeMultitermTerm
argument_list|(
name|field
argument_list|,
name|part1
argument_list|)
else|:
operator|new
name|BytesRef
argument_list|(
name|part1
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|part2
operator|==
literal|null
condition|)
block|{
name|end
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|end
operator|=
name|analyzeRangeTerms
condition|?
name|analyzeMultitermTerm
argument_list|(
name|field
argument_list|,
name|part2
argument_list|)
else|:
operator|new
name|BytesRef
argument_list|(
name|part2
argument_list|)
expr_stmt|;
block|}
specifier|final
name|TermRangeQuery
name|query
init|=
operator|new
name|TermRangeQuery
argument_list|(
name|field
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|startInclusive
argument_list|,
name|endInclusive
argument_list|)
decl_stmt|;
name|query
operator|.
name|setRewriteMethod
argument_list|(
name|multiTermRewriteMethod
argument_list|)
expr_stmt|;
return|return
name|query
return|;
block|}
comment|/**    * Builds a new MatchAllDocsQuery instance    * @return new MatchAllDocsQuery instance    */
DECL|method|newMatchAllDocsQuery
specifier|protected
name|Query
name|newMatchAllDocsQuery
parameter_list|()
block|{
return|return
operator|new
name|MatchAllDocsQuery
argument_list|()
return|;
block|}
comment|/**    * Builds a new WildcardQuery instance    * @param t wildcard term    * @return new WildcardQuery instance    */
DECL|method|newWildcardQuery
specifier|protected
name|Query
name|newWildcardQuery
parameter_list|(
name|Term
name|t
parameter_list|)
block|{
name|WildcardQuery
name|query
init|=
operator|new
name|WildcardQuery
argument_list|(
name|t
argument_list|)
decl_stmt|;
name|query
operator|.
name|setRewriteMethod
argument_list|(
name|multiTermRewriteMethod
argument_list|)
expr_stmt|;
return|return
name|query
return|;
block|}
comment|/**    * Factory method for generating query, given a set of clauses.    * By default creates a boolean query composed of clauses passed in.    *    * Can be overridden by extending classes, to modify query being    * returned.    *    * @param clauses List that contains {@link org.apache.lucene.search.BooleanClause} instances    *    to join.    *    * @return Resulting {@link org.apache.lucene.search.Query} object.    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getBooleanQuery
specifier|protected
name|Query
name|getBooleanQuery
parameter_list|(
name|List
argument_list|<
name|BooleanClause
argument_list|>
name|clauses
parameter_list|)
throws|throws
name|ParseException
block|{
return|return
name|getBooleanQuery
argument_list|(
name|clauses
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Factory method for generating query, given a set of clauses.    * By default creates a boolean query composed of clauses passed in.    *    * Can be overridden by extending classes, to modify query being    * returned.    *    * @param clauses List that contains {@link org.apache.lucene.search.BooleanClause} instances    *    to join.    * @param disableCoord true if coord scoring should be disabled.    *    * @return Resulting {@link org.apache.lucene.search.Query} object.    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getBooleanQuery
specifier|protected
name|Query
name|getBooleanQuery
parameter_list|(
name|List
argument_list|<
name|BooleanClause
argument_list|>
name|clauses
parameter_list|,
name|boolean
name|disableCoord
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
name|clauses
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
comment|// all clause words were filtered away by the analyzer.
block|}
name|BooleanQuery
name|query
init|=
name|newBooleanQuery
argument_list|(
name|disableCoord
argument_list|)
decl_stmt|;
for|for
control|(
specifier|final
name|BooleanClause
name|clause
range|:
name|clauses
control|)
block|{
name|query
operator|.
name|add
argument_list|(
name|clause
argument_list|)
expr_stmt|;
block|}
return|return
name|query
return|;
block|}
comment|/**    * Factory method for generating a query. Called when parser    * parses an input term token that contains one or more wildcard    * characters (? and *), but is not a prefix term token (one    * that has just a single * character at the end)    *<p>    * Depending on settings, prefix term may be lower-cased    * automatically. It will not go through the default Analyzer,    * however, since normal Analyzers are unlikely to work properly    * with wildcard templates.    *<p>    * Can be overridden by extending classes, to provide custom handling for    * wildcard queries, which may be necessary due to missing analyzer calls.    *    * @param field Name of the field query will use.    * @param termStr Term token that contains one or more wild card    *   characters (? or *), but is not simple prefix term    *    * @return Resulting {@link org.apache.lucene.search.Query} built for the term    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getWildcardQuery
specifier|protected
name|Query
name|getWildcardQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|termStr
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
literal|"*"
operator|.
name|equals
argument_list|(
name|field
argument_list|)
condition|)
block|{
if|if
condition|(
literal|"*"
operator|.
name|equals
argument_list|(
name|termStr
argument_list|)
condition|)
return|return
name|newMatchAllDocsQuery
argument_list|()
return|;
block|}
if|if
condition|(
operator|!
name|allowLeadingWildcard
operator|&&
operator|(
name|termStr
operator|.
name|startsWith
argument_list|(
literal|"*"
argument_list|)
operator|||
name|termStr
operator|.
name|startsWith
argument_list|(
literal|"?"
argument_list|)
operator|)
condition|)
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"'*' or '?' not allowed as first character in WildcardQuery"
argument_list|)
throw|;
if|if
condition|(
name|lowercaseExpandedTerms
condition|)
block|{
name|termStr
operator|=
name|termStr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
block|}
name|Term
name|t
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|termStr
argument_list|)
decl_stmt|;
return|return
name|newWildcardQuery
argument_list|(
name|t
argument_list|)
return|;
block|}
comment|/**    * Factory method for generating a query. Called when parser    * parses an input term token that contains a regular expression    * query.    *<p>    * Depending on settings, pattern term may be lower-cased    * automatically. It will not go through the default Analyzer,    * however, since normal Analyzers are unlikely to work properly    * with regular expression templates.    *<p>    * Can be overridden by extending classes, to provide custom handling for    * regular expression queries, which may be necessary due to missing analyzer    * calls.    *    * @param field Name of the field query will use.    * @param termStr Term token that contains a regular expression    *    * @return Resulting {@link org.apache.lucene.search.Query} built for the term    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getRegexpQuery
specifier|protected
name|Query
name|getRegexpQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|termStr
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
name|lowercaseExpandedTerms
condition|)
block|{
name|termStr
operator|=
name|termStr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
block|}
name|Term
name|t
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|termStr
argument_list|)
decl_stmt|;
return|return
name|newRegexpQuery
argument_list|(
name|t
argument_list|)
return|;
block|}
comment|/**    * Factory method for generating a query (similar to    * {@link #getWildcardQuery}). Called when parser parses an input term    * token that uses prefix notation; that is, contains a single '*' wildcard    * character as its last character. Since this is a special case    * of generic wildcard term, and such a query can be optimized easily,    * this usually results in a different query object.    *<p>    * Depending on settings, a prefix term may be lower-cased    * automatically. It will not go through the default Analyzer,    * however, since normal Analyzers are unlikely to work properly    * with wildcard templates.    *<p>    * Can be overridden by extending classes, to provide custom handling for    * wild card queries, which may be necessary due to missing analyzer calls.    *    * @param field Name of the field query will use.    * @param termStr Term token to use for building term for the query    *    (<b>without</b> trailing '*' character!)    *    * @return Resulting {@link org.apache.lucene.search.Query} built for the term    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getPrefixQuery
specifier|protected
name|Query
name|getPrefixQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|termStr
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
operator|!
name|allowLeadingWildcard
operator|&&
name|termStr
operator|.
name|startsWith
argument_list|(
literal|"*"
argument_list|)
condition|)
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"'*' not allowed as first character in PrefixQuery"
argument_list|)
throw|;
if|if
condition|(
name|lowercaseExpandedTerms
condition|)
block|{
name|termStr
operator|=
name|termStr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
block|}
name|Term
name|t
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|termStr
argument_list|)
decl_stmt|;
return|return
name|newPrefixQuery
argument_list|(
name|t
argument_list|)
return|;
block|}
comment|/**    * Factory method for generating a query (similar to    * {@link #getWildcardQuery}). Called when parser parses    * an input term token that has the fuzzy suffix (~) appended.    *    * @param field Name of the field query will use.    * @param termStr Term token to use for building term for the query    *    * @return Resulting {@link org.apache.lucene.search.Query} built for the term    * @exception org.apache.lucene.queryparser.classic.ParseException throw in overridden method to disallow    */
DECL|method|getFuzzyQuery
specifier|protected
name|Query
name|getFuzzyQuery
parameter_list|(
name|String
name|field
parameter_list|,
name|String
name|termStr
parameter_list|,
name|float
name|minSimilarity
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
name|lowercaseExpandedTerms
condition|)
block|{
name|termStr
operator|=
name|termStr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
block|}
name|Term
name|t
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|termStr
argument_list|)
decl_stmt|;
return|return
name|newFuzzyQuery
argument_list|(
name|t
argument_list|,
name|minSimilarity
argument_list|,
name|fuzzyPrefixLength
argument_list|)
return|;
block|}
comment|// extracted from the .jj grammar
DECL|method|handleBareTokenQuery
name|Query
name|handleBareTokenQuery
parameter_list|(
name|String
name|qfield
parameter_list|,
name|Token
name|term
parameter_list|,
name|Token
name|fuzzySlop
parameter_list|,
name|boolean
name|prefix
parameter_list|,
name|boolean
name|wildcard
parameter_list|,
name|boolean
name|fuzzy
parameter_list|,
name|boolean
name|regexp
parameter_list|)
throws|throws
name|ParseException
block|{
name|Query
name|q
decl_stmt|;
name|String
name|termImage
init|=
name|discardEscapeChar
argument_list|(
name|term
operator|.
name|image
argument_list|)
decl_stmt|;
if|if
condition|(
name|wildcard
condition|)
block|{
name|q
operator|=
name|getWildcardQuery
argument_list|(
name|qfield
argument_list|,
name|term
operator|.
name|image
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|prefix
condition|)
block|{
name|q
operator|=
name|getPrefixQuery
argument_list|(
name|qfield
argument_list|,
name|discardEscapeChar
argument_list|(
name|term
operator|.
name|image
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|term
operator|.
name|image
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|regexp
condition|)
block|{
name|q
operator|=
name|getRegexpQuery
argument_list|(
name|qfield
argument_list|,
name|term
operator|.
name|image
operator|.
name|substring
argument_list|(
literal|1
argument_list|,
name|term
operator|.
name|image
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|fuzzy
condition|)
block|{
name|float
name|fms
init|=
name|fuzzyMinSim
decl_stmt|;
try|try
block|{
name|fms
operator|=
name|Float
operator|.
name|valueOf
argument_list|(
name|fuzzySlop
operator|.
name|image
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
argument_list|)
operator|.
name|floatValue
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignored
parameter_list|)
block|{ }
if|if
condition|(
name|fms
operator|<
literal|0.0f
condition|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|fms
operator|>=
literal|1.0f
operator|&&
name|fms
operator|!=
operator|(
name|int
operator|)
name|fms
condition|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Fractional edit distances are not allowed!"
argument_list|)
throw|;
block|}
name|q
operator|=
name|getFuzzyQuery
argument_list|(
name|qfield
argument_list|,
name|termImage
argument_list|,
name|fms
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|q
operator|=
name|getFieldQuery
argument_list|(
name|qfield
argument_list|,
name|termImage
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
return|return
name|q
return|;
block|}
comment|// extracted from the .jj grammar
DECL|method|handleQuotedTerm
name|Query
name|handleQuotedTerm
parameter_list|(
name|String
name|qfield
parameter_list|,
name|Token
name|term
parameter_list|,
name|Token
name|fuzzySlop
parameter_list|)
throws|throws
name|ParseException
block|{
name|int
name|s
init|=
name|phraseSlop
decl_stmt|;
comment|// default
if|if
condition|(
name|fuzzySlop
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|s
operator|=
name|Float
operator|.
name|valueOf
argument_list|(
name|fuzzySlop
operator|.
name|image
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
argument_list|)
operator|.
name|intValue
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignored
parameter_list|)
block|{ }
block|}
return|return
name|getFieldQuery
argument_list|(
name|qfield
argument_list|,
name|discardEscapeChar
argument_list|(
name|term
operator|.
name|image
operator|.
name|substring
argument_list|(
literal|1
argument_list|,
name|term
operator|.
name|image
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
argument_list|,
name|s
argument_list|)
return|;
block|}
comment|// extracted from the .jj grammar
DECL|method|handleBoost
name|Query
name|handleBoost
parameter_list|(
name|Query
name|q
parameter_list|,
name|Token
name|boost
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
name|boost
operator|!=
literal|null
condition|)
block|{
name|float
name|f
init|=
operator|(
name|float
operator|)
literal|1.0
decl_stmt|;
try|try
block|{
name|f
operator|=
name|Float
operator|.
name|valueOf
argument_list|(
name|boost
operator|.
name|image
argument_list|)
operator|.
name|floatValue
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignored
parameter_list|)
block|{
comment|/* Should this be handled somehow? (defaults to "no boost", if      * boost number is invalid)      */
block|}
comment|// avoid boosting null queries, such as those caused by stop words
if|if
condition|(
name|q
operator|!=
literal|null
condition|)
block|{
name|q
operator|.
name|setBoost
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|q
return|;
block|}
comment|/**    * Returns a String where the escape char has been    * removed, or kept only once if there was a double escape.    *    * Supports escaped unicode characters, e. g. translates    *<code>\\u0041</code> to<code>A</code>.    *    */
DECL|method|discardEscapeChar
name|String
name|discardEscapeChar
parameter_list|(
name|String
name|input
parameter_list|)
throws|throws
name|ParseException
block|{
comment|// Create char array to hold unescaped char sequence
name|char
index|[]
name|output
init|=
operator|new
name|char
index|[
name|input
operator|.
name|length
argument_list|()
index|]
decl_stmt|;
comment|// The length of the output can be less than the input
comment|// due to discarded escape chars. This variable holds
comment|// the actual length of the output
name|int
name|length
init|=
literal|0
decl_stmt|;
comment|// We remember whether the last processed character was
comment|// an escape character
name|boolean
name|lastCharWasEscapeChar
init|=
literal|false
decl_stmt|;
comment|// The multiplier the current unicode digit must be multiplied with.
comment|// E. g. the first digit must be multiplied with 16^3, the second with 16^2...
name|int
name|codePointMultiplier
init|=
literal|0
decl_stmt|;
comment|// Used to calculate the codepoint of the escaped unicode character
name|int
name|codePoint
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|input
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|char
name|curChar
init|=
name|input
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|codePointMultiplier
operator|>
literal|0
condition|)
block|{
name|codePoint
operator|+=
name|hexToInt
argument_list|(
name|curChar
argument_list|)
operator|*
name|codePointMultiplier
expr_stmt|;
name|codePointMultiplier
operator|>>>=
literal|4
expr_stmt|;
if|if
condition|(
name|codePointMultiplier
operator|==
literal|0
condition|)
block|{
name|output
index|[
name|length
operator|++
index|]
operator|=
operator|(
name|char
operator|)
name|codePoint
expr_stmt|;
name|codePoint
operator|=
literal|0
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|lastCharWasEscapeChar
condition|)
block|{
if|if
condition|(
name|curChar
operator|==
literal|'u'
condition|)
block|{
comment|// found an escaped unicode character
name|codePointMultiplier
operator|=
literal|16
operator|*
literal|16
operator|*
literal|16
expr_stmt|;
block|}
else|else
block|{
comment|// this character was escaped
name|output
index|[
name|length
index|]
operator|=
name|curChar
expr_stmt|;
name|length
operator|++
expr_stmt|;
block|}
name|lastCharWasEscapeChar
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|curChar
operator|==
literal|'\\'
condition|)
block|{
name|lastCharWasEscapeChar
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|output
index|[
name|length
index|]
operator|=
name|curChar
expr_stmt|;
name|length
operator|++
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|codePointMultiplier
operator|>
literal|0
condition|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Truncated unicode escape sequence."
argument_list|)
throw|;
block|}
if|if
condition|(
name|lastCharWasEscapeChar
condition|)
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Term can not end with escape character."
argument_list|)
throw|;
block|}
return|return
operator|new
name|String
argument_list|(
name|output
argument_list|,
literal|0
argument_list|,
name|length
argument_list|)
return|;
block|}
comment|/** Returns the numeric value of the hexadecimal character */
DECL|method|hexToInt
specifier|static
specifier|final
name|int
name|hexToInt
parameter_list|(
name|char
name|c
parameter_list|)
throws|throws
name|ParseException
block|{
if|if
condition|(
literal|'0'
operator|<=
name|c
operator|&&
name|c
operator|<=
literal|'9'
condition|)
block|{
return|return
name|c
operator|-
literal|'0'
return|;
block|}
elseif|else
if|if
condition|(
literal|'a'
operator|<=
name|c
operator|&&
name|c
operator|<=
literal|'f'
condition|)
block|{
return|return
name|c
operator|-
literal|'a'
operator|+
literal|10
return|;
block|}
elseif|else
if|if
condition|(
literal|'A'
operator|<=
name|c
operator|&&
name|c
operator|<=
literal|'F'
condition|)
block|{
return|return
name|c
operator|-
literal|'A'
operator|+
literal|10
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"Non-hex character in Unicode escape sequence: "
operator|+
name|c
argument_list|)
throw|;
block|}
block|}
comment|/**    * Returns a String where those characters that QueryParser    * expects to be escaped are escaped by a preceding<code>\</code>.    */
DECL|method|escape
specifier|public
specifier|static
name|String
name|escape
parameter_list|(
name|String
name|s
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|s
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|char
name|c
init|=
name|s
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// These characters are part of the query syntax and must be escaped
if|if
condition|(
name|c
operator|==
literal|'\\'
operator|||
name|c
operator|==
literal|'+'
operator|||
name|c
operator|==
literal|'-'
operator|||
name|c
operator|==
literal|'!'
operator|||
name|c
operator|==
literal|'('
operator|||
name|c
operator|==
literal|')'
operator|||
name|c
operator|==
literal|':'
operator|||
name|c
operator|==
literal|'^'
operator|||
name|c
operator|==
literal|'['
operator|||
name|c
operator|==
literal|']'
operator|||
name|c
operator|==
literal|'\"'
operator|||
name|c
operator|==
literal|'{'
operator|||
name|c
operator|==
literal|'}'
operator|||
name|c
operator|==
literal|'~'
operator|||
name|c
operator|==
literal|'*'
operator|||
name|c
operator|==
literal|'?'
operator|||
name|c
operator|==
literal|'|'
operator|||
name|c
operator|==
literal|'&'
operator|||
name|c
operator|==
literal|'/'
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|'\\'
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|c
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
end_class
end_unit
