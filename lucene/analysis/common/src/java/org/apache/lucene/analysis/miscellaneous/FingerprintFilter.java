begin_unit
begin_package
DECL|package|org.apache.lucene.analysis.miscellaneous
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|miscellaneous
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionLengthAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TypeAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|util
operator|.
name|CharArraySet
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|AttributeSource
import|;
end_import
begin_comment
comment|/**  * Filter outputs a single token which is a concatenation of the sorted and  * de-duplicated set of input tokens. This can be useful for clustering/linking  * use cases.  */
end_comment
begin_class
DECL|class|FingerprintFilter
specifier|public
class|class
name|FingerprintFilter
extends|extends
name|TokenFilter
block|{
DECL|field|DEFAULT_MAX_OUTPUT_TOKEN_SIZE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_OUTPUT_TOKEN_SIZE
init|=
literal|1024
decl_stmt|;
DECL|field|DEFAULT_SEPARATOR
specifier|public
specifier|static
specifier|final
name|char
name|DEFAULT_SEPARATOR
init|=
literal|' '
decl_stmt|;
DECL|field|termAttribute
specifier|private
specifier|final
name|CharTermAttribute
name|termAttribute
init|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|offsetAtt
specifier|private
specifier|final
name|OffsetAttribute
name|offsetAtt
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|posIncrAtt
specifier|private
specifier|final
name|PositionIncrementAttribute
name|posIncrAtt
init|=
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|posLenAtt
specifier|private
specifier|final
name|PositionLengthAttribute
name|posLenAtt
init|=
name|addAttribute
argument_list|(
name|PositionLengthAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|typeAtt
specifier|private
specifier|final
name|TypeAttribute
name|typeAtt
init|=
name|addAttribute
argument_list|(
name|TypeAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|uniqueTerms
specifier|private
name|CharArraySet
name|uniqueTerms
init|=
literal|null
decl_stmt|;
DECL|field|maxOutputTokenSize
specifier|private
specifier|final
name|int
name|maxOutputTokenSize
decl_stmt|;
DECL|field|finalState
specifier|private
name|AttributeSource
operator|.
name|State
name|finalState
decl_stmt|;
DECL|field|separator
specifier|private
specifier|final
name|char
name|separator
decl_stmt|;
DECL|field|inputEnded
specifier|private
name|boolean
name|inputEnded
init|=
literal|false
decl_stmt|;
comment|/**    * Create a new FingerprintFilter with default settings    */
DECL|method|FingerprintFilter
specifier|public
name|FingerprintFilter
parameter_list|(
name|TokenStream
name|input
parameter_list|)
block|{
name|this
argument_list|(
name|input
argument_list|,
name|DEFAULT_MAX_OUTPUT_TOKEN_SIZE
argument_list|,
name|DEFAULT_SEPARATOR
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a new FingerprintFilter with control over all settings    *     * @param input    *          the source of tokens to be summarized into a single token    * @param maxOutputTokenSize    *          the maximum length of the summarized output token. If exceeded, no    *          output token is emitted    * @param separator    *          the character used to separate tokens combined into the single    *          output token    */
DECL|method|FingerprintFilter
specifier|public
name|FingerprintFilter
parameter_list|(
name|TokenStream
name|input
parameter_list|,
name|int
name|maxOutputTokenSize
parameter_list|,
name|char
name|separator
parameter_list|)
block|{
name|super
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxOutputTokenSize
operator|=
name|maxOutputTokenSize
expr_stmt|;
name|this
operator|.
name|separator
operator|=
name|separator
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|incrementToken
specifier|public
specifier|final
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|uniqueTerms
operator|!=
literal|null
condition|)
block|{
comment|// We have already built the single output token - there's no more
return|return
literal|false
return|;
block|}
name|boolean
name|result
init|=
name|buildSingleOutputToken
argument_list|()
decl_stmt|;
name|finalState
operator|=
name|captureState
argument_list|()
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**    * Gathers all tokens from input, de-duplicates, sorts then concatenates.    *     * @return false for end of stream; true otherwise    */
DECL|method|buildSingleOutputToken
specifier|private
specifier|final
name|boolean
name|buildSingleOutputToken
parameter_list|()
throws|throws
name|IOException
block|{
name|inputEnded
operator|=
literal|false
expr_stmt|;
name|char
name|clonedLastTerm
index|[]
init|=
literal|null
decl_stmt|;
name|uniqueTerms
operator|=
operator|new
name|CharArraySet
argument_list|(
literal|8
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|int
name|outputTokenSize
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|input
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
if|if
condition|(
name|outputTokenSize
operator|>
name|maxOutputTokenSize
condition|)
block|{
continue|continue;
block|}
specifier|final
name|char
name|term
index|[]
init|=
name|termAttribute
operator|.
name|buffer
argument_list|()
decl_stmt|;
specifier|final
name|int
name|length
init|=
name|termAttribute
operator|.
name|length
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|uniqueTerms
operator|.
name|contains
argument_list|(
name|term
argument_list|,
literal|0
argument_list|,
name|length
argument_list|)
condition|)
block|{
comment|// clone the term, and add to the set of seen terms.
name|clonedLastTerm
operator|=
operator|new
name|char
index|[
name|length
index|]
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|term
argument_list|,
literal|0
argument_list|,
name|clonedLastTerm
argument_list|,
literal|0
argument_list|,
name|length
argument_list|)
expr_stmt|;
if|if
condition|(
name|uniqueTerms
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|outputTokenSize
operator|++
expr_stmt|;
comment|//Add 1 for the separator char we will output
block|}
name|uniqueTerms
operator|.
name|add
argument_list|(
name|clonedLastTerm
argument_list|)
expr_stmt|;
name|outputTokenSize
operator|+=
name|length
expr_stmt|;
block|}
block|}
comment|//Force end-of-stream operations to get the final state.
name|input
operator|.
name|end
argument_list|()
expr_stmt|;
name|inputEnded
operator|=
literal|true
expr_stmt|;
comment|//Gathering complete - now output exactly zero or one token:
comment|//Set the attributes for the single output token
name|offsetAtt
operator|.
name|setOffset
argument_list|(
literal|0
argument_list|,
name|offsetAtt
operator|.
name|endOffset
argument_list|()
argument_list|)
expr_stmt|;
name|posLenAtt
operator|.
name|setPositionLength
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|posIncrAtt
operator|.
name|setPositionIncrement
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|typeAtt
operator|.
name|setType
argument_list|(
literal|"fingerprint"
argument_list|)
expr_stmt|;
comment|//No tokens gathered - no output
if|if
condition|(
name|uniqueTerms
operator|.
name|size
argument_list|()
operator|<
literal|1
condition|)
block|{
name|termAttribute
operator|.
name|setEmpty
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|//Tokens gathered are too large - no output
if|if
condition|(
name|outputTokenSize
operator|>
name|maxOutputTokenSize
condition|)
block|{
name|termAttribute
operator|.
name|setEmpty
argument_list|()
expr_stmt|;
name|uniqueTerms
operator|.
name|clear
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Special case - faster option when we have a single token
if|if
condition|(
name|uniqueTerms
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
name|termAttribute
operator|.
name|setEmpty
argument_list|()
operator|.
name|append
argument_list|(
operator|new
name|String
argument_list|(
name|clonedLastTerm
argument_list|)
argument_list|)
expr_stmt|;
name|uniqueTerms
operator|.
name|clear
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|// Sort the set of deduplicated tokens and combine
name|Object
index|[]
name|items
init|=
name|uniqueTerms
operator|.
name|toArray
argument_list|()
decl_stmt|;
name|Arrays
operator|.
name|sort
argument_list|(
name|items
argument_list|,
operator|new
name|Comparator
argument_list|<
name|Object
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Object
name|o1
parameter_list|,
name|Object
name|o2
parameter_list|)
block|{
name|char
name|v1
index|[]
init|=
operator|(
name|char
index|[]
operator|)
name|o1
decl_stmt|;
name|char
name|v2
index|[]
init|=
operator|(
name|char
index|[]
operator|)
name|o2
decl_stmt|;
name|int
name|len1
init|=
name|v1
operator|.
name|length
decl_stmt|;
name|int
name|len2
init|=
name|v2
operator|.
name|length
decl_stmt|;
name|int
name|lim
init|=
name|Math
operator|.
name|min
argument_list|(
name|len1
argument_list|,
name|len2
argument_list|)
decl_stmt|;
name|int
name|k
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|k
operator|<
name|lim
condition|)
block|{
name|char
name|c1
init|=
name|v1
index|[
name|k
index|]
decl_stmt|;
name|char
name|c2
init|=
name|v2
index|[
name|k
index|]
decl_stmt|;
if|if
condition|(
name|c1
operator|!=
name|c2
condition|)
block|{
return|return
name|c1
operator|-
name|c2
return|;
block|}
name|k
operator|++
expr_stmt|;
block|}
return|return
name|len1
operator|-
name|len2
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Object
name|item
range|:
name|items
control|)
block|{
if|if
condition|(
name|sb
operator|.
name|length
argument_list|()
operator|>=
literal|1
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|separator
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
operator|(
name|char
index|[]
operator|)
name|item
argument_list|)
expr_stmt|;
block|}
name|termAttribute
operator|.
name|setEmpty
argument_list|()
operator|.
name|append
argument_list|(
name|sb
argument_list|)
expr_stmt|;
name|uniqueTerms
operator|.
name|clear
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
annotation|@
name|Override
DECL|method|end
specifier|public
specifier|final
name|void
name|end
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|inputEnded
condition|)
block|{
comment|// Rare case - If an IOException occurs while performing buildSingleOutputToken
comment|// we may not have called input.end() already
name|input
operator|.
name|end
argument_list|()
expr_stmt|;
name|inputEnded
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|finalState
operator|!=
literal|null
condition|)
block|{
name|restoreState
argument_list|(
name|finalState
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
name|inputEnded
operator|=
literal|false
expr_stmt|;
name|uniqueTerms
operator|=
literal|null
expr_stmt|;
block|}
block|}
end_class
end_unit
