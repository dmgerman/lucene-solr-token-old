begin_unit
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_package
DECL|package|org.apache.lucene.analysis.cn.smart
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|cn
operator|.
name|smart
package|;
end_package
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|cn
operator|.
name|smart
operator|.
name|hhmm
operator|.
name|HHMMSegmenter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|cn
operator|.
name|smart
operator|.
name|hhmm
operator|.
name|SegToken
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|cn
operator|.
name|smart
operator|.
name|hhmm
operator|.
name|SegTokenFilter
import|;
end_import
begin_comment
comment|/**  * Segment a sentence of Chinese text into words.  * @lucene.experimental  */
end_comment
begin_class
DECL|class|WordSegmenter
class|class
name|WordSegmenter
block|{
DECL|field|hhmmSegmenter
specifier|private
name|HHMMSegmenter
name|hhmmSegmenter
init|=
operator|new
name|HHMMSegmenter
argument_list|()
decl_stmt|;
DECL|field|tokenFilter
specifier|private
name|SegTokenFilter
name|tokenFilter
init|=
operator|new
name|SegTokenFilter
argument_list|()
decl_stmt|;
comment|/**    * Segment a sentence into words with {@link HHMMSegmenter}    *     * @param sentence input sentence    * @param startOffset start offset of sentence    * @return {@link List} of {@link SegToken}    */
DECL|method|segmentSentence
specifier|public
name|List
argument_list|<
name|SegToken
argument_list|>
name|segmentSentence
parameter_list|(
name|String
name|sentence
parameter_list|,
name|int
name|startOffset
parameter_list|)
block|{
name|List
argument_list|<
name|SegToken
argument_list|>
name|segTokenList
init|=
name|hhmmSegmenter
operator|.
name|process
argument_list|(
name|sentence
argument_list|)
decl_stmt|;
comment|// tokens from sentence, excluding WordType.SENTENCE_BEGIN and WordType.SENTENCE_END
name|List
argument_list|<
name|SegToken
argument_list|>
name|result
init|=
name|Collections
operator|.
name|emptyList
argument_list|()
decl_stmt|;
if|if
condition|(
name|segTokenList
operator|.
name|size
argument_list|()
operator|>
literal|2
condition|)
comment|// if it's not an empty sentence
name|result
operator|=
name|segTokenList
operator|.
name|subList
argument_list|(
literal|1
argument_list|,
name|segTokenList
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
for|for
control|(
name|SegToken
name|st
range|:
name|result
control|)
name|convertSegToken
argument_list|(
name|st
argument_list|,
name|sentence
argument_list|,
name|startOffset
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**    * Process a {@link SegToken} so that it is ready for indexing.    *     * This method calculates offsets and normalizes the token with {@link SegTokenFilter}.    *     * @param st input {@link SegToken}    * @param sentence associated Sentence    * @param sentenceStartOffset offset into sentence    * @return Lucene {@link SegToken}    */
DECL|method|convertSegToken
specifier|public
name|SegToken
name|convertSegToken
parameter_list|(
name|SegToken
name|st
parameter_list|,
name|String
name|sentence
parameter_list|,
name|int
name|sentenceStartOffset
parameter_list|)
block|{
switch|switch
condition|(
name|st
operator|.
name|wordType
condition|)
block|{
case|case
name|WordType
operator|.
name|STRING
case|:
case|case
name|WordType
operator|.
name|NUMBER
case|:
case|case
name|WordType
operator|.
name|FULLWIDTH_NUMBER
case|:
case|case
name|WordType
operator|.
name|FULLWIDTH_STRING
case|:
name|st
operator|.
name|charArray
operator|=
name|sentence
operator|.
name|substring
argument_list|(
name|st
operator|.
name|startOffset
argument_list|,
name|st
operator|.
name|endOffset
argument_list|)
operator|.
name|toCharArray
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
name|st
operator|=
name|tokenFilter
operator|.
name|filter
argument_list|(
name|st
argument_list|)
expr_stmt|;
name|st
operator|.
name|startOffset
operator|+=
name|sentenceStartOffset
expr_stmt|;
name|st
operator|.
name|endOffset
operator|+=
name|sentenceStartOffset
expr_stmt|;
return|return
name|st
return|;
block|}
block|}
end_class
end_unit
