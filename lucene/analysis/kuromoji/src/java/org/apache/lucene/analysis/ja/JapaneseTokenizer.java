begin_unit
begin_package
DECL|package|org.apache.lucene.analysis.ja
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
package|;
end_package
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Reader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Tokenizer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|CharacterDefinition
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|ConnectionCosts
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|Dictionary
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|TokenInfoDictionary
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|TokenInfoFST
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|UnknownDictionary
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|UserDictionary
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|tokenattributes
operator|.
name|*
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionLengthAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ArrayUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntsRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RamUsageEstimator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RollingCharBuffer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|FST
import|;
end_import
begin_comment
comment|// TODO: somehow factor out a reusable viterbi search here,
end_comment
begin_comment
comment|// so other decompounders/tokenizers can reuse...
end_comment
begin_comment
comment|/**  * Tokenizer for Japanese that uses morphological analysis.  *<p>  * This tokenizer sets a number of additional attributes:  *<ul>  *<li>{@link BaseFormAttribute} containing base form for inflected  *       adjectives and verbs.  *<li>{@link PartOfSpeechAttribute} containing part-of-speech.  *<li>{@link ReadingAttribute} containing reading and pronunciation.  *<li>{@link InflectionAttribute} containing additional part-of-speech  *       information for inflected forms.  *</ul>  *<p>  * This tokenizer uses a rolling Viterbi search to find the   * least cost segmentation (path) of the incoming characters.    * For tokens that appear to be compound (> length 2 for all  * Kanji, or> length 7 for non-Kanji), we see if there is a  * 2nd best segmentation of that token after applying  * penalties to the long tokens.  If so, and the Mode is  * {@link Mode#SEARCH}, we output the alternate segmentation   * as well.  */
end_comment
begin_class
DECL|class|JapaneseTokenizer
specifier|public
specifier|final
class|class
name|JapaneseTokenizer
extends|extends
name|Tokenizer
block|{
comment|/**    * Tokenization mode: this determines how the tokenizer handles    * compound and unknown words.    */
DECL|enum|Mode
specifier|public
specifier|static
enum|enum
name|Mode
block|{
comment|/**      * Ordinary segmentation: no decomposition for compounds,      */
DECL|enum constant|NORMAL
name|NORMAL
block|,
comment|/**      * Segmentation geared towards search: this includes a       * decompounding process for long nouns, also including      * the full compound token as a synonym.      */
DECL|enum constant|SEARCH
name|SEARCH
block|,
comment|/**      * Extended mode outputs unigrams for unknown words.      * @lucene.experimental      */
DECL|enum constant|EXTENDED
name|EXTENDED
block|}
comment|/**    * Default tokenization mode. Currently this is {@link Mode#SEARCH}.    */
DECL|field|DEFAULT_MODE
specifier|public
specifier|static
specifier|final
name|Mode
name|DEFAULT_MODE
init|=
name|Mode
operator|.
name|SEARCH
decl_stmt|;
DECL|enum|Type
specifier|public
enum|enum
name|Type
block|{
DECL|enum constant|KNOWN
name|KNOWN
block|,
DECL|enum constant|UNKNOWN
name|UNKNOWN
block|,
DECL|enum constant|USER
name|USER
block|}
DECL|field|VERBOSE
specifier|private
specifier|static
specifier|final
name|boolean
name|VERBOSE
init|=
literal|false
decl_stmt|;
DECL|field|SEARCH_MODE_KANJI_LENGTH
specifier|private
specifier|static
specifier|final
name|int
name|SEARCH_MODE_KANJI_LENGTH
init|=
literal|2
decl_stmt|;
DECL|field|SEARCH_MODE_OTHER_LENGTH
specifier|private
specifier|static
specifier|final
name|int
name|SEARCH_MODE_OTHER_LENGTH
init|=
literal|7
decl_stmt|;
comment|// Must be>= SEARCH_MODE_KANJI_LENGTH
DECL|field|SEARCH_MODE_KANJI_PENALTY
specifier|private
specifier|static
specifier|final
name|int
name|SEARCH_MODE_KANJI_PENALTY
init|=
literal|3000
decl_stmt|;
DECL|field|SEARCH_MODE_OTHER_PENALTY
specifier|private
specifier|static
specifier|final
name|int
name|SEARCH_MODE_OTHER_PENALTY
init|=
literal|1700
decl_stmt|;
comment|// For safety:
DECL|field|MAX_UNKNOWN_WORD_LENGTH
specifier|private
specifier|static
specifier|final
name|int
name|MAX_UNKNOWN_WORD_LENGTH
init|=
literal|1024
decl_stmt|;
DECL|field|MAX_BACKTRACE_GAP
specifier|private
specifier|static
specifier|final
name|int
name|MAX_BACKTRACE_GAP
init|=
literal|1024
decl_stmt|;
DECL|field|dictionaryMap
specifier|private
specifier|final
name|EnumMap
argument_list|<
name|Type
argument_list|,
name|Dictionary
argument_list|>
name|dictionaryMap
init|=
operator|new
name|EnumMap
argument_list|<
name|Type
argument_list|,
name|Dictionary
argument_list|>
argument_list|(
name|Type
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|fst
specifier|private
specifier|final
name|TokenInfoFST
name|fst
decl_stmt|;
DECL|field|dictionary
specifier|private
specifier|final
name|TokenInfoDictionary
name|dictionary
decl_stmt|;
DECL|field|unkDictionary
specifier|private
specifier|final
name|UnknownDictionary
name|unkDictionary
decl_stmt|;
DECL|field|costs
specifier|private
specifier|final
name|ConnectionCosts
name|costs
decl_stmt|;
DECL|field|userDictionary
specifier|private
specifier|final
name|UserDictionary
name|userDictionary
decl_stmt|;
DECL|field|characterDefinition
specifier|private
specifier|final
name|CharacterDefinition
name|characterDefinition
decl_stmt|;
DECL|field|arc
specifier|private
specifier|final
name|FST
operator|.
name|Arc
argument_list|<
name|Long
argument_list|>
name|arc
init|=
operator|new
name|FST
operator|.
name|Arc
argument_list|<
name|Long
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|fstReader
specifier|private
specifier|final
name|FST
operator|.
name|BytesReader
name|fstReader
decl_stmt|;
DECL|field|wordIdRef
specifier|private
specifier|final
name|IntsRef
name|wordIdRef
init|=
operator|new
name|IntsRef
argument_list|()
decl_stmt|;
DECL|field|userFSTReader
specifier|private
specifier|final
name|FST
operator|.
name|BytesReader
name|userFSTReader
decl_stmt|;
DECL|field|userFST
specifier|private
specifier|final
name|TokenInfoFST
name|userFST
decl_stmt|;
DECL|field|buffer
specifier|private
specifier|final
name|RollingCharBuffer
name|buffer
init|=
operator|new
name|RollingCharBuffer
argument_list|()
decl_stmt|;
DECL|field|positions
specifier|private
specifier|final
name|WrappedPositionArray
name|positions
init|=
operator|new
name|WrappedPositionArray
argument_list|()
decl_stmt|;
DECL|field|discardPunctuation
specifier|private
specifier|final
name|boolean
name|discardPunctuation
decl_stmt|;
DECL|field|searchMode
specifier|private
specifier|final
name|boolean
name|searchMode
decl_stmt|;
DECL|field|extendedMode
specifier|private
specifier|final
name|boolean
name|extendedMode
decl_stmt|;
DECL|field|outputCompounds
specifier|private
specifier|final
name|boolean
name|outputCompounds
decl_stmt|;
comment|// Index of the last character of unknown word:
DECL|field|unknownWordEndIndex
specifier|private
name|int
name|unknownWordEndIndex
init|=
operator|-
literal|1
decl_stmt|;
comment|// True once we've hit the EOF from the input reader:
DECL|field|end
specifier|private
name|boolean
name|end
decl_stmt|;
comment|// Last absolute position we backtraced from:
DECL|field|lastBackTracePos
specifier|private
name|int
name|lastBackTracePos
decl_stmt|;
comment|// Position of last token we returned; we use this to
comment|// figure out whether to set posIncr to 0 or 1:
DECL|field|lastTokenPos
specifier|private
name|int
name|lastTokenPos
decl_stmt|;
comment|// Next absolute position to process:
DECL|field|pos
specifier|private
name|int
name|pos
decl_stmt|;
comment|// Already parsed, but not yet passed to caller, tokens:
DECL|field|pending
specifier|private
specifier|final
name|List
argument_list|<
name|Token
argument_list|>
name|pending
init|=
operator|new
name|ArrayList
argument_list|<
name|Token
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|termAtt
specifier|private
specifier|final
name|CharTermAttribute
name|termAtt
init|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|offsetAtt
specifier|private
specifier|final
name|OffsetAttribute
name|offsetAtt
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|posIncAtt
specifier|private
specifier|final
name|PositionIncrementAttribute
name|posIncAtt
init|=
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|posLengthAtt
specifier|private
specifier|final
name|PositionLengthAttribute
name|posLengthAtt
init|=
name|addAttribute
argument_list|(
name|PositionLengthAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|basicFormAtt
specifier|private
specifier|final
name|BaseFormAttribute
name|basicFormAtt
init|=
name|addAttribute
argument_list|(
name|BaseFormAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|posAtt
specifier|private
specifier|final
name|PartOfSpeechAttribute
name|posAtt
init|=
name|addAttribute
argument_list|(
name|PartOfSpeechAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|readingAtt
specifier|private
specifier|final
name|ReadingAttribute
name|readingAtt
init|=
name|addAttribute
argument_list|(
name|ReadingAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|inflectionAtt
specifier|private
specifier|final
name|InflectionAttribute
name|inflectionAtt
init|=
name|addAttribute
argument_list|(
name|InflectionAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**    * Create a new JapaneseTokenizer.    *     * @param input Reader containing text    * @param userDictionary Optional: if non-null, user dictionary.    * @param discardPunctuation true if punctuation tokens should be dropped from the output.    * @param mode tokenization mode.    */
DECL|method|JapaneseTokenizer
specifier|public
name|JapaneseTokenizer
parameter_list|(
name|Reader
name|input
parameter_list|,
name|UserDictionary
name|userDictionary
parameter_list|,
name|boolean
name|discardPunctuation
parameter_list|,
name|Mode
name|mode
parameter_list|)
block|{
name|super
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|dictionary
operator|=
name|TokenInfoDictionary
operator|.
name|getInstance
argument_list|()
expr_stmt|;
name|fst
operator|=
name|dictionary
operator|.
name|getFST
argument_list|()
expr_stmt|;
name|unkDictionary
operator|=
name|UnknownDictionary
operator|.
name|getInstance
argument_list|()
expr_stmt|;
name|characterDefinition
operator|=
name|unkDictionary
operator|.
name|getCharacterDefinition
argument_list|()
expr_stmt|;
name|this
operator|.
name|userDictionary
operator|=
name|userDictionary
expr_stmt|;
name|costs
operator|=
name|ConnectionCosts
operator|.
name|getInstance
argument_list|()
expr_stmt|;
name|fstReader
operator|=
name|fst
operator|.
name|getBytesReader
argument_list|(
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|userDictionary
operator|!=
literal|null
condition|)
block|{
name|userFST
operator|=
name|userDictionary
operator|.
name|getFST
argument_list|()
expr_stmt|;
name|userFSTReader
operator|=
name|userFST
operator|.
name|getBytesReader
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|userFST
operator|=
literal|null
expr_stmt|;
name|userFSTReader
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|discardPunctuation
operator|=
name|discardPunctuation
expr_stmt|;
switch|switch
condition|(
name|mode
condition|)
block|{
case|case
name|SEARCH
case|:
name|searchMode
operator|=
literal|true
expr_stmt|;
name|extendedMode
operator|=
literal|false
expr_stmt|;
name|outputCompounds
operator|=
literal|true
expr_stmt|;
break|break;
case|case
name|EXTENDED
case|:
name|searchMode
operator|=
literal|true
expr_stmt|;
name|extendedMode
operator|=
literal|true
expr_stmt|;
name|outputCompounds
operator|=
literal|false
expr_stmt|;
break|break;
default|default:
name|searchMode
operator|=
literal|false
expr_stmt|;
name|extendedMode
operator|=
literal|false
expr_stmt|;
name|outputCompounds
operator|=
literal|false
expr_stmt|;
break|break;
block|}
name|buffer
operator|.
name|reset
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|resetState
argument_list|()
expr_stmt|;
name|dictionaryMap
operator|.
name|put
argument_list|(
name|Type
operator|.
name|KNOWN
argument_list|,
name|dictionary
argument_list|)
expr_stmt|;
name|dictionaryMap
operator|.
name|put
argument_list|(
name|Type
operator|.
name|UNKNOWN
argument_list|,
name|unkDictionary
argument_list|)
expr_stmt|;
name|dictionaryMap
operator|.
name|put
argument_list|(
name|Type
operator|.
name|USER
argument_list|,
name|userDictionary
argument_list|)
expr_stmt|;
block|}
DECL|field|dotOut
specifier|private
name|GraphvizFormatter
name|dotOut
decl_stmt|;
comment|/** Expert: set this to produce graphviz (dot) output of    *  the Viterbi lattice */
DECL|method|setGraphvizFormatter
specifier|public
name|void
name|setGraphvizFormatter
parameter_list|(
name|GraphvizFormatter
name|dotOut
parameter_list|)
block|{
name|this
operator|.
name|dotOut
operator|=
name|dotOut
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|(
name|Reader
name|input
parameter_list|)
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|reset
argument_list|(
name|input
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
name|resetState
argument_list|()
expr_stmt|;
block|}
DECL|method|resetState
specifier|private
name|void
name|resetState
parameter_list|()
block|{
name|positions
operator|.
name|reset
argument_list|()
expr_stmt|;
name|unknownWordEndIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|pos
operator|=
literal|0
expr_stmt|;
name|end
operator|=
literal|false
expr_stmt|;
name|lastBackTracePos
operator|=
literal|0
expr_stmt|;
name|lastTokenPos
operator|=
operator|-
literal|1
expr_stmt|;
name|pending
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// Add BOS:
name|positions
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|add
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
operator|-
literal|1
argument_list|,
operator|-
literal|1
argument_list|,
operator|-
literal|1
argument_list|,
name|Type
operator|.
name|KNOWN
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|end
specifier|public
name|void
name|end
parameter_list|()
block|{
comment|// Set final offset
name|int
name|finalOffset
init|=
name|correctOffset
argument_list|(
name|pos
argument_list|)
decl_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|finalOffset
argument_list|,
name|finalOffset
argument_list|)
expr_stmt|;
block|}
comment|// Returns the added cost that a 2nd best segmentation is
comment|// allowed to have.  Ie, if we see path with cost X,
comment|// ending in a compound word, and this method returns
comment|// threshold> 0, then we will also find the 2nd best
comment|// segmentation and if its path score is within this
comment|// threshold of X, we'll include it in the output:
DECL|method|computeSecondBestThreshold
specifier|private
name|int
name|computeSecondBestThreshold
parameter_list|(
name|int
name|pos
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: maybe we do something else here, instead of just
comment|// using the penalty...?  EG we can be more aggressive on
comment|// when to also test for 2nd best path
return|return
name|computePenalty
argument_list|(
name|pos
argument_list|,
name|length
argument_list|)
return|;
block|}
DECL|method|computePenalty
specifier|private
name|int
name|computePenalty
parameter_list|(
name|int
name|pos
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|length
operator|>
name|SEARCH_MODE_KANJI_LENGTH
condition|)
block|{
name|boolean
name|allKanji
init|=
literal|true
decl_stmt|;
comment|// check if node consists of only kanji
specifier|final
name|int
name|endPos
init|=
name|pos
operator|+
name|length
decl_stmt|;
for|for
control|(
name|int
name|pos2
init|=
name|pos
init|;
name|pos2
operator|<
name|endPos
condition|;
name|pos2
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|characterDefinition
operator|.
name|isKanji
argument_list|(
operator|(
name|char
operator|)
name|buffer
operator|.
name|get
argument_list|(
name|pos2
argument_list|)
argument_list|)
condition|)
block|{
name|allKanji
operator|=
literal|false
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|allKanji
condition|)
block|{
comment|// Process only Kanji keywords
return|return
operator|(
name|length
operator|-
name|SEARCH_MODE_KANJI_LENGTH
operator|)
operator|*
name|SEARCH_MODE_KANJI_PENALTY
return|;
block|}
elseif|else
if|if
condition|(
name|length
operator|>
name|SEARCH_MODE_OTHER_LENGTH
condition|)
block|{
return|return
operator|(
name|length
operator|-
name|SEARCH_MODE_OTHER_LENGTH
operator|)
operator|*
name|SEARCH_MODE_OTHER_PENALTY
return|;
block|}
block|}
return|return
literal|0
return|;
block|}
comment|// Holds all back pointers arriving to this position:
DECL|class|Position
specifier|final
specifier|static
class|class
name|Position
block|{
DECL|field|pos
name|int
name|pos
decl_stmt|;
DECL|field|count
name|int
name|count
decl_stmt|;
comment|// maybe single int array * 5?
DECL|field|costs
name|int
index|[]
name|costs
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|lastRightID
name|int
index|[]
name|lastRightID
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|backPos
name|int
index|[]
name|backPos
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|backIndex
name|int
index|[]
name|backIndex
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|backID
name|int
index|[]
name|backID
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|backType
name|Type
index|[]
name|backType
init|=
operator|new
name|Type
index|[
literal|8
index|]
decl_stmt|;
comment|// Only used when finding 2nd best segmentation under a
comment|// too-long token:
DECL|field|forwardCount
name|int
name|forwardCount
decl_stmt|;
DECL|field|forwardPos
name|int
index|[]
name|forwardPos
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|forwardID
name|int
index|[]
name|forwardID
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|forwardIndex
name|int
index|[]
name|forwardIndex
init|=
operator|new
name|int
index|[
literal|8
index|]
decl_stmt|;
DECL|field|forwardType
name|Type
index|[]
name|forwardType
init|=
operator|new
name|Type
index|[
literal|8
index|]
decl_stmt|;
DECL|method|grow
specifier|public
name|void
name|grow
parameter_list|()
block|{
name|costs
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|costs
argument_list|,
literal|1
operator|+
name|count
argument_list|)
expr_stmt|;
name|lastRightID
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|lastRightID
argument_list|,
literal|1
operator|+
name|count
argument_list|)
expr_stmt|;
name|backPos
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|backPos
argument_list|,
literal|1
operator|+
name|count
argument_list|)
expr_stmt|;
name|backIndex
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|backIndex
argument_list|,
literal|1
operator|+
name|count
argument_list|)
expr_stmt|;
name|backID
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|backID
argument_list|,
literal|1
operator|+
name|count
argument_list|)
expr_stmt|;
comment|// NOTE: sneaky: grow separately because
comment|// ArrayUtil.grow will otherwise pick a different
comment|// length than the int[]s we just grew:
specifier|final
name|Type
index|[]
name|newBackType
init|=
operator|new
name|Type
index|[
name|backID
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|backType
argument_list|,
literal|0
argument_list|,
name|newBackType
argument_list|,
literal|0
argument_list|,
name|backType
operator|.
name|length
argument_list|)
expr_stmt|;
name|backType
operator|=
name|newBackType
expr_stmt|;
block|}
DECL|method|growForward
specifier|public
name|void
name|growForward
parameter_list|()
block|{
name|forwardPos
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|forwardPos
argument_list|,
literal|1
operator|+
name|forwardCount
argument_list|)
expr_stmt|;
name|forwardID
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|forwardID
argument_list|,
literal|1
operator|+
name|forwardCount
argument_list|)
expr_stmt|;
name|forwardIndex
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|forwardIndex
argument_list|,
literal|1
operator|+
name|forwardCount
argument_list|)
expr_stmt|;
comment|// NOTE: sneaky: grow separately because
comment|// ArrayUtil.grow will otherwise pick a different
comment|// length than the int[]s we just grew:
specifier|final
name|Type
index|[]
name|newForwardType
init|=
operator|new
name|Type
index|[
name|forwardPos
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|forwardType
argument_list|,
literal|0
argument_list|,
name|newForwardType
argument_list|,
literal|0
argument_list|,
name|forwardType
operator|.
name|length
argument_list|)
expr_stmt|;
name|forwardType
operator|=
name|newForwardType
expr_stmt|;
block|}
DECL|method|add
specifier|public
name|void
name|add
parameter_list|(
name|int
name|cost
parameter_list|,
name|int
name|lastRightID
parameter_list|,
name|int
name|backPos
parameter_list|,
name|int
name|backIndex
parameter_list|,
name|int
name|backID
parameter_list|,
name|Type
name|backType
parameter_list|)
block|{
comment|// NOTE: this isn't quite a true Viterbit search,
comment|// becase we should check if lastRightID is
comment|// already present here, and only update if the new
comment|// cost is less than the current cost, instead of
comment|// simply appending.  However, that will likely hurt
comment|// performance (usually we add a lastRightID only once),
comment|// and it means we actually create the full graph
comment|// intersection instead of a "normal" Viterbi lattice:
if|if
condition|(
name|count
operator|==
name|costs
operator|.
name|length
condition|)
block|{
name|grow
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|costs
index|[
name|count
index|]
operator|=
name|cost
expr_stmt|;
name|this
operator|.
name|lastRightID
index|[
name|count
index|]
operator|=
name|lastRightID
expr_stmt|;
name|this
operator|.
name|backPos
index|[
name|count
index|]
operator|=
name|backPos
expr_stmt|;
name|this
operator|.
name|backIndex
index|[
name|count
index|]
operator|=
name|backIndex
expr_stmt|;
name|this
operator|.
name|backID
index|[
name|count
index|]
operator|=
name|backID
expr_stmt|;
name|this
operator|.
name|backType
index|[
name|count
index|]
operator|=
name|backType
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
DECL|method|addForward
specifier|public
name|void
name|addForward
parameter_list|(
name|int
name|forwardPos
parameter_list|,
name|int
name|forwardIndex
parameter_list|,
name|int
name|forwardID
parameter_list|,
name|Type
name|forwardType
parameter_list|)
block|{
if|if
condition|(
name|forwardCount
operator|==
name|this
operator|.
name|forwardID
operator|.
name|length
condition|)
block|{
name|growForward
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|forwardPos
index|[
name|forwardCount
index|]
operator|=
name|forwardPos
expr_stmt|;
name|this
operator|.
name|forwardIndex
index|[
name|forwardCount
index|]
operator|=
name|forwardIndex
expr_stmt|;
name|this
operator|.
name|forwardID
index|[
name|forwardCount
index|]
operator|=
name|forwardID
expr_stmt|;
name|this
operator|.
name|forwardType
index|[
name|forwardCount
index|]
operator|=
name|forwardType
expr_stmt|;
name|forwardCount
operator|++
expr_stmt|;
block|}
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
block|{
name|count
operator|=
literal|0
expr_stmt|;
comment|// forwardCount naturally resets after it runs:
assert|assert
name|forwardCount
operator|==
literal|0
operator|:
literal|"pos="
operator|+
name|pos
operator|+
literal|" forwardCount="
operator|+
name|forwardCount
assert|;
block|}
block|}
DECL|method|add
specifier|private
name|void
name|add
parameter_list|(
name|Dictionary
name|dict
parameter_list|,
name|Position
name|fromPosData
parameter_list|,
name|int
name|endPos
parameter_list|,
name|int
name|wordID
parameter_list|,
name|Type
name|type
parameter_list|,
name|boolean
name|addPenalty
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|int
name|wordCost
init|=
name|dict
operator|.
name|getWordCost
argument_list|(
name|wordID
argument_list|)
decl_stmt|;
specifier|final
name|int
name|leftID
init|=
name|dict
operator|.
name|getLeftId
argument_list|(
name|wordID
argument_list|)
decl_stmt|;
name|int
name|leastCost
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
name|int
name|leastIDX
init|=
operator|-
literal|1
decl_stmt|;
assert|assert
name|fromPosData
operator|.
name|count
operator|>
literal|0
assert|;
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|fromPosData
operator|.
name|count
condition|;
name|idx
operator|++
control|)
block|{
comment|// Cost is path cost so far, plus word cost (added at
comment|// end of loop), plus bigram cost:
specifier|final
name|int
name|cost
init|=
name|fromPosData
operator|.
name|costs
index|[
name|idx
index|]
operator|+
name|costs
operator|.
name|get
argument_list|(
name|fromPosData
operator|.
name|lastRightID
index|[
name|idx
index|]
argument_list|,
name|leftID
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      fromIDX="
operator|+
name|idx
operator|+
literal|": cost="
operator|+
name|cost
operator|+
literal|" (prevCost="
operator|+
name|fromPosData
operator|.
name|costs
index|[
name|idx
index|]
operator|+
literal|" wordCost="
operator|+
name|wordCost
operator|+
literal|" bgCost="
operator|+
name|costs
operator|.
name|get
argument_list|(
name|fromPosData
operator|.
name|lastRightID
index|[
name|idx
index|]
argument_list|,
name|leftID
argument_list|)
operator|+
literal|" leftID="
operator|+
name|leftID
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cost
operator|<
name|leastCost
condition|)
block|{
name|leastCost
operator|=
name|cost
expr_stmt|;
name|leastIDX
operator|=
name|idx
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"        **"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|leastCost
operator|+=
name|wordCost
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      + cost="
operator|+
name|leastCost
operator|+
literal|" wordID="
operator|+
name|wordID
operator|+
literal|" leftID="
operator|+
name|leftID
operator|+
literal|" leastIDX="
operator|+
name|leastIDX
operator|+
literal|" toPos="
operator|+
name|endPos
operator|+
literal|" toPos.idx="
operator|+
name|positions
operator|.
name|get
argument_list|(
name|endPos
argument_list|)
operator|.
name|count
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|addPenalty
operator|||
operator|(
operator|!
name|outputCompounds
operator|&&
name|searchMode
operator|)
operator|)
operator|&&
name|type
operator|!=
name|Type
operator|.
name|USER
condition|)
block|{
specifier|final
name|int
name|penalty
init|=
name|computePenalty
argument_list|(
name|fromPosData
operator|.
name|pos
argument_list|,
name|endPos
operator|-
name|fromPosData
operator|.
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
if|if
condition|(
name|penalty
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"        + penalty="
operator|+
name|penalty
operator|+
literal|" cost="
operator|+
operator|(
name|leastCost
operator|+
name|penalty
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
name|leastCost
operator|+=
name|penalty
expr_stmt|;
block|}
comment|//positions.get(endPos).add(leastCost, dict.getRightId(wordID), fromPosData.pos, leastIDX, wordID, type);
assert|assert
name|leftID
operator|==
name|dict
operator|.
name|getRightId
argument_list|(
name|wordID
argument_list|)
assert|;
name|positions
operator|.
name|get
argument_list|(
name|endPos
argument_list|)
operator|.
name|add
argument_list|(
name|leastCost
argument_list|,
name|leftID
argument_list|,
name|fromPosData
operator|.
name|pos
argument_list|,
name|leastIDX
argument_list|,
name|wordID
argument_list|,
name|type
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|incrementToken
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
comment|// parse() is able to return w/o producing any new
comment|// tokens, when the tokens it had produced were entirely
comment|// punctuation.  So we loop here until we get a real
comment|// token or we end:
while|while
condition|(
name|pending
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|end
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// Push Viterbi forward some more:
name|parse
argument_list|()
expr_stmt|;
block|}
specifier|final
name|Token
name|token
init|=
name|pending
operator|.
name|remove
argument_list|(
name|pending
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|int
name|position
init|=
name|token
operator|.
name|getPosition
argument_list|()
decl_stmt|;
name|int
name|length
init|=
name|token
operator|.
name|getLength
argument_list|()
decl_stmt|;
name|clearAttributes
argument_list|()
expr_stmt|;
assert|assert
name|length
operator|>
literal|0
assert|;
comment|//System.out.println("off=" + token.getOffset() + " len=" + length + " vs " + token.getSurfaceForm().length);
name|termAtt
operator|.
name|copyBuffer
argument_list|(
name|token
operator|.
name|getSurfaceForm
argument_list|()
argument_list|,
name|token
operator|.
name|getOffset
argument_list|()
argument_list|,
name|length
argument_list|)
expr_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|correctOffset
argument_list|(
name|position
argument_list|)
argument_list|,
name|correctOffset
argument_list|(
name|position
operator|+
name|length
argument_list|)
argument_list|)
expr_stmt|;
name|basicFormAtt
operator|.
name|setToken
argument_list|(
name|token
argument_list|)
expr_stmt|;
name|posAtt
operator|.
name|setToken
argument_list|(
name|token
argument_list|)
expr_stmt|;
name|readingAtt
operator|.
name|setToken
argument_list|(
name|token
argument_list|)
expr_stmt|;
name|inflectionAtt
operator|.
name|setToken
argument_list|(
name|token
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|getPosition
argument_list|()
operator|==
name|lastTokenPos
condition|)
block|{
name|posIncAtt
operator|.
name|setPositionIncrement
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|posLengthAtt
operator|.
name|setPositionLength
argument_list|(
name|token
operator|.
name|getPositionLength
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
assert|assert
name|token
operator|.
name|getPosition
argument_list|()
operator|>
name|lastTokenPos
assert|;
name|posIncAtt
operator|.
name|setPositionIncrement
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|posLengthAtt
operator|.
name|setPositionLength
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|":    incToken: return token="
operator|+
name|token
argument_list|)
expr_stmt|;
block|}
name|lastTokenPos
operator|=
name|token
operator|.
name|getPosition
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|// TODO: make generic'd version of this "circular array"?
comment|// It's a bit tricky because we do things to the Position
comment|// (eg, set .pos = N on reuse)...
DECL|class|WrappedPositionArray
specifier|static
specifier|final
class|class
name|WrappedPositionArray
block|{
DECL|field|positions
specifier|private
name|Position
index|[]
name|positions
init|=
operator|new
name|Position
index|[
literal|8
index|]
decl_stmt|;
DECL|method|WrappedPositionArray
specifier|public
name|WrappedPositionArray
parameter_list|()
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|positions
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|positions
index|[
name|i
index|]
operator|=
operator|new
name|Position
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Next array index to write to in positions:
DECL|field|nextWrite
specifier|private
name|int
name|nextWrite
decl_stmt|;
comment|// Next position to write:
DECL|field|nextPos
specifier|private
name|int
name|nextPos
decl_stmt|;
comment|// How many valid Position instances are held in the
comment|// positions array:
DECL|field|count
specifier|private
name|int
name|count
decl_stmt|;
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
block|{
name|nextWrite
operator|--
expr_stmt|;
while|while
condition|(
name|count
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|nextWrite
operator|==
operator|-
literal|1
condition|)
block|{
name|nextWrite
operator|=
name|positions
operator|.
name|length
operator|-
literal|1
expr_stmt|;
block|}
name|positions
index|[
name|nextWrite
operator|--
index|]
operator|.
name|reset
argument_list|()
expr_stmt|;
name|count
operator|--
expr_stmt|;
block|}
name|nextWrite
operator|=
literal|0
expr_stmt|;
name|nextPos
operator|=
literal|0
expr_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
block|}
comment|/** Get Position instance for this absolute position;      *  this is allowed to be arbitrarily far "in the      *  future" but cannot be before the last freeBefore. */
DECL|method|get
specifier|public
name|Position
name|get
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
while|while
condition|(
name|pos
operator|>=
name|nextPos
condition|)
block|{
comment|//System.out.println("count=" + count + " vs len=" + positions.length);
if|if
condition|(
name|count
operator|==
name|positions
operator|.
name|length
condition|)
block|{
name|Position
index|[]
name|newPositions
init|=
operator|new
name|Position
index|[
name|ArrayUtil
operator|.
name|oversize
argument_list|(
literal|1
operator|+
name|count
argument_list|,
name|RamUsageEstimator
operator|.
name|NUM_BYTES_OBJECT_REF
argument_list|)
index|]
decl_stmt|;
comment|//System.out.println("grow positions " + newPositions.length);
name|System
operator|.
name|arraycopy
argument_list|(
name|positions
argument_list|,
name|nextWrite
argument_list|,
name|newPositions
argument_list|,
literal|0
argument_list|,
name|positions
operator|.
name|length
operator|-
name|nextWrite
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|positions
argument_list|,
literal|0
argument_list|,
name|newPositions
argument_list|,
name|positions
operator|.
name|length
operator|-
name|nextWrite
argument_list|,
name|nextWrite
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
name|positions
operator|.
name|length
init|;
name|i
operator|<
name|newPositions
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|newPositions
index|[
name|i
index|]
operator|=
operator|new
name|Position
argument_list|()
expr_stmt|;
block|}
name|nextWrite
operator|=
name|positions
operator|.
name|length
expr_stmt|;
name|positions
operator|=
name|newPositions
expr_stmt|;
block|}
if|if
condition|(
name|nextWrite
operator|==
name|positions
operator|.
name|length
condition|)
block|{
name|nextWrite
operator|=
literal|0
expr_stmt|;
block|}
comment|// Should have already been reset:
assert|assert
name|positions
index|[
name|nextWrite
index|]
operator|.
name|count
operator|==
literal|0
assert|;
name|positions
index|[
name|nextWrite
operator|++
index|]
operator|.
name|pos
operator|=
name|nextPos
operator|++
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
assert|assert
name|inBounds
argument_list|(
name|pos
argument_list|)
assert|;
specifier|final
name|int
name|index
init|=
name|getIndex
argument_list|(
name|pos
argument_list|)
decl_stmt|;
assert|assert
name|positions
index|[
name|index
index|]
operator|.
name|pos
operator|==
name|pos
assert|;
return|return
name|positions
index|[
name|index
index|]
return|;
block|}
DECL|method|getNextPos
specifier|public
name|int
name|getNextPos
parameter_list|()
block|{
return|return
name|nextPos
return|;
block|}
comment|// For assert:
DECL|method|inBounds
specifier|private
name|boolean
name|inBounds
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
return|return
name|pos
operator|<
name|nextPos
operator|&&
name|pos
operator|>=
name|nextPos
operator|-
name|count
return|;
block|}
DECL|method|getIndex
specifier|private
name|int
name|getIndex
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
name|int
name|index
init|=
name|nextWrite
operator|-
operator|(
name|nextPos
operator|-
name|pos
operator|)
decl_stmt|;
if|if
condition|(
name|index
operator|<
literal|0
condition|)
block|{
name|index
operator|+=
name|positions
operator|.
name|length
expr_stmt|;
block|}
return|return
name|index
return|;
block|}
DECL|method|freeBefore
specifier|public
name|void
name|freeBefore
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
specifier|final
name|int
name|toFree
init|=
name|count
operator|-
operator|(
name|nextPos
operator|-
name|pos
operator|)
decl_stmt|;
assert|assert
name|toFree
operator|>=
literal|0
assert|;
assert|assert
name|toFree
operator|<=
name|count
assert|;
name|int
name|index
init|=
name|nextWrite
operator|-
name|count
decl_stmt|;
if|if
condition|(
name|index
operator|<
literal|0
condition|)
block|{
name|index
operator|+=
name|positions
operator|.
name|length
expr_stmt|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|toFree
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|index
operator|==
name|positions
operator|.
name|length
condition|)
block|{
name|index
operator|=
literal|0
expr_stmt|;
block|}
comment|//System.out.println("  fb idx=" + index);
name|positions
index|[
name|index
index|]
operator|.
name|reset
argument_list|()
expr_stmt|;
name|index
operator|++
expr_stmt|;
block|}
name|count
operator|-=
name|toFree
expr_stmt|;
block|}
block|}
comment|/* Incrementally parse some more characters.  This runs    * the viterbi search forwards "enough" so that we    * generate some more tokens.  How much forward depends on    * the chars coming in, since some chars could cause    * longer-lasting ambiguity in the parsing.  Once the    * ambiguity is resolved, then we back trace, produce    * the pending tokens, and return. */
DECL|method|parse
specifier|private
name|void
name|parse
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\nPARSE"
argument_list|)
expr_stmt|;
block|}
comment|// Advances over each position (character):
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|)
operator|==
operator|-
literal|1
condition|)
block|{
comment|// End
break|break;
block|}
specifier|final
name|Position
name|posData
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|isFrontier
init|=
name|positions
operator|.
name|getNextPos
argument_list|()
operator|==
name|pos
operator|+
literal|1
decl_stmt|;
if|if
condition|(
name|posData
operator|.
name|count
operator|==
literal|0
condition|)
block|{
comment|// No arcs arrive here; move to next position:
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    no arcs in; skip pos="
operator|+
name|pos
argument_list|)
expr_stmt|;
block|}
name|pos
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|pos
operator|>
name|lastBackTracePos
operator|&&
name|posData
operator|.
name|count
operator|==
literal|1
operator|&&
name|isFrontier
condition|)
block|{
comment|//  if (pos> lastBackTracePos&& posData.count == 1&& isFrontier) {
comment|// We are at a "frontier", and only one node is
comment|// alive, so whatever the eventual best path is must
comment|// come through this node.  So we can safely commit
comment|// to the prefix of the best path at this point:
name|backtrace
argument_list|(
name|posData
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|// Re-base cost so we don't risk int overflow:
name|posData
operator|.
name|costs
index|[
literal|0
index|]
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pending
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
else|else
block|{
comment|// This means the backtrace only produced
comment|// punctuation tokens, so we must keep parsing.
block|}
block|}
if|if
condition|(
name|pos
operator|-
name|lastBackTracePos
operator|>=
name|MAX_BACKTRACE_GAP
condition|)
block|{
comment|// Safety: if we've buffered too much, force a
comment|// backtrace now.  We find the least-cost partial
comment|// path, across all paths, backtrace from it, and
comment|// then prune all others.  Note that this, in
comment|// general, can produce the wrong result, if the
comment|// total bast path did not in fact back trace
comment|// through this partial best path.  But it's the
comment|// best we can do... (short of not having a
comment|// safety!).
comment|// First pass: find least cost parital path so far,
comment|// including ending at future positions:
name|int
name|leastIDX
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|leastCost
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
name|Position
name|leastPosData
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|pos2
init|=
name|pos
init|;
name|pos2
operator|<
name|positions
operator|.
name|getNextPos
argument_list|()
condition|;
name|pos2
operator|++
control|)
block|{
specifier|final
name|Position
name|posData2
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos2
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|posData2
operator|.
name|count
condition|;
name|idx
operator|++
control|)
block|{
comment|//System.out.println("    idx=" + idx + " cost=" + cost);
specifier|final
name|int
name|cost
init|=
name|posData2
operator|.
name|costs
index|[
name|idx
index|]
decl_stmt|;
if|if
condition|(
name|cost
operator|<
name|leastCost
condition|)
block|{
name|leastCost
operator|=
name|cost
expr_stmt|;
name|leastIDX
operator|=
name|idx
expr_stmt|;
name|leastPosData
operator|=
name|posData2
expr_stmt|;
block|}
block|}
block|}
comment|// We will always have at least one live path:
assert|assert
name|leastIDX
operator|!=
operator|-
literal|1
assert|;
comment|// Second pass: prune all but the best path:
for|for
control|(
name|int
name|pos2
init|=
name|pos
init|;
name|pos2
operator|<
name|positions
operator|.
name|getNextPos
argument_list|()
condition|;
name|pos2
operator|++
control|)
block|{
specifier|final
name|Position
name|posData2
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos2
argument_list|)
decl_stmt|;
if|if
condition|(
name|posData2
operator|!=
name|leastPosData
condition|)
block|{
name|posData2
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|leastIDX
operator|!=
literal|0
condition|)
block|{
name|posData2
operator|.
name|costs
index|[
literal|0
index|]
operator|=
name|posData2
operator|.
name|costs
index|[
name|leastIDX
index|]
expr_stmt|;
name|posData2
operator|.
name|lastRightID
index|[
literal|0
index|]
operator|=
name|posData2
operator|.
name|lastRightID
index|[
name|leastIDX
index|]
expr_stmt|;
name|posData2
operator|.
name|backPos
index|[
literal|0
index|]
operator|=
name|posData2
operator|.
name|backPos
index|[
name|leastIDX
index|]
expr_stmt|;
name|posData2
operator|.
name|backIndex
index|[
literal|0
index|]
operator|=
name|posData2
operator|.
name|backIndex
index|[
name|leastIDX
index|]
expr_stmt|;
name|posData2
operator|.
name|backID
index|[
literal|0
index|]
operator|=
name|posData2
operator|.
name|backID
index|[
name|leastIDX
index|]
expr_stmt|;
name|posData2
operator|.
name|backType
index|[
literal|0
index|]
operator|=
name|posData2
operator|.
name|backType
index|[
name|leastIDX
index|]
expr_stmt|;
block|}
name|posData2
operator|.
name|count
operator|=
literal|1
expr_stmt|;
block|}
block|}
name|backtrace
argument_list|(
name|leastPosData
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|// Re-base cost so we don't risk int overflow:
name|Arrays
operator|.
name|fill
argument_list|(
name|leastPosData
operator|.
name|costs
argument_list|,
literal|0
argument_list|,
name|leastPosData
operator|.
name|count
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|pos
operator|!=
name|leastPosData
operator|.
name|pos
condition|)
block|{
comment|// We jumped into a future position:
assert|assert
name|pos
operator|<
name|leastPosData
operator|.
name|pos
assert|;
name|pos
operator|=
name|leastPosData
operator|.
name|pos
expr_stmt|;
block|}
if|if
condition|(
name|pending
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
else|else
block|{
comment|// This means the backtrace only produced
comment|// punctuation tokens, so we must keep parsing.
continue|continue;
block|}
block|}
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\n  extend @ pos="
operator|+
name|pos
operator|+
literal|" char="
operator|+
operator|(
name|char
operator|)
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    "
operator|+
name|posData
operator|.
name|count
operator|+
literal|" arcs in"
argument_list|)
expr_stmt|;
block|}
name|boolean
name|anyMatches
init|=
literal|false
decl_stmt|;
comment|// First try user dict:
if|if
condition|(
name|userFST
operator|!=
literal|null
condition|)
block|{
name|userFST
operator|.
name|getFirstArc
argument_list|(
name|arc
argument_list|)
expr_stmt|;
name|int
name|output
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|posAhead
init|=
name|posData
operator|.
name|pos
init|;
condition|;
name|posAhead
operator|++
control|)
block|{
specifier|final
name|int
name|ch
init|=
name|buffer
operator|.
name|get
argument_list|(
name|posAhead
argument_list|)
decl_stmt|;
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|userFST
operator|.
name|findTargetArc
argument_list|(
name|ch
argument_list|,
name|arc
argument_list|,
name|arc
argument_list|,
name|posAhead
operator|==
name|posData
operator|.
name|pos
argument_list|,
name|userFSTReader
argument_list|)
operator|==
literal|null
condition|)
block|{
break|break;
block|}
name|output
operator|+=
name|arc
operator|.
name|output
operator|.
name|intValue
argument_list|()
expr_stmt|;
if|if
condition|(
name|arc
operator|.
name|isFinal
argument_list|()
condition|)
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    USER word "
operator|+
operator|new
name|String
argument_list|(
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|,
name|posAhead
operator|-
name|pos
operator|+
literal|1
argument_list|)
argument_list|)
operator|+
literal|" toPos="
operator|+
operator|(
name|posAhead
operator|+
literal|1
operator|)
argument_list|)
expr_stmt|;
block|}
name|add
argument_list|(
name|userDictionary
argument_list|,
name|posData
argument_list|,
name|posAhead
operator|+
literal|1
argument_list|,
name|output
operator|+
name|arc
operator|.
name|nextFinalOutput
operator|.
name|intValue
argument_list|()
argument_list|,
name|Type
operator|.
name|USER
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|anyMatches
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
comment|// TODO: we can be more aggressive about user
comment|// matches?  if we are "under" a user match then don't
comment|// extend KNOWN/UNKNOWN paths?
if|if
condition|(
operator|!
name|anyMatches
condition|)
block|{
comment|// Next, try known dictionary matches
name|fst
operator|.
name|getFirstArc
argument_list|(
name|arc
argument_list|)
expr_stmt|;
name|int
name|output
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|posAhead
init|=
name|posData
operator|.
name|pos
init|;
condition|;
name|posAhead
operator|++
control|)
block|{
specifier|final
name|int
name|ch
init|=
name|buffer
operator|.
name|get
argument_list|(
name|posAhead
argument_list|)
decl_stmt|;
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
break|break;
block|}
comment|//System.out.println("    match " + (char) ch + " posAhead=" + posAhead);
if|if
condition|(
name|fst
operator|.
name|findTargetArc
argument_list|(
name|ch
argument_list|,
name|arc
argument_list|,
name|arc
argument_list|,
name|posAhead
operator|==
name|posData
operator|.
name|pos
argument_list|,
name|fstReader
argument_list|)
operator|==
literal|null
condition|)
block|{
break|break;
block|}
name|output
operator|+=
name|arc
operator|.
name|output
operator|.
name|intValue
argument_list|()
expr_stmt|;
comment|// Optimization: for known words that are too-long
comment|// (compound), we should pre-compute the 2nd
comment|// best segmentation and store it in the
comment|// dictionary instead of recomputing it each time a
comment|// match is found.
if|if
condition|(
name|arc
operator|.
name|isFinal
argument_list|()
condition|)
block|{
name|dictionary
operator|.
name|lookupWordIds
argument_list|(
name|output
operator|+
name|arc
operator|.
name|nextFinalOutput
operator|.
name|intValue
argument_list|()
argument_list|,
name|wordIdRef
argument_list|)
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    KNOWN word "
operator|+
operator|new
name|String
argument_list|(
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|,
name|posAhead
operator|-
name|pos
operator|+
literal|1
argument_list|)
argument_list|)
operator|+
literal|" toPos="
operator|+
operator|(
name|posAhead
operator|+
literal|1
operator|)
operator|+
literal|" "
operator|+
name|wordIdRef
operator|.
name|length
operator|+
literal|" wordIDs"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|ofs
init|=
literal|0
init|;
name|ofs
operator|<
name|wordIdRef
operator|.
name|length
condition|;
name|ofs
operator|++
control|)
block|{
name|add
argument_list|(
name|dictionary
argument_list|,
name|posData
argument_list|,
name|posAhead
operator|+
literal|1
argument_list|,
name|wordIdRef
operator|.
name|ints
index|[
name|wordIdRef
operator|.
name|offset
operator|+
name|ofs
index|]
argument_list|,
name|Type
operator|.
name|KNOWN
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|anyMatches
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// In the case of normal mode, it doesn't process unknown word greedily.
if|if
condition|(
operator|!
name|searchMode
operator|&&
name|unknownWordEndIndex
operator|>
name|posData
operator|.
name|pos
condition|)
block|{
name|pos
operator|++
expr_stmt|;
continue|continue;
block|}
specifier|final
name|char
name|firstCharacter
init|=
operator|(
name|char
operator|)
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|anyMatches
operator|||
name|characterDefinition
operator|.
name|isInvoke
argument_list|(
name|firstCharacter
argument_list|)
condition|)
block|{
comment|// Find unknown match:
specifier|final
name|int
name|characterId
init|=
name|characterDefinition
operator|.
name|getCharacterClass
argument_list|(
name|firstCharacter
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|isPunct
init|=
name|isPunctuation
argument_list|(
name|firstCharacter
argument_list|)
decl_stmt|;
comment|// NOTE: copied from UnknownDictionary.lookup:
name|int
name|unknownWordLength
decl_stmt|;
if|if
condition|(
operator|!
name|characterDefinition
operator|.
name|isGroup
argument_list|(
name|firstCharacter
argument_list|)
condition|)
block|{
name|unknownWordLength
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
comment|// Extract unknown word. Characters with the same character class are considered to be part of unknown word
name|unknownWordLength
operator|=
literal|1
expr_stmt|;
for|for
control|(
name|int
name|posAhead
init|=
name|pos
operator|+
literal|1
init|;
name|unknownWordLength
operator|<
name|MAX_UNKNOWN_WORD_LENGTH
condition|;
name|posAhead
operator|++
control|)
block|{
specifier|final
name|int
name|ch
init|=
name|buffer
operator|.
name|get
argument_list|(
name|posAhead
argument_list|)
decl_stmt|;
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|characterId
operator|==
name|characterDefinition
operator|.
name|getCharacterClass
argument_list|(
operator|(
name|char
operator|)
name|ch
argument_list|)
operator|&&
name|isPunctuation
argument_list|(
operator|(
name|char
operator|)
name|ch
argument_list|)
operator|==
name|isPunct
condition|)
block|{
name|unknownWordLength
operator|++
expr_stmt|;
block|}
else|else
block|{
break|break;
block|}
block|}
block|}
name|unkDictionary
operator|.
name|lookupWordIds
argument_list|(
name|characterId
argument_list|,
name|wordIdRef
argument_list|)
expr_stmt|;
comment|// characters in input text are supposed to be the same
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    UNKNOWN word len="
operator|+
name|unknownWordLength
operator|+
literal|" "
operator|+
name|wordIdRef
operator|.
name|length
operator|+
literal|" wordIDs"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|ofs
init|=
literal|0
init|;
name|ofs
operator|<
name|wordIdRef
operator|.
name|length
condition|;
name|ofs
operator|++
control|)
block|{
name|add
argument_list|(
name|unkDictionary
argument_list|,
name|posData
argument_list|,
name|posData
operator|.
name|pos
operator|+
name|unknownWordLength
argument_list|,
name|wordIdRef
operator|.
name|ints
index|[
name|wordIdRef
operator|.
name|offset
operator|+
name|ofs
index|]
argument_list|,
name|Type
operator|.
name|UNKNOWN
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|unknownWordEndIndex
operator|=
name|posData
operator|.
name|pos
operator|+
name|unknownWordLength
expr_stmt|;
block|}
name|pos
operator|++
expr_stmt|;
block|}
name|end
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|pos
operator|>
literal|0
condition|)
block|{
specifier|final
name|Position
name|endPosData
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
name|int
name|leastCost
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
name|int
name|leastIDX
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"  end: "
operator|+
name|endPosData
operator|.
name|count
operator|+
literal|" nodes"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|endPosData
operator|.
name|count
condition|;
name|idx
operator|++
control|)
block|{
comment|// Add EOS cost:
specifier|final
name|int
name|cost
init|=
name|endPosData
operator|.
name|costs
index|[
name|idx
index|]
operator|+
name|costs
operator|.
name|get
argument_list|(
name|endPosData
operator|.
name|lastRightID
index|[
name|idx
index|]
argument_list|,
literal|0
argument_list|)
decl_stmt|;
comment|//System.out.println("    idx=" + idx + " cost=" + cost + " (pathCost=" + endPosData.costs[idx] + " bgCost=" + costs.get(endPosData.lastRightID[idx], 0) + ") backPos=" + endPosData.backPos[idx]);
if|if
condition|(
name|cost
operator|<
name|leastCost
condition|)
block|{
name|leastCost
operator|=
name|cost
expr_stmt|;
name|leastIDX
operator|=
name|idx
expr_stmt|;
block|}
block|}
name|backtrace
argument_list|(
name|endPosData
argument_list|,
name|leastIDX
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// No characters in the input string; return no tokens!
block|}
block|}
comment|// Eliminates arcs from the lattice that are compound
comment|// tokens (have a penalty) or are not congruent with the
comment|// compound token we've matched (ie, span across the
comment|// startPos).  This should be fairly efficient, because we
comment|// just keep the already intersected structure of the
comment|// graph, eg we don't have to consult the FSTs again:
DECL|method|pruneAndRescore
specifier|private
name|void
name|pruneAndRescore
parameter_list|(
name|int
name|startPos
parameter_list|,
name|int
name|endPos
parameter_list|,
name|int
name|bestStartIDX
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"  pruneAndRescore startPos="
operator|+
name|startPos
operator|+
literal|" endPos="
operator|+
name|endPos
operator|+
literal|" bestStartIDX="
operator|+
name|bestStartIDX
argument_list|)
expr_stmt|;
block|}
comment|// First pass: walk backwards, building up the forward
comment|// arcs and pruning inadmissible arcs:
for|for
control|(
name|int
name|pos
init|=
name|endPos
init|;
name|pos
operator|>
name|startPos
condition|;
name|pos
operator|--
control|)
block|{
specifier|final
name|Position
name|posData
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    back pos="
operator|+
name|pos
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|arcIDX
init|=
literal|0
init|;
name|arcIDX
operator|<
name|posData
operator|.
name|count
condition|;
name|arcIDX
operator|++
control|)
block|{
specifier|final
name|int
name|backPos
init|=
name|posData
operator|.
name|backPos
index|[
name|arcIDX
index|]
decl_stmt|;
if|if
condition|(
name|backPos
operator|>=
name|startPos
condition|)
block|{
comment|// Keep this arc:
comment|//System.out.println("      keep backPos=" + backPos);
name|positions
operator|.
name|get
argument_list|(
name|backPos
argument_list|)
operator|.
name|addForward
argument_list|(
name|pos
argument_list|,
name|arcIDX
argument_list|,
name|posData
operator|.
name|backID
index|[
name|arcIDX
index|]
argument_list|,
name|posData
operator|.
name|backType
index|[
name|arcIDX
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      prune"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|pos
operator|!=
name|startPos
condition|)
block|{
name|posData
operator|.
name|count
operator|=
literal|0
expr_stmt|;
block|}
block|}
comment|// Second pass: walk forward, re-scoring:
for|for
control|(
name|int
name|pos
init|=
name|startPos
init|;
name|pos
operator|<
name|endPos
condition|;
name|pos
operator|++
control|)
block|{
specifier|final
name|Position
name|posData
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    forward pos="
operator|+
name|pos
operator|+
literal|" count="
operator|+
name|posData
operator|.
name|forwardCount
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|posData
operator|.
name|count
operator|==
literal|0
condition|)
block|{
comment|// No arcs arrive here...
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      skip"
argument_list|)
expr_stmt|;
block|}
name|posData
operator|.
name|forwardCount
operator|=
literal|0
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|pos
operator|==
name|startPos
condition|)
block|{
comment|// On the initial position, only consider the best
comment|// path so we "force congruence":  the
comment|// sub-segmentation is "in context" of what the best
comment|// path (compound token) had matched:
specifier|final
name|int
name|rightID
decl_stmt|;
if|if
condition|(
name|startPos
operator|==
literal|0
condition|)
block|{
name|rightID
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|rightID
operator|=
name|getDict
argument_list|(
name|posData
operator|.
name|backType
index|[
name|bestStartIDX
index|]
argument_list|)
operator|.
name|getRightId
argument_list|(
name|posData
operator|.
name|backID
index|[
name|bestStartIDX
index|]
argument_list|)
expr_stmt|;
block|}
specifier|final
name|int
name|pathCost
init|=
name|posData
operator|.
name|costs
index|[
name|bestStartIDX
index|]
decl_stmt|;
for|for
control|(
name|int
name|forwardArcIDX
init|=
literal|0
init|;
name|forwardArcIDX
operator|<
name|posData
operator|.
name|forwardCount
condition|;
name|forwardArcIDX
operator|++
control|)
block|{
specifier|final
name|Type
name|forwardType
init|=
name|posData
operator|.
name|forwardType
index|[
name|forwardArcIDX
index|]
decl_stmt|;
specifier|final
name|Dictionary
name|dict2
init|=
name|getDict
argument_list|(
name|forwardType
argument_list|)
decl_stmt|;
specifier|final
name|int
name|wordID
init|=
name|posData
operator|.
name|forwardID
index|[
name|forwardArcIDX
index|]
decl_stmt|;
specifier|final
name|int
name|toPos
init|=
name|posData
operator|.
name|forwardPos
index|[
name|forwardArcIDX
index|]
decl_stmt|;
specifier|final
name|int
name|newCost
init|=
name|pathCost
operator|+
name|dict2
operator|.
name|getWordCost
argument_list|(
name|wordID
argument_list|)
operator|+
name|costs
operator|.
name|get
argument_list|(
name|rightID
argument_list|,
name|dict2
operator|.
name|getLeftId
argument_list|(
name|wordID
argument_list|)
argument_list|)
operator|+
name|computePenalty
argument_list|(
name|pos
argument_list|,
name|toPos
operator|-
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      + "
operator|+
name|forwardType
operator|+
literal|" word "
operator|+
operator|new
name|String
argument_list|(
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|,
name|toPos
operator|-
name|pos
argument_list|)
argument_list|)
operator|+
literal|" toPos="
operator|+
name|toPos
operator|+
literal|" cost="
operator|+
name|newCost
operator|+
literal|" penalty="
operator|+
name|computePenalty
argument_list|(
name|pos
argument_list|,
name|toPos
operator|-
name|pos
argument_list|)
operator|+
literal|" toPos.idx="
operator|+
name|positions
operator|.
name|get
argument_list|(
name|toPos
argument_list|)
operator|.
name|count
argument_list|)
expr_stmt|;
block|}
name|positions
operator|.
name|get
argument_list|(
name|toPos
argument_list|)
operator|.
name|add
argument_list|(
name|newCost
argument_list|,
name|dict2
operator|.
name|getRightId
argument_list|(
name|wordID
argument_list|)
argument_list|,
name|pos
argument_list|,
name|bestStartIDX
argument_list|,
name|wordID
argument_list|,
name|forwardType
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// On non-initial positions, we maximize score
comment|// across all arriving lastRightIDs:
for|for
control|(
name|int
name|forwardArcIDX
init|=
literal|0
init|;
name|forwardArcIDX
operator|<
name|posData
operator|.
name|forwardCount
condition|;
name|forwardArcIDX
operator|++
control|)
block|{
specifier|final
name|Type
name|forwardType
init|=
name|posData
operator|.
name|forwardType
index|[
name|forwardArcIDX
index|]
decl_stmt|;
specifier|final
name|int
name|toPos
init|=
name|posData
operator|.
name|forwardPos
index|[
name|forwardArcIDX
index|]
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      + "
operator|+
name|forwardType
operator|+
literal|" word "
operator|+
operator|new
name|String
argument_list|(
name|buffer
operator|.
name|get
argument_list|(
name|pos
argument_list|,
name|toPos
operator|-
name|pos
argument_list|)
argument_list|)
operator|+
literal|" toPos="
operator|+
name|toPos
argument_list|)
expr_stmt|;
block|}
name|add
argument_list|(
name|getDict
argument_list|(
name|forwardType
argument_list|)
argument_list|,
name|posData
argument_list|,
name|toPos
argument_list|,
name|posData
operator|.
name|forwardID
index|[
name|forwardArcIDX
index|]
argument_list|,
name|forwardType
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
name|posData
operator|.
name|forwardCount
operator|=
literal|0
expr_stmt|;
block|}
block|}
comment|// Backtrace from the provided position, back to the last
comment|// time we back-traced, accumulating the resulting tokens to
comment|// the pending list.  The pending list is then in-reverse
comment|// (last token should be returned first).
DECL|method|backtrace
specifier|private
name|void
name|backtrace
parameter_list|(
specifier|final
name|Position
name|endPosData
parameter_list|,
specifier|final
name|int
name|fromIDX
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|int
name|endPos
init|=
name|endPosData
operator|.
name|pos
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\n  backtrace: endPos="
operator|+
name|endPos
operator|+
literal|" pos="
operator|+
name|pos
operator|+
literal|"; "
operator|+
operator|(
name|pos
operator|-
name|lastBackTracePos
operator|)
operator|+
literal|" characters; last="
operator|+
name|lastBackTracePos
operator|+
literal|" cost="
operator|+
name|endPosData
operator|.
name|costs
index|[
name|fromIDX
index|]
argument_list|)
expr_stmt|;
block|}
specifier|final
name|char
index|[]
name|fragment
init|=
name|buffer
operator|.
name|get
argument_list|(
name|lastBackTracePos
argument_list|,
name|endPos
operator|-
name|lastBackTracePos
argument_list|)
decl_stmt|;
if|if
condition|(
name|dotOut
operator|!=
literal|null
condition|)
block|{
name|dotOut
operator|.
name|onBacktrace
argument_list|(
name|this
argument_list|,
name|positions
argument_list|,
name|lastBackTracePos
argument_list|,
name|endPosData
argument_list|,
name|fromIDX
argument_list|,
name|fragment
argument_list|,
name|end
argument_list|)
expr_stmt|;
block|}
name|int
name|pos
init|=
name|endPos
decl_stmt|;
name|int
name|bestIDX
init|=
name|fromIDX
decl_stmt|;
name|Token
name|altToken
init|=
literal|null
decl_stmt|;
comment|// We trace backwards, so this will be the leftWordID of
comment|// the token after the one we are now on:
name|int
name|lastLeftWordID
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|backCount
init|=
literal|0
decl_stmt|;
comment|// TODO: sort of silly to make Token instances here; the
comment|// back trace has all info needed to generate the
comment|// token.  So, we could just directly set the attrs,
comment|// from the backtrace, in incrementToken w/o ever
comment|// creating Token; we'd have to defer calling freeBefore
comment|// until after the bactrace was fully "consumed" by
comment|// incrementToken.
while|while
condition|(
name|pos
operator|>
name|lastBackTracePos
condition|)
block|{
comment|//System.out.println("BT: back pos=" + pos + " bestIDX=" + bestIDX);
specifier|final
name|Position
name|posData
init|=
name|positions
operator|.
name|get
argument_list|(
name|pos
argument_list|)
decl_stmt|;
assert|assert
name|bestIDX
operator|<
name|posData
operator|.
name|count
assert|;
name|int
name|backPos
init|=
name|posData
operator|.
name|backPos
index|[
name|bestIDX
index|]
decl_stmt|;
assert|assert
name|backPos
operator|>=
name|lastBackTracePos
operator|:
literal|"backPos="
operator|+
name|backPos
operator|+
literal|" vs lastBackTracePos="
operator|+
name|lastBackTracePos
assert|;
name|int
name|length
init|=
name|pos
operator|-
name|backPos
decl_stmt|;
name|Type
name|backType
init|=
name|posData
operator|.
name|backType
index|[
name|bestIDX
index|]
decl_stmt|;
name|int
name|backID
init|=
name|posData
operator|.
name|backID
index|[
name|bestIDX
index|]
decl_stmt|;
name|int
name|nextBestIDX
init|=
name|posData
operator|.
name|backIndex
index|[
name|bestIDX
index|]
decl_stmt|;
if|if
condition|(
name|outputCompounds
operator|&&
name|searchMode
operator|&&
name|altToken
operator|==
literal|null
operator|&&
name|backType
operator|!=
name|Type
operator|.
name|USER
condition|)
block|{
comment|// In searchMode, if best path had picked a too-long
comment|// token, we use the "penalty" to compute the allowed
comment|// max cost of an alternate back-trace.  If we find an
comment|// alternate back trace with cost below that
comment|// threshold, we pursue it instead (but also output
comment|// the long token).
comment|//System.out.println("    2nd best backPos=" + backPos + " pos=" + pos);
specifier|final
name|int
name|penalty
init|=
name|computeSecondBestThreshold
argument_list|(
name|backPos
argument_list|,
name|pos
operator|-
name|backPos
argument_list|)
decl_stmt|;
if|if
condition|(
name|penalty
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"  compound="
operator|+
operator|new
name|String
argument_list|(
name|buffer
operator|.
name|get
argument_list|(
name|backPos
argument_list|,
name|pos
operator|-
name|backPos
argument_list|)
argument_list|)
operator|+
literal|" backPos="
operator|+
name|backPos
operator|+
literal|" pos="
operator|+
name|pos
operator|+
literal|" penalty="
operator|+
name|penalty
operator|+
literal|" cost="
operator|+
name|posData
operator|.
name|costs
index|[
name|bestIDX
index|]
operator|+
literal|" bestIDX="
operator|+
name|bestIDX
operator|+
literal|" lastLeftID="
operator|+
name|lastLeftWordID
argument_list|)
expr_stmt|;
block|}
comment|// Use the penalty to set maxCost on the 2nd best
comment|// segmentation:
name|int
name|maxCost
init|=
name|posData
operator|.
name|costs
index|[
name|bestIDX
index|]
operator|+
name|penalty
decl_stmt|;
if|if
condition|(
name|lastLeftWordID
operator|!=
operator|-
literal|1
condition|)
block|{
name|maxCost
operator|+=
name|costs
operator|.
name|get
argument_list|(
name|getDict
argument_list|(
name|backType
argument_list|)
operator|.
name|getRightId
argument_list|(
name|backID
argument_list|)
argument_list|,
name|lastLeftWordID
argument_list|)
expr_stmt|;
block|}
comment|// Now, prune all too-long tokens from the graph:
name|pruneAndRescore
argument_list|(
name|backPos
argument_list|,
name|pos
argument_list|,
name|posData
operator|.
name|backIndex
index|[
name|bestIDX
index|]
argument_list|)
expr_stmt|;
comment|// Finally, find 2nd best back-trace and resume
comment|// backtrace there:
name|int
name|leastCost
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
name|int
name|leastIDX
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|posData
operator|.
name|count
condition|;
name|idx
operator|++
control|)
block|{
name|int
name|cost
init|=
name|posData
operator|.
name|costs
index|[
name|idx
index|]
decl_stmt|;
comment|//System.out.println("    idx=" + idx + " prevCost=" + cost);
if|if
condition|(
name|lastLeftWordID
operator|!=
operator|-
literal|1
condition|)
block|{
name|cost
operator|+=
name|costs
operator|.
name|get
argument_list|(
name|getDict
argument_list|(
name|posData
operator|.
name|backType
index|[
name|idx
index|]
argument_list|)
operator|.
name|getRightId
argument_list|(
name|posData
operator|.
name|backID
index|[
name|idx
index|]
argument_list|)
argument_list|,
name|lastLeftWordID
argument_list|)
expr_stmt|;
comment|//System.out.println("      += bgCost=" + costs.get(getDict(posData.backType[idx]).getRightId(posData.backID[idx]),
comment|//lastLeftWordID) + " -> " + cost);
block|}
comment|//System.out.println("penalty " + posData.backPos[idx] + " to " + pos);
comment|//cost += computePenalty(posData.backPos[idx], pos - posData.backPos[idx]);
if|if
condition|(
name|cost
operator|<
name|leastCost
condition|)
block|{
comment|//System.out.println("      ** ");
name|leastCost
operator|=
name|cost
expr_stmt|;
name|leastIDX
operator|=
name|idx
expr_stmt|;
block|}
block|}
comment|//System.out.println("  leastIDX=" + leastIDX);
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"  afterPrune: "
operator|+
name|posData
operator|.
name|count
operator|+
literal|" arcs arriving; leastCost="
operator|+
name|leastCost
operator|+
literal|" vs threshold="
operator|+
name|maxCost
operator|+
literal|" lastLeftWordID="
operator|+
name|lastLeftWordID
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|leastIDX
operator|!=
operator|-
literal|1
operator|&&
name|leastCost
operator|<=
name|maxCost
operator|&&
name|posData
operator|.
name|backPos
index|[
name|leastIDX
index|]
operator|!=
name|backPos
condition|)
block|{
comment|// We should have pruned the altToken from the graph:
assert|assert
name|posData
operator|.
name|backPos
index|[
name|leastIDX
index|]
operator|!=
name|backPos
assert|;
comment|// Save the current compound token, to output when
comment|// this alternate path joins back:
name|altToken
operator|=
operator|new
name|Token
argument_list|(
name|backID
argument_list|,
name|fragment
argument_list|,
name|backPos
operator|-
name|lastBackTracePos
argument_list|,
name|length
argument_list|,
name|backType
argument_list|,
name|backPos
argument_list|,
name|getDict
argument_list|(
name|backType
argument_list|)
argument_list|)
expr_stmt|;
comment|// Redirect our backtrace to 2nd best:
name|bestIDX
operator|=
name|leastIDX
expr_stmt|;
name|nextBestIDX
operator|=
name|posData
operator|.
name|backIndex
index|[
name|bestIDX
index|]
expr_stmt|;
name|backPos
operator|=
name|posData
operator|.
name|backPos
index|[
name|bestIDX
index|]
expr_stmt|;
name|length
operator|=
name|pos
operator|-
name|backPos
expr_stmt|;
name|backType
operator|=
name|posData
operator|.
name|backType
index|[
name|bestIDX
index|]
expr_stmt|;
name|backID
operator|=
name|posData
operator|.
name|backID
index|[
name|bestIDX
index|]
expr_stmt|;
name|backCount
operator|=
literal|0
expr_stmt|;
comment|//System.out.println("  do alt token!");
block|}
else|else
block|{
comment|// I think in theory it's possible there is no
comment|// 2nd best path, which is fine; in this case we
comment|// only output the compound token:
comment|//System.out.println("  no alt token! bestIDX=" + bestIDX);
block|}
block|}
block|}
specifier|final
name|int
name|offset
init|=
name|backPos
operator|-
name|lastBackTracePos
decl_stmt|;
assert|assert
name|offset
operator|>=
literal|0
assert|;
if|if
condition|(
name|altToken
operator|!=
literal|null
operator|&&
name|altToken
operator|.
name|getPosition
argument_list|()
operator|>=
name|backPos
condition|)
block|{
comment|// We've backtraced to the position where the
comment|// compound token starts; add it now:
comment|// The pruning we did when we created the altToken
comment|// ensures that the back trace will align back with
comment|// the start of the altToken:
assert|assert
name|altToken
operator|.
name|getPosition
argument_list|()
operator|==
name|backPos
operator|:
name|altToken
operator|.
name|getPosition
argument_list|()
operator|+
literal|" vs "
operator|+
name|backPos
assert|;
comment|// NOTE: not quite right: the compound token may
comment|// have had all punctuation back traced so far, but
comment|// then the decompounded token at this position is
comment|// not punctuation.  In this case backCount is 0,
comment|// but we should maybe add the altToken anyway...?
if|if
condition|(
name|backCount
operator|>
literal|0
condition|)
block|{
name|backCount
operator|++
expr_stmt|;
name|altToken
operator|.
name|setPositionLength
argument_list|(
name|backCount
argument_list|)
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    add altToken="
operator|+
name|altToken
argument_list|)
expr_stmt|;
block|}
name|pending
operator|.
name|add
argument_list|(
name|altToken
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// This means alt token was all punct tokens:
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    discard all-punctuation altToken="
operator|+
name|altToken
argument_list|)
expr_stmt|;
block|}
assert|assert
name|discardPunctuation
assert|;
block|}
name|altToken
operator|=
literal|null
expr_stmt|;
block|}
specifier|final
name|Dictionary
name|dict
init|=
name|getDict
argument_list|(
name|backType
argument_list|)
decl_stmt|;
if|if
condition|(
name|backType
operator|==
name|Type
operator|.
name|USER
condition|)
block|{
comment|// Expand the phraseID we recorded into the actual
comment|// segmentation:
specifier|final
name|int
index|[]
name|wordIDAndLength
init|=
name|userDictionary
operator|.
name|lookupSegmentation
argument_list|(
name|backID
argument_list|)
decl_stmt|;
name|int
name|wordID
init|=
name|wordIDAndLength
index|[
literal|0
index|]
decl_stmt|;
name|int
name|current
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|1
init|;
name|j
operator|<
name|wordIDAndLength
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
specifier|final
name|int
name|len
init|=
name|wordIDAndLength
index|[
name|j
index|]
decl_stmt|;
comment|//System.out.println("    add user: len=" + len);
name|pending
operator|.
name|add
argument_list|(
operator|new
name|Token
argument_list|(
name|wordID
operator|+
name|j
operator|-
literal|1
argument_list|,
name|fragment
argument_list|,
name|current
operator|+
name|offset
argument_list|,
name|len
argument_list|,
name|Type
operator|.
name|USER
argument_list|,
name|current
operator|+
name|backPos
argument_list|,
name|dict
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    add USER token="
operator|+
name|pending
operator|.
name|get
argument_list|(
name|pending
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|current
operator|+=
name|len
expr_stmt|;
block|}
comment|// Reverse the tokens we just added, because when we
comment|// serve them up from incrementToken we serve in
comment|// reverse:
name|Collections
operator|.
name|reverse
argument_list|(
name|pending
operator|.
name|subList
argument_list|(
name|pending
operator|.
name|size
argument_list|()
operator|-
operator|(
name|wordIDAndLength
operator|.
name|length
operator|-
literal|1
operator|)
argument_list|,
name|pending
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|backCount
operator|+=
name|wordIDAndLength
operator|.
name|length
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|extendedMode
operator|&&
name|backType
operator|==
name|Type
operator|.
name|UNKNOWN
condition|)
block|{
comment|// In EXTENDED mode we convert unknown word into
comment|// unigrams:
name|int
name|unigramTokenCount
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|int
name|charLen
init|=
literal|1
decl_stmt|;
if|if
condition|(
name|i
operator|>
literal|0
operator|&&
name|Character
operator|.
name|isLowSurrogate
argument_list|(
name|fragment
index|[
name|offset
operator|+
name|i
index|]
argument_list|)
condition|)
block|{
name|i
operator|--
expr_stmt|;
name|charLen
operator|=
literal|2
expr_stmt|;
block|}
comment|//System.out.println("    extended tok offset="
comment|//+ (offset + i));
if|if
condition|(
operator|!
name|discardPunctuation
operator|||
operator|!
name|isPunctuation
argument_list|(
name|fragment
index|[
name|offset
operator|+
name|i
index|]
argument_list|)
condition|)
block|{
name|pending
operator|.
name|add
argument_list|(
operator|new
name|Token
argument_list|(
name|CharacterDefinition
operator|.
name|NGRAM
argument_list|,
name|fragment
argument_list|,
name|offset
operator|+
name|i
argument_list|,
name|charLen
argument_list|,
name|Type
operator|.
name|UNKNOWN
argument_list|,
name|backPos
operator|+
name|i
argument_list|,
name|unkDictionary
argument_list|)
argument_list|)
expr_stmt|;
name|unigramTokenCount
operator|++
expr_stmt|;
block|}
block|}
name|backCount
operator|+=
name|unigramTokenCount
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|discardPunctuation
operator|||
name|length
operator|==
literal|0
operator|||
operator|!
name|isPunctuation
argument_list|(
name|fragment
index|[
name|offset
index|]
argument_list|)
condition|)
block|{
name|pending
operator|.
name|add
argument_list|(
operator|new
name|Token
argument_list|(
name|backID
argument_list|,
name|fragment
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|backType
argument_list|,
name|backPos
argument_list|,
name|dict
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    add token="
operator|+
name|pending
operator|.
name|get
argument_list|(
name|pending
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|backCount
operator|++
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    skip punctuation token="
operator|+
operator|new
name|String
argument_list|(
name|fragment
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|lastLeftWordID
operator|=
name|dict
operator|.
name|getLeftId
argument_list|(
name|backID
argument_list|)
expr_stmt|;
name|pos
operator|=
name|backPos
expr_stmt|;
name|bestIDX
operator|=
name|nextBestIDX
expr_stmt|;
block|}
name|lastBackTracePos
operator|=
name|endPos
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"  freeBefore pos="
operator|+
name|endPos
argument_list|)
expr_stmt|;
block|}
comment|// Notify the circular buffers that we are done with
comment|// these positions:
name|buffer
operator|.
name|freeBefore
argument_list|(
name|endPos
argument_list|)
expr_stmt|;
name|positions
operator|.
name|freeBefore
argument_list|(
name|endPos
argument_list|)
expr_stmt|;
block|}
DECL|method|getDict
name|Dictionary
name|getDict
parameter_list|(
name|Type
name|type
parameter_list|)
block|{
return|return
name|dictionaryMap
operator|.
name|get
argument_list|(
name|type
argument_list|)
return|;
block|}
DECL|method|isPunctuation
specifier|private
specifier|static
name|boolean
name|isPunctuation
parameter_list|(
name|char
name|ch
parameter_list|)
block|{
switch|switch
condition|(
name|Character
operator|.
name|getType
argument_list|(
name|ch
argument_list|)
condition|)
block|{
case|case
name|Character
operator|.
name|SPACE_SEPARATOR
case|:
case|case
name|Character
operator|.
name|LINE_SEPARATOR
case|:
case|case
name|Character
operator|.
name|PARAGRAPH_SEPARATOR
case|:
case|case
name|Character
operator|.
name|CONTROL
case|:
case|case
name|Character
operator|.
name|FORMAT
case|:
case|case
name|Character
operator|.
name|DASH_PUNCTUATION
case|:
case|case
name|Character
operator|.
name|START_PUNCTUATION
case|:
case|case
name|Character
operator|.
name|END_PUNCTUATION
case|:
case|case
name|Character
operator|.
name|CONNECTOR_PUNCTUATION
case|:
case|case
name|Character
operator|.
name|OTHER_PUNCTUATION
case|:
case|case
name|Character
operator|.
name|MATH_SYMBOL
case|:
case|case
name|Character
operator|.
name|CURRENCY_SYMBOL
case|:
case|case
name|Character
operator|.
name|MODIFIER_SYMBOL
case|:
case|case
name|Character
operator|.
name|OTHER_SYMBOL
case|:
case|case
name|Character
operator|.
name|INITIAL_QUOTE_PUNCTUATION
case|:
case|case
name|Character
operator|.
name|FINAL_QUOTE_PUNCTUATION
case|:
return|return
literal|true
return|;
default|default:
return|return
literal|false
return|;
block|}
block|}
block|}
end_class
end_unit
