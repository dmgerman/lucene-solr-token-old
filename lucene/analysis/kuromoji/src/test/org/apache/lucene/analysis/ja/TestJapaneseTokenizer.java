begin_unit
begin_package
DECL|package|org.apache.lucene.analysis.ja
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStreamReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|LineNumberReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Reader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|BaseTokenStreamTestCase
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|MockGraphTokenFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Tokenizer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|JapaneseTokenizer
operator|.
name|Mode
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|ConnectionCosts
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|dict
operator|.
name|UserDictionary
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ja
operator|.
name|tokenattributes
operator|.
name|*
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|TestUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|UnicodeUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|LuceneTestCase
operator|.
name|Slow
import|;
end_import
begin_class
DECL|class|TestJapaneseTokenizer
specifier|public
class|class
name|TestJapaneseTokenizer
extends|extends
name|BaseTokenStreamTestCase
block|{
DECL|method|readDict
specifier|public
specifier|static
name|UserDictionary
name|readDict
parameter_list|()
block|{
name|InputStream
name|is
init|=
name|TestJapaneseTokenizer
operator|.
name|class
operator|.
name|getResourceAsStream
argument_list|(
literal|"userdict.txt"
argument_list|)
decl_stmt|;
if|if
condition|(
name|is
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cannot find userdict.txt in test classpath!"
argument_list|)
throw|;
block|}
try|try
block|{
try|try
block|{
name|Reader
name|reader
init|=
operator|new
name|InputStreamReader
argument_list|(
name|is
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
argument_list|)
decl_stmt|;
return|return
operator|new
name|UserDictionary
argument_list|(
name|reader
argument_list|)
return|;
block|}
finally|finally
block|{
name|is
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ioe
argument_list|)
throw|;
block|}
block|}
DECL|field|analyzer
specifier|private
name|Analyzer
name|analyzer
init|=
operator|new
name|Analyzer
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|createComponents
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|JapaneseTokenizer
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|,
name|readDict
argument_list|()
argument_list|,
literal|false
argument_list|,
name|Mode
operator|.
name|SEARCH
argument_list|)
decl_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|tokenizer
argument_list|,
name|tokenizer
argument_list|)
return|;
block|}
block|}
decl_stmt|;
DECL|field|analyzerNormal
specifier|private
name|Analyzer
name|analyzerNormal
init|=
operator|new
name|Analyzer
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|createComponents
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|JapaneseTokenizer
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|,
name|readDict
argument_list|()
argument_list|,
literal|false
argument_list|,
name|Mode
operator|.
name|NORMAL
argument_list|)
decl_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|tokenizer
argument_list|,
name|tokenizer
argument_list|)
return|;
block|}
block|}
decl_stmt|;
DECL|field|analyzerNoPunct
specifier|private
name|Analyzer
name|analyzerNoPunct
init|=
operator|new
name|Analyzer
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|createComponents
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|JapaneseTokenizer
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|,
name|readDict
argument_list|()
argument_list|,
literal|true
argument_list|,
name|Mode
operator|.
name|SEARCH
argument_list|)
decl_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|tokenizer
argument_list|,
name|tokenizer
argument_list|)
return|;
block|}
block|}
decl_stmt|;
DECL|field|extendedModeAnalyzerNoPunct
specifier|private
name|Analyzer
name|extendedModeAnalyzerNoPunct
init|=
operator|new
name|Analyzer
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|createComponents
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|JapaneseTokenizer
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|,
name|readDict
argument_list|()
argument_list|,
literal|true
argument_list|,
name|Mode
operator|.
name|EXTENDED
argument_list|)
decl_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|tokenizer
argument_list|,
name|tokenizer
argument_list|)
return|;
block|}
block|}
decl_stmt|;
DECL|method|testNormalMode
specifier|public
name|void
name|testNormalMode
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzerNormal
argument_list|,
literal|"ã·ãã¢ã½ããã¦ã§ã¢ã¨ã³ã¸ãã¢"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ã·ãã¢ã½ããã¦ã§ã¢ã¨ã³ã¸ãã¢"
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testDecomposition1
specifier|public
name|void
name|testDecomposition1
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzerNoPunct
argument_list|,
literal|"æ¬æ¥ã¯ãè²§å°å±¤ã®å¥³æ§ãå­ä¾ã«å»çä¿è­·ãæä¾ããããã«åµè¨­ãããå¶åº¦ã§ããã"
operator|+
literal|"ã¢ã¡ãªã«ä½æå¾èå»çæ´å©å¶åº¦ããä»æ¥ã§ã¯ããã®äºç®ã®ç´ï¼åã®ï¼ãèäººã«è²»ããã¦ããã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"æ¬æ¥"
block|,
literal|"ã¯"
block|,
literal|"è²§å°"
block|,
literal|"å±¤"
block|,
literal|"ã®"
block|,
literal|"å¥³æ§"
block|,
literal|"ã"
block|,
literal|"å­ä¾"
block|,
literal|"ã«"
block|,
literal|"å»ç"
block|,
literal|"ä¿è­·"
block|,
literal|"ã"
block|,
literal|"æä¾"
block|,
literal|"ãã"
block|,
literal|"ãã"
block|,
literal|"ã«"
block|,
literal|"åµè¨­"
block|,
literal|"ã"
block|,
literal|"ã"
block|,
literal|"ã"
block|,
literal|"å¶åº¦"
block|,
literal|"ã§"
block|,
literal|"ãã"
block|,
literal|"ã¢ã¡ãªã«"
block|,
literal|"ä½"
block|,
literal|"æå¾"
block|,
literal|"è"
block|,
literal|"å»ç"
block|,
literal|"æ´å©"
block|,
literal|"å¶åº¦"
block|,
literal|"ã"
block|,
literal|"ä»æ¥"
block|,
literal|"ã§"
block|,
literal|"ã¯"
block|,
literal|"ãã®"
block|,
literal|"äºç®"
block|,
literal|"ã®"
block|,
literal|"ç´"
block|,
literal|"ï¼"
block|,
literal|"åã®"
block|,
literal|"ï¼"
block|,
literal|"ã"
block|,
literal|"èäºº"
block|,
literal|"ã«"
block|,
literal|"è²»ãã"
block|,
literal|"ã¦"
block|,
literal|"ãã"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|4
block|,
literal|6
block|,
literal|7
block|,
literal|8
block|,
literal|10
block|,
literal|11
block|,
literal|13
block|,
literal|14
block|,
literal|16
block|,
literal|18
block|,
literal|19
block|,
literal|21
block|,
literal|23
block|,
literal|25
block|,
literal|26
block|,
literal|28
block|,
literal|29
block|,
literal|30
block|,
literal|31
block|,
literal|33
block|,
literal|34
block|,
literal|37
block|,
literal|41
block|,
literal|42
block|,
literal|44
block|,
literal|45
block|,
literal|47
block|,
literal|49
block|,
literal|51
block|,
literal|53
block|,
literal|55
block|,
literal|56
block|,
literal|58
block|,
literal|60
block|,
literal|62
block|,
literal|63
block|,
literal|64
block|,
literal|65
block|,
literal|67
block|,
literal|68
block|,
literal|69
block|,
literal|71
block|,
literal|72
block|,
literal|75
block|,
literal|76
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|6
block|,
literal|7
block|,
literal|8
block|,
literal|10
block|,
literal|11
block|,
literal|13
block|,
literal|14
block|,
literal|16
block|,
literal|18
block|,
literal|19
block|,
literal|21
block|,
literal|23
block|,
literal|25
block|,
literal|26
block|,
literal|28
block|,
literal|29
block|,
literal|30
block|,
literal|31
block|,
literal|33
block|,
literal|34
block|,
literal|36
block|,
literal|41
block|,
literal|42
block|,
literal|44
block|,
literal|45
block|,
literal|47
block|,
literal|49
block|,
literal|51
block|,
literal|52
block|,
literal|55
block|,
literal|56
block|,
literal|57
block|,
literal|60
block|,
literal|62
block|,
literal|63
block|,
literal|64
block|,
literal|65
block|,
literal|67
block|,
literal|68
block|,
literal|69
block|,
literal|71
block|,
literal|72
block|,
literal|75
block|,
literal|76
block|,
literal|78
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testDecomposition2
specifier|public
name|void
name|testDecomposition2
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzerNoPunct
argument_list|,
literal|"éº»è¬ã®å¯å£²ã¯æ ¹ãããçµ¶ãããªããã°ãªããªã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"éº»è¬"
block|,
literal|"ã®"
block|,
literal|"å¯å£²"
block|,
literal|"ã¯"
block|,
literal|"æ ¹ããã"
block|,
literal|"çµ¶ãã"
block|,
literal|"ãªãã"
block|,
literal|"ã°"
block|,
literal|"ãªã"
block|,
literal|"ãªã"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|3
block|,
literal|5
block|,
literal|6
block|,
literal|10
block|,
literal|13
block|,
literal|16
block|,
literal|17
block|,
literal|19
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|5
block|,
literal|6
block|,
literal|10
block|,
literal|13
block|,
literal|16
block|,
literal|17
block|,
literal|19
block|,
literal|21
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testDecomposition3
specifier|public
name|void
name|testDecomposition3
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzerNoPunct
argument_list|,
literal|"é­å¥³ç©å¤§å°ãã·ã¥ã¼ã»ããã­ã³ã¹ã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"é­å¥³"
block|,
literal|"ç©"
block|,
literal|"å¤§å°"
block|,
literal|"ãã·ã¥ã¼"
block|,
literal|"ããã­ã³ã¹"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|3
block|,
literal|5
block|,
literal|10
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|5
block|,
literal|9
block|,
literal|15
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testDecomposition4
specifier|public
name|void
name|testDecomposition4
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzer
argument_list|,
literal|"ããã¯æ¬ã§ã¯ãªã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ãã"
block|,
literal|"ã¯"
block|,
literal|"æ¬"
block|,
literal|"ã§"
block|,
literal|"ã¯"
block|,
literal|"ãªã"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|3
block|,
literal|4
block|,
literal|5
block|,
literal|6
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|4
block|,
literal|5
block|,
literal|6
block|,
literal|8
block|}
argument_list|)
expr_stmt|;
block|}
comment|/* Note this is really a stupid test just to see if things arent horribly slow.    * ideally the test would actually fail instead of hanging...    */
DECL|method|testDecomposition5
specifier|public
name|void
name|testDecomposition5
parameter_list|()
throws|throws
name|Exception
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"bogus"
argument_list|,
literal|"ãããããããããããããããããããããããããããããããããããããããã"
argument_list|)
init|)
block|{
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
block|{              }
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*     // NOTE: intentionally fails!  Just trying to debug this     // one input...   public void testDecomposition6() throws Exception {     assertAnalyzesTo(analyzer, "å¥è¯åç«¯ç§å­¦æè¡å¤§å­¦é¢å¤§å­¦",       new String[] { "ãã", "ã¯", "æ¬", "ã§", "ã¯", "ãªã" },       new int[] { 0, 2, 3, 4, 5, 6 },       new int[] { 2, 3, 4, 5, 6, 8 }                      );   }   */
comment|/** Tests that sentence offset is incorporated into the resulting offsets */
DECL|method|testTwoSentences
specifier|public
name|void
name|testTwoSentences
parameter_list|()
throws|throws
name|Exception
block|{
comment|/*     //TokenStream ts = a.tokenStream("foo", "å¦¹ã®å²å­ã§ããä¿ºã¨å¹´å­ã§ãä»åé¨çã§ãã");     TokenStream ts = analyzer.tokenStream("foo", "&#x250cdf66<!--\"<!--#<!--;?><!--#<!--#><!---->?>-->;");     ts.reset();     CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);     while(ts.incrementToken()) {       System.out.println("  " + termAtt.toString());     }     System.out.println("DONE PARSE\n\n");     */
name|assertAnalyzesTo
argument_list|(
name|analyzerNoPunct
argument_list|,
literal|"é­å¥³ç©å¤§å°ãã·ã¥ã¼ã»ããã­ã³ã¹ã é­å¥³ç©å¤§å°ãã·ã¥ã¼ã»ããã­ã³ã¹ã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"é­å¥³"
block|,
literal|"ç©"
block|,
literal|"å¤§å°"
block|,
literal|"ãã·ã¥ã¼"
block|,
literal|"ããã­ã³ã¹"
block|,
literal|"é­å¥³"
block|,
literal|"ç©"
block|,
literal|"å¤§å°"
block|,
literal|"ãã·ã¥ã¼"
block|,
literal|"ããã­ã³ã¹"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|3
block|,
literal|5
block|,
literal|10
block|,
literal|17
block|,
literal|19
block|,
literal|20
block|,
literal|22
block|,
literal|27
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|5
block|,
literal|9
block|,
literal|15
block|,
literal|19
block|,
literal|20
block|,
literal|22
block|,
literal|26
block|,
literal|32
block|}
argument_list|)
expr_stmt|;
block|}
comment|/** blast some random strings through the analyzer */
DECL|method|testRandomStrings
specifier|public
name|void
name|testRandomStrings
parameter_list|()
throws|throws
name|Exception
block|{
name|checkRandomData
argument_list|(
name|random
argument_list|()
argument_list|,
name|analyzer
argument_list|,
literal|500
operator|*
name|RANDOM_MULTIPLIER
argument_list|)
expr_stmt|;
name|checkRandomData
argument_list|(
name|random
argument_list|()
argument_list|,
name|analyzerNoPunct
argument_list|,
literal|500
operator|*
name|RANDOM_MULTIPLIER
argument_list|)
expr_stmt|;
block|}
comment|/** blast some random large strings through the analyzer */
DECL|method|testRandomHugeStrings
specifier|public
name|void
name|testRandomHugeStrings
parameter_list|()
throws|throws
name|Exception
block|{
name|Random
name|random
init|=
name|random
argument_list|()
decl_stmt|;
name|checkRandomData
argument_list|(
name|random
argument_list|,
name|analyzer
argument_list|,
literal|20
operator|*
name|RANDOM_MULTIPLIER
argument_list|,
literal|8192
argument_list|)
expr_stmt|;
name|checkRandomData
argument_list|(
name|random
argument_list|,
name|analyzerNoPunct
argument_list|,
literal|20
operator|*
name|RANDOM_MULTIPLIER
argument_list|,
literal|8192
argument_list|)
expr_stmt|;
block|}
DECL|method|testRandomHugeStringsMockGraphAfter
specifier|public
name|void
name|testRandomHugeStringsMockGraphAfter
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Randomly inject graph tokens after JapaneseTokenizer:
name|Random
name|random
init|=
name|random
argument_list|()
decl_stmt|;
name|checkRandomData
argument_list|(
name|random
argument_list|,
operator|new
name|Analyzer
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|createComponents
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
name|Tokenizer
name|tokenizer
init|=
operator|new
name|JapaneseTokenizer
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|,
name|readDict
argument_list|()
argument_list|,
literal|false
argument_list|,
name|Mode
operator|.
name|SEARCH
argument_list|)
decl_stmt|;
name|TokenStream
name|graph
init|=
operator|new
name|MockGraphTokenFilter
argument_list|(
name|random
argument_list|()
argument_list|,
name|tokenizer
argument_list|)
decl_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|tokenizer
argument_list|,
name|graph
argument_list|)
return|;
block|}
block|}
argument_list|,
literal|20
operator|*
name|RANDOM_MULTIPLIER
argument_list|,
literal|8192
argument_list|)
expr_stmt|;
block|}
DECL|method|testLargeDocReliability
specifier|public
name|void
name|testLargeDocReliability
parameter_list|()
throws|throws
name|Exception
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
literal|10
condition|;
name|i
operator|++
control|)
block|{
name|String
name|s
init|=
name|TestUtil
operator|.
name|randomUnicodeString
argument_list|(
name|random
argument_list|()
argument_list|,
literal|10000
argument_list|)
decl_stmt|;
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
name|s
argument_list|)
init|)
block|{
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
block|{         }
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/** simple test for supplementary characters */
DECL|method|testSurrogates
specifier|public
name|void
name|testSurrogates
parameter_list|()
throws|throws
name|IOException
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzer
argument_list|,
literal|"ð©¬è±éä¹æ¯ç"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ð©¬"
block|,
literal|"è±"
block|,
literal|"é"
block|,
literal|"ä¹"
block|,
literal|"æ¯"
block|,
literal|"ç"
block|}
argument_list|)
expr_stmt|;
block|}
comment|/** random test ensuring we don't ever split supplementaries */
DECL|method|testSurrogates2
specifier|public
name|void
name|testSurrogates2
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|numIterations
init|=
name|atLeast
argument_list|(
literal|10000
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numIterations
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"\nTEST: iter="
operator|+
name|i
argument_list|)
expr_stmt|;
block|}
name|String
name|s
init|=
name|TestUtil
operator|.
name|randomUnicodeString
argument_list|(
name|random
argument_list|()
argument_list|,
literal|100
argument_list|)
decl_stmt|;
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
name|s
argument_list|)
init|)
block|{
name|CharTermAttribute
name|termAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
name|assertTrue
argument_list|(
name|UnicodeUtil
operator|.
name|validUTF16String
argument_list|(
name|termAtt
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|method|testOnlyPunctuation
specifier|public
name|void
name|testOnlyPunctuation
parameter_list|()
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzerNoPunct
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"ãããã"
argument_list|)
init|)
block|{
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|testOnlyPunctuationExtended
specifier|public
name|void
name|testOnlyPunctuationExtended
parameter_list|()
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|extendedModeAnalyzerNoPunct
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"......"
argument_list|)
init|)
block|{
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
comment|// note: test is kinda silly since kuromoji emits punctuation tokens.
comment|// but, when/if we filter these out it will be useful.
DECL|method|testEnd
specifier|public
name|void
name|testEnd
parameter_list|()
throws|throws
name|Exception
block|{
name|assertTokenStreamContents
argument_list|(
name|analyzerNoPunct
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"ããã¯æ¬ã§ã¯ãªã"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ãã"
block|,
literal|"ã¯"
block|,
literal|"æ¬"
block|,
literal|"ã§"
block|,
literal|"ã¯"
block|,
literal|"ãªã"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|3
block|,
literal|4
block|,
literal|5
block|,
literal|6
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|4
block|,
literal|5
block|,
literal|6
block|,
literal|8
block|}
argument_list|,
operator|new
name|Integer
argument_list|(
literal|8
argument_list|)
argument_list|)
expr_stmt|;
name|assertTokenStreamContents
argument_list|(
name|analyzerNoPunct
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"ããã¯æ¬ã§ã¯ãªã    "
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ãã"
block|,
literal|"ã¯"
block|,
literal|"æ¬"
block|,
literal|"ã§"
block|,
literal|"ã¯"
block|,
literal|"ãªã"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|3
block|,
literal|4
block|,
literal|5
block|,
literal|6
block|,
literal|8
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|3
block|,
literal|4
block|,
literal|5
block|,
literal|6
block|,
literal|8
block|,
literal|9
block|}
argument_list|,
operator|new
name|Integer
argument_list|(
literal|12
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|testUserDict
specifier|public
name|void
name|testUserDict
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Not a great test because w/o userdict.txt the
comment|// segmentation is the same:
name|assertTokenStreamContents
argument_list|(
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"é¢è¥¿å½éç©ºæ¸¯ã«è¡ã£ã"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"é¢è¥¿"
block|,
literal|"å½é"
block|,
literal|"ç©ºæ¸¯"
block|,
literal|"ã«"
block|,
literal|"è¡ã£"
block|,
literal|"ã"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|2
block|,
literal|4
block|,
literal|6
block|,
literal|7
block|,
literal|9
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|2
block|,
literal|4
block|,
literal|6
block|,
literal|7
block|,
literal|9
block|,
literal|10
block|}
argument_list|,
operator|new
name|Integer
argument_list|(
literal|10
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|testUserDict2
specifier|public
name|void
name|testUserDict2
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Better test: w/o userdict the segmentation is different:
name|assertTokenStreamContents
argument_list|(
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"æéé¾"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"æéé¾"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|3
block|}
argument_list|,
operator|new
name|Integer
argument_list|(
literal|3
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|testUserDict3
specifier|public
name|void
name|testUserDict3
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Test entry that breaks into multiple tokens:
name|assertTokenStreamContents
argument_list|(
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"foo"
argument_list|,
literal|"abcd"
argument_list|)
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a"
block|,
literal|"b"
block|,
literal|"cd"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|1
block|,
literal|2
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|2
block|,
literal|4
block|}
argument_list|,
operator|new
name|Integer
argument_list|(
literal|4
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// HMM: fails (segments as a/b/cd/efghij)... because the
comment|// two paths have exactly equal paths (1 KNOWN + 1
comment|// UNKNOWN) and we don't seem to favor longer KNOWN /
comment|// shorter UNKNOWN matches:
comment|/*   public void testUserDict4() throws Exception {     // Test entry that has another entry as prefix     assertTokenStreamContents(analyzer.tokenStream("foo", "abcdefghij"),                               new String[] { "ab", "cd", "efg", "hij"  },                               new int[] { 0, 2, 4, 7 },                               new int[] { 2, 4, 7, 10 },                               new Integer(10)     );   }   */
DECL|method|testSegmentation
specifier|public
name|void
name|testSegmentation
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Skip tests for Michelle Kwan -- UniDic segments Kwan as ã¯ ã¯ã³
comment|//   String input = "ãã·ã§ã«ã»ã¯ã¯ã³ãåªåãã¾ãããã¹ãã¼ã¹ã¹ãã¼ã·ã§ã³ã«è¡ãã¾ããããããããã";
comment|//   String[] surfaceForms = {
comment|//        "ãã·ã§ã«", "ã»", "ã¯ã¯ã³", "ã", "åªå", "ã", "ã¾ã", "ã", "ã",
comment|//        "ã¹ãã¼ã¹", "ã¹ãã¼ã·ã§ã³", "ã«", "è¡ã", "ã¾ã", "ã",
comment|//        "ãããããã", "ã"
comment|//   };
name|String
name|input
init|=
literal|"ã¹ãã¼ã¹ã¹ãã¼ã·ã§ã³ã«è¡ãã¾ããããããããã"
decl_stmt|;
name|String
index|[]
name|surfaceForms
init|=
block|{
literal|"ã¹ãã¼ã¹"
block|,
literal|"ã¹ãã¼ã·ã§ã³"
block|,
literal|"ã«"
block|,
literal|"è¡ã"
block|,
literal|"ã¾ã"
block|,
literal|"ã"
block|,
literal|"ãããããã"
block|,
literal|"ã"
block|}
decl_stmt|;
name|assertAnalyzesTo
argument_list|(
name|analyzer
argument_list|,
name|input
argument_list|,
name|surfaceForms
argument_list|)
expr_stmt|;
block|}
DECL|method|testLatticeToDot
specifier|public
name|void
name|testLatticeToDot
parameter_list|()
throws|throws
name|Exception
block|{
specifier|final
name|GraphvizFormatter
name|gv2
init|=
operator|new
name|GraphvizFormatter
argument_list|(
name|ConnectionCosts
operator|.
name|getInstance
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|Analyzer
name|analyzer
init|=
operator|new
name|Analyzer
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|createComponents
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
name|JapaneseTokenizer
name|tokenizer
init|=
operator|new
name|JapaneseTokenizer
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|,
name|readDict
argument_list|()
argument_list|,
literal|false
argument_list|,
name|Mode
operator|.
name|SEARCH
argument_list|)
decl_stmt|;
name|tokenizer
operator|.
name|setGraphvizFormatter
argument_list|(
name|gv2
argument_list|)
expr_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|tokenizer
argument_list|,
name|tokenizer
argument_list|)
return|;
block|}
block|}
decl_stmt|;
name|String
name|input
init|=
literal|"ã¹ãã¼ã¹ã¹ãã¼ã·ã§ã³ã«è¡ãã¾ããããããããã"
decl_stmt|;
name|String
index|[]
name|surfaceForms
init|=
block|{
literal|"ã¹ãã¼ã¹"
block|,
literal|"ã¹ãã¼ã·ã§ã³"
block|,
literal|"ã«"
block|,
literal|"è¡ã"
block|,
literal|"ã¾ã"
block|,
literal|"ã"
block|,
literal|"ãããããã"
block|,
literal|"ã"
block|}
decl_stmt|;
name|assertAnalyzesTo
argument_list|(
name|analyzer
argument_list|,
name|input
argument_list|,
name|surfaceForms
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|gv2
operator|.
name|finish
argument_list|()
operator|.
name|indexOf
argument_list|(
literal|"22.0"
argument_list|)
operator|!=
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
DECL|method|assertReadings
specifier|private
name|void
name|assertReadings
parameter_list|(
name|String
name|input
parameter_list|,
name|String
modifier|...
name|readings
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|input
argument_list|)
init|)
block|{
name|ReadingAttribute
name|readingAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|ReadingAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|reading
range|:
name|readings
control|)
block|{
name|assertTrue
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|reading
argument_list|,
name|readingAtt
operator|.
name|getReading
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|assertPronunciations
specifier|private
name|void
name|assertPronunciations
parameter_list|(
name|String
name|input
parameter_list|,
name|String
modifier|...
name|pronunciations
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|input
argument_list|)
init|)
block|{
name|ReadingAttribute
name|readingAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|ReadingAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|pronunciation
range|:
name|pronunciations
control|)
block|{
name|assertTrue
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|pronunciation
argument_list|,
name|readingAtt
operator|.
name|getPronunciation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|assertBaseForms
specifier|private
name|void
name|assertBaseForms
parameter_list|(
name|String
name|input
parameter_list|,
name|String
modifier|...
name|baseForms
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|input
argument_list|)
init|)
block|{
name|BaseFormAttribute
name|baseFormAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|BaseFormAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|baseForm
range|:
name|baseForms
control|)
block|{
name|assertTrue
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|baseForm
argument_list|,
name|baseFormAtt
operator|.
name|getBaseForm
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|assertInflectionTypes
specifier|private
name|void
name|assertInflectionTypes
parameter_list|(
name|String
name|input
parameter_list|,
name|String
modifier|...
name|inflectionTypes
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|input
argument_list|)
init|)
block|{
name|InflectionAttribute
name|inflectionAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|InflectionAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|inflectionType
range|:
name|inflectionTypes
control|)
block|{
name|assertTrue
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|inflectionType
argument_list|,
name|inflectionAtt
operator|.
name|getInflectionType
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|assertInflectionForms
specifier|private
name|void
name|assertInflectionForms
parameter_list|(
name|String
name|input
parameter_list|,
name|String
modifier|...
name|inflectionForms
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|input
argument_list|)
init|)
block|{
name|InflectionAttribute
name|inflectionAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|InflectionAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|inflectionForm
range|:
name|inflectionForms
control|)
block|{
name|assertTrue
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|inflectionForm
argument_list|,
name|inflectionAtt
operator|.
name|getInflectionForm
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|assertPartsOfSpeech
specifier|private
name|void
name|assertPartsOfSpeech
parameter_list|(
name|String
name|input
parameter_list|,
name|String
modifier|...
name|partsOfSpeech
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|input
argument_list|)
init|)
block|{
name|PartOfSpeechAttribute
name|partOfSpeechAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|PartOfSpeechAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|partOfSpeech
range|:
name|partsOfSpeech
control|)
block|{
name|assertTrue
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|partOfSpeech
argument_list|,
name|partOfSpeechAtt
operator|.
name|getPartOfSpeech
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
name|ts
operator|.
name|incrementToken
argument_list|()
argument_list|)
expr_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|testReadings
specifier|public
name|void
name|testReadings
parameter_list|()
throws|throws
name|Exception
block|{
name|assertReadings
argument_list|(
literal|"å¯¿å¸ãé£ã¹ããã§ãã"
argument_list|,
literal|"ã¹ã·"
argument_list|,
literal|"ã¬"
argument_list|,
literal|"ã¿ã"
argument_list|,
literal|"ã¿ã¤"
argument_list|,
literal|"ãã¹"
argument_list|,
literal|"ã"
argument_list|)
expr_stmt|;
block|}
DECL|method|testReadings2
specifier|public
name|void
name|testReadings2
parameter_list|()
throws|throws
name|Exception
block|{
name|assertReadings
argument_list|(
literal|"å¤ãã®å­¦çãè©¦é¨ã«è½ã¡ãã"
argument_list|,
literal|"ãªãªã¯"
argument_list|,
literal|"ã"
argument_list|,
literal|"ã¬ã¯ã»ã¤"
argument_list|,
literal|"ã¬"
argument_list|,
literal|"ã·ã±ã³"
argument_list|,
literal|"ã"
argument_list|,
literal|"ãªã"
argument_list|,
literal|"ã¿"
argument_list|,
literal|"ã"
argument_list|)
expr_stmt|;
block|}
DECL|method|testPronunciations
specifier|public
name|void
name|testPronunciations
parameter_list|()
throws|throws
name|Exception
block|{
name|assertPronunciations
argument_list|(
literal|"å¯¿å¸ãé£ã¹ããã§ãã"
argument_list|,
literal|"ã¹ã·"
argument_list|,
literal|"ã¬"
argument_list|,
literal|"ã¿ã"
argument_list|,
literal|"ã¿ã¤"
argument_list|,
literal|"ãã¹"
argument_list|,
literal|"ã"
argument_list|)
expr_stmt|;
block|}
DECL|method|testPronunciations2
specifier|public
name|void
name|testPronunciations2
parameter_list|()
throws|throws
name|Exception
block|{
comment|// pronunciation differs from reading here
name|assertPronunciations
argument_list|(
literal|"å¤ãã®å­¦çãè©¦é¨ã«è½ã¡ãã"
argument_list|,
literal|"ãªã¼ã¯"
argument_list|,
literal|"ã"
argument_list|,
literal|"ã¬ã¯ã»ã¤"
argument_list|,
literal|"ã¬"
argument_list|,
literal|"ã·ã±ã³"
argument_list|,
literal|"ã"
argument_list|,
literal|"ãªã"
argument_list|,
literal|"ã¿"
argument_list|,
literal|"ã"
argument_list|)
expr_stmt|;
block|}
DECL|method|testBasicForms
specifier|public
name|void
name|testBasicForms
parameter_list|()
throws|throws
name|Exception
block|{
name|assertBaseForms
argument_list|(
literal|"ããã¯ã¾ã å®é¨æ®µéã«ããã¾ãã"
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|"ãã"
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
DECL|method|testInflectionTypes
specifier|public
name|void
name|testInflectionTypes
parameter_list|()
throws|throws
name|Exception
block|{
name|assertInflectionTypes
argument_list|(
literal|"ããã¯ã¾ã å®é¨æ®µéã«ããã¾ãã"
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|"äºæ®µã»ã©è¡"
argument_list|,
literal|"ç¹æ®ã»ãã¹"
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
DECL|method|testInflectionForms
specifier|public
name|void
name|testInflectionForms
parameter_list|()
throws|throws
name|Exception
block|{
name|assertInflectionForms
argument_list|(
literal|"ããã¯ã¾ã å®é¨æ®µéã«ããã¾ãã"
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|"é£ç¨å½¢"
argument_list|,
literal|"åºæ¬å½¢"
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
DECL|method|testPartOfSpeech
specifier|public
name|void
name|testPartOfSpeech
parameter_list|()
throws|throws
name|Exception
block|{
name|assertPartsOfSpeech
argument_list|(
literal|"ããã¯ã¾ã å®é¨æ®µéã«ããã¾ãã"
argument_list|,
literal|"åè©-ä»£åè©-ä¸è¬"
argument_list|,
literal|"å©è©-ä¿å©è©"
argument_list|,
literal|"å¯è©-å©è©é¡æ¥ç¶"
argument_list|,
literal|"åè©-ãµå¤æ¥ç¶"
argument_list|,
literal|"åè©-ä¸è¬"
argument_list|,
literal|"å©è©-æ ¼å©è©-ä¸è¬"
argument_list|,
literal|"åè©-èªç«"
argument_list|,
literal|"å©åè©"
argument_list|,
literal|"è¨å·-å¥ç¹"
argument_list|)
expr_stmt|;
block|}
comment|// TODO: the next 2 tests are no longer using the first/last word ids, maybe lookup the words and fix?
comment|// do we have a possibility to actually lookup the first and last word from dictionary?
DECL|method|testYabottai
specifier|public
name|void
name|testYabottai
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzer
argument_list|,
literal|"ãã¼ã£ãã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ãã¼ã£ãã"
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testTsukitosha
specifier|public
name|void
name|testTsukitosha
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzer
argument_list|,
literal|"çªãéãã"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"çªãéãã"
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testBocchan
specifier|public
name|void
name|testBocchan
parameter_list|()
throws|throws
name|Exception
block|{
name|doTestBocchan
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Nightly
DECL|method|testBocchanBig
specifier|public
name|void
name|testBocchanBig
parameter_list|()
throws|throws
name|Exception
block|{
name|doTestBocchan
argument_list|(
literal|100
argument_list|)
expr_stmt|;
block|}
comment|/*   public void testWikipedia() throws Exception {     final FileInputStream fis = new FileInputStream("/q/lucene/jawiki-20120220-pages-articles.xml");     final Reader r = new BufferedReader(new InputStreamReader(fis, StandardCharsets.UTF_8));      final long startTimeNS = System.nanoTime();     boolean done = false;     long compoundCount = 0;     long nonCompoundCount = 0;     long netOffset = 0;     while (!done) {       final TokenStream ts = analyzer.tokenStream("ignored", r);       ts.reset();       final PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);       final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);       int count = 0;       while (true) {         if (!ts.incrementToken()) {           done = true;           break;         }         count++;         if (posIncAtt.getPositionIncrement() == 0) {           compoundCount++;         } else {           nonCompoundCount++;           if (nonCompoundCount % 1000000 == 0) {             System.out.println(String.format("%.2f msec [pos=%d, %d, %d]",                                              (System.nanoTime()-startTimeNS)/1000000.0,                                              netOffset + offsetAtt.startOffset(),                                              nonCompoundCount,                                              compoundCount));           }         }         if (count == 100000000) {           System.out.println("  again...");           break;         }       }       ts.end();       netOffset += offsetAtt.endOffset();     }     System.out.println("compoundCount=" + compoundCount + " nonCompoundCount=" + nonCompoundCount);     r.close();   }   */
DECL|method|doTestBocchan
specifier|private
name|void
name|doTestBocchan
parameter_list|(
name|int
name|numIterations
parameter_list|)
throws|throws
name|Exception
block|{
name|LineNumberReader
name|reader
init|=
operator|new
name|LineNumberReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getResourceAsStream
argument_list|(
literal|"bocchan.utf-8"
argument_list|)
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|line
init|=
name|reader
operator|.
name|readLine
argument_list|()
decl_stmt|;
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Test for Bocchan without pre-splitting sentences"
argument_list|)
expr_stmt|;
block|}
comment|/*     if (numIterations> 1) {       // warmup       for (int i = 0; i< numIterations; i++) {         final TokenStream ts = analyzer.tokenStream("ignored", line);         ts.reset();         while(ts.incrementToken());       }     }     */
name|long
name|totalStart
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numIterations
condition|;
name|i
operator|++
control|)
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|line
argument_list|)
init|)
block|{
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
empty_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
name|String
index|[]
name|sentences
init|=
name|line
operator|.
name|split
argument_list|(
literal|"ã|ã"
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Total time : "
operator|+
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|totalStart
operator|)
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Test for Bocchan with pre-splitting sentences ("
operator|+
name|sentences
operator|.
name|length
operator|+
literal|" sentences)"
argument_list|)
expr_stmt|;
block|}
name|totalStart
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numIterations
condition|;
name|i
operator|++
control|)
block|{
for|for
control|(
name|String
name|sentence
range|:
name|sentences
control|)
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
literal|"ignored"
argument_list|,
name|sentence
argument_list|)
init|)
block|{
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
empty_stmt|;
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|VERBOSE
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Total time : "
operator|+
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|totalStart
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|testWithPunctuation
specifier|public
name|void
name|testWithPunctuation
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesTo
argument_list|(
name|analyzerNoPunct
argument_list|,
literal|"ç¾½ç°ãç©ºæ¸¯"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"ç¾½ç°"
block|,
literal|"ç©ºæ¸¯"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testCompoundOverPunctuation
specifier|public
name|void
name|testCompoundOverPunctuation
parameter_list|()
throws|throws
name|Exception
block|{
name|assertAnalyzesToPositions
argument_list|(
name|analyzerNoPunct
argument_list|,
literal|"dÎµÎµÏ¶Ï¢ÏÎÏ·ÎÍºç¾½ç°"
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"d"
block|,
literal|"Îµ"
block|,
literal|"Îµ"
block|,
literal|"Ï¢ÏÎÏ·ÎÍº"
block|,
literal|"ç¾½ç°"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
block|}
end_class
end_unit
