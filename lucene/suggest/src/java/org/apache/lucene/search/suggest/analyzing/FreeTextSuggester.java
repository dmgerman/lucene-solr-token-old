begin_unit
begin_package
DECL|package|org.apache.lucene.search.suggest.analyzing
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|analyzing
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_comment
comment|// TODO
end_comment
begin_comment
comment|//   - test w/ syns
end_comment
begin_comment
comment|//   - add pruning of low-freq ngrams?
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Files
import|;
end_import
begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Path
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|AnalyzerWrapper
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|shingle
operator|.
name|ShingleFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionLengthAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TermToBytesRefAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|CodecUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Document
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Field
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|FieldType
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|TextField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|DirectoryReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexOptions
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriterConfig
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MultiFields
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Terms
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|TermsEnum
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|InputIterator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|Lookup
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|ByteArrayDataInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|DataInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|DataOutput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|FSDirectory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Accountable
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Accountables
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|CharsRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IOUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntsRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IntsRefBuilder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|Builder
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|FST
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|FST
operator|.
name|Arc
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|FST
operator|.
name|BytesReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|Outputs
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|PositiveIntOutputs
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|Util
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|Util
operator|.
name|Result
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|Util
operator|.
name|TopResults
import|;
end_import
begin_comment
comment|//import java.io.PrintWriter;
end_comment
begin_comment
comment|/**  * Builds an ngram model from the text sent to {@link  * #build} and predicts based on the last grams-1 tokens in  * the request sent to {@link #lookup}.  This tries to  * handle the "long tail" of suggestions for when the  * incoming query is a never before seen query string.  *  *<p>Likely this suggester would only be used as a  * fallback, when the primary suggester fails to find  * any suggestions.  *  *<p>Note that the weight for each suggestion is unused,  * and the suggestions are the analyzed forms (so your  * analysis process should normally be very "light").  *  *<p>This uses the stupid backoff language model to smooth  * scores across ngram models; see  * "Large language models in machine translation",  * http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.76.1126  * for details.  *  *<p> From {@link #lookup}, the key of each result is the  * ngram token; the value is Long.MAX_VALUE * score (fixed  * point, cast to long).  Divide by Long.MAX_VALUE to get  * the score back, which ranges from 0.0 to 1.0.  *   * onlyMorePopular is unused.  *  * @lucene.experimental  */
end_comment
begin_comment
comment|// redundant 'implements Accountable' to workaround javadocs bugs
end_comment
begin_class
DECL|class|FreeTextSuggester
specifier|public
class|class
name|FreeTextSuggester
extends|extends
name|Lookup
implements|implements
name|Accountable
block|{
comment|/** Codec name used in the header for the saved model. */
DECL|field|CODEC_NAME
specifier|public
specifier|final
specifier|static
name|String
name|CODEC_NAME
init|=
literal|"freetextsuggest"
decl_stmt|;
comment|/** Initial version of the the saved model file format. */
DECL|field|VERSION_START
specifier|public
specifier|final
specifier|static
name|int
name|VERSION_START
init|=
literal|0
decl_stmt|;
comment|/** Current version of the the saved model file format. */
DECL|field|VERSION_CURRENT
specifier|public
specifier|final
specifier|static
name|int
name|VERSION_CURRENT
init|=
name|VERSION_START
decl_stmt|;
comment|/** By default we use a bigram model. */
DECL|field|DEFAULT_GRAMS
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_GRAMS
init|=
literal|2
decl_stmt|;
comment|// In general this could vary with gram, but the
comment|// original paper seems to use this constant:
comment|/** The constant used for backoff smoothing; during    *  lookup, this means that if a given trigram did not    *  occur, and we backoff to the bigram, the overall score    *  will be 0.4 times what the bigram model would have    *  assigned. */
DECL|field|ALPHA
specifier|public
specifier|final
specifier|static
name|double
name|ALPHA
init|=
literal|0.4
decl_stmt|;
comment|/** Holds 1gram, 2gram, 3gram models as a single FST. */
DECL|field|fst
specifier|private
name|FST
argument_list|<
name|Long
argument_list|>
name|fst
decl_stmt|;
comment|/**     * Analyzer that will be used for analyzing suggestions at    * index time.    */
DECL|field|indexAnalyzer
specifier|private
specifier|final
name|Analyzer
name|indexAnalyzer
decl_stmt|;
DECL|field|totTokens
specifier|private
name|long
name|totTokens
decl_stmt|;
comment|/**     * Analyzer that will be used for analyzing suggestions at    * query time.    */
DECL|field|queryAnalyzer
specifier|private
specifier|final
name|Analyzer
name|queryAnalyzer
decl_stmt|;
comment|// 2 = bigram, 3 = trigram
DECL|field|grams
specifier|private
specifier|final
name|int
name|grams
decl_stmt|;
DECL|field|separator
specifier|private
specifier|final
name|byte
name|separator
decl_stmt|;
comment|/** Number of entries the lookup was built with */
DECL|field|count
specifier|private
name|long
name|count
init|=
literal|0
decl_stmt|;
comment|/** The default character used to join multiple tokens    *  into a single ngram token.  The input tokens produced    *  by the analyzer must not contain this character. */
DECL|field|DEFAULT_SEPARATOR
specifier|public
specifier|static
specifier|final
name|byte
name|DEFAULT_SEPARATOR
init|=
literal|0x1e
decl_stmt|;
comment|/** Instantiate, using the provided analyzer for both    *  indexing and lookup, using bigram model by default. */
DECL|method|FreeTextSuggester
specifier|public
name|FreeTextSuggester
parameter_list|(
name|Analyzer
name|analyzer
parameter_list|)
block|{
name|this
argument_list|(
name|analyzer
argument_list|,
name|analyzer
argument_list|,
name|DEFAULT_GRAMS
argument_list|)
expr_stmt|;
block|}
comment|/** Instantiate, using the provided indexing and lookup    *  analyzers, using bigram model by default. */
DECL|method|FreeTextSuggester
specifier|public
name|FreeTextSuggester
parameter_list|(
name|Analyzer
name|indexAnalyzer
parameter_list|,
name|Analyzer
name|queryAnalyzer
parameter_list|)
block|{
name|this
argument_list|(
name|indexAnalyzer
argument_list|,
name|queryAnalyzer
argument_list|,
name|DEFAULT_GRAMS
argument_list|)
expr_stmt|;
block|}
comment|/** Instantiate, using the provided indexing and lookup    *  analyzers, with the specified model (2    *  = bigram, 3 = trigram, etc.). */
DECL|method|FreeTextSuggester
specifier|public
name|FreeTextSuggester
parameter_list|(
name|Analyzer
name|indexAnalyzer
parameter_list|,
name|Analyzer
name|queryAnalyzer
parameter_list|,
name|int
name|grams
parameter_list|)
block|{
name|this
argument_list|(
name|indexAnalyzer
argument_list|,
name|queryAnalyzer
argument_list|,
name|grams
argument_list|,
name|DEFAULT_SEPARATOR
argument_list|)
expr_stmt|;
block|}
comment|/** Instantiate, using the provided indexing and lookup    *  analyzers, and specified model (2 = bigram, 3 =    *  trigram ,etc.).  The separator is passed to {@link    *  ShingleFilter#setTokenSeparator} to join multiple    *  tokens into a single ngram token; it must be an ascii    *  (7-bit-clean) byte.  No input tokens should have this    *  byte, otherwise {@code IllegalArgumentException} is    *  thrown. */
DECL|method|FreeTextSuggester
specifier|public
name|FreeTextSuggester
parameter_list|(
name|Analyzer
name|indexAnalyzer
parameter_list|,
name|Analyzer
name|queryAnalyzer
parameter_list|,
name|int
name|grams
parameter_list|,
name|byte
name|separator
parameter_list|)
block|{
name|this
operator|.
name|grams
operator|=
name|grams
expr_stmt|;
name|this
operator|.
name|indexAnalyzer
operator|=
name|addShingles
argument_list|(
name|indexAnalyzer
argument_list|)
expr_stmt|;
name|this
operator|.
name|queryAnalyzer
operator|=
name|addShingles
argument_list|(
name|queryAnalyzer
argument_list|)
expr_stmt|;
if|if
condition|(
name|grams
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"grams must be>= 1"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|(
name|separator
operator|&
literal|0x80
operator|)
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"separator must be simple ascii character"
argument_list|)
throw|;
block|}
name|this
operator|.
name|separator
operator|=
name|separator
expr_stmt|;
block|}
comment|/** Returns byte size of the underlying FST. */
annotation|@
name|Override
DECL|method|ramBytesUsed
specifier|public
name|long
name|ramBytesUsed
parameter_list|()
block|{
if|if
condition|(
name|fst
operator|==
literal|null
condition|)
block|{
return|return
literal|0
return|;
block|}
return|return
name|fst
operator|.
name|ramBytesUsed
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|getChildResources
specifier|public
name|Collection
argument_list|<
name|Accountable
argument_list|>
name|getChildResources
parameter_list|()
block|{
if|if
condition|(
name|fst
operator|==
literal|null
condition|)
block|{
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
else|else
block|{
return|return
name|Collections
operator|.
name|singletonList
argument_list|(
name|Accountables
operator|.
name|namedAccountable
argument_list|(
literal|"fst"
argument_list|,
name|fst
argument_list|)
argument_list|)
return|;
block|}
block|}
DECL|class|AnalyzingComparator
specifier|private
specifier|static
class|class
name|AnalyzingComparator
implements|implements
name|Comparator
argument_list|<
name|BytesRef
argument_list|>
block|{
DECL|field|readerA
specifier|private
specifier|final
name|ByteArrayDataInput
name|readerA
init|=
operator|new
name|ByteArrayDataInput
argument_list|()
decl_stmt|;
DECL|field|readerB
specifier|private
specifier|final
name|ByteArrayDataInput
name|readerB
init|=
operator|new
name|ByteArrayDataInput
argument_list|()
decl_stmt|;
DECL|field|scratchA
specifier|private
specifier|final
name|BytesRef
name|scratchA
init|=
operator|new
name|BytesRef
argument_list|()
decl_stmt|;
DECL|field|scratchB
specifier|private
specifier|final
name|BytesRef
name|scratchB
init|=
operator|new
name|BytesRef
argument_list|()
decl_stmt|;
annotation|@
name|Override
DECL|method|compare
specifier|public
name|int
name|compare
parameter_list|(
name|BytesRef
name|a
parameter_list|,
name|BytesRef
name|b
parameter_list|)
block|{
name|readerA
operator|.
name|reset
argument_list|(
name|a
operator|.
name|bytes
argument_list|,
name|a
operator|.
name|offset
argument_list|,
name|a
operator|.
name|length
argument_list|)
expr_stmt|;
name|readerB
operator|.
name|reset
argument_list|(
name|b
operator|.
name|bytes
argument_list|,
name|b
operator|.
name|offset
argument_list|,
name|b
operator|.
name|length
argument_list|)
expr_stmt|;
comment|// By token:
name|scratchA
operator|.
name|length
operator|=
name|readerA
operator|.
name|readShort
argument_list|()
expr_stmt|;
name|scratchA
operator|.
name|bytes
operator|=
name|a
operator|.
name|bytes
expr_stmt|;
name|scratchA
operator|.
name|offset
operator|=
name|readerA
operator|.
name|getPosition
argument_list|()
expr_stmt|;
name|scratchB
operator|.
name|bytes
operator|=
name|b
operator|.
name|bytes
expr_stmt|;
name|scratchB
operator|.
name|length
operator|=
name|readerB
operator|.
name|readShort
argument_list|()
expr_stmt|;
name|scratchB
operator|.
name|offset
operator|=
name|readerB
operator|.
name|getPosition
argument_list|()
expr_stmt|;
name|int
name|cmp
init|=
name|scratchA
operator|.
name|compareTo
argument_list|(
name|scratchB
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
name|readerA
operator|.
name|skipBytes
argument_list|(
name|scratchA
operator|.
name|length
argument_list|)
expr_stmt|;
name|readerB
operator|.
name|skipBytes
argument_list|(
name|scratchB
operator|.
name|length
argument_list|)
expr_stmt|;
comment|// By length (smaller surface forms sorted first):
name|cmp
operator|=
name|a
operator|.
name|length
operator|-
name|b
operator|.
name|length
expr_stmt|;
if|if
condition|(
name|cmp
operator|!=
literal|0
condition|)
block|{
return|return
name|cmp
return|;
block|}
comment|// By surface form:
name|scratchA
operator|.
name|offset
operator|=
name|readerA
operator|.
name|getPosition
argument_list|()
expr_stmt|;
name|scratchA
operator|.
name|length
operator|=
name|a
operator|.
name|length
operator|-
name|scratchA
operator|.
name|offset
expr_stmt|;
name|scratchB
operator|.
name|offset
operator|=
name|readerB
operator|.
name|getPosition
argument_list|()
expr_stmt|;
name|scratchB
operator|.
name|length
operator|=
name|b
operator|.
name|length
operator|-
name|scratchB
operator|.
name|offset
expr_stmt|;
return|return
name|scratchA
operator|.
name|compareTo
argument_list|(
name|scratchB
argument_list|)
return|;
block|}
block|}
DECL|method|addShingles
specifier|private
name|Analyzer
name|addShingles
parameter_list|(
specifier|final
name|Analyzer
name|other
parameter_list|)
block|{
if|if
condition|(
name|grams
operator|==
literal|1
condition|)
block|{
return|return
name|other
return|;
block|}
else|else
block|{
comment|// TODO: use ShingleAnalyzerWrapper?
comment|// Tack on ShingleFilter to the end, to generate token ngrams:
return|return
operator|new
name|AnalyzerWrapper
argument_list|(
name|other
operator|.
name|getReuseStrategy
argument_list|()
argument_list|)
block|{
annotation|@
name|Override
specifier|protected
name|Analyzer
name|getWrappedAnalyzer
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
return|return
name|other
return|;
block|}
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|wrapComponents
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TokenStreamComponents
name|components
parameter_list|)
block|{
name|ShingleFilter
name|shingles
init|=
operator|new
name|ShingleFilter
argument_list|(
name|components
operator|.
name|getTokenStream
argument_list|()
argument_list|,
literal|2
argument_list|,
name|grams
argument_list|)
decl_stmt|;
name|shingles
operator|.
name|setTokenSeparator
argument_list|(
name|Character
operator|.
name|toString
argument_list|(
operator|(
name|char
operator|)
name|separator
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|components
operator|.
name|getTokenizer
argument_list|()
argument_list|,
name|shingles
argument_list|)
return|;
block|}
block|}
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|build
specifier|public
name|void
name|build
parameter_list|(
name|InputIterator
name|iterator
parameter_list|)
throws|throws
name|IOException
block|{
name|build
argument_list|(
name|iterator
argument_list|,
name|IndexWriterConfig
operator|.
name|DEFAULT_RAM_BUFFER_SIZE_MB
argument_list|)
expr_stmt|;
block|}
comment|/** Build the suggest index, using up to the specified    *  amount of temporary RAM while building.  Note that    *  the weights for the suggestions are ignored. */
DECL|method|build
specifier|public
name|void
name|build
parameter_list|(
name|InputIterator
name|iterator
parameter_list|,
name|double
name|ramBufferSizeMB
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|iterator
operator|.
name|hasPayloads
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"this suggester doesn't support payloads"
argument_list|)
throw|;
block|}
if|if
condition|(
name|iterator
operator|.
name|hasContexts
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"this suggester doesn't support contexts"
argument_list|)
throw|;
block|}
name|String
name|prefix
init|=
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
decl_stmt|;
name|Path
name|tempIndexPath
init|=
name|Files
operator|.
name|createTempDirectory
argument_list|(
name|prefix
operator|+
literal|".index."
argument_list|)
decl_stmt|;
name|Directory
name|dir
init|=
name|FSDirectory
operator|.
name|open
argument_list|(
name|tempIndexPath
argument_list|)
decl_stmt|;
name|IndexWriterConfig
name|iwc
init|=
operator|new
name|IndexWriterConfig
argument_list|(
name|indexAnalyzer
argument_list|)
decl_stmt|;
name|iwc
operator|.
name|setOpenMode
argument_list|(
name|IndexWriterConfig
operator|.
name|OpenMode
operator|.
name|CREATE
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setRAMBufferSizeMB
argument_list|(
name|ramBufferSizeMB
argument_list|)
expr_stmt|;
name|IndexWriter
name|writer
init|=
operator|new
name|IndexWriter
argument_list|(
name|dir
argument_list|,
name|iwc
argument_list|)
decl_stmt|;
name|FieldType
name|ft
init|=
operator|new
name|FieldType
argument_list|(
name|TextField
operator|.
name|TYPE_NOT_STORED
argument_list|)
decl_stmt|;
comment|// TODO: if only we had IndexOptions.TERMS_ONLY...
name|ft
operator|.
name|setIndexOptions
argument_list|(
name|IndexOptions
operator|.
name|DOCS_AND_FREQS
argument_list|)
expr_stmt|;
name|ft
operator|.
name|setOmitNorms
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|ft
operator|.
name|freeze
argument_list|()
expr_stmt|;
name|Document
name|doc
init|=
operator|new
name|Document
argument_list|()
decl_stmt|;
name|Field
name|field
init|=
operator|new
name|Field
argument_list|(
literal|"body"
argument_list|,
literal|""
argument_list|,
name|ft
argument_list|)
decl_stmt|;
name|doc
operator|.
name|add
argument_list|(
name|field
argument_list|)
expr_stmt|;
name|totTokens
operator|=
literal|0
expr_stmt|;
name|IndexReader
name|reader
init|=
literal|null
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
name|BytesRef
name|surfaceForm
init|=
name|iterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|surfaceForm
operator|==
literal|null
condition|)
block|{
break|break;
block|}
name|field
operator|.
name|setStringValue
argument_list|(
name|surfaceForm
operator|.
name|utf8ToString
argument_list|()
argument_list|)
expr_stmt|;
name|writer
operator|.
name|addDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
name|reader
operator|=
name|DirectoryReader
operator|.
name|open
argument_list|(
name|writer
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|Terms
name|terms
init|=
name|MultiFields
operator|.
name|getTerms
argument_list|(
name|reader
argument_list|,
literal|"body"
argument_list|)
decl_stmt|;
if|if
condition|(
name|terms
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"need at least one suggestion"
argument_list|)
throw|;
block|}
comment|// Move all ngrams into an FST:
name|TermsEnum
name|termsEnum
init|=
name|terms
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Outputs
argument_list|<
name|Long
argument_list|>
name|outputs
init|=
name|PositiveIntOutputs
operator|.
name|getSingleton
argument_list|()
decl_stmt|;
name|Builder
argument_list|<
name|Long
argument_list|>
name|builder
init|=
operator|new
name|Builder
argument_list|<>
argument_list|(
name|FST
operator|.
name|INPUT_TYPE
operator|.
name|BYTE1
argument_list|,
name|outputs
argument_list|)
decl_stmt|;
name|IntsRefBuilder
name|scratchInts
init|=
operator|new
name|IntsRefBuilder
argument_list|()
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|BytesRef
name|term
init|=
name|termsEnum
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|term
operator|==
literal|null
condition|)
block|{
break|break;
block|}
name|int
name|ngramCount
init|=
name|countGrams
argument_list|(
name|term
argument_list|)
decl_stmt|;
if|if
condition|(
name|ngramCount
operator|>
name|grams
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"tokens must not contain separator byte; got token="
operator|+
name|term
operator|+
literal|" but gramCount="
operator|+
name|ngramCount
operator|+
literal|", which is greater than expected max ngram size="
operator|+
name|grams
argument_list|)
throw|;
block|}
if|if
condition|(
name|ngramCount
operator|==
literal|1
condition|)
block|{
name|totTokens
operator|+=
name|termsEnum
operator|.
name|totalTermFreq
argument_list|()
expr_stmt|;
block|}
name|builder
operator|.
name|add
argument_list|(
name|Util
operator|.
name|toIntsRef
argument_list|(
name|term
argument_list|,
name|scratchInts
argument_list|)
argument_list|,
name|encodeWeight
argument_list|(
name|termsEnum
operator|.
name|totalTermFreq
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|fst
operator|=
name|builder
operator|.
name|finish
argument_list|()
expr_stmt|;
if|if
condition|(
name|fst
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"need at least one suggestion"
argument_list|)
throw|;
block|}
comment|//System.out.println("FST: " + fst.getNodeCount() + " nodes");
comment|/*       PrintWriter pw = new PrintWriter("/x/tmp/out.dot");       Util.toDot(fst, pw, true, true);       pw.close();       */
comment|// Writer was only temporary, to count up bigrams,
comment|// which we transferred to the FST, so now we
comment|// rollback:
name|writer
operator|.
name|rollback
argument_list|()
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
try|try
block|{
if|if
condition|(
name|success
condition|)
block|{
name|IOUtils
operator|.
name|close
argument_list|(
name|reader
argument_list|,
name|dir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|reader
argument_list|,
name|writer
argument_list|,
name|dir
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|rm
argument_list|(
name|tempIndexPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|store
specifier|public
name|boolean
name|store
parameter_list|(
name|DataOutput
name|output
parameter_list|)
throws|throws
name|IOException
block|{
name|CodecUtil
operator|.
name|writeHeader
argument_list|(
name|output
argument_list|,
name|CODEC_NAME
argument_list|,
name|VERSION_CURRENT
argument_list|)
expr_stmt|;
name|output
operator|.
name|writeVLong
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|output
operator|.
name|writeByte
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|output
operator|.
name|writeVInt
argument_list|(
name|grams
argument_list|)
expr_stmt|;
name|output
operator|.
name|writeVLong
argument_list|(
name|totTokens
argument_list|)
expr_stmt|;
name|fst
operator|.
name|save
argument_list|(
name|output
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
annotation|@
name|Override
DECL|method|load
specifier|public
name|boolean
name|load
parameter_list|(
name|DataInput
name|input
parameter_list|)
throws|throws
name|IOException
block|{
name|CodecUtil
operator|.
name|checkHeader
argument_list|(
name|input
argument_list|,
name|CODEC_NAME
argument_list|,
name|VERSION_START
argument_list|,
name|VERSION_START
argument_list|)
expr_stmt|;
name|count
operator|=
name|input
operator|.
name|readVLong
argument_list|()
expr_stmt|;
name|byte
name|separatorOrig
init|=
name|input
operator|.
name|readByte
argument_list|()
decl_stmt|;
if|if
condition|(
name|separatorOrig
operator|!=
name|separator
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"separator="
operator|+
name|separator
operator|+
literal|" is incorrect: original model was built with separator="
operator|+
name|separatorOrig
argument_list|)
throw|;
block|}
name|int
name|gramsOrig
init|=
name|input
operator|.
name|readVInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|gramsOrig
operator|!=
name|grams
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"grams="
operator|+
name|grams
operator|+
literal|" is incorrect: original model was built with grams="
operator|+
name|gramsOrig
argument_list|)
throw|;
block|}
name|totTokens
operator|=
name|input
operator|.
name|readVLong
argument_list|()
expr_stmt|;
name|fst
operator|=
operator|new
name|FST
argument_list|<>
argument_list|(
name|input
argument_list|,
name|PositiveIntOutputs
operator|.
name|getSingleton
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
annotation|@
name|Override
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
specifier|final
name|CharSequence
name|key
parameter_list|,
comment|/* ignored */
name|boolean
name|onlyMorePopular
parameter_list|,
name|int
name|num
parameter_list|)
block|{
return|return
name|lookup
argument_list|(
name|key
argument_list|,
literal|null
argument_list|,
name|onlyMorePopular
argument_list|,
name|num
argument_list|)
return|;
block|}
comment|/** Lookup, without any context. */
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
specifier|final
name|CharSequence
name|key
parameter_list|,
name|int
name|num
parameter_list|)
block|{
return|return
name|lookup
argument_list|(
name|key
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|,
name|num
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
specifier|final
name|CharSequence
name|key
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
comment|/* ignored */
name|boolean
name|onlyMorePopular
parameter_list|,
name|int
name|num
parameter_list|)
block|{
try|try
block|{
return|return
name|lookup
argument_list|(
name|key
argument_list|,
name|contexts
argument_list|,
name|num
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// bogus:
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ioe
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|getCount
specifier|public
name|long
name|getCount
parameter_list|()
block|{
return|return
name|count
return|;
block|}
DECL|method|countGrams
specifier|private
name|int
name|countGrams
parameter_list|(
name|BytesRef
name|token
parameter_list|)
block|{
name|int
name|count
init|=
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|token
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|token
operator|.
name|bytes
index|[
name|token
operator|.
name|offset
operator|+
name|i
index|]
operator|==
name|separator
condition|)
block|{
name|count
operator|++
expr_stmt|;
block|}
block|}
return|return
name|count
return|;
block|}
comment|/** Retrieve suggestions. */
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
specifier|final
name|CharSequence
name|key
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
name|int
name|num
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|contexts
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"this suggester doesn't support contexts"
argument_list|)
throw|;
block|}
if|if
condition|(
name|fst
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Lookup not supported at this time"
argument_list|)
throw|;
block|}
try|try
init|(
name|TokenStream
name|ts
init|=
name|queryAnalyzer
operator|.
name|tokenStream
argument_list|(
literal|""
argument_list|,
name|key
operator|.
name|toString
argument_list|()
argument_list|)
init|)
block|{
name|TermToBytesRefAttribute
name|termBytesAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|TermToBytesRefAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|OffsetAttribute
name|offsetAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|PositionLengthAttribute
name|posLenAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|PositionLengthAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|PositionIncrementAttribute
name|posIncAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
name|BytesRefBuilder
index|[]
name|lastTokens
init|=
operator|new
name|BytesRefBuilder
index|[
name|grams
index|]
decl_stmt|;
comment|//System.out.println("lookup: key='" + key + "'");
comment|// Run full analysis, but save only the
comment|// last 1gram, last 2gram, etc.:
name|BytesRef
name|tokenBytes
init|=
name|termBytesAtt
operator|.
name|getBytesRef
argument_list|()
decl_stmt|;
name|int
name|maxEndOffset
init|=
operator|-
literal|1
decl_stmt|;
name|boolean
name|sawRealToken
init|=
literal|false
decl_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
name|termBytesAtt
operator|.
name|fillBytesRef
argument_list|()
expr_stmt|;
name|sawRealToken
operator||=
name|tokenBytes
operator|.
name|length
operator|>
literal|0
expr_stmt|;
comment|// TODO: this is somewhat iffy; today, ShingleFilter
comment|// sets posLen to the gram count; maybe we should make
comment|// a separate dedicated att for this?
name|int
name|gramCount
init|=
name|posLenAtt
operator|.
name|getPositionLength
argument_list|()
decl_stmt|;
assert|assert
name|gramCount
operator|<=
name|grams
assert|;
comment|// Safety: make sure the recalculated count "agrees":
if|if
condition|(
name|countGrams
argument_list|(
name|tokenBytes
argument_list|)
operator|!=
name|gramCount
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"tokens must not contain separator byte; got token="
operator|+
name|tokenBytes
operator|+
literal|" but gramCount="
operator|+
name|gramCount
operator|+
literal|" does not match recalculated count="
operator|+
name|countGrams
argument_list|(
name|tokenBytes
argument_list|)
argument_list|)
throw|;
block|}
name|maxEndOffset
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxEndOffset
argument_list|,
name|offsetAtt
operator|.
name|endOffset
argument_list|()
argument_list|)
expr_stmt|;
name|BytesRefBuilder
name|b
init|=
operator|new
name|BytesRefBuilder
argument_list|()
decl_stmt|;
name|b
operator|.
name|append
argument_list|(
name|tokenBytes
argument_list|)
expr_stmt|;
name|lastTokens
index|[
name|gramCount
operator|-
literal|1
index|]
operator|=
name|b
expr_stmt|;
block|}
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|sawRealToken
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"no tokens produced by analyzer, or the only tokens were empty strings"
argument_list|)
throw|;
block|}
comment|// Carefully fill last tokens with _ tokens;
comment|// ShingleFilter appraently won't emit "only hole"
comment|// tokens:
name|int
name|endPosInc
init|=
name|posIncAtt
operator|.
name|getPositionIncrement
argument_list|()
decl_stmt|;
comment|// Note this will also be true if input is the empty
comment|// string (in which case we saw no tokens and
comment|// maxEndOffset is still -1), which in fact works out OK
comment|// because we fill the unigram with an empty BytesRef
comment|// below:
name|boolean
name|lastTokenEnded
init|=
name|offsetAtt
operator|.
name|endOffset
argument_list|()
operator|>
name|maxEndOffset
operator|||
name|endPosInc
operator|>
literal|0
decl_stmt|;
comment|//System.out.println("maxEndOffset=" + maxEndOffset + " vs " + offsetAtt.endOffset());
if|if
condition|(
name|lastTokenEnded
condition|)
block|{
comment|//System.out.println("  lastTokenEnded");
comment|// If user hit space after the last token, then
comment|// "upgrade" all tokens.  This way "foo " will suggest
comment|// all bigrams starting w/ foo, and not any unigrams
comment|// starting with "foo":
for|for
control|(
name|int
name|i
init|=
name|grams
operator|-
literal|1
init|;
name|i
operator|>
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|BytesRefBuilder
name|token
init|=
name|lastTokens
index|[
name|i
operator|-
literal|1
index|]
decl_stmt|;
if|if
condition|(
name|token
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|token
operator|.
name|append
argument_list|(
name|separator
argument_list|)
expr_stmt|;
name|lastTokens
index|[
name|i
index|]
operator|=
name|token
expr_stmt|;
block|}
name|lastTokens
index|[
literal|0
index|]
operator|=
operator|new
name|BytesRefBuilder
argument_list|()
expr_stmt|;
block|}
name|Arc
argument_list|<
name|Long
argument_list|>
name|arc
init|=
operator|new
name|Arc
argument_list|<>
argument_list|()
decl_stmt|;
name|BytesReader
name|bytesReader
init|=
name|fst
operator|.
name|getBytesReader
argument_list|()
decl_stmt|;
comment|// Try highest order models first, and if they return
comment|// results, return that; else, fallback:
name|double
name|backoff
init|=
literal|1.0
decl_stmt|;
name|List
argument_list|<
name|LookupResult
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|num
argument_list|)
decl_stmt|;
comment|// We only add a given suffix once, from the highest
comment|// order model that saw it; for subsequent lower order
comment|// models we skip it:
specifier|final
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|seen
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|gram
init|=
name|grams
operator|-
literal|1
init|;
name|gram
operator|>=
literal|0
condition|;
name|gram
operator|--
control|)
block|{
name|BytesRefBuilder
name|token
init|=
name|lastTokens
index|[
name|gram
index|]
decl_stmt|;
comment|// Don't make unigram predictions from empty string:
if|if
condition|(
name|token
operator|==
literal|null
operator|||
operator|(
name|token
operator|.
name|length
argument_list|()
operator|==
literal|0
operator|&&
name|key
operator|.
name|length
argument_list|()
operator|>
literal|0
operator|)
condition|)
block|{
comment|// Input didn't have enough tokens:
comment|//System.out.println("  gram=" + gram + ": skip: not enough input");
continue|continue;
block|}
if|if
condition|(
name|endPosInc
operator|>
literal|0
operator|&&
name|gram
operator|<=
name|endPosInc
condition|)
block|{
comment|// Skip hole-only predictions; in theory we
comment|// shouldn't have to do this, but we'd need to fix
comment|// ShingleFilter to produce only-hole tokens:
comment|//System.out.println("  break: only holes now");
break|break;
block|}
comment|//System.out.println("try " + (gram+1) + " gram token=" + token.utf8ToString());
comment|// TODO: we could add fuzziness here
comment|// match the prefix portion exactly
comment|//Pair<Long,BytesRef> prefixOutput = null;
name|Long
name|prefixOutput
init|=
literal|null
decl_stmt|;
try|try
block|{
name|prefixOutput
operator|=
name|lookupPrefix
argument_list|(
name|fst
argument_list|,
name|bytesReader
argument_list|,
name|token
operator|.
name|get
argument_list|()
argument_list|,
name|arc
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|bogus
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|bogus
argument_list|)
throw|;
block|}
comment|//System.out.println("  prefixOutput=" + prefixOutput);
if|if
condition|(
name|prefixOutput
operator|==
literal|null
condition|)
block|{
comment|// This model never saw this prefix, e.g. the
comment|// trigram model never saw context "purple mushroom"
name|backoff
operator|*=
name|ALPHA
expr_stmt|;
continue|continue;
block|}
comment|// TODO: we could do this division at build time, and
comment|// bake it into the FST?
comment|// Denominator for computing scores from current
comment|// model's predictions:
name|long
name|contextCount
init|=
name|totTokens
decl_stmt|;
name|BytesRef
name|lastTokenFragment
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|token
operator|.
name|length
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
if|if
condition|(
name|token
operator|.
name|byteAt
argument_list|(
name|i
argument_list|)
operator|==
name|separator
condition|)
block|{
name|BytesRef
name|context
init|=
operator|new
name|BytesRef
argument_list|(
name|token
operator|.
name|bytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|Long
name|output
init|=
name|Util
operator|.
name|get
argument_list|(
name|fst
argument_list|,
name|Util
operator|.
name|toIntsRef
argument_list|(
name|context
argument_list|,
operator|new
name|IntsRefBuilder
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
assert|assert
name|output
operator|!=
literal|null
assert|;
name|contextCount
operator|=
name|decodeWeight
argument_list|(
name|output
argument_list|)
expr_stmt|;
name|lastTokenFragment
operator|=
operator|new
name|BytesRef
argument_list|(
name|token
operator|.
name|bytes
argument_list|()
argument_list|,
name|i
operator|+
literal|1
argument_list|,
name|token
operator|.
name|length
argument_list|()
operator|-
name|i
operator|-
literal|1
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
specifier|final
name|BytesRefBuilder
name|finalLastToken
init|=
operator|new
name|BytesRefBuilder
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastTokenFragment
operator|==
literal|null
condition|)
block|{
name|finalLastToken
operator|.
name|copyBytes
argument_list|(
name|token
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|finalLastToken
operator|.
name|copyBytes
argument_list|(
name|lastTokenFragment
argument_list|)
expr_stmt|;
block|}
name|CharsRefBuilder
name|spare
init|=
operator|new
name|CharsRefBuilder
argument_list|()
decl_stmt|;
comment|// complete top-N
name|TopResults
argument_list|<
name|Long
argument_list|>
name|completions
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// Because we store multiple models in one FST
comment|// (1gram, 2gram, 3gram), we must restrict the
comment|// search so that it only considers the current
comment|// model.  For highest order model, this is not
comment|// necessary since all completions in the FST
comment|// must be from this model, but for lower order
comment|// models we have to filter out the higher order
comment|// ones:
comment|// Must do num+seen.size() for queue depth because we may
comment|// reject up to seen.size() paths in acceptResult():
name|Util
operator|.
name|TopNSearcher
argument_list|<
name|Long
argument_list|>
name|searcher
init|=
operator|new
name|Util
operator|.
name|TopNSearcher
argument_list|<
name|Long
argument_list|>
argument_list|(
name|fst
argument_list|,
name|num
argument_list|,
name|num
operator|+
name|seen
operator|.
name|size
argument_list|()
argument_list|,
name|weightComparator
argument_list|)
block|{
name|BytesRefBuilder
name|scratchBytes
init|=
operator|new
name|BytesRefBuilder
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|protected
name|void
name|addIfCompetitive
parameter_list|(
name|Util
operator|.
name|FSTPath
argument_list|<
name|Long
argument_list|>
name|path
parameter_list|)
block|{
if|if
condition|(
name|path
operator|.
name|arc
operator|.
name|label
operator|!=
name|separator
condition|)
block|{
comment|//System.out.println("    keep path: " + Util.toBytesRef(path.input, new BytesRef()).utf8ToString() + "; " + path + "; arc=" + path.arc);
name|super
operator|.
name|addIfCompetitive
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//System.out.println("    prevent path: " + Util.toBytesRef(path.input, new BytesRef()).utf8ToString() + "; " + path + "; arc=" + path.arc);
block|}
block|}
annotation|@
name|Override
specifier|protected
name|boolean
name|acceptResult
parameter_list|(
name|IntsRef
name|input
parameter_list|,
name|Long
name|output
parameter_list|)
block|{
name|Util
operator|.
name|toBytesRef
argument_list|(
name|input
argument_list|,
name|scratchBytes
argument_list|)
expr_stmt|;
name|finalLastToken
operator|.
name|grow
argument_list|(
name|finalLastToken
operator|.
name|length
argument_list|()
operator|+
name|scratchBytes
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|lenSav
init|=
name|finalLastToken
operator|.
name|length
argument_list|()
decl_stmt|;
name|finalLastToken
operator|.
name|append
argument_list|(
name|scratchBytes
argument_list|)
expr_stmt|;
comment|//System.out.println("    accept? input='" + scratchBytes.utf8ToString() + "'; lastToken='" + finalLastToken.utf8ToString() + "'; return " + (seen.contains(finalLastToken) == false));
name|boolean
name|ret
init|=
name|seen
operator|.
name|contains
argument_list|(
name|finalLastToken
operator|.
name|get
argument_list|()
argument_list|)
operator|==
literal|false
decl_stmt|;
name|finalLastToken
operator|.
name|setLength
argument_list|(
name|lenSav
argument_list|)
expr_stmt|;
return|return
name|ret
return|;
block|}
block|}
decl_stmt|;
comment|// since this search is initialized with a single start node
comment|// it is okay to start with an empty input path here
name|searcher
operator|.
name|addStartPaths
argument_list|(
name|arc
argument_list|,
name|prefixOutput
argument_list|,
literal|true
argument_list|,
operator|new
name|IntsRefBuilder
argument_list|()
argument_list|)
expr_stmt|;
name|completions
operator|=
name|searcher
operator|.
name|search
argument_list|()
expr_stmt|;
assert|assert
name|completions
operator|.
name|isComplete
assert|;
block|}
catch|catch
parameter_list|(
name|IOException
name|bogus
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|bogus
argument_list|)
throw|;
block|}
name|int
name|prefixLength
init|=
name|token
operator|.
name|length
argument_list|()
decl_stmt|;
name|BytesRefBuilder
name|suffix
init|=
operator|new
name|BytesRefBuilder
argument_list|()
decl_stmt|;
comment|//System.out.println("    " + completions.length + " completions");
name|nextCompletion
label|:
for|for
control|(
name|Result
argument_list|<
name|Long
argument_list|>
name|completion
range|:
name|completions
control|)
block|{
name|token
operator|.
name|setLength
argument_list|(
name|prefixLength
argument_list|)
expr_stmt|;
comment|// append suffix
name|Util
operator|.
name|toBytesRef
argument_list|(
name|completion
operator|.
name|input
argument_list|,
name|suffix
argument_list|)
expr_stmt|;
name|token
operator|.
name|append
argument_list|(
name|suffix
argument_list|)
expr_stmt|;
comment|//System.out.println("    completion " + token.utf8ToString());
comment|// Skip this path if a higher-order model already
comment|// saw/predicted its last token:
name|BytesRef
name|lastToken
init|=
name|token
operator|.
name|get
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|token
operator|.
name|length
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
if|if
condition|(
name|token
operator|.
name|byteAt
argument_list|(
name|i
argument_list|)
operator|==
name|separator
condition|)
block|{
assert|assert
name|token
operator|.
name|length
argument_list|()
operator|-
name|i
operator|-
literal|1
operator|>
literal|0
assert|;
name|lastToken
operator|=
operator|new
name|BytesRef
argument_list|(
name|token
operator|.
name|bytes
argument_list|()
argument_list|,
name|i
operator|+
literal|1
argument_list|,
name|token
operator|.
name|length
argument_list|()
operator|-
name|i
operator|-
literal|1
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|seen
operator|.
name|contains
argument_list|(
name|lastToken
argument_list|)
condition|)
block|{
comment|//System.out.println("      skip dup " + lastToken.utf8ToString());
continue|continue
name|nextCompletion
continue|;
block|}
name|seen
operator|.
name|add
argument_list|(
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|lastToken
argument_list|)
argument_list|)
expr_stmt|;
name|spare
operator|.
name|copyUTF8Bytes
argument_list|(
name|token
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|LookupResult
name|result
init|=
operator|new
name|LookupResult
argument_list|(
name|spare
operator|.
name|toString
argument_list|()
argument_list|,
call|(
name|long
call|)
argument_list|(
name|Long
operator|.
name|MAX_VALUE
operator|*
name|backoff
operator|*
operator|(
operator|(
name|double
operator|)
name|decodeWeight
argument_list|(
name|completion
operator|.
name|output
argument_list|)
operator|)
operator|/
name|contextCount
argument_list|)
argument_list|)
decl_stmt|;
name|results
operator|.
name|add
argument_list|(
name|result
argument_list|)
expr_stmt|;
assert|assert
name|results
operator|.
name|size
argument_list|()
operator|==
name|seen
operator|.
name|size
argument_list|()
assert|;
comment|//System.out.println("  add result=" + result);
block|}
name|backoff
operator|*=
name|ALPHA
expr_stmt|;
block|}
name|Collections
operator|.
name|sort
argument_list|(
name|results
argument_list|,
operator|new
name|Comparator
argument_list|<
name|LookupResult
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|LookupResult
name|a
parameter_list|,
name|LookupResult
name|b
parameter_list|)
block|{
if|if
condition|(
name|a
operator|.
name|value
operator|>
name|b
operator|.
name|value
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
elseif|else
if|if
condition|(
name|a
operator|.
name|value
operator|<
name|b
operator|.
name|value
condition|)
block|{
return|return
literal|1
return|;
block|}
else|else
block|{
comment|// Tie break by UTF16 sort order:
return|return
operator|(
operator|(
name|String
operator|)
name|a
operator|.
name|key
operator|)
operator|.
name|compareTo
argument_list|(
operator|(
name|String
operator|)
name|b
operator|.
name|key
argument_list|)
return|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
if|if
condition|(
name|results
operator|.
name|size
argument_list|()
operator|>
name|num
condition|)
block|{
name|results
operator|.
name|subList
argument_list|(
name|num
argument_list|,
name|results
operator|.
name|size
argument_list|()
argument_list|)
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
block|}
comment|/** weight -&gt; cost */
DECL|method|encodeWeight
specifier|private
name|long
name|encodeWeight
parameter_list|(
name|long
name|ngramCount
parameter_list|)
block|{
return|return
name|Long
operator|.
name|MAX_VALUE
operator|-
name|ngramCount
return|;
block|}
comment|/** cost -&gt; weight */
comment|//private long decodeWeight(Pair<Long,BytesRef> output) {
DECL|method|decodeWeight
specifier|private
name|long
name|decodeWeight
parameter_list|(
name|Long
name|output
parameter_list|)
block|{
assert|assert
name|output
operator|!=
literal|null
assert|;
return|return
call|(
name|int
call|)
argument_list|(
name|Long
operator|.
name|MAX_VALUE
operator|-
name|output
argument_list|)
return|;
block|}
comment|// NOTE: copied from WFSTCompletionLookup& tweaked
DECL|method|lookupPrefix
specifier|private
name|Long
name|lookupPrefix
parameter_list|(
name|FST
argument_list|<
name|Long
argument_list|>
name|fst
parameter_list|,
name|FST
operator|.
name|BytesReader
name|bytesReader
parameter_list|,
name|BytesRef
name|scratch
parameter_list|,
name|Arc
argument_list|<
name|Long
argument_list|>
name|arc
parameter_list|)
throws|throws
comment|/*Bogus*/
name|IOException
block|{
name|Long
name|output
init|=
name|fst
operator|.
name|outputs
operator|.
name|getNoOutput
argument_list|()
decl_stmt|;
name|fst
operator|.
name|getFirstArc
argument_list|(
name|arc
argument_list|)
expr_stmt|;
name|byte
index|[]
name|bytes
init|=
name|scratch
operator|.
name|bytes
decl_stmt|;
name|int
name|pos
init|=
name|scratch
operator|.
name|offset
decl_stmt|;
name|int
name|end
init|=
name|pos
operator|+
name|scratch
operator|.
name|length
decl_stmt|;
while|while
condition|(
name|pos
operator|<
name|end
condition|)
block|{
if|if
condition|(
name|fst
operator|.
name|findTargetArc
argument_list|(
name|bytes
index|[
name|pos
operator|++
index|]
operator|&
literal|0xff
argument_list|,
name|arc
argument_list|,
name|arc
argument_list|,
name|bytesReader
argument_list|)
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
name|output
operator|=
name|fst
operator|.
name|outputs
operator|.
name|add
argument_list|(
name|output
argument_list|,
name|arc
operator|.
name|output
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|output
return|;
block|}
DECL|field|weightComparator
specifier|static
specifier|final
name|Comparator
argument_list|<
name|Long
argument_list|>
name|weightComparator
init|=
operator|new
name|Comparator
argument_list|<
name|Long
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Long
name|left
parameter_list|,
name|Long
name|right
parameter_list|)
block|{
return|return
name|left
operator|.
name|compareTo
argument_list|(
name|right
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Returns the weight associated with an input string,    * or null if it does not exist.    */
DECL|method|get
specifier|public
name|Object
name|get
parameter_list|(
name|CharSequence
name|key
parameter_list|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
block|}
block|}
end_class
end_unit
