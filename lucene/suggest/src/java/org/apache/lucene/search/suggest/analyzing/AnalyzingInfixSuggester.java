begin_unit
begin_package
DECL|package|org.apache.lucene.search.suggest.analyzing
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|analyzing
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import
begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Path
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import
begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|AnalyzerWrapper
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|ngram
operator|.
name|EdgeNGramTokenFilter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|BinaryDocValuesField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Document
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|Field
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|FieldType
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|NumericDocValuesField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|SortedSetDocValuesField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|StringField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|TextField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|BinaryDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|DirectoryReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FilterLeafReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexOptions
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriterConfig
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReaderContext
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MultiDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|ReaderUtil
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SegmentReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SortedSetDocValues
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Term
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|sorter
operator|.
name|EarlyTerminatingSortingCollector
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|sorter
operator|.
name|SortingMergePolicy
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|BooleanClause
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|BooleanQuery
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Collector
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|FieldDoc
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|PrefixQuery
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Query
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|SearcherManager
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Sort
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|SortField
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TermQuery
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TopFieldCollector
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TopFieldDocs
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|InputIterator
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|Lookup
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|suggest
operator|.
name|Lookup
operator|.
name|LookupResult
import|;
end_import
begin_comment
comment|// javadocs
end_comment
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|DataInput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|DataOutput
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|FSDirectory
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Accountable
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|Accountables
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|RamUsageEstimator
import|;
end_import
begin_comment
comment|// TODO:
end_comment
begin_comment
comment|//   - a PostingsFormat that stores super-high-freq terms as
end_comment
begin_comment
comment|//     a bitset should be a win for the prefix terms?
end_comment
begin_comment
comment|//     (LUCENE-5052)
end_comment
begin_comment
comment|//   - we could offer a better integration with
end_comment
begin_comment
comment|//     DocumentDictionary and NRT?  so that your suggester
end_comment
begin_comment
comment|//     "automatically" keeps in sync w/ your index
end_comment
begin_comment
comment|/** Analyzes the input text and then suggests matches based  *  on prefix matches to any tokens in the indexed text.  *  This also highlights the tokens that match.  *  *<p>This suggester supports payloads.  Matches are sorted only  *  by the suggest weight; it would be nice to support  *  blended score + weight sort in the future.  This means  *  this suggester best applies when there is a strong  *  a-priori ranking of all the suggestions.  *  *<p>This suggester supports contexts, however the  *  contexts must be valid utf8 (arbitrary binary terms will  *  not work).  *  * @lucene.experimental */
end_comment
begin_class
DECL|class|AnalyzingInfixSuggester
specifier|public
class|class
name|AnalyzingInfixSuggester
extends|extends
name|Lookup
implements|implements
name|Closeable
block|{
comment|/** Field name used for the indexed text. */
DECL|field|TEXT_FIELD_NAME
specifier|protected
specifier|final
specifier|static
name|String
name|TEXT_FIELD_NAME
init|=
literal|"text"
decl_stmt|;
comment|/** Field name used for the indexed text, as a    *  StringField, for exact lookup. */
DECL|field|EXACT_TEXT_FIELD_NAME
specifier|protected
specifier|final
specifier|static
name|String
name|EXACT_TEXT_FIELD_NAME
init|=
literal|"exacttext"
decl_stmt|;
comment|/** Field name used for the indexed context, as a    *  StringField and a SortedSetDVField, for filtering. */
DECL|field|CONTEXTS_FIELD_NAME
specifier|protected
specifier|final
specifier|static
name|String
name|CONTEXTS_FIELD_NAME
init|=
literal|"contexts"
decl_stmt|;
comment|/** Analyzer used at search time */
DECL|field|queryAnalyzer
specifier|protected
specifier|final
name|Analyzer
name|queryAnalyzer
decl_stmt|;
comment|/** Analyzer used at index time */
DECL|field|indexAnalyzer
specifier|protected
specifier|final
name|Analyzer
name|indexAnalyzer
decl_stmt|;
DECL|field|dir
specifier|private
specifier|final
name|Directory
name|dir
decl_stmt|;
DECL|field|minPrefixChars
specifier|final
name|int
name|minPrefixChars
decl_stmt|;
DECL|field|commitOnBuild
specifier|private
specifier|final
name|boolean
name|commitOnBuild
decl_stmt|;
comment|/** Used for ongoing NRT additions/updates. */
DECL|field|writer
specifier|private
name|IndexWriter
name|writer
decl_stmt|;
comment|/** {@link IndexSearcher} used for lookups. */
DECL|field|searcherMgr
specifier|protected
name|SearcherManager
name|searcherMgr
decl_stmt|;
comment|/** Default minimum number of leading characters before    *  PrefixQuery is used (4). */
DECL|field|DEFAULT_MIN_PREFIX_CHARS
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MIN_PREFIX_CHARS
init|=
literal|4
decl_stmt|;
comment|/** How we sort the postings and search results. */
DECL|field|SORT
specifier|private
specifier|static
specifier|final
name|Sort
name|SORT
init|=
operator|new
name|Sort
argument_list|(
operator|new
name|SortField
argument_list|(
literal|"weight"
argument_list|,
name|SortField
operator|.
name|Type
operator|.
name|LONG
argument_list|,
literal|true
argument_list|)
argument_list|)
decl_stmt|;
comment|/** Create a new instance, loading from a previously built    *  AnalyzingInfixSuggester directory, if it exists.  This directory must be    *  private to the infix suggester (i.e., not an external    *  Lucene index).  Note that {@link #close}    *  will also close the provided directory. */
DECL|method|AnalyzingInfixSuggester
specifier|public
name|AnalyzingInfixSuggester
parameter_list|(
name|Directory
name|dir
parameter_list|,
name|Analyzer
name|analyzer
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|dir
argument_list|,
name|analyzer
argument_list|,
name|analyzer
argument_list|,
name|DEFAULT_MIN_PREFIX_CHARS
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/** Create a new instance, loading from a previously built    *  AnalyzingInfixSuggester directory, if it exists.  This directory must be    *  private to the infix suggester (i.e., not an external    *  Lucene index).  Note that {@link #close}    *  will also close the provided directory.    *    *  @param minPrefixChars Minimum number of leading characters    *     before PrefixQuery is used (default 4).    *     Prefixes shorter than this are indexed as character    *     ngrams (increasing index size but making lookups    *     faster).    *    *  @param commitOnBuild Call commit after the index has finished building. This would persist the    *                       suggester index to disk and future instances of this suggester can use this pre-built dictionary.    */
DECL|method|AnalyzingInfixSuggester
specifier|public
name|AnalyzingInfixSuggester
parameter_list|(
name|Directory
name|dir
parameter_list|,
name|Analyzer
name|indexAnalyzer
parameter_list|,
name|Analyzer
name|queryAnalyzer
parameter_list|,
name|int
name|minPrefixChars
parameter_list|,
name|boolean
name|commitOnBuild
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|minPrefixChars
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"minPrefixChars must be>= 0; got: "
operator|+
name|minPrefixChars
argument_list|)
throw|;
block|}
name|this
operator|.
name|queryAnalyzer
operator|=
name|queryAnalyzer
expr_stmt|;
name|this
operator|.
name|indexAnalyzer
operator|=
name|indexAnalyzer
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|minPrefixChars
operator|=
name|minPrefixChars
expr_stmt|;
name|this
operator|.
name|commitOnBuild
operator|=
name|commitOnBuild
expr_stmt|;
if|if
condition|(
name|DirectoryReader
operator|.
name|indexExists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
comment|// Already built; open it:
name|writer
operator|=
operator|new
name|IndexWriter
argument_list|(
name|dir
argument_list|,
name|getIndexWriterConfig
argument_list|(
name|getGramAnalyzer
argument_list|()
argument_list|,
name|IndexWriterConfig
operator|.
name|OpenMode
operator|.
name|APPEND
argument_list|)
argument_list|)
expr_stmt|;
name|searcherMgr
operator|=
operator|new
name|SearcherManager
argument_list|(
name|writer
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Override this to customize index settings, e.g. which    *  codec to use. */
DECL|method|getIndexWriterConfig
specifier|protected
name|IndexWriterConfig
name|getIndexWriterConfig
parameter_list|(
name|Analyzer
name|indexAnalyzer
parameter_list|,
name|IndexWriterConfig
operator|.
name|OpenMode
name|openMode
parameter_list|)
block|{
name|IndexWriterConfig
name|iwc
init|=
operator|new
name|IndexWriterConfig
argument_list|(
name|indexAnalyzer
argument_list|)
decl_stmt|;
name|iwc
operator|.
name|setOpenMode
argument_list|(
name|openMode
argument_list|)
expr_stmt|;
comment|// This way all merged segments will be sorted at
comment|// merge time, allow for per-segment early termination
comment|// when those segments are searched:
name|iwc
operator|.
name|setMergePolicy
argument_list|(
operator|new
name|SortingMergePolicy
argument_list|(
name|iwc
operator|.
name|getMergePolicy
argument_list|()
argument_list|,
name|SORT
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|iwc
return|;
block|}
comment|/** Subclass can override to choose a specific {@link    *  Directory} implementation. */
DECL|method|getDirectory
specifier|protected
name|Directory
name|getDirectory
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|FSDirectory
operator|.
name|open
argument_list|(
name|path
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|build
specifier|public
name|void
name|build
parameter_list|(
name|InputIterator
name|iter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|searcherMgr
operator|!=
literal|null
condition|)
block|{
name|searcherMgr
operator|.
name|close
argument_list|()
expr_stmt|;
name|searcherMgr
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|writer
operator|!=
literal|null
condition|)
block|{
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|writer
operator|=
literal|null
expr_stmt|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// First pass: build a temporary normal Lucene index,
comment|// just indexing the suggestions as they iterate:
name|writer
operator|=
operator|new
name|IndexWriter
argument_list|(
name|dir
argument_list|,
name|getIndexWriterConfig
argument_list|(
name|getGramAnalyzer
argument_list|()
argument_list|,
name|IndexWriterConfig
operator|.
name|OpenMode
operator|.
name|CREATE
argument_list|)
argument_list|)
expr_stmt|;
comment|//long t0 = System.nanoTime();
comment|// TODO: use threads?
name|BytesRef
name|text
decl_stmt|;
while|while
condition|(
operator|(
name|text
operator|=
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|BytesRef
name|payload
decl_stmt|;
if|if
condition|(
name|iter
operator|.
name|hasPayloads
argument_list|()
condition|)
block|{
name|payload
operator|=
name|iter
operator|.
name|payload
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|payload
operator|=
literal|null
expr_stmt|;
block|}
name|add
argument_list|(
name|text
argument_list|,
name|iter
operator|.
name|contexts
argument_list|()
argument_list|,
name|iter
operator|.
name|weight
argument_list|()
argument_list|,
name|payload
argument_list|)
expr_stmt|;
block|}
comment|//System.out.println("initial indexing time: " + ((System.nanoTime()-t0)/1000000) + " msec");
if|if
condition|(
name|commitOnBuild
condition|)
block|{
name|commit
argument_list|()
expr_stmt|;
block|}
name|searcherMgr
operator|=
operator|new
name|SearcherManager
argument_list|(
name|writer
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|success
operator|==
literal|false
operator|&&
name|writer
operator|!=
literal|null
condition|)
block|{
name|writer
operator|.
name|rollback
argument_list|()
expr_stmt|;
name|writer
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/** Commits all pending changes made to this suggester to disk.    *    *  @see IndexWriter#commit */
DECL|method|commit
specifier|public
name|void
name|commit
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|writer
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Cannot commit on an closed writer. Add documents first"
argument_list|)
throw|;
block|}
name|writer
operator|.
name|commit
argument_list|()
expr_stmt|;
block|}
DECL|method|getGramAnalyzer
specifier|private
name|Analyzer
name|getGramAnalyzer
parameter_list|()
block|{
return|return
operator|new
name|AnalyzerWrapper
argument_list|(
name|Analyzer
operator|.
name|PER_FIELD_REUSE_STRATEGY
argument_list|)
block|{
annotation|@
name|Override
specifier|protected
name|Analyzer
name|getWrappedAnalyzer
parameter_list|(
name|String
name|fieldName
parameter_list|)
block|{
return|return
name|indexAnalyzer
return|;
block|}
annotation|@
name|Override
specifier|protected
name|TokenStreamComponents
name|wrapComponents
parameter_list|(
name|String
name|fieldName
parameter_list|,
name|TokenStreamComponents
name|components
parameter_list|)
block|{
if|if
condition|(
name|fieldName
operator|.
name|equals
argument_list|(
literal|"textgrams"
argument_list|)
operator|&&
name|minPrefixChars
operator|>
literal|0
condition|)
block|{
comment|// TODO: should use an EdgeNGramTokenFilterFactory here
name|TokenFilter
name|filter
init|=
operator|new
name|EdgeNGramTokenFilter
argument_list|(
name|components
operator|.
name|getTokenStream
argument_list|()
argument_list|,
literal|1
argument_list|,
name|minPrefixChars
argument_list|)
decl_stmt|;
return|return
operator|new
name|TokenStreamComponents
argument_list|(
name|components
operator|.
name|getTokenizer
argument_list|()
argument_list|,
name|filter
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|components
return|;
block|}
block|}
block|}
return|;
block|}
DECL|method|ensureOpen
specifier|private
specifier|synchronized
name|void
name|ensureOpen
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|writer
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|searcherMgr
operator|!=
literal|null
condition|)
block|{
name|searcherMgr
operator|.
name|close
argument_list|()
expr_stmt|;
name|searcherMgr
operator|=
literal|null
expr_stmt|;
block|}
name|writer
operator|=
operator|new
name|IndexWriter
argument_list|(
name|dir
argument_list|,
name|getIndexWriterConfig
argument_list|(
name|getGramAnalyzer
argument_list|()
argument_list|,
name|IndexWriterConfig
operator|.
name|OpenMode
operator|.
name|CREATE
argument_list|)
argument_list|)
expr_stmt|;
name|searcherMgr
operator|=
operator|new
name|SearcherManager
argument_list|(
name|writer
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Adds a new suggestion.  Be sure to use {@link #update}    *  instead if you want to replace a previous suggestion.    *  After adding or updating a batch of new suggestions,    *  you must call {@link #refresh} in the end in order to    *  see the suggestions in {@link #lookup} */
DECL|method|add
specifier|public
name|void
name|add
parameter_list|(
name|BytesRef
name|text
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
name|long
name|weight
parameter_list|,
name|BytesRef
name|payload
parameter_list|)
throws|throws
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|writer
operator|.
name|addDocument
argument_list|(
name|buildDocument
argument_list|(
name|text
argument_list|,
name|contexts
argument_list|,
name|weight
argument_list|,
name|payload
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/** Updates a previous suggestion, matching the exact same    *  text as before.  Use this to change the weight or    *  payload of an already added suggstion.  If you know    *  this text is not already present you can use {@link    *  #add} instead.  After adding or updating a batch of    *  new suggestions, you must call {@link #refresh} in the    *  end in order to see the suggestions in {@link #lookup} */
DECL|method|update
specifier|public
name|void
name|update
parameter_list|(
name|BytesRef
name|text
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
name|long
name|weight
parameter_list|,
name|BytesRef
name|payload
parameter_list|)
throws|throws
name|IOException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|writer
operator|.
name|updateDocument
argument_list|(
operator|new
name|Term
argument_list|(
name|EXACT_TEXT_FIELD_NAME
argument_list|,
name|text
operator|.
name|utf8ToString
argument_list|()
argument_list|)
argument_list|,
name|buildDocument
argument_list|(
name|text
argument_list|,
name|contexts
argument_list|,
name|weight
argument_list|,
name|payload
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|buildDocument
specifier|private
name|Document
name|buildDocument
parameter_list|(
name|BytesRef
name|text
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
name|long
name|weight
parameter_list|,
name|BytesRef
name|payload
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|textString
init|=
name|text
operator|.
name|utf8ToString
argument_list|()
decl_stmt|;
name|Document
name|doc
init|=
operator|new
name|Document
argument_list|()
decl_stmt|;
name|FieldType
name|ft
init|=
name|getTextFieldType
argument_list|()
decl_stmt|;
name|doc
operator|.
name|add
argument_list|(
operator|new
name|Field
argument_list|(
name|TEXT_FIELD_NAME
argument_list|,
name|textString
argument_list|,
name|ft
argument_list|)
argument_list|)
expr_stmt|;
name|doc
operator|.
name|add
argument_list|(
operator|new
name|Field
argument_list|(
literal|"textgrams"
argument_list|,
name|textString
argument_list|,
name|ft
argument_list|)
argument_list|)
expr_stmt|;
name|doc
operator|.
name|add
argument_list|(
operator|new
name|StringField
argument_list|(
name|EXACT_TEXT_FIELD_NAME
argument_list|,
name|textString
argument_list|,
name|Field
operator|.
name|Store
operator|.
name|NO
argument_list|)
argument_list|)
expr_stmt|;
name|doc
operator|.
name|add
argument_list|(
operator|new
name|BinaryDocValuesField
argument_list|(
name|TEXT_FIELD_NAME
argument_list|,
name|text
argument_list|)
argument_list|)
expr_stmt|;
name|doc
operator|.
name|add
argument_list|(
operator|new
name|NumericDocValuesField
argument_list|(
literal|"weight"
argument_list|,
name|weight
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|payload
operator|!=
literal|null
condition|)
block|{
name|doc
operator|.
name|add
argument_list|(
operator|new
name|BinaryDocValuesField
argument_list|(
literal|"payloads"
argument_list|,
name|payload
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|contexts
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|BytesRef
name|context
range|:
name|contexts
control|)
block|{
comment|// TODO: if we had a BinaryTermField we could fix
comment|// this "must be valid ut8f" limitation:
name|doc
operator|.
name|add
argument_list|(
operator|new
name|StringField
argument_list|(
name|CONTEXTS_FIELD_NAME
argument_list|,
name|context
operator|.
name|utf8ToString
argument_list|()
argument_list|,
name|Field
operator|.
name|Store
operator|.
name|NO
argument_list|)
argument_list|)
expr_stmt|;
name|doc
operator|.
name|add
argument_list|(
operator|new
name|SortedSetDocValuesField
argument_list|(
name|CONTEXTS_FIELD_NAME
argument_list|,
name|context
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|doc
return|;
block|}
comment|/** Reopens the underlying searcher; it's best to "batch    *  up" many additions/updates, and then call refresh    *  once in the end. */
DECL|method|refresh
specifier|public
name|void
name|refresh
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|searcherMgr
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"suggester was not built"
argument_list|)
throw|;
block|}
name|searcherMgr
operator|.
name|maybeRefreshBlocking
argument_list|()
expr_stmt|;
block|}
comment|/**    * Subclass can override this method to change the field type of the text field    * e.g. to change the index options    */
DECL|method|getTextFieldType
specifier|protected
name|FieldType
name|getTextFieldType
parameter_list|()
block|{
name|FieldType
name|ft
init|=
operator|new
name|FieldType
argument_list|(
name|TextField
operator|.
name|TYPE_NOT_STORED
argument_list|)
decl_stmt|;
name|ft
operator|.
name|setIndexOptions
argument_list|(
name|IndexOptions
operator|.
name|DOCS
argument_list|)
expr_stmt|;
name|ft
operator|.
name|setOmitNorms
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|ft
return|;
block|}
annotation|@
name|Override
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
name|CharSequence
name|key
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
name|boolean
name|onlyMorePopular
parameter_list|,
name|int
name|num
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|lookup
argument_list|(
name|key
argument_list|,
name|contexts
argument_list|,
name|num
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/** Lookup, without any context. */
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
name|CharSequence
name|key
parameter_list|,
name|int
name|num
parameter_list|,
name|boolean
name|allTermsRequired
parameter_list|,
name|boolean
name|doHighlight
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|lookup
argument_list|(
name|key
argument_list|,
operator|(
name|Map
argument_list|<
name|BytesRef
argument_list|,
name|BooleanClause
operator|.
name|Occur
argument_list|>
operator|)
literal|null
argument_list|,
name|num
argument_list|,
name|allTermsRequired
argument_list|,
name|doHighlight
argument_list|)
return|;
block|}
comment|/** Lookup, with context but without booleans. Context booleans default to SHOULD,    *  so each suggestion must have at least one of the contexts. */
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
name|CharSequence
name|key
parameter_list|,
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
parameter_list|,
name|int
name|num
parameter_list|,
name|boolean
name|allTermsRequired
parameter_list|,
name|boolean
name|doHighlight
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|contexts
operator|==
literal|null
condition|)
block|{
return|return
name|lookup
argument_list|(
name|key
argument_list|,
name|num
argument_list|,
name|allTermsRequired
argument_list|,
name|doHighlight
argument_list|)
return|;
block|}
name|Map
argument_list|<
name|BytesRef
argument_list|,
name|BooleanClause
operator|.
name|Occur
argument_list|>
name|contextInfo
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|BytesRef
name|context
range|:
name|contexts
control|)
block|{
name|contextInfo
operator|.
name|put
argument_list|(
name|context
argument_list|,
name|BooleanClause
operator|.
name|Occur
operator|.
name|SHOULD
argument_list|)
expr_stmt|;
block|}
return|return
name|lookup
argument_list|(
name|key
argument_list|,
name|contextInfo
argument_list|,
name|num
argument_list|,
name|allTermsRequired
argument_list|,
name|doHighlight
argument_list|)
return|;
block|}
comment|/** This is called if the last token isn't ended    *  (e.g. user did not type a space after it).  Return an    *  appropriate Query clause to add to the BooleanQuery. */
DECL|method|getLastTokenQuery
specifier|protected
name|Query
name|getLastTokenQuery
parameter_list|(
name|String
name|token
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|token
operator|.
name|length
argument_list|()
operator|<
name|minPrefixChars
condition|)
block|{
comment|// The leading ngram was directly indexed:
return|return
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
literal|"textgrams"
argument_list|,
name|token
argument_list|)
argument_list|)
return|;
block|}
return|return
operator|new
name|PrefixQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|TEXT_FIELD_NAME
argument_list|,
name|token
argument_list|)
argument_list|)
return|;
block|}
comment|/** Retrieve suggestions, specifying whether all terms    *  must match ({@code allTermsRequired}) and whether the hits    *  should be highlighted ({@code doHighlight}). */
DECL|method|lookup
specifier|public
name|List
argument_list|<
name|LookupResult
argument_list|>
name|lookup
parameter_list|(
name|CharSequence
name|key
parameter_list|,
name|Map
argument_list|<
name|BytesRef
argument_list|,
name|BooleanClause
operator|.
name|Occur
argument_list|>
name|contextInfo
parameter_list|,
name|int
name|num
parameter_list|,
name|boolean
name|allTermsRequired
parameter_list|,
name|boolean
name|doHighlight
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|searcherMgr
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"suggester was not built"
argument_list|)
throw|;
block|}
specifier|final
name|BooleanClause
operator|.
name|Occur
name|occur
decl_stmt|;
if|if
condition|(
name|allTermsRequired
condition|)
block|{
name|occur
operator|=
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST
expr_stmt|;
block|}
else|else
block|{
name|occur
operator|=
name|BooleanClause
operator|.
name|Occur
operator|.
name|SHOULD
expr_stmt|;
block|}
name|BooleanQuery
name|query
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|matchedTokens
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|String
name|prefixToken
init|=
literal|null
decl_stmt|;
try|try
init|(
name|TokenStream
name|ts
init|=
name|queryAnalyzer
operator|.
name|tokenStream
argument_list|(
literal|""
argument_list|,
operator|new
name|StringReader
argument_list|(
name|key
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
init|)
block|{
comment|//long t0 = System.currentTimeMillis();
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
specifier|final
name|CharTermAttribute
name|termAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|final
name|OffsetAttribute
name|offsetAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|String
name|lastToken
init|=
literal|null
decl_stmt|;
name|query
operator|=
operator|new
name|BooleanQuery
argument_list|()
expr_stmt|;
name|int
name|maxEndOffset
init|=
operator|-
literal|1
decl_stmt|;
name|matchedTokens
operator|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
expr_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
if|if
condition|(
name|lastToken
operator|!=
literal|null
condition|)
block|{
name|matchedTokens
operator|.
name|add
argument_list|(
name|lastToken
argument_list|)
expr_stmt|;
name|query
operator|.
name|add
argument_list|(
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|TEXT_FIELD_NAME
argument_list|,
name|lastToken
argument_list|)
argument_list|)
argument_list|,
name|occur
argument_list|)
expr_stmt|;
block|}
name|lastToken
operator|=
name|termAtt
operator|.
name|toString
argument_list|()
expr_stmt|;
if|if
condition|(
name|lastToken
operator|!=
literal|null
condition|)
block|{
name|maxEndOffset
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxEndOffset
argument_list|,
name|offsetAtt
operator|.
name|endOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
if|if
condition|(
name|lastToken
operator|!=
literal|null
condition|)
block|{
name|Query
name|lastQuery
decl_stmt|;
if|if
condition|(
name|maxEndOffset
operator|==
name|offsetAtt
operator|.
name|endOffset
argument_list|()
condition|)
block|{
comment|// Use PrefixQuery (or the ngram equivalent) when
comment|// there was no trailing discarded chars in the
comment|// string (e.g. whitespace), so that if query does
comment|// not end with a space we show prefix matches for
comment|// that token:
name|lastQuery
operator|=
name|getLastTokenQuery
argument_list|(
name|lastToken
argument_list|)
expr_stmt|;
name|prefixToken
operator|=
name|lastToken
expr_stmt|;
block|}
else|else
block|{
comment|// Use TermQuery for an exact match if there were
comment|// trailing discarded chars (e.g. whitespace), so
comment|// that if query ends with a space we only show
comment|// exact matches for that term:
name|matchedTokens
operator|.
name|add
argument_list|(
name|lastToken
argument_list|)
expr_stmt|;
name|lastQuery
operator|=
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|TEXT_FIELD_NAME
argument_list|,
name|lastToken
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|lastQuery
operator|!=
literal|null
condition|)
block|{
name|query
operator|.
name|add
argument_list|(
name|lastQuery
argument_list|,
name|occur
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|contextInfo
operator|!=
literal|null
condition|)
block|{
name|boolean
name|allMustNot
init|=
literal|true
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|BytesRef
argument_list|,
name|BooleanClause
operator|.
name|Occur
argument_list|>
name|entry
range|:
name|contextInfo
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|entry
operator|.
name|getValue
argument_list|()
operator|!=
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST_NOT
condition|)
block|{
name|allMustNot
operator|=
literal|false
expr_stmt|;
break|break;
block|}
block|}
comment|// do not make a subquery if all context booleans are must not
if|if
condition|(
name|allMustNot
operator|==
literal|true
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|BytesRef
argument_list|,
name|BooleanClause
operator|.
name|Occur
argument_list|>
name|entry
range|:
name|contextInfo
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|query
operator|.
name|add
argument_list|(
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|CONTEXTS_FIELD_NAME
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|utf8ToString
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST_NOT
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|BooleanQuery
name|sub
init|=
operator|new
name|BooleanQuery
argument_list|()
decl_stmt|;
name|query
operator|.
name|add
argument_list|(
name|sub
argument_list|,
name|BooleanClause
operator|.
name|Occur
operator|.
name|MUST
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|BytesRef
argument_list|,
name|BooleanClause
operator|.
name|Occur
argument_list|>
name|entry
range|:
name|contextInfo
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// NOTE: we "should" wrap this in
comment|// ConstantScoreQuery, or maybe send this as a
comment|// Filter instead to search.
comment|// TODO: if we had a BinaryTermField we could fix
comment|// this "must be valid ut8f" limitation:
name|sub
operator|.
name|add
argument_list|(
operator|new
name|TermQuery
argument_list|(
operator|new
name|Term
argument_list|(
name|CONTEXTS_FIELD_NAME
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|utf8ToString
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// TODO: we could allow blended sort here, combining
comment|// weight w/ score.  Now we ignore score and sort only
comment|// by weight:
name|Query
name|finalQuery
init|=
name|finishQuery
argument_list|(
name|query
argument_list|,
name|allTermsRequired
argument_list|)
decl_stmt|;
comment|//System.out.println("finalQuery=" + query);
comment|// Sort by weight, descending:
name|TopFieldCollector
name|c
init|=
name|TopFieldCollector
operator|.
name|create
argument_list|(
name|SORT
argument_list|,
name|num
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// We sorted postings by weight during indexing, so we
comment|// only retrieve the first num hits now:
name|Collector
name|c2
init|=
operator|new
name|EarlyTerminatingSortingCollector
argument_list|(
name|c
argument_list|,
name|SORT
argument_list|,
name|num
argument_list|)
decl_stmt|;
name|IndexSearcher
name|searcher
init|=
name|searcherMgr
operator|.
name|acquire
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|LookupResult
argument_list|>
name|results
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|//System.out.println("got searcher=" + searcher);
name|searcher
operator|.
name|search
argument_list|(
name|finalQuery
argument_list|,
name|c2
argument_list|)
expr_stmt|;
name|TopFieldDocs
name|hits
init|=
operator|(
name|TopFieldDocs
operator|)
name|c
operator|.
name|topDocs
argument_list|()
decl_stmt|;
comment|// Slower way if postings are not pre-sorted by weight:
comment|// hits = searcher.search(query, null, num, SORT);
name|results
operator|=
name|createResults
argument_list|(
name|searcher
argument_list|,
name|hits
argument_list|,
name|num
argument_list|,
name|key
argument_list|,
name|doHighlight
argument_list|,
name|matchedTokens
argument_list|,
name|prefixToken
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|searcherMgr
operator|.
name|release
argument_list|(
name|searcher
argument_list|)
expr_stmt|;
block|}
comment|//System.out.println((System.currentTimeMillis() - t0) + " msec for infix suggest");
comment|//System.out.println(results);
return|return
name|results
return|;
block|}
comment|/**    * Create the results based on the search hits.    * Can be overridden by subclass to add particular behavior (e.g. weight transformation)    * @throws IOException If there are problems reading fields from the underlying Lucene index.    */
DECL|method|createResults
specifier|protected
name|List
argument_list|<
name|LookupResult
argument_list|>
name|createResults
parameter_list|(
name|IndexSearcher
name|searcher
parameter_list|,
name|TopFieldDocs
name|hits
parameter_list|,
name|int
name|num
parameter_list|,
name|CharSequence
name|charSequence
parameter_list|,
name|boolean
name|doHighlight
parameter_list|,
name|Set
argument_list|<
name|String
argument_list|>
name|matchedTokens
parameter_list|,
name|String
name|prefixToken
parameter_list|)
throws|throws
name|IOException
block|{
name|BinaryDocValues
name|textDV
init|=
name|MultiDocValues
operator|.
name|getBinaryValues
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|,
name|TEXT_FIELD_NAME
argument_list|)
decl_stmt|;
comment|// This will just be null if app didn't pass payloads to build():
comment|// TODO: maybe just stored fields?  they compress...
name|BinaryDocValues
name|payloadsDV
init|=
name|MultiDocValues
operator|.
name|getBinaryValues
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|,
literal|"payloads"
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|LeafReaderContext
argument_list|>
name|leaves
init|=
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|.
name|leaves
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|LookupResult
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hits
operator|.
name|scoreDocs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|FieldDoc
name|fd
init|=
operator|(
name|FieldDoc
operator|)
name|hits
operator|.
name|scoreDocs
index|[
name|i
index|]
decl_stmt|;
name|BytesRef
name|term
init|=
name|textDV
operator|.
name|get
argument_list|(
name|fd
operator|.
name|doc
argument_list|)
decl_stmt|;
name|String
name|text
init|=
name|term
operator|.
name|utf8ToString
argument_list|()
decl_stmt|;
name|long
name|score
init|=
operator|(
name|Long
operator|)
name|fd
operator|.
name|fields
index|[
literal|0
index|]
decl_stmt|;
name|BytesRef
name|payload
decl_stmt|;
if|if
condition|(
name|payloadsDV
operator|!=
literal|null
condition|)
block|{
name|payload
operator|=
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|payloadsDV
operator|.
name|get
argument_list|(
name|fd
operator|.
name|doc
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|payload
operator|=
literal|null
expr_stmt|;
block|}
comment|// Must look up sorted-set by segment:
name|int
name|segment
init|=
name|ReaderUtil
operator|.
name|subIndex
argument_list|(
name|fd
operator|.
name|doc
argument_list|,
name|leaves
argument_list|)
decl_stmt|;
name|SortedSetDocValues
name|contextsDV
init|=
name|leaves
operator|.
name|get
argument_list|(
name|segment
argument_list|)
operator|.
name|reader
argument_list|()
operator|.
name|getSortedSetDocValues
argument_list|(
name|CONTEXTS_FIELD_NAME
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|BytesRef
argument_list|>
name|contexts
decl_stmt|;
if|if
condition|(
name|contextsDV
operator|!=
literal|null
condition|)
block|{
name|contexts
operator|=
operator|new
name|HashSet
argument_list|<
name|BytesRef
argument_list|>
argument_list|()
expr_stmt|;
name|contextsDV
operator|.
name|setDocument
argument_list|(
name|fd
operator|.
name|doc
operator|-
name|leaves
operator|.
name|get
argument_list|(
name|segment
argument_list|)
operator|.
name|docBase
argument_list|)
expr_stmt|;
name|long
name|ord
decl_stmt|;
while|while
condition|(
operator|(
name|ord
operator|=
name|contextsDV
operator|.
name|nextOrd
argument_list|()
operator|)
operator|!=
name|SortedSetDocValues
operator|.
name|NO_MORE_ORDS
condition|)
block|{
name|BytesRef
name|context
init|=
name|BytesRef
operator|.
name|deepCopyOf
argument_list|(
name|contextsDV
operator|.
name|lookupOrd
argument_list|(
name|ord
argument_list|)
argument_list|)
decl_stmt|;
name|contexts
operator|.
name|add
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|contexts
operator|=
literal|null
expr_stmt|;
block|}
name|LookupResult
name|result
decl_stmt|;
if|if
condition|(
name|doHighlight
condition|)
block|{
name|result
operator|=
operator|new
name|LookupResult
argument_list|(
name|text
argument_list|,
name|highlight
argument_list|(
name|text
argument_list|,
name|matchedTokens
argument_list|,
name|prefixToken
argument_list|)
argument_list|,
name|score
argument_list|,
name|payload
argument_list|,
name|contexts
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|result
operator|=
operator|new
name|LookupResult
argument_list|(
name|text
argument_list|,
name|score
argument_list|,
name|payload
argument_list|,
name|contexts
argument_list|)
expr_stmt|;
block|}
name|results
operator|.
name|add
argument_list|(
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
comment|/** Subclass can override this to tweak the Query before    *  searching. */
DECL|method|finishQuery
specifier|protected
name|Query
name|finishQuery
parameter_list|(
name|BooleanQuery
name|in
parameter_list|,
name|boolean
name|allTermsRequired
parameter_list|)
block|{
return|return
name|in
return|;
block|}
comment|/** Override this method to customize the Object    *  representing a single highlighted suggestions; the    *  result is set on each {@link    *  LookupResult#highlightKey} member. */
DECL|method|highlight
specifier|protected
name|Object
name|highlight
parameter_list|(
name|String
name|text
parameter_list|,
name|Set
argument_list|<
name|String
argument_list|>
name|matchedTokens
parameter_list|,
name|String
name|prefixToken
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TokenStream
name|ts
init|=
name|queryAnalyzer
operator|.
name|tokenStream
argument_list|(
literal|"text"
argument_list|,
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
init|)
block|{
name|CharTermAttribute
name|termAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|OffsetAttribute
name|offsetAtt
init|=
name|ts
operator|.
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
name|ts
operator|.
name|reset
argument_list|()
expr_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|int
name|upto
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|ts
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
name|String
name|token
init|=
name|termAtt
operator|.
name|toString
argument_list|()
decl_stmt|;
name|int
name|startOffset
init|=
name|offsetAtt
operator|.
name|startOffset
argument_list|()
decl_stmt|;
name|int
name|endOffset
init|=
name|offsetAtt
operator|.
name|endOffset
argument_list|()
decl_stmt|;
if|if
condition|(
name|upto
operator|<
name|startOffset
condition|)
block|{
name|addNonMatch
argument_list|(
name|sb
argument_list|,
name|text
operator|.
name|substring
argument_list|(
name|upto
argument_list|,
name|startOffset
argument_list|)
argument_list|)
expr_stmt|;
name|upto
operator|=
name|startOffset
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|upto
operator|>
name|startOffset
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|matchedTokens
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
comment|// Token matches.
name|addWholeMatch
argument_list|(
name|sb
argument_list|,
name|text
operator|.
name|substring
argument_list|(
name|startOffset
argument_list|,
name|endOffset
argument_list|)
argument_list|,
name|token
argument_list|)
expr_stmt|;
name|upto
operator|=
name|endOffset
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|prefixToken
operator|!=
literal|null
operator|&&
name|token
operator|.
name|startsWith
argument_list|(
name|prefixToken
argument_list|)
condition|)
block|{
name|addPrefixMatch
argument_list|(
name|sb
argument_list|,
name|text
operator|.
name|substring
argument_list|(
name|startOffset
argument_list|,
name|endOffset
argument_list|)
argument_list|,
name|token
argument_list|,
name|prefixToken
argument_list|)
expr_stmt|;
name|upto
operator|=
name|endOffset
expr_stmt|;
block|}
block|}
name|ts
operator|.
name|end
argument_list|()
expr_stmt|;
name|int
name|endOffset
init|=
name|offsetAtt
operator|.
name|endOffset
argument_list|()
decl_stmt|;
if|if
condition|(
name|upto
operator|<
name|endOffset
condition|)
block|{
name|addNonMatch
argument_list|(
name|sb
argument_list|,
name|text
operator|.
name|substring
argument_list|(
name|upto
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|/** Called while highlighting a single result, to append a    *  non-matching chunk of text from the suggestion to the    *  provided fragments list.    *  @param sb The {@code StringBuilder} to append to    *  @param text The text chunk to add    */
DECL|method|addNonMatch
specifier|protected
name|void
name|addNonMatch
parameter_list|(
name|StringBuilder
name|sb
parameter_list|,
name|String
name|text
parameter_list|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|text
argument_list|)
expr_stmt|;
block|}
comment|/** Called while highlighting a single result, to append    *  the whole matched token to the provided fragments list.    *  @param sb The {@code StringBuilder} to append to    *  @param surface The surface form (original) text    *  @param analyzed The analyzed token corresponding to the surface form text    */
DECL|method|addWholeMatch
specifier|protected
name|void
name|addWholeMatch
parameter_list|(
name|StringBuilder
name|sb
parameter_list|,
name|String
name|surface
parameter_list|,
name|String
name|analyzed
parameter_list|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"<b>"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|surface
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"</b>"
argument_list|)
expr_stmt|;
block|}
comment|/** Called while highlighting a single result, to append a    *  matched prefix token, to the provided fragments list.    *  @param sb The {@code StringBuilder} to append to    *  @param surface The fragment of the surface form    *        (indexed during {@link #build}, corresponding to    *        this match    *  @param analyzed The analyzed token that matched    *  @param prefixToken The prefix of the token that matched    */
DECL|method|addPrefixMatch
specifier|protected
name|void
name|addPrefixMatch
parameter_list|(
name|StringBuilder
name|sb
parameter_list|,
name|String
name|surface
parameter_list|,
name|String
name|analyzed
parameter_list|,
name|String
name|prefixToken
parameter_list|)
block|{
comment|// TODO: apps can try to invert their analysis logic
comment|// here, e.g. downcase the two before checking prefix:
if|if
condition|(
name|prefixToken
operator|.
name|length
argument_list|()
operator|>=
name|surface
operator|.
name|length
argument_list|()
condition|)
block|{
name|addWholeMatch
argument_list|(
name|sb
argument_list|,
name|surface
argument_list|,
name|analyzed
argument_list|)
expr_stmt|;
return|return;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"<b>"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|surface
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|prefixToken
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"</b>"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|surface
operator|.
name|substring
argument_list|(
name|prefixToken
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|store
specifier|public
name|boolean
name|store
parameter_list|(
name|DataOutput
name|in
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
DECL|method|load
specifier|public
name|boolean
name|load
parameter_list|(
name|DataInput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
DECL|method|close
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|searcherMgr
operator|!=
literal|null
condition|)
block|{
name|searcherMgr
operator|.
name|close
argument_list|()
expr_stmt|;
name|searcherMgr
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|writer
operator|!=
literal|null
condition|)
block|{
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|dir
operator|.
name|close
argument_list|()
expr_stmt|;
name|writer
operator|=
literal|null
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|ramBytesUsed
specifier|public
name|long
name|ramBytesUsed
parameter_list|()
block|{
name|long
name|mem
init|=
name|RamUsageEstimator
operator|.
name|shallowSizeOf
argument_list|(
name|this
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
name|searcherMgr
operator|!=
literal|null
condition|)
block|{
name|IndexSearcher
name|searcher
init|=
name|searcherMgr
operator|.
name|acquire
argument_list|()
decl_stmt|;
try|try
block|{
for|for
control|(
name|LeafReaderContext
name|context
range|:
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|.
name|leaves
argument_list|()
control|)
block|{
name|LeafReader
name|reader
init|=
name|FilterLeafReader
operator|.
name|unwrap
argument_list|(
name|context
operator|.
name|reader
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|instanceof
name|SegmentReader
condition|)
block|{
name|mem
operator|+=
operator|(
operator|(
name|SegmentReader
operator|)
name|context
operator|.
name|reader
argument_list|()
operator|)
operator|.
name|ramBytesUsed
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|searcherMgr
operator|.
name|release
argument_list|(
name|searcher
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|mem
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ioe
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|getChildResources
specifier|public
name|Iterable
argument_list|<
name|?
extends|extends
name|Accountable
argument_list|>
name|getChildResources
parameter_list|()
block|{
name|List
argument_list|<
name|Accountable
argument_list|>
name|resources
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
try|try
block|{
if|if
condition|(
name|searcherMgr
operator|!=
literal|null
condition|)
block|{
name|IndexSearcher
name|searcher
init|=
name|searcherMgr
operator|.
name|acquire
argument_list|()
decl_stmt|;
try|try
block|{
for|for
control|(
name|LeafReaderContext
name|context
range|:
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|.
name|leaves
argument_list|()
control|)
block|{
name|LeafReader
name|reader
init|=
name|FilterLeafReader
operator|.
name|unwrap
argument_list|(
name|context
operator|.
name|reader
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|instanceof
name|SegmentReader
condition|)
block|{
name|resources
operator|.
name|add
argument_list|(
name|Accountables
operator|.
name|namedAccountable
argument_list|(
literal|"segment"
argument_list|,
operator|(
name|SegmentReader
operator|)
name|reader
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|searcherMgr
operator|.
name|release
argument_list|(
name|searcher
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|resources
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ioe
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|getCount
specifier|public
name|long
name|getCount
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|searcherMgr
operator|==
literal|null
condition|)
block|{
return|return
literal|0
return|;
block|}
name|IndexSearcher
name|searcher
init|=
name|searcherMgr
operator|.
name|acquire
argument_list|()
decl_stmt|;
try|try
block|{
return|return
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|.
name|numDocs
argument_list|()
return|;
block|}
finally|finally
block|{
name|searcherMgr
operator|.
name|release
argument_list|(
name|searcher
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class
begin_empty_stmt
empty_stmt|;
end_empty_stmt
end_unit
