begin_unit
begin_package
DECL|package|org.apache.lucene.codecs.temp
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|temp
package|;
end_package
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment
begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|FieldsConsumer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|FieldsProducer
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|PostingsFormat
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|PostingsReaderBase
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|PostingsWriterBase
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|lucene41
operator|.
name|Lucene41PostingsWriter
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|lucene41
operator|.
name|Lucene41PostingsReader
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInfo
operator|.
name|IndexOptions
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SegmentReadState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SegmentWriteState
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IOUtils
import|;
end_import
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|codecs
operator|.
name|CodecUtil
import|;
end_import
begin_comment
comment|// javadocs
end_comment
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|DataOutput
import|;
end_import
begin_comment
comment|// javadocs
end_comment
begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|fst
operator|.
name|FST
import|;
end_import
begin_comment
comment|// javadocs
end_comment
begin_comment
comment|/**  * FST-based term dict, using metadata as FST output.  *  * The FST directly holds the mapping between&lt;term, metadata&gt;.  *  * Term metadata consists of three parts:  * 1. term statistics: docFreq, totalTermFreq;  * 2. monotonic long[], e.g. the pointer to the postings list for that term;  * 3. generic byte[], e.g. other information need by postings reader.  *  *<p>  * File:  *<ul>  *<li><tt>.tst</tt>:<a href="#Termdictionary">Term Dictionary</a></li>  *</ul>  *<p>  *  *<a name="Termdictionary" id="Termdictionary"></a>  *<h3>Term Dictionary</h3>  *<p>  *  The .tst contains a list of FSTs, one for each field.  *  The FST maps a term to its corresponding statistics (e.g. docfreq)   *  and metadata (e.g. information for postings list reader like file pointer  *  to postings list).  *</p>  *<p>  *  Typically the metadata is separated into two parts:  *<ul>  *<li>  *    Monotonical long array: Some metadata will always be ascending in order  *    with the corresponding term. This part is used by FST to share outputs between arcs.  *</li>  *<li>  *    Generic byte array: Used to store non-monotonical metadata.  *</li>  *</ul>  *</p>  *  * File format:  *<ul>  *<li>TermsDict(.tst) --&gt; Header,<i>PostingsHeader</i>, FieldSummary, DirOffset</li>  *<li>FieldSummary --&gt; NumFields,&lt;FieldNumber, NumTerms, SumTotalTermFreq?,   *                                      SumDocFreq, DocCount, LongsSize, TermFST&gt;<sup>NumFields</sup></li>  *<li>TermFST --&gt; {@link FST FST&lt;TermData&gt;}</li>  *<li>TermData --&gt; Flag, BytesSize?, LongDelta<sup>LongsSize</sup>?, Byte<sup>BytesSize</sup>?,   *&lt; DocFreq[Same?], (TotalTermFreq-DocFreq)&gt; ?</li>  *<li>Header --&gt; {@link CodecUtil#writeHeader CodecHeader}</li>  *<li>DirOffset --&gt; {@link DataOutput#writeLong Uint64}</li>  *<li>DocFreq, LongsSize, BytesSize, NumFields,  *        FieldNumber, DocCount --&gt; {@link DataOutput#writeVInt VInt}</li>  *<li>TotalTermFreq, NumTerms, SumTotalTermFreq, SumDocFreq, LongDelta --&gt;   *        {@link DataOutput#writeVLong VLong}</li>  *</ul>  *<p>Notes:</p>  *<ul>  *<li>  *   The format of PostingsHeader and generic meta bytes are customized by the specific postings implementation:  *   they contain arbitrary per-file data (such as parameters or versioning information), and per-term data  *   (non-monotonical ones like pulsed postings data).  *</li>  *<li>  *   The format of TermData is determined by FST, typically monotonical metadata will be dense around shallow arcs,  *   while in deeper arcs only generic bytes and term statistics exist.  *</li>  *<li>  *   The byte Flag is used to indicate which part of metadata exists on current arc. Specially the monotonical part  *   is omitted when it is an array of 0s.  *</li>  *<li>  *   Since LongsSize is per-field fixed, it is only written once in field summary.  *</li>  *</ul>  *  * @lucene.experimental  */
end_comment
begin_class
DECL|class|TempFSTPostingsFormat
specifier|public
specifier|final
class|class
name|TempFSTPostingsFormat
extends|extends
name|PostingsFormat
block|{
DECL|method|TempFSTPostingsFormat
specifier|public
name|TempFSTPostingsFormat
parameter_list|()
block|{
name|super
argument_list|(
literal|"TempFST"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|toString
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|getName
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|fieldsConsumer
specifier|public
name|FieldsConsumer
name|fieldsConsumer
parameter_list|(
name|SegmentWriteState
name|state
parameter_list|)
throws|throws
name|IOException
block|{
name|PostingsWriterBase
name|postingsWriter
init|=
operator|new
name|Lucene41PostingsWriter
argument_list|(
name|state
argument_list|)
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|FieldsConsumer
name|ret
init|=
operator|new
name|TempFSTTermsWriter
argument_list|(
name|state
argument_list|,
name|postingsWriter
argument_list|)
decl_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
return|return
name|ret
return|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|postingsWriter
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|fieldsProducer
specifier|public
name|FieldsProducer
name|fieldsProducer
parameter_list|(
name|SegmentReadState
name|state
parameter_list|)
throws|throws
name|IOException
block|{
name|PostingsReaderBase
name|postingsReader
init|=
operator|new
name|Lucene41PostingsReader
argument_list|(
name|state
operator|.
name|directory
argument_list|,
name|state
operator|.
name|fieldInfos
argument_list|,
name|state
operator|.
name|segmentInfo
argument_list|,
name|state
operator|.
name|context
argument_list|,
name|state
operator|.
name|segmentSuffix
argument_list|)
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|FieldsProducer
name|ret
init|=
operator|new
name|TempFSTTermsReader
argument_list|(
name|state
argument_list|,
name|postingsReader
argument_list|)
decl_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
return|return
name|ret
return|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|postingsReader
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class
end_unit
